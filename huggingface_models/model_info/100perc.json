{"pretrained_model_name": "adamlin/100perc", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\ndatasets:\n- null\nmodel_index:\n- name: 100perc\n  results:\n  - task:\n      name: Causal Language Modeling\n      type: text-generation\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# 100perc\n\nThis model is a fine-tuned version of [distilgpt2](https://huggingface.co/distilgpt2) on the None dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 1.4594\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 5e-05\n- train_batch_size: 64\n- eval_batch_size: 64\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 100.0\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss |\n|:-------------:|:-----:|:-----:|:---------------:|\n| No log        | 1.0   | 140   | 1.8292          |\n| No log        | 2.0   | 280   | 1.7373          |\n| No log        | 3.0   | 420   | 1.6889          |\n| 2.26          | 4.0   | 560   | 1.6515          |\n| 2.26          | 5.0   | 700   | 1.6258          |\n| 2.26          | 6.0   | 840   | 1.6063          |\n| 2.26          | 7.0   | 980   | 1.5873          |\n| 1.6847        | 8.0   | 1120  | 1.5749          |\n| 1.6847        | 9.0   | 1260  | 1.5634          |\n| 1.6847        | 10.0  | 1400  | 1.5513          |\n| 1.6073        | 11.0  | 1540  | 1.5421          |\n| 1.6073        | 12.0  | 1680  | 1.5352          |\n| 1.6073        | 13.0  | 1820  | 1.5270          |\n| 1.6073        | 14.0  | 1960  | 1.5203          |\n| 1.5545        | 15.0  | 2100  | 1.5142          |\n| 1.5545        | 16.0  | 2240  | 1.5089          |\n| 1.5545        | 17.0  | 2380  | 1.5048          |\n| 1.5156        | 18.0  | 2520  | 1.5009          |\n| 1.5156        | 19.0  | 2660  | 1.4970          |\n| 1.5156        | 20.0  | 2800  | 1.4935          |\n| 1.5156        | 21.0  | 2940  | 1.4897          |\n| 1.4835        | 22.0  | 3080  | 1.4865          |\n| 1.4835        | 23.0  | 3220  | 1.4851          |\n| 1.4835        | 24.0  | 3360  | 1.4820          |\n| 1.4565        | 25.0  | 3500  | 1.4787          |\n| 1.4565        | 26.0  | 3640  | 1.4774          |\n| 1.4565        | 27.0  | 3780  | 1.4749          |\n| 1.4565        | 28.0  | 3920  | 1.4748          |\n| 1.4326        | 29.0  | 4060  | 1.4728          |\n| 1.4326        | 30.0  | 4200  | 1.4692          |\n| 1.4326        | 31.0  | 4340  | 1.4692          |\n| 1.4326        | 32.0  | 4480  | 1.4668          |\n| 1.4126        | 33.0  | 4620  | 1.4664          |\n| 1.4126        | 34.0  | 4760  | 1.4659          |\n| 1.4126        | 35.0  | 4900  | 1.4643          |\n| 1.394         | 36.0  | 5040  | 1.4622          |\n| 1.394         | 37.0  | 5180  | 1.4629          |\n| 1.394         | 38.0  | 5320  | 1.4610          |\n| 1.394         | 39.0  | 5460  | 1.4623          |\n| 1.3775        | 40.0  | 5600  | 1.4599          |\n| 1.3775        | 41.0  | 5740  | 1.4600          |\n| 1.3775        | 42.0  | 5880  | 1.4580          |\n| 1.363         | 43.0  | 6020  | 1.4584          |\n| 1.363         | 44.0  | 6160  | 1.4577          |\n| 1.363         | 45.0  | 6300  | 1.4559          |\n| 1.363         | 46.0  | 6440  | 1.4545          |\n| 1.3484        | 47.0  | 6580  | 1.4568          |\n| 1.3484        | 48.0  | 6720  | 1.4579          |\n| 1.3484        | 49.0  | 6860  | 1.4562          |\n| 1.3379        | 50.0  | 7000  | 1.4558          |\n| 1.3379        | 51.0  | 7140  | 1.4556          |\n| 1.3379        | 52.0  | 7280  | 1.4581          |\n| 1.3379        | 53.0  | 7420  | 1.4554          |\n| 1.3258        | 54.0  | 7560  | 1.4561          |\n| 1.3258        | 55.0  | 7700  | 1.4553          |\n| 1.3258        | 56.0  | 7840  | 1.4555          |\n| 1.3258        | 57.0  | 7980  | 1.4572          |\n| 1.3158        | 58.0  | 8120  | 1.4551          |\n| 1.3158        | 59.0  | 8260  | 1.4573          |\n| 1.3158        | 60.0  | 8400  | 1.4561          |\n| 1.3072        | 61.0  | 8540  | 1.4557          |\n| 1.3072        | 62.0  | 8680  | 1.4548          |\n| 1.3072        | 63.0  | 8820  | 1.4547          |\n| 1.3072        | 64.0  | 8960  | 1.4556          |\n| 1.2986        | 65.0  | 9100  | 1.4555          |\n| 1.2986        | 66.0  | 9240  | 1.4566          |\n| 1.2986        | 67.0  | 9380  | 1.4558          |\n| 1.2916        | 68.0  | 9520  | 1.4565          |\n| 1.2916        | 69.0  | 9660  | 1.4552          |\n| 1.2916        | 70.0  | 9800  | 1.4558          |\n| 1.2916        | 71.0  | 9940  | 1.4553          |\n| 1.2846        | 72.0  | 10080 | 1.4579          |\n| 1.2846        | 73.0  | 10220 | 1.4572          |\n| 1.2846        | 74.0  | 10360 | 1.4572          |\n| 1.2792        | 75.0  | 10500 | 1.4564          |\n| 1.2792        | 76.0  | 10640 | 1.4576          |\n| 1.2792        | 77.0  | 10780 | 1.4571          |\n| 1.2792        | 78.0  | 10920 | 1.4580          |\n| 1.2736        | 79.0  | 11060 | 1.4578          |\n| 1.2736        | 80.0  | 11200 | 1.4583          |\n| 1.2736        | 81.0  | 11340 | 1.4576          |\n| 1.2736        | 82.0  | 11480 | 1.4580          |\n| 1.2699        | 83.0  | 11620 | 1.4575          |\n| 1.2699        | 84.0  | 11760 | 1.4583          |\n| 1.2699        | 85.0  | 11900 | 1.4588          |\n| 1.2664        | 86.0  | 12040 | 1.4590          |\n| 1.2664        | 87.0  | 12180 | 1.4593          |\n| 1.2664        | 88.0  | 12320 | 1.4582          |\n| 1.2664        | 89.0  | 12460 | 1.4591          |\n| 1.2627        | 90.0  | 12600 | 1.4595          |\n| 1.2627        | 91.0  | 12740 | 1.4585          |\n| 1.2627        | 92.0  | 12880 | 1.4590          |\n| 1.2613        | 93.0  | 13020 | 1.4590          |\n| 1.2613        | 94.0  | 13160 | 1.4598          |\n| 1.2613        | 95.0  | 13300 | 1.4592          |\n| 1.2613        | 96.0  | 13440 | 1.4597          |\n| 1.2591        | 97.0  | 13580 | 1.4593          |\n| 1.2591        | 98.0  | 13720 | 1.4593          |\n| 1.2591        | 99.0  | 13860 | 1.4597          |\n| 1.258         | 100.0 | 14000 | 1.4594          |\n\n\n### Framework versions\n\n- Transformers 4.8.0\n- Pytorch 1.8.1+cu111\n- Datasets 1.8.0\n- Tokenizers 0.10.3\n", "size_bytes": "333990984", "downloads": 6}