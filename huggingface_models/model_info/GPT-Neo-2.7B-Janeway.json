{"pretrained_model_name": "KoboldAI/GPT-Neo-2.7B-Janeway", "description": "---\nlanguage: en\nlicense: mit\n---\n# GPT-Neo 2.7B - Janeway\n## Model Description\nGPT-Neo 2.7B-Janeway is a finetune created using EleutherAI's GPT-Neo 2.7B model.\n## Training data\nThe training data contains around 2210 ebooks, mostly in the sci-fi and fantasy genres. The dataset is based on the same dataset used by GPT-Neo-2.7B-Picard, with 20% more data in various genres.\nSome parts of the dataset have been prepended using the following text: `[Genre: <genre1>,<genre2>]`\n### How to use\nYou can use this model directly with a pipeline for text generation. This example generates a different sequence each time it's run:\n```py\n>>> from transformers import pipeline\n>>> generator = pipeline('text-generation', model='KoboldAI/GPT-Neo-2.7B-Janeway')\n>>> generator(\"Welcome Captain Janeway, I apologize for the delay.\", do_sample=True, min_length=50)\n[{'generated_text': 'Welcome Captain Janeway, I apologize for the delay.\"\\nIt's all right,\" Janeway said. \"I'm certain that you're doing your best to keep me informed of what\\'s going on.\"'}]\n```\n### Limitations and Biases\nGPT-Neo was trained as an autoregressive language model. This means that its core functionality is taking a string of text and predicting the next token. While language models are widely used for tasks other than this, there are a lot of unknowns with this work.\nGPT-Neo was trained on the Pile, a dataset known to contain profanity, lewd, and otherwise abrasive language. Depending on your usecase GPT-Neo may produce socially unacceptable text. See Sections 5 and 6 of the Pile paper for a more detailed analysis of the biases in the Pile.\nAs with all language models, it is hard to predict in advance how GPT-Neo will respond to particular prompts and offensive content may occur without warning. We recommend having a human curate or filter the outputs before releasing them, both to censor undesirable content and to improve the quality of the results. \n### BibTeX entry and citation info\nThe model is made using the following software:\n```bibtex\n@software{gpt-neo,\n  author       = {Black, Sid and\n                  Leo, Gao and\n                  Wang, Phil and\n                  Leahy, Connor and\n                  Biderman, Stella},\n  title        = {{GPT-Neo: Large Scale Autoregressive Language \n                   Modeling with Mesh-Tensorflow}},\n  month        = mar,\n  year         = 2021,\n  note         = {{If you use this software, please cite it using \n                   these metadata.}},\n  publisher    = {Zenodo},\n  version      = {1.0},\n  doi          = {10.5281/zenodo.5297715},\n  url          = {https://doi.org/10.5281/zenodo.5297715}\n}\n```", "size_bytes": "5436936394", "downloads": 1256}