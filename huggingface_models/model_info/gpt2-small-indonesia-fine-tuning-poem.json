{"pretrained_model_name": "ayameRushia/gpt2-small-indonesia-fine-tuning-poem", "description": "---\nlanguage: id\nwidget:\n- text: \"Wahai rembulan yang tertutup awan hujan\"\n---\n# Indonesian GPT-2 finetuned on Indonesian poems\nThis is the [Indonesian gpt2-small model](https://huggingface.co/flax-community/gpt2-small-indonesian) fine-tuned to Indonesian poems. The dataset can be found in [here](https://huggingface.co/datasets/id_puisi) All training was done on Google Colab Jupyter Notebook (soon).\n\nThe dataset is splitted into two subset with details belows:\n\n| split | count (examples) | percentage |\n| ---------- | ---------- | -------------- |\n| train    | 7,358     | 80%         |\n| validation    | 1,890      | 20%         |\n\n\n### Evaluation results \nThe model evaluation results after 10 epochs are as follows:\n\n| dataset | train/loss | eval/loss | eval perplexity |\n| ---------- | ---------- | -------------- | ---------- |\n| [id puisi](https://huggingface.co/datasets/id_puisi)   | 3.324700    | 3.502665     | 33.20   |\n\nThe logs can be found in [wandb page here](https://wandb.ai/ayamerushia/gpt-2_poem/runs/36ymudz9/overview?workspace=user-ayamerushia) or tensorboard [here](https://huggingface.co/ayameRushia/gpt2-small-indonesia-fine-tuning-poem/tensorboard)\n\n", "size_bytes": "510403817", "downloads": 4}