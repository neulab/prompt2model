{"pretrained_model_name": "ECE1786-AG/lyrics-generator", "description": "---\nlicense: mit\ntags:\n- generated_from_trainer\nmodel-index:\n- name: lyrics-generator-v2\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# lyrics-generator-v2\n\nThis model is a fine-tuned version of [gpt2](https://huggingface.co/gpt2) on the None dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 2.1114\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 5e-05\n- train_batch_size: 8\n- eval_batch_size: 8\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 10\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss |\n|:-------------:|:-----:|:----:|:---------------:|\n| 3.4325        | 0.36  | 200  | 2.3267          |\n| 2.4121        | 0.71  | 400  | 2.2693          |\n| 2.3582        | 1.07  | 600  | 2.2401          |\n| 2.2903        | 1.42  | 800  | 2.2182          |\n| 2.2738        | 1.78  | 1000 | 2.2046          |\n| 2.2322        | 2.14  | 1200 | 2.1922          |\n| 2.1933        | 2.49  | 1400 | 2.1832          |\n| 2.1944        | 2.85  | 1600 | 2.1736          |\n| 2.1632        | 3.2   | 1800 | 2.1648          |\n| 2.1366        | 3.56  | 2000 | 2.1554          |\n| 2.1492        | 3.91  | 2200 | 2.1491          |\n| 2.1108        | 4.27  | 2400 | 2.1472          |\n| 2.0882        | 4.63  | 2600 | 2.1422          |\n| 2.0971        | 4.98  | 2800 | 2.1343          |\n| 2.0829        | 5.34  | 3000 | 2.1318          |\n| 2.042         | 5.69  | 3200 | 2.1280          |\n| 2.0375        | 6.05  | 3400 | 2.1261          |\n| 2.0146        | 6.41  | 3600 | 2.1245          |\n| 2.0551        | 6.76  | 3800 | 2.1217          |\n| 1.992         | 7.12  | 4000 | 2.1182          |\n| 1.9994        | 7.47  | 4200 | 2.1170          |\n| 2.0189        | 7.83  | 4400 | 2.1156          |\n| 1.9795        | 8.19  | 4600 | 2.1133          |\n| 2.0101        | 8.54  | 4800 | 2.1143          |\n| 1.9864        | 8.9   | 5000 | 2.1111          |\n| 1.9602        | 9.25  | 5200 | 2.1120          |\n| 1.9899        | 9.61  | 5400 | 2.1117          |\n| 1.9928        | 9.96  | 5600 | 2.1114          |\n\n\n### Framework versions\n\n- Transformers 4.25.1\n- Pytorch 1.12.1+cu113\n- Datasets 2.7.1\n- Tokenizers 0.13.2\n", "size_bytes": "510427241", "downloads": 19}