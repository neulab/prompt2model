{"pretrained_model_name": "mabaji/thepoet", "description": "---\nlanguage:\n  - ar\ntags:\n  - text-generation\nlicense: apache-2.0\nwidget:\n  - text:  \"\u064a\u0627 \u0644\u064a\u0644 \u0627\u0644\u062d\u0628 \"\n---\n\nThepoet is an Arabic poem generator, pre-trained language model based on OpenAi GPT2 architechture.\n\nSpecial thanks to aubmindlab for their pretrained Arabic model - Aragpt2 - large (https://huggingface.co/aubmindlab/aragpt2-large)\n\nAraGPT2-large adafactor 1024 1280 20 36 2.98GB/792M\n\nTrained on two huge (APCD) datasets:\n\n512MB Arabic Poem Comprehensive Dataset from Kaggle (https://www.kaggle.com/datasets/mohamedkhaledelsafty/best-arabic-poem-comprehensive-dataset)\n\n150MB Arabic Poem Dataset from Kaggle(https://www.kaggle.com/datasets/ahmedabelal/arabic-poetry)\n\n## Eval results \nFinal perplexity reached was 119.5661\n\n### BibTeX entry and citation info\n\n```bibtex\n@inproceedings{Mohamad El Abaji,\n  year={2022}\n}\n```", "size_bytes": "3204395657", "downloads": 5}