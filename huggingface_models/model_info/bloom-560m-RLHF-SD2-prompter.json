{"pretrained_model_name": "crumb/bloom-560m-RLHF-SD2-prompter", "description": "---\nlicense: bigscience-bloom-rail-1.0\ntags:\n- stable-diffusion\n- diffusion\nmodel-index:\n- name: bloom-560m-RLHF-SD2-prompter\n  results: []\n  \ndatasets:\n - Gustavosta/Stable-Diffusion-Prompts\n\nwidget:\n- text: \"<s>Prompt: \"\n\ninference:\n  parameters:\n    eos_token_id: 2\n    max_length: 128\n    do_sample: true\n---\n\n# BLOOM-560m RLHF SD2 Prompter \n\n**COLAB DEMO INCLUDING STABLE DIFFUSION: https://colab.research.google.com/github/aicrumb/doohickey/blob/main/rlhf_prompt_tuner.ipynb**\n\nUsing RLHF (Reinforcement Learning from Human Feedback) to finetune [mrm8488/bloom-560m-finetuned-sd-prompts](https://hf.co/mrm8488/bloom-560m-finetuned-sd-prompts) further for SD2.0\n\n```\nbatch_size = 16\nlearning_rate = 0.001 # this is why I didn't have to spend _forever_ on it\n```\n\nGenerate extension with \"\\<s>Prompt: \" and whatever your normal prompt is.\n\nI did this myself. I sat down and just ranked images for so long. It's gone through a couple iterations. Only the biases and layernorm weights were trained. The commit messages are a MESS. **First iteration of this project**\n\ndonate so i can do this on real hardware : https://github.com/aicrumb/aicrumb/blob/main/README.md\n\n## Example usage\n\n```python\n# Install libraries needed to run the models\n!pip install transformers diffusers accelerate -qq\n\n# Import the libraries\nfrom diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\nfrom transformers import pipeline\nimport torch\n\n# This is the model that the transformer was finetuned to generate prompts for\nmodel_id = \"stabilityai/stable-diffusion-2-base\"\n\n# Use the Euler scheduler here\nscheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\npipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16)\npipe = pipe.to(\"cuda\")\n\n# Load the transformer model\nprompt_pipe = pipeline(\"text-generation\", model=\"crumb/bloom-560m-RLHF-SD2-prompter\")\nprompt = \"cool landscape\"\n\n# Auto-complete prompt\nprompt = \"<s>Prompt: \" + prompt + \",\"\nextended_prompt = prompt_pipe(prompt, do_sample=True, max_length=42)[0]['generated_text']\nextended_prompt = extended_prompt[10:]\nprint(\"Prompt is now: \", extended_prompt)\n\n# Generate image\nimage = pipe(extended_prompt).images[0]  \n\nimage.save(\"output.png\")\nimage\n```\n*Prompt is now:   cool landscape, concept art*\n![](https://cdn.discordapp.com/attachments/1010693530181718146/1047831482808406067/image.png)\n\n*Prompt is now:   cool landscape, concept art, sharp focus, digital painting*\n![](https://cdn.discordapp.com/attachments/1010693530181718146/1047832480335536249/image.png)\n\nshort additions, they work though I guess (results vary)\n\nIt's also very good at generating prompts by itself, with just the \"Prompt:\" prompt.\n\n*\\<s>Prompt: 1 0 th century, highly detailed, concept art, cinematic lighting, unreal engine, trending on artstation, artstation hd, artstation hq, very very detailed*\n![](https://cdn.discordapp.com/attachments/1010693530181718146/1047843202050310174/image.png)\n\nFurther testing to be done in this area (automated training with aesthetic predicting models, larger data collection about prompt scores, better training in general)\n\nAlso, enjoy this graphic I had to make myself because I kept being indecisive of the reward methodology ![](https://cdn.discordapp.com/attachments/1010693530181718146/1047846272096292925/image.png)", "size_bytes": "1118526007", "downloads": 58}