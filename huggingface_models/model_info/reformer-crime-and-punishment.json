{"pretrained_model_name": "google/reformer-crime-and-punishment", "description": "## Reformer Model trained on \"Crime and Punishment\" \n\nCrime and Punishment is a novel written by Fyodor Dostoevsky and was translated into English. \n\nCrime and Punishment training data was taken from `gs://trax-ml/reformer/crime-and-punishment-2554.txt` and contains \nroughly 0.5M tokens. \n\nThe ReformerLM model was trained in flax using colab notebook proposed by authors: https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/text_generation.ipynb and the weights were converted to Hugging Face's PyTorch ReformerLM model `ReformerModelWithLMHead`.\n\nThe model is a language model that operates on small sub-word units. Text can be generated as follows:\n\n```python\nmodel = ReformerModelWithLMHead.from_pretrained(\"google/reformer-crime-and-punishment\")\ntok = ReformerTokenizer.from_pretrained(\"google/reformer-crime-and-punishment\")\ntok.decode(model.generate(tok.encode(\"A few months later\", return_tensors=\"pt\"), do_sample=True,temperature=0.7, max_length=100)[0])\n\n# gives:'A few months later on was more than anything in the flat. \n# \u201cI have already.\u201d \u201cThat\u2019s not my notion that he had forgotten him. \n# What does that matter? And why do you mean? It\u2019s only another fellow,\u201d he said as he went out, as though he want'\n```\n", "size_bytes": "11013576", "downloads": 8793}