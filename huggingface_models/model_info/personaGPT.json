{"pretrained_model_name": "af1tang/personaGPT", "description": "---\ntags:\n- conversational\nlicense: gpl-3.0\n---\n## A conversational agent with many personalities (PersonaGPT)\nPersonaGPT is an open-domain conversational agent designed to do 2 tasks:\n\n1. decoding _personalized_ responses based on input personality facts (the \"persona\" profile of the bot). \n2. incorporating _turn-level goals_ into its responses through \"action codes\" (e.g., \"talk about work\", \"ask about favorite music\").\n\nIt builds on the [DialoGPT-medium](https://huggingface.co/microsoft/DialoGPT-medium) pretrained model based on the [GPT-2](https://github.com/openai/gpt-2) architecture. \nThis model is trained on the [Persona-Chat](https://arxiv.org/pdf/1801.07243) dataset, with added special tokens to better distinguish between conversational history and personality traits for dyadic conversations. Furthermore, some active learning was used to train the model to do _controlled_ decoding using turn-level goals.\n\n## Full Repo\n\nPreprocessing, training and implementation details can be found in the [personaGPT repo](https://github.com/af1tang/personaGPT).\n\n### How to Use\n\n\n1. Load the model and define some helper functions.\n\n```python\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nimport torch\ntokenizer = AutoTokenizer.from_pretrained(\"af1tang/personaGPT\")\nmodel = AutoModelForCausalLM.from_pretrained(\"af1tang/personaGPT\")\nif torch.cuda.is_available():\n\tmodel = model.cuda()\n## utility functions ##\nflatten = lambda l: [item for sublist in l for item in sublist]\n\ndef to_data(x):\n    if torch.cuda.is_available():\n        x = x.cpu()\n    return x.data.numpy()\n\ndef to_var(x):\n    if not torch.is_tensor(x):\n        x = torch.Tensor(x)\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return x\n\ndef display_dialog_history(dialog_hx):\n    for j, line in enumerate(dialog_hx):\n        msg = tokenizer.decode(line)\n        if j %2 == 0:\n            print(\">> User: \"+ msg)\n        else:\n            print(\"Bot: \"+msg)\n            print()\n\ndef generate_next(bot_input_ids, do_sample=True, top_k=10, top_p=.92,\n                  max_length=1000, pad_token=tokenizer.eos_token_id):\n    full_msg = model.generate(bot_input_ids, do_sample=True,\n                                              top_k=top_k, top_p=top_p, \n                                              max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n    msg = to_data(full_msg.detach()[0])[bot_input_ids.shape[-1]:]\n    return msg\n```\n\n2. Give your chatbot partner a set of personalities. \n\n\n```python\n# get personality facts for conversation\npersonas = []\nfor i in range(3):\n    response = input(\">> Fact %d: \"%(i+1))+ tokenizer.eos_token\n    personas.append(response)\npersonas = tokenizer.encode(''.join(['<|p2|>'] + personas + ['<|sep|>'] + ['<|start|>']))\n```\n\n3. The first use of PersonaGPT is to do _personalized_ dialog generation. Use the following loop to interact with the model.\n\n```python\n# converse for 8 turns\ndialog_hx = []\nfor step in range(8):\n    # encode the user input\n    user_inp = tokenizer.encode(input(\">> User: \") + tokenizer.eos_token)\n    # append to the chat history\n    dialog_hx.append(user_inp)\n        \n    # generated a response while limiting the total chat history to 1000 tokens, \n    bot_input_ids = to_var([personas + flatten(dialog_hx)]).long()\n    msg = generate_next(bot_input_ids)\n    dialog_hx.append(msg)\n    print(\"Bot: {}\".format(tokenizer.decode(msg, skip_special_tokens=True)))\n```\n\n\nExample of personalized decoding:\n\n| | Persona Facts |\n|---|---|\n| 1 | i am 64 years old but feel quite young. |\n| 2 | i try to eat healthy but limit mcdonalds to once a week. |\n| 3 | i regret working as a doctor for the last 20 years. |\n| 4 | my secret hobby is making self-help youtube videos. |\n| 5 | i've been to spain many times and wish i could go again. |\n\n| Role | Response|\n|---|---|\n| Human | yo whats good fam? |\n| Bot | hello, how are you doing? |\n| Human | not bad what you doing today?|\n| Bot | eating a lot healthier now that i'm in my 60s |\n| Human | i'm more of a fast food guy |\n| Bot | me too but i'm very healthy so i try to avoid it |\n| Human | what do you do for fun? |\n| Bot | i make videos for fun and eat very healthy |\n| Human | nice what kind of videos? |\n| Bot | i love making videos about self help stuff |\n| Human | i think i need some help | \n| Bot | what kind of help would you like to get |\n| Human | i'm 21 and feel lost in life | \n| Bot | i can relate, i'm only 65 |\n\n\n4. The second use of PersonaGPT is to do _controlled response generation_. Use the following program to interact with the model.\n\n```python\n## available actions ##\naction_space = [ 'ask about kids.', \"ask about pets.\", 'talk about work.', \n               'ask about marital status.', 'talk about travel.', 'ask about age and gender.',\n        'ask about hobbies.', 'ask about favorite food.', 'talk about movies.', \n        'talk about music.', 'talk about politics.']\n# converse for 8 turns\ndialog_hx = []\nfor step in range(8):\n\t# choose an action\n    act = None\n    while act not in action_space:\n        display_dialog_history(dialog_hx)\n        print()\n        print(\" actions: \")\n        for k,v in enumerate(action_space): print(k,v)\n        try:\n            act = action_space[int(input(\" input [0-10]: \" ))]\n        except:\n            act = None\n    print()\n    # format into prefix code\n    action_prefix = tokenizer.encode(''.join(['<|act|> '] + [act] + ['<|p1|>'] + [] + ['<|sep|>'] + ['<|start|>']))\n    bot_input_ids = to_var([action_prefix + flatten(dialog_hx)]).long()\n    \n    # generate query conditioned on action\n    msg = generate_next(bot_input_ids, top_k=top_k, top_p=top_p, max_length=max_length)\n    dialog_hx.append(msg)\n    \n    # generate bot response\n    bot_input_ids = to_var([personas+ flatten(dialog_hx)]).long()\n    msg = generate_next(bot_input_ids, top_k=top_k, top_p=top_p, max_length=max_length)\n    dialog_hx.append(msg)\ndisplay_dialog_history(dialog_hx)\n```\n\n\nExample of controlled response generation: \n\n\n| | Bot 2's Persona Facts |\n|---|---|\n| 1 | i am a quiet engineer. |\n| 2 | i'm single and am looking for love. |\n| 3 | sadly, i don't have any relatable hobbies. |\n| 4 | luckily, however, i am tall and athletic. |\n| 5 | on friday nights, i watch re-runs of the simpsons alone. |\n\n| Role | Action | Response |\n|---|---|---|\n| Bot 1 | talk about movies | hello do you like movies? |\n| Bot 2 | - | i love the simpsons. how about you? |\n| Bot 1 | talk about music | i like the walking dead. do you play an instrument? |\n| Bot 2 | - | yes i play the violin. |\n| Bot 1 | ask about marital status | are you married or single? |\n| Bot 2 | - | i am single but i am looking for love. |\n| Bot 1 | talk about work | my job is working in a factory. what's your occupation? |\n| Bot 2 | - | engineer. i'm very quiet so no one hears me. |\n| Bot 1 | talk about hobbies | do you have any hobbies? |\n| Bot 2 | - | i watch reruns of the simpsons. | \n| Bot 1 | ask about favorite food | what's your favorite food? |\n| Bot 2 | - | i love pizza. how about yourself? |\n| Bot 1 | ask about pets | i also love pizza. do you like animals? | \n| Bot 2 | - | i have two dogs. what is your occupation? | \n| Bot 1 | talk about work | i'm a factory worker. what's your dream job? |\n| Bot 2 | - | i'd love to be a writer one day. |", "size_bytes": "1444556021", "downloads": 1128}