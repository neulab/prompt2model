{"pretrained_model_name": "fpuentes/gpt2-galician", "description": "---\nlicense: apache-2.0\nlanguage:\n- gl\nlibrary_name: transformers\npipeline_tag: text-generation\n---\nModelo de 125M de par\u00e1metros, adestrado e afinado desde un modelo preentrenado (GPT2-Spanish), usando un dataset en galego de 387MB obtido da wikipedia en galego.\n\nNo contexto da\n**[Resoluci\u00f3n do 22 de decembro de 2021 da Secretar\u00eda Xeral de Educaci\u00f3n e Formaci\u00f3n Profesional pola que se convocan premios para o desenvolvemento de proxectos de innovaci\u00f3n tecnol\u00f3xica ou cient\u00edfica e proxectos de innovaci\u00f3n did\u00e1ctica no \u00e1mbito da formaci\u00f3n profesional en centros p\u00fablicos dependentes da Conseller\u00eda de Cultura, Educaci\u00f3n e Universidade](http://www.edu.xunta.gal/fp/sites/fp/files/pi2022__resolucion_de_convocatoria.pdf)**,\nbaixo o nome de\n\"*Creaci\u00f3n dun modelo de linguaxe adestrado previamente mediante t\u00e9cnicas de autoatenci\u00f3n para explorar arquitecturas que permitan o seu uso en soluci\u00f3ns de procesamento da linguaxe natural en galego tanto na docencia como na contorna empresarial*\"\n", "size_bytes": "510393405", "downloads": 0}