{"pretrained_model_name": "Cedille/fr-boris", "description": "---\nlanguage: fr\nlicense: mit\ntags:\n- pytorch\n- causal-lm\ndatasets:\n- c4\n---\n\n# Cedille AI\nCedille is a project to bring large language models to non-English languages.\n\n## fr-boris\nBoris is a 6B parameter autoregressive language model based on the GPT-J architecture and trained using the [mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax) codebase.\n\nBoris was trained on around 78B tokens of French text from the [C4](https://huggingface.co/datasets/c4) dataset. We started training from GPT-J, which has been trained on [The Pile](https://pile.eleuther.ai/). As a consequence the model still has good performance in English language. Boris makes use of the unmodified GPT-2 tokenizer.\n\nBoris is named after the great French writer [Boris Vian](https://en.wikipedia.org/wiki/Boris_Vian).\n\n# How do I test Cedille?\nFor the time being, the easiest way to test the model is to use our [publicly accessible playground](https://en.cedille.ai/).\n\nCedille is a relatively large model and running it in production can get expensive. Consider contacting us for API access at hello@cedille.ai.\n\n\n## \ud83d\udcca Cedille paper\nOur paper is out now! https://arxiv.org/abs/2202.03371\n\nThanks for citing our work if you make use of Cedille\n```bibtex\n@misc{muller2022cedille,\n      title={Cedille: A large autoregressive French language model}, \n      author={Martin M{\\\"{u}}ller and Florian Laurent},\n      year={2022},\n      eprint={2202.03371},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\n## Contact us\nFor any custom development please contact us at hello@cedille.ai.\n\n## Links\n* [Official website](https://en.cedille.ai/)\n* [Blog](https://en.cedille.ai/blog)\n* [GitHub](https://github.com/coteries/cedille-ai)\n* [Twitter](https://twitter.com/CedilleAI)\n\n", "size_bytes": "24321098883", "downloads": 859}