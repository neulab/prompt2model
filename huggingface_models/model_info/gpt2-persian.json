{"pretrained_model_name": "bolbolzaban/gpt2-persian", "description": "---\nlanguage: fa\nlicense: apache-2.0\ntags: \n- farsi\n- persian\n---\n# GPT2-Persian\nbolbolzaban/gpt2-persian is gpt2 language model that is trained with hyper parameters similar to standard gpt2-medium with following differences:\n1. The context size is reduced from 1024 to 256 sub words in order to make the training affordable \n2. Instead of BPE, google sentence piece tokenizor is used for tokenization.\n3. The training dataset only include Persian text. All non-persian characters are replaced with especial tokens (e.g [LAT], [URL], [NUM])\n\nPlease refer to this [blog post](https://medium.com/@khashei/a-not-so-dangerous-ai-in-the-persian-language-39172a641c84) for further detail. \nAlso try the model [here](https://huggingface.co/bolbolzaban/gpt2-persian?text=%D8%AF%D8%B1+%DB%8C%DA%A9+%D8%A7%D8%AA%D9%81%D8%A7%D9%82+%D8%B4%DA%AF%D9%81%D8%AA+%D8%A7%D9%86%DA%AF%DB%8C%D8%B2%D8%8C+%D9%BE%DA%98%D9%88%D9%87%D8%B4%DA%AF%D8%B1%D8%A7%D9%86) or on [Bolbolzaban.com](http://www.bolbolzaban.com/text).\n\n## How to use\nYou can use this model directly with a pipeline for text generation:\n\n```python\nfrom transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\ntokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\nmodel = GPT2LMHeadModel.from_pretrained('bolbolzaban/gpt2-persian')\ngenerator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':256})\nsample = generator('\u062f\u0631 \u06cc\u06a9 \u0627\u062a\u0641\u0627\u0642 \u0634\u06af\u0641\u062a \u0627\u0646\u06af\u06cc\u0632\u060c \u067e\u0698\u0648\u0647\u0634\u06af\u0631\u0627\u0646')\n```\nIf you are using Tensorflow import TFGPT2LMHeadModel instead of GPT2LMHeadModel.\n\n## Fine-tuning\nFind a basic fine-tuning example on this [Github Repo](https://github.com/khashei/bolbolzaban-gpt2-persian).\n\n## Special Tokens\ngpt-persian is trained for the purpose of research on Persian poetry. Because of that all english words and numbers are replaced with special tokens and only standard Persian alphabet is used as part of input text. Here is one example:\n\nOriginal text: \u0627\u06af\u0631 \u0622\u06cc\u0641\u0648\u0646 \u06cc\u0627 \u0622\u06cc\u067e\u062f \u0634\u0645\u0627 \u062f\u0627\u0631\u0627\u06cc \u0633\u06cc\u0633\u062a\u0645 \u0639\u0627\u0645\u0644 iOS 14.3 \u06cc\u0627 iPadOS 14.3 \u06cc\u0627 \u0646\u0633\u062e\u0647\u200c\u0647\u0627\u06cc \u062c\u062f\u06cc\u062f\u062a\u0631 \u0628\u0627\u0634\u062f\n\nText used in training: \u0627\u06af\u0631 \u0622\u06cc\u0641\u0648\u0646 \u06cc\u0627 \u0622\u06cc\u067e\u062f \u0634\u0645\u0627 \u062f\u0627\u0631\u0627\u06cc \u0633\u06cc\u0633\u062a\u0645 \u0639\u0627\u0645\u0644 [LAT] [NUM] \u06cc\u0627 [LAT] [NUM] \u06cc\u0627 \u0646\u0633\u062e\u0647\u200c\u0647\u0627\u06cc \u062c\u062f\u06cc\u062f\u062a\u0631 \u0628\u0627\u0634\u062f\n\nPlease consider normalizing your input text using [Hazm](https://github.com/sobhe/hazm) or similar libraries and ensure only Persian characters are provided as input.\n\nIf you want to use classical Persian poetry as input use [BOM] (begining of mesra) at the beginning of each verse (\u0645\u0635\u0631\u0639) followed by [EOS] (end of statement) at the end of each couplet (\u0628\u06cc\u062a). \n\nSee following links for example:\n\n[[BOM] \u062a\u0648\u0627\u0646\u0627 \u0628\u0648\u062f](https://huggingface.co/bolbolzaban/gpt2-persian?text=%5BBOM%5D+%D8%AA%D9%88%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF)\n\n[[BOM] \u062a\u0648\u0627\u0646\u0627 \u0628\u0648\u062f \u0647\u0631 \u06a9\u0647 \u062f\u0627\u0646\u0627 \u0628\u0648\u062f [BOM]](https://huggingface.co/bolbolzaban/gpt2-persian?text=%5BBOM%5D+%D8%AA%D9%88%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF+%D9%87%D8%B1+%DA%A9%D9%87+%D8%AF%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF+%5BBOM%5D)\n\n[[BOM] \u062a\u0648\u0627\u0646\u0627 \u0628\u0648\u062f \u0647\u0631 \u06a9\u0647 \u062f\u0627\u0646\u0627 \u0628\u0648\u062f [BOM] \u0632 \u062f\u0627\u0646\u0634 \u062f\u0644 \u067e\u06cc\u0631](https://huggingface.co/bolbolzaban/gpt2-persian?text=%5BBOM%5D+%D8%AA%D9%88%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF+%D9%87%D8%B1+%DA%A9%D9%87+%D8%AF%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF+%5BBOM%5D+%D8%B2+%D8%AF%D8%A7%D9%86%D8%B4+%D8%AF%D9%84+%D9%BE%DB%8C%D8%B1)\n\n[[BOM] \u062a\u0648\u0627\u0646\u0627 \u0628\u0648\u062f \u0647\u0631 \u06a9\u0647 \u062f\u0627\u0646\u0627 \u0628\u0648\u062f [BOM] \u0632 \u062f\u0627\u0646\u0634 \u062f\u0644 \u067e\u06cc\u0631\u0628\u0631\u0646\u0627 \u0628\u0648\u062f  [EOS]](https://huggingface.co/bolbolzaban/gpt2-persian?text=%5BBOM%5D+%D8%AA%D9%88%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF+%D9%87%D8%B1+%DA%A9%D9%87+%D8%AF%D8%A7%D9%86%D8%A7+%D8%A8%D9%88%D8%AF+%5BBOM%5D+%D8%B2+%D8%AF%D8%A7%D9%86%D8%B4+%D8%AF%D9%84+%D9%BE%DB%8C%D8%B1%D8%A8%D8%B1%D9%86%D8%A7+%D8%A8%D9%88%D8%AF++%5BEOS%5D)\n\nIf you like to know about structure of classical Persian poetry refer to these [blog posts](https://medium.com/@khashei).\n## Acknowledgment\nThis project is supported by Cloud TPUs from Google\u2019s TensorFlow Research Cloud (TFRC).\n## Citation and Reference\nPlease reference \"bolbolzaban.com\" website if you are using gpt2-persian in your research or commertial application.\n## Contacts\nPlease reachout on [Linkedin](https://www.linkedin.com/in/khashei/) or [Telegram](https://t.me/khasheia) if you have any question or need any help to use the model.\n\nFollow [Bolbolzaban](http://bolbolzaban.com/about) on [Twitter](https://twitter.com/bolbol_zaban), [Telegram](https://t.me/bolbol_zaban) or [Instagram](https://www.instagram.com/bolbolzaban/)", "size_bytes": "1314326862", "downloads": 380}