{"pretrained_model_name": "FredZhang7/distilgpt2-stable-diffusion-v2", "description": "---\nlicense: creativeml-openrail-m\ntags:\n- stable-diffusion\n- prompt-generator\n- arxiv:2210.14140\nwidget:\n- text: \"amazing\"\n- text: \"a photo of\"\n- text: \"a sci-fi\"\n- text: \"a portrait of\"\n- text: \"a person standing\"\n- text: \"a boy watching\"\ndatasets:\n- FredZhang7/stable-diffusion-prompts-2.47M\n- poloclub/diffusiondb\n- Gustavosta/Stable-Diffusion-Prompts\n- bartman081523/stable-diffusion-discord-prompts\n---\n# Fast GPT2 PromptGen\n\n<style>\n.container {\n  padding-left: 20px;\n  border-left: 5px solid gray;\n}\n</style>\n\n<div class=\"container\">\n  <p><strong><a href=\"https://huggingface.co/FredZhang7/anime-anything-promptgen-v2\">Fast Anime PromptGen</a></strong> generates descriptive safebooru and danbooru tags for anime text-to-image models.</p>\n</div>\n\n\nThis model was trained on 2,470,000 descriptive stable diffusion prompts on the [FredZhang7/distilgpt2-stable-diffusion](https://huggingface.co/FredZhang7/distilgpt2-stable-diffusion) checkpoint for another 4,270,000 steps.\n\nCompared to other prompt generation models using GPT2, this one runs with 50% faster forwardpropagation and 40% less disk space & RAM.\n\nMajor improvements from v1 are:\n- 25% more variations\n- faster and more fluent prompt generation\n- cleaned training data\n  * removed prompts that generate images with nsfw scores > 0.5\n  * removed duplicates, including prompts that differ by capitalization and punctuations\n  * removed punctuations at random places\n  * removed prompts shorter than 15 characters\n\n\n## Live WebUI Demo\nSee the Prompt Generator tab of [Paint Journey Demo](https://huggingface.co/spaces/FredZhang7/paint-journey-demo).\n\n\n## Contrastive Search\n\n```bash\npip install --upgrade transformers\n```\n\n```python\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\ntokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\nmodel = GPT2LMHeadModel.from_pretrained('FredZhang7/distilgpt2-stable-diffusion-v2')\n\nprompt = r'a cat sitting'     # the beginning of the prompt\ntemperature = 0.9             # a higher temperature will produce more diverse results, but with a higher risk of less coherent text\ntop_k = 8                     # the number of tokens to sample from at each step\nmax_length = 80               # the maximum number of tokens for the output of the model\nrepitition_penalty = 1.2      # the penalty value for each repetition of a token\nnum_return_sequences=5        # the number of results to generate\n\n# generate the result with contrastive search\ninput_ids = tokenizer(prompt, return_tensors='pt').input_ids\noutput = model.generate(input_ids, do_sample=True, temperature=temperature, top_k=top_k, max_length=max_length, num_return_sequences=num_return_sequences, repetition_penalty=repitition_penalty, penalty_alpha=0.6, no_repeat_ngram_size=1, early_stopping=True)\n\nprint('\\nInput:\\n' + 100 * '-')\nprint('\\033[96m' + prompt + '\\033[0m')\nprint('\\nOutput:\\n' + 100 * '-')\nfor i in range(len(output)):\n    print('\\033[92m' + tokenizer.decode(output[i], skip_special_tokens=True) + '\\033[0m\\n')\n```\n\nNo comma style:\n![constrastive search](./constrastive_search.png)\n\n\nTo bring back the commas, assign output without `penalty_alpha` and `no_repeat_ngram_size`:\n```python\noutput = model.generate(input_ids, do_sample=True, temperature=temperature, top_k=top_k, max_length=max_length, num_return_sequences=num_return_sequences, repetition_penalty=repitition_penalty, early_stopping=True)\n```\n\n![constrastive search](./contrastive_comma_style.png)", "size_bytes": "333969117", "downloads": 42242}