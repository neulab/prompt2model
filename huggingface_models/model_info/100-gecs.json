{"pretrained_model_name": "huggingartists/100-gecs", "description": "---\nlanguage: en\ndatasets:\n- huggingartists/100-gecs\ntags:\n- huggingartists\n- lyrics\n- lm-head\n- causal-lm\nwidget:\n- text: \"I am\"\n---\n\n<div class=\"inline-flex flex-col\" style=\"line-height: 1.5;\">\n    <div class=\"flex\">\n        <div\n\t\t\tstyle=\"display:DISPLAY_1; margin-left: auto; margin-right: auto; width: 92px; height:92px; border-radius: 50%; background-size: cover; background-image: url(&#39;https://images.genius.com/9fd98af9a817af8cd78636f71895b6ad.500x500x1.jpg&#39;)\">\n        </div>\n    </div>\n    <div style=\"text-align: center; margin-top: 3px; font-size: 16px; font-weight: 800\">\ud83e\udd16 HuggingArtists Model \ud83e\udd16</div>\n    <div style=\"text-align: center; font-size: 16px; font-weight: 800\">100 gecs</div>\n    <a href=\"https://genius.com/artists/100-gecs\">\n    \t<div style=\"text-align: center; font-size: 14px;\">@100-gecs</div>\n    </a>\n</div>\n\nI was made with [huggingartists](https://github.com/AlekseyKorshuk/huggingartists).\n\nCreate your own bot based on your favorite artist with [the demo](https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb)!\n\n## How does it work?\n\nTo understand how the model was developed, check the [W&B report](https://wandb.ai/huggingartists/huggingartists/reportlist).\n\n## Training data\n\nThe model was trained on lyrics from 100 gecs.\n\nDataset is available [here](https://huggingface.co/datasets/huggingartists/100-gecs).\nAnd can be used with:\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"huggingartists/100-gecs\")\n```\n\n[Explore the data](https://wandb.ai/huggingartists/huggingartists/runs/3c9j4tvq/artifacts), which is tracked with [W&B artifacts](https://docs.wandb.com/artifacts) at every step of the pipeline.\n\n## Training procedure\n\nThe model is based on a pre-trained [GPT-2](https://huggingface.co/gpt2) which is fine-tuned on 100 gecs's lyrics.\n\nHyperparameters and metrics are recorded in the [W&B training run](https://wandb.ai/huggingartists/huggingartists/runs/1v0ffa4e) for full transparency and reproducibility.\n\nAt the end of training, [the final model](https://wandb.ai/huggingartists/huggingartists/runs/1v0ffa4e/artifacts) is logged and versioned.\n\n## How to use\n\nYou can use this model directly with a pipeline for text generation:\n\n```python\nfrom transformers import pipeline\ngenerator = pipeline('text-generation',\n                     model='huggingartists/100-gecs')\ngenerator(\"I am\", num_return_sequences=5)\n```\n\nOr with Transformers library:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\n  \ntokenizer = AutoTokenizer.from_pretrained(\"huggingartists/100-gecs\")\n\nmodel = AutoModelWithLMHead.from_pretrained(\"huggingartists/100-gecs\")\n```\n\n## Limitations and bias\n\nThe model suffers from [the same limitations and bias as GPT-2](https://huggingface.co/gpt2#limitations-and-bias).\n\nIn addition, the data present in the user's tweets further affects the text generated by the model.\n\n## About\n\n*Built by Aleksey Korshuk*\n\n[![Follow](https://img.shields.io/github/followers/AlekseyKorshuk?style=social)](https://github.com/AlekseyKorshuk)\n\n[![Follow](https://img.shields.io/twitter/follow/alekseykorshuk?style=social)](https://twitter.com/intent/follow?screen_name=alekseykorshuk)\n\n[![Follow](https://img.shields.io/badge/dynamic/json?color=blue&label=Telegram%20Channel&query=%24.result&url=https%3A%2F%2Fapi.telegram.org%2Fbot1929545866%3AAAFGhV-KKnegEcLiyYJxsc4zV6C-bdPEBtQ%2FgetChatMemberCount%3Fchat_id%3D-1001253621662&style=social&logo=telegram)](https://t.me/joinchat/_CQ04KjcJ-4yZTky)\n\nFor more details, visit the project repository.\n\n[![GitHub stars](https://img.shields.io/github/stars/AlekseyKorshuk/huggingartists?style=social)](https://github.com/AlekseyKorshuk/huggingartists)\n", "size_bytes": "510403817", "downloads": 7}