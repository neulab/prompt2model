{"pretrained_model_name": "ayameRushia/gpt2-medium-fine-tuning-indonesia-poem", "description": "---\nlanguage: id\nwidget:\n- text: \"Wahai rembulan yang tertutup awan hujan\"\n---\n# Indonesian GPT-2-medium finetuned on Indonesian poems\nThis is the [Indonesian gpt2-medium model](https://huggingface.co/flax-community/gpt2-medium-indonesian) fine-tuned to Indonesian poems. The dataset can be found in [here](https://huggingface.co/datasets/id_puisi) All training was done on Google Colab Jupyter Notebook (soon).\n\nThe dataset is splitted into two subset with details belows:\n\n| split | count (examples) | percentage |\n| ---------- | ---------- | -------------- |\n| train    | 7,358     | 80%         |\n| validation    | 1,890      | 20%         |\n\n\n### Evaluation results \nThe model evaluation results after 10 epochs are as follows:\n\n| dataset | train/loss | eval/loss | eval perplexity |\n| ---------- | ---------- | -------------- | ---------- |\n| [id puisi](https://huggingface.co/datasets/id_puisi)   | 3.104   | 3.384         | 29.4884  |\n\nThe logs can be found in [wandb page here](https://wandb.ai/ayamerushia/gpt-2_poem/runs/3jsu1orj/overview?workspace=user-ayamerushia)\n\n", "size_bytes": "1444581337", "downloads": 0}