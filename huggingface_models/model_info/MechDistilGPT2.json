{"pretrained_model_name": "geralt/MechDistilGPT2", "description": "\\n---\ntags:\n- Causal Language modeling\n- text-generation\n- CLM\nmodel_index:\n- name: MechDistilGPT2\n  results:\n  - task:\n      name: Causal Language modeling\n      type: Causal Language modeling\n---\n## MechDistilGPT2\nThis model is fine-tuned on text scraped from 100+ Mechanical/Automotive pdf books.\n\nBase model is DistilGPT2(https://huggingface.co/gpt2) (the smallest version of GPT2)\n\n## Fine-Tuning\n* Default Training Args\n* Epochs = 3\n* Training set = 200k sentences\n* Validation set = 40k sentences\n\n## Framework versions\n* Transformers 4.7.0.dev0\n* Pytorch 1.8.1+cu111\n* Datasets 1.6.2\n* Tokenizers 0.10.2\n\n## References\nhttps://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb", "size_bytes": "333972957", "downloads": 6}