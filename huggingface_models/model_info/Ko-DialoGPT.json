{"pretrained_model_name": "byeongal/Ko-DialoGPT", "description": "---\nlanguage: ko\ntags:\n- gpt2\n- conversational\nlicense: cc-by-nc-sa-4.0\n---\n## Ko-DialoGPT\n\n\n### How to use\n```python\nfrom transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\nimport torch\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ntokenizer = PreTrainedTokenizerFast.from_pretrained('byeongal/Ko-DialoGPT')\nmodel = GPT2LMHeadModel.from_pretrained('byeongal/Ko-DialoGPT').to(device)\n\npast_user_inputs = []\ngenerated_responses = []\n\nwhile True:\n    user_input = input(\">> User:\")\n    if user_input == 'bye':\n        break\n    text_idx = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n    for i in range(len(generated_responses)-1, len(generated_responses)-3, -1):\n        if i < 0:\n            break\n        encoded_vector = tokenizer.encode(generated_responses[i] + tokenizer.eos_token, return_tensors='pt')\n        if text_idx.shape[-1] + encoded_vector.shape[-1] < 1000:\n            text_idx = torch.cat([encoded_vector, text_idx], dim=-1)\n        else:\n            break\n        encoded_vector = tokenizer.encode(past_user_inputs[i] + tokenizer.eos_token, return_tensors='pt')\n        if text_idx.shape[-1] + encoded_vector.shape[-1] < 1000:\n            text_idx = torch.cat([encoded_vector, text_idx], dim=-1)\n        else:\n            break\n    text_idx = text_idx.to(device)\n    inference_output = model.generate(\n            text_idx,\n            max_length=1000,\n            num_beams=5,\n            top_k=20,\n            no_repeat_ngram_size=4,\n            length_penalty=0.65,\n            repetition_penalty=2.0,\n        )\n    inference_output = inference_output.tolist()\n    bot_response = tokenizer.decode(inference_output[0][text_idx.shape[-1]:], skip_special_tokens=True)\n    print(f\"Bot: {bot_response}\")\n    past_user_inputs.append(user_input)\n    generated_responses.append(bot_response)\n```\n\n### Reference\n* [SKT-KoGPT2](https://huggingface.co/skt/kogpt2-base-v2)\n* [KETI R&D \ub370\uc774\ud130](https://aihub.or.kr/opendata/keti-data/recognition-laguage/KETI-02-008)\n* [\ud55c\uad6d\uc5b4 \ub300\ud654 \uc694\uc57d](https://aihub.or.kr/aidata/30714)\n", "size_bytes": "513305211", "downloads": 36}