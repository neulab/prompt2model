{"pretrained_model_name": "NlpHUST/gpt-neo-vi-small", "description": "---\nlanguage: vi\ntags:\n- vi\n- vietnamese\n- text-generation\n- gpt3\n- lm\n- nlp\ndatasets:\n- vietnamese\nwidget:\n- text: Vi\u1ec7t Nam l\u00e0 qu\u1ed1c gia c\u00f3\npipeline_tag: text-generation\n---\n\n# GPT-Neo-small for vietnamese\nFirst GPT for vietnamese\n## Model Description\nGPT-Neo-vi-small is a transformer model designed using EleutherAI's replication of the GPT-3 architecture.\n## Training data\nGPT-Neo-vi-smal was trained on the News datasets, a large scale dataset created by from News Website for the purpose of training this model.\n### How to use\nhis example generates a different sequence each time it's run:\n```py\nfrom transformers import GPTNeoForCausalLM, GPT2Tokenizer\nmodel = GPTNeoForCausalLM.from_pretrained(\"NlpHUST/gpt-neo-vi-small\")\ntokenizer = GPT2Tokenizer.from_pretrained(\"NlpHUST/gpt-neo-vi-small\")\nprompt = \"Ngay sau T\u1ebft Nguy\u00ean \u0111\u00e1n T\u00e2n S\u1eedu, hi\u1ec7n t\u01b0\u1ee3ng gi\u00e1 \u0111\u1ea5t t\u0103ng t\u1ea1i nhi\u1ec1u \u0111\u1ecba ph\u01b0\u01a1ng. Th\u1ecb tr\u01b0\u1eddng nh\u1ed9n nh\u1ecbp, t\u1ea1o ra nh\u1eefng c\u01a1n s\u00f3ng s\u1ed1t \u0111\u1ea5t kh\u00f3 tin khi\u1ebfn b\u1ed9 ng\u00e0nh, \u0111\u1ecba ph\u01b0\u01a1ng \u0111\u01b0a c\u1ea3nh b\u00e1o.\"\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\ngen_tokens = model.generate(input_ids, do_sample=True, temperature=1.0, max_length=1024)\ngen_text = tokenizer.batch_decode(gen_tokens)[0]\nprint(gen_text)\n\n\n\n```\n### Contact information\nFor personal communication related to this project, please contact Nha Nguyen Van (nha282@gmail.com).", "size_bytes": "546367087", "downloads": 124}