{"pretrained_model_name": "BigSalmon/ParaphraseParentheses2.0", "description": "This can be used to paraphrase. I recommend using the code I have attached below. You can generate it without using LogProbs, but you are likely to be best served by manually examining the most likely outputs.\n\nIf this interests you, check out https://huggingface.co/BigSalmon/MrLincoln12 or my other MrLincoln repos.\n\n```\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\nmodel = AutoModelWithLMHead.from_pretrained(\"BigSalmon/ParaphraseParentheses2.0\")\n```\n\nExample Prompt:\n```\nthe nba is [mask] [mask] viewership.\nthe nba is ( facing / witnessing / confronted with / suffering from / grappling with ) ( lost / tanking ) viewership...\n\nai is certain to [mask] the third industrial revolution.\nai is certain to ( breed / catalyze / inaugurate / catalyze / usher in / call forth / turn loose / lend its name to ) the third industrial revolution.\n\nthe modern-day knicks are a disgrace to [mask].\nthe modern-day knicks are a disgrace to the franchise's ( rich legacy / tradition of excellence / uniquely distinguished record ).\n\nHuggingFace is [mask].\nHuggingFace is ( an amazing company /\n```\n\n```\nimport torch\nprompt = \"Insert Your Prompt Here. It is Best To Have a Few Examples Before Like The Example Prompt Shows.\"\ntext = tokenizer.encode(prompt)\nmyinput, past_key_values = torch.tensor([text]), None\nmyinput = myinput\nmyinput= myinput.to(device)\nlogits, past_key_values = model(myinput, past_key_values = past_key_values, return_dict=False)\nlogits = logits[0,-1]\nprobabilities = torch.nn.functional.softmax(logits)\nbest_logits, best_indices = logits.topk(500)\nbest_words = [tokenizer.decode([idx.item()]) for idx in best_indices]\ntext.append(best_indices[0].item())\nbest_probabilities = probabilities[best_indices].tolist()\nwords = []\nfor i in range(500):\n    m = ([best_words[i]])\n    m = str(m)\n    m = m.replace(\"[' \", \"\").replace(\"']\", \"\")\n    print(m)\n```", "size_bytes": "1444581337", "downloads": 0}