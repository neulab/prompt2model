{"pretrained_model_name": "flax-community/gpt2-medium-persian", "description": "---\nlanguage: fa\ntags:\n- text-generation\nwidget:\n - text: \"\u062f\u0631 \u06cc\u06a9 \u0627\u062a\u0641\u0627\u0642 \u0634\u06af\u0641\u062a \u0627\u0646\u06af\u06cc\u0632\u060c \u067e\u0698\u0648\u0647\u0634\u06af\u0631\u0627\u0646\"\n - text: \"\u06af\u0631\u0641\u062a\u06af\u06cc \u0628\u06cc\u0646\u06cc \u062f\u0631 \u06a9\u0648\u062f\u06a9\u0627\u0646 \u0648 \u0628\u0647\u200c\u062e\u0635\u0648\u0635 \u0646\u0648\u0632\u0627\u062f\u0627\u0646 \u0628\u0627\u0639\u062b \u0645\u06cc\u200c\u0634\u0648\u062f\"\n - text: \"\u0627\u0645\u06cc\u062f\u0648\u0627\u0631\u06cc\u0645 \u0646\u0648\u0631\u0648\u0632 \u0627\u0645\u0633\u0627\u0644 \u0633\u0627\u0644\u06cc\"\n---\n\n# GPT2 Medium 4 Persian\n> This is part of the\n[Flax/Jax Community Week](https://discuss.huggingface.co/t/pretrain-gpt2-from-scratch-in-persian/7560), organized by [HuggingFace](https://huggingface.co/) and TPU usage sponsored by Google.\n\n\n## Team Members\n- [Mehrdad Farahani](huggingface.co/m3hrdadfi)\n- [Saied Alimoradi](https://discuss.huggingface.co/u/saied)\n- [M. Reza Zerehpoosh](huggingface.co/ironcladgeek)\n- [Hooman Sedghamiz](https://discuss.huggingface.co/u/hooman650)\n- [Mazeyar Moeini Feizabadi](https://discuss.huggingface.co/u/mazy1998)\n\n## Dataset\nWe used  [Oscar](https://huggingface.co/datasets/oscar) dataset, which is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus.\n\n## How To Use\nYou can use this model directly with a pipeline for text generation.\n\n```python\nfrom transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\ntokenizer = AutoTokenizer.from_pretrained('flax-community/gpt2-medium-persian')\nmodel = GPT2LMHeadModel.from_pretrained('flax-community/gpt2-medium-persian')\ngenerator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':100})\ngenerated_text = generator('\u062f\u0631 \u06cc\u06a9 \u0627\u062a\u0641\u0627\u0642 \u0634\u06af\u0641\u062a \u0627\u0646\u06af\u06cc\u0632\u060c \u067e\u0698\u0648\u0647\u0634\u06af\u0631\u0627\u0646')\n```\nFor using Tensorflow import TFGPT2LMHeadModel instead of GPT2LMHeadModel.\n## Demo\n\n... SOON\n\n## Evaluation\n\n... SOON", "size_bytes": "1443523865", "downloads": 41}