{"pretrained_model_name": "fractalego/fact-checking", "description": "## Fact checking\n\nThis generative model - trained on FEVER - aims to predict whether a claim is consistent with the provided evidence.\n\n\n### Installation and simple usage\nOne quick way to install it is to type\n\n```bash\npip install fact_checking\n```\n\nand then use the following code:\n\n```python\nfrom transformers import (\n    GPT2LMHeadModel,\n    GPT2Tokenizer,\n)\n\nfrom fact_checking import FactChecker\n\n_evidence = \"\"\"\nJustine Tanya Bateman (born February 19, 1966) is an American writer, producer, and actress . She is best known for her regular role as Mallory Keaton on the sitcom Family Ties (1982 -- 1989). Until recently, Bateman ran a production and consulting company, SECTION 5 . In the fall of 2012, she started studying computer science at UCLA.\n\"\"\"\n\n_claim = 'Justine Bateman is a poet.'\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nfact_checking_model = GPT2LMHeadModel.from_pretrained('fractalego/fact-checking')\nfact_checker = FactChecker(fact_checking_model, tokenizer)\nis_claim_true = fact_checker.validate(_evidence, _claim)\n\nprint(is_claim_true)\n```\n\nwhich gives the output\n\n```bash\nFalse\n```\n\n### Probabilistic output with replicas\nThe output can include a probabilistic component, obtained by iterating a number of times the output generation.\nThe system generates an ensemble of answers and groups them by Yes or No.\n\nFor example, one can ask\n```python\nfrom transformers import (\n    GPT2LMHeadModel,\n    GPT2Tokenizer,\n)\n\nfrom fact_checking import FactChecker\n\n_evidence = \"\"\"\nJane writes code for Huggingface.\n\"\"\"\n\n_claim = 'Jane is an engineer.'\n\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nfact_checking_model = GPT2LMHeadModel.from_pretrained('fractalego/fact-checking')\nfact_checker = FactChecker(fact_checking_model, tokenizer)\nis_claim_true = fact_checker.validate_with_replicas(_evidence, _claim)\n\nprint(is_claim_true)\n\n```\n\nwith output\n```bash\n{'Y': 0.95, 'N': 0.05}\n```\n\n\n### Score on FEVER\n\nThe predictions are evaluated on a subset of the FEVER dev dataset,\nrestricted to the SUPPORTING and REFUTING options:\n\n| precision | recall | F1|\n| --- | --- | --- |\n|0.94|0.98|0.96|\n\nThese results should be taken with many grains of salt. This is still a work in progress, \nand there might be leakage coming from the underlining GPT2 model unnaturally raising the scores.\n\n ", "size_bytes": "510401385", "downloads": 191}