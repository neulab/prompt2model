{"pretrained_model_name": "LorenzoDeMattei/GePpeTto", "description": "---\nlanguage: it\n---\n\n# GePpeTto GPT2 Model \ud83c\uddee\ud83c\uddf9\n\nPretrained GPT2 117M model for Italian.\n\nYou can find further details in the paper:\n\nLorenzo De Mattei, Michele Cafagna, Felice Dell\u2019Orletta, Malvina Nissim, Marco Guerini \"GePpeTto Carves Italian into a Language Model\", arXiv preprint. Pdf available at: https://arxiv.org/abs/2004.14253\n\n## Pretraining Corpus\n\nThe pretraining set comprises two main sources. The first one is a dump of Italian Wikipedia (November 2019), \nconsisting of 2.8GB of text. The second one is the ItWac corpus (Baroni et al., 2009), which amounts to 11GB of web\ntexts. This collection provides a mix of standard and less standard Italian, on a rather wide chronological span, \nwith older texts than the Wikipedia dump (the latter stretches only to the late 2000s).\n\n## Pretraining details\n\nThis model was trained using GPT2's Hugging Face implemenation on 4 NVIDIA Tesla T4 GPU for 620k steps.\n\nTraining parameters:\n\n- GPT-2 small configuration\n- vocabulary size: 30k\n- Batch size: 32\n- Block size: 100\n- Adam Optimizer\n- Initial learning rate: 5e-5\n- Warm up steps: 10k\n\n## Perplexity scores\n\n| Domain | Perplexity |\n|---|---|\n| Wikipedia | 26.1052 |\n| ItWac | 30.3965 |\n| Legal | 37.2197 |\n| News | 45.3859 |\n| Social Media | 84.6408 |\n\nFor further details, qualitative analysis and human evaluation check out: https://arxiv.org/abs/2004.14253\n\n## Load Pretrained Model\n\nYou can use this model by installing Huggingface library `transformers`. And you can use it directly by initializing it like this:  \n\n```python\nfrom transformers import GPT2Tokenizer, GPT2Model\n\nmodel = GPT2Model.from_pretrained('LorenzoDeMattei/GePpeTto')\ntokenizer = GPT2Tokenizer.from_pretrained(\n    'LorenzoDeMattei/GePpeTto',\n)\n```\n\n## Example using GPT2LMHeadModel\n\n```python\nfrom transformers import AutoTokenizer, AutoModelWithLMHead, pipeline, GPT2Tokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"LorenzoDeMattei/GePpeTto\")\nmodel = AutoModelWithLMHead.from_pretrained(\"LorenzoDeMattei/GePpeTto\")\n\ntext_generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\nprompts = [\n    \"Wikipedia Geppetto\",\n    \"Maestro Ciliegia regala il pezzo di legno al suo amico Geppetto, il quale lo prende per fabbricarsi un burattino maraviglioso\"]\n\n\nsamples_outputs = text_generator(\n    prompts,\n    do_sample=True,\n    max_length=50,\n    top_k=50,\n    top_p=0.95,\n    num_return_sequences=3\n)\n\n\nfor i, sample_outputs in enumerate(samples_outputs):\n    print(100 * '-')\n    print(\"Prompt:\", prompts[i])\n    for sample_output in sample_outputs:\n        print(\"Sample:\", sample_output['generated_text'])\n        print()\n\n```\n\nOutput is,\n\n```\n----------------------------------------------------------------------------------------------------\nPrompt: Wikipedia Geppetto\nSample: Wikipedia Geppetto rosso (film 1920)\n\nGeppetto rosso (\"The Smokes in the Black\") \u00e8 un film muto del 1920 diretto da Henry H. Leonard.\n\nIl film fu prodotto dalla Selig Poly\n\nSample: Wikipedia Geppetto\n\nGeppetto (\"Geppetto\" in piemontese) \u00e8 un comune italiano di 978 abitanti della provincia di Cuneo in Piemonte.\n\nL'abitato, che si trova nel versante valtellinese, si sviluppa nella\n\nSample: Wikipedia Geppetto di Natale (romanzo)\n\nGeppetto di Natale \u00e8 un romanzo di Mario Caiano, pubblicato nel 2012.\n\n----------------------------------------------------------------------------------------------------\nPrompt: Maestro Ciliegia regala il pezzo di legno al suo amico Geppetto, il quale lo prende per fabbricarsi un burattino maraviglioso\nSample: Maestro Ciliegia regala il pezzo di legno al suo amico Geppetto, il quale lo prende per fabbricarsi un burattino maraviglioso. Il burattino riesce a scappare. Dopo aver trovato un prezioso sacchetto si reca\n\nSample: Maestro Ciliegia regala il pezzo di legno al suo amico Geppetto, il quale lo prende per fabbricarsi un burattino maraviglioso, e l'unico che lo possiede, ma, di fronte a tutte queste prove\n\nSample: Maestro Ciliegia regala il pezzo di legno al suo amico Geppetto, il quale lo prende per fabbricarsi un burattino maraviglioso: - A voi gli occhi, le guance! A voi il mio pezzo!\n```\n\n## Citation\n\nPlease use the following bibtex entry:\n\n```\n@misc{mattei2020geppetto,\n    title={GePpeTto Carves Italian into a Language Model},\n    author={Lorenzo De Mattei and Michele Cafagna and Felice Dell'Orletta and Malvina Nissim and Marco Guerini},\n    year={2020},\n    eprint={2004.14253},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n```\n\n## References\n\nMarco Baroni, Silvia Bernardini, Adriano Ferraresi,\nand Eros Zanchetta. 2009. The WaCky wide web: a\ncollection of very large linguistically processed webcrawled corpora. Language resources and evaluation, 43(3):209\u2013226.\n", "size_bytes": "485894375", "downloads": 667}