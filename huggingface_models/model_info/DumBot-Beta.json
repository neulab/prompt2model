{"pretrained_model_name": "deepparag/DumBot-Beta", "description": "---\nthumbnail: https://cdn.discordapp.com/app-icons/870239976690970625/c02cae78ae105f07969cfd8f8ea3d0a0.png\ntags:\n- conversational\nlicense: mit\n---\nAn generative AI made using [microsoft/DialoGPT-small](https://huggingface.co/microsoft/DialoGPT-small).\n\nTrained on:\n\n     https://www.kaggle.com/Cornell-University/movie-dialog-corpus\n\n     https://www.kaggle.com/jef1056/discord-data\n\n\n\nImportant:\n\n      The AI can be a bit weird at times as it is still undergoing training!\n      \n      At times it send stuff using :<random_wierd_words>: as they are discord emotes.\n      \n      It also send random @RandomName as it is trying to ping people.\n      \n      This works well on discord but on the web not so much but it is easy enough to remove such stuff using [re.sub](https://docs.python.org/3/library/re.html#re.sub)\n  \n\n\nIssues:\n\n     The AI like with all conversation AI lacks a character, it changes its name way too often. This can be solved using an AIML chatbot to give it a stable character!\n     \n[Live Demo](https://dumbot-331213.uc.r.appspot.com/)\n \nExample:\n```python\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\n  \ntokenizer = AutoTokenizer.from_pretrained(\"deepparag/DumBot\")\nmodel = AutoModelWithLMHead.from_pretrained(\"deepparag/DumBot\")\n# Let's chat for 4 lines\nfor step in range(4):\n    # encode the new user input, add the eos_token and return a tensor in Pytorch\n    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n    # print(new_user_input_ids)\n    # append the new user input tokens to the chat history\n    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n    # generated a response while limiting the total chat history to 1000 tokens, \n    chat_history_ids = model.generate(\n        bot_input_ids, max_length=200,\n        pad_token_id=tokenizer.eos_token_id,  \n        no_repeat_ngram_size=4,       \n        do_sample=True, \n        top_k=100, \n        top_p=0.7,\n        temperature=0.8\n    )\n    \n    # pretty print last ouput tokens from bot\n    print(\"DumBot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n```", "size_bytes": "551192465", "downloads": 2}