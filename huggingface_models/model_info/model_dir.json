{"pretrained_model_name": "gaochangkuan/model_dir", "description": "## Generating Chinese poetry by topic.\n\n```python\nfrom transformers import *\n\ntokenizer = BertTokenizer.from_pretrained(\"gaochangkuan/model_dir\")\n\nmodel = AutoModelWithLMHead.from_pretrained(\"gaochangkuan/model_dir\")\n\n\nprompt= '''<s>\u7530\u56ed\u8eac\u8015'''\n\nlength= 84    \nstop_token='</s>'        \n\ntemperature = 1.2 \n  \nrepetition_penalty=1.3 \n \nk= 30\np= 0.95\n \ndevice ='cuda'\nseed=2020          \nno_cuda=False      \n \nprompt_text = prompt if prompt else input(\"Model prompt >>> \")\n\nencoded_prompt = tokenizer.encode(\n                                  '<s>'+prompt_text+'<sep>',\n                                  add_special_tokens=False, \n                                  return_tensors=\"pt\"\n                                 )\n\nencoded_prompt = encoded_prompt.to(device)\n\noutput_sequences = model.generate(\n    input_ids=encoded_prompt,\n    max_length=length,\n    min_length=10,\n    do_sample=True,\n    early_stopping=True,\n    num_beams=10,\n    temperature=temperature,\n    top_k=k,\n    top_p=p,\n    repetition_penalty=repetition_penalty,\n    bad_words_ids=None,\n    bos_token_id=tokenizer.bos_token_id,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n    length_penalty=1.2,\n    no_repeat_ngram_size=2,\n    num_return_sequences=1,\n    attention_mask=None,\n    decoder_start_token_id=tokenizer.bos_token_id,)\n    \n    \n    generated_sequence = output_sequences[0].tolist()\ntext = tokenizer.decode(generated_sequence)\n\n\ntext = text[: text.find(stop_token) if stop_token else None]\n\nprint(''.join(text).replace(' ','').replace('<pad>','').replace('<s>',''))\n```\n", "size_bytes": "425283937", "downloads": 1}