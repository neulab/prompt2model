{"pretrained_model_name": "NYTK/text-generation-poem-petofi-gpt2-small-hungarian", "description": "---\nlanguage:\n- hu\ntags:\n- text-generation\nlicense: mit\nwidget:\n- text: Szegeden, janu\u00e1r v\u00e9g\u00e9n,\n---\n\n# Hungarian GPT-2 poem generator in Pet\u0151fi style\n\nFor further models, scripts and details, see [our repository](https://github.com/nytud/neural-models) or [our demo site](https://juniper.nytud.hu/demo/nlp).\n\n- Pretrained on Hungarian Wikipedia\n- Finetuned on Pet\u0151fi S\u00e1ndor \u00f6sszes k\u00f6ltem\u00e9nyei\n\n\n## Results\n\n| Model | Perplexity |\n| ------------- | ------------- |\n| **GPT-2 poem**  | **47.46** | \n| GPT-2 news | 22.06 | \n\n\n## Citation\nIf you use this model, please cite the following paper:\n```\n@inproceedings {yang-gpt2,\n    title = {{\"Az invaz\u00edv medv\u00e9k nem toler\u00e1lj\u00e1k a suzukis agresszi\u00f3t\" - Magyar GPT-2 k\u00eds\u00e9rleti modell}},\n\tbooktitle = {XVIII. Magyar Sz\u00e1m\u00edt\u00f3g\u00e9pes Nyelv\u00e9szeti Konferencia},\n\tyear = {2022},\n\tpublisher = {Szegedi Tudom\u00e1nyegyetem, Informatikai Int\u00e9zet},\n\taddress = {Szeged, Magyarorsz\u00e1g},\n\tauthor = {Yang, Zijian Gy\u0151z\u0151},\n\tpages = {463--476}\n}\n\n```", "size_bytes": "457394811", "downloads": 16}