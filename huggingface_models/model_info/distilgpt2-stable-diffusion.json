{"pretrained_model_name": "FredZhang7/distilgpt2-stable-diffusion", "description": "---\nlicense: creativeml-openrail-m\ntags:\n- stable-diffusion\n- prompt-generator\n- distilgpt2\ndatasets:\n- FredZhang7/krea-ai-prompts\n- Gustavosta/Stable-Diffusion-Prompts\n- bartman081523/stable-diffusion-discord-prompts\nwidget:\n- text: \"amazing\"\n- text: \"a photo of\"\n- text: \"a sci-fi\"\n- text: \"a portrait of\"\n- text: \"a person standing\"\n- text: \"a boy watching\"\n---\n# DistilGPT2 Stable Diffusion Model Card\n\n\n<a href=\"https://huggingface.co/FredZhang7/distilgpt2-stable-diffusion-v2\"> <font size=\"4\"> <bold> Version 2 is here! </bold> </font> </a>\n\n\nDistilGPT2 Stable Diffusion is a text generation model used to generate creative and coherent prompts for text-to-image models, given any text.\nThis model was finetuned on 2.03 million descriptive stable diffusion prompts from [Stable Diffusion discord](https://huggingface.co/datasets/bartman081523/stable-diffusion-discord-prompts), [Lexica.art](https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts), and (my hand-picked) [Krea.ai](https://huggingface.co/datasets/FredZhang7/krea-ai-prompts). I filtered the hand-picked prompts based on the output results from Stable Diffusion v1.4.\n\nCompared to other prompt generation models using GPT2, this one runs with 50% faster forwardpropagation and 40% less disk space & RAM.\n\n\n### PyTorch\n\n```bash\npip install --upgrade transformers\n```\n\n```python\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n# load the pretrained tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\ntokenizer.max_len = 512\n\n# load the fine-tuned model\nmodel = GPT2LMHeadModel.from_pretrained('FredZhang7/distilgpt2-stable-diffusion')\n\n# generate text using fine-tuned model\nfrom transformers import pipeline\nnlp = pipeline('text-generation', model=model, tokenizer=tokenizer)\nins = \"a beautiful city\"\n\n# generate 10 samples\nouts = nlp(ins, max_length=80, num_return_sequences=10)\n\n# print the 10 samples\nfor i in range(len(outs)):\n    outs[i] = str(outs[i]['generated_text']).replace('  ', '')\nprint('\\033[96m' + ins + '\\033[0m')\nprint('\\033[93m' + '\\n\\n'.join(outs) + '\\033[0m')\n```\n\nExample Output:\n![Example Output](./prompt-examples.png)", "size_bytes": "333969117", "downloads": 155}