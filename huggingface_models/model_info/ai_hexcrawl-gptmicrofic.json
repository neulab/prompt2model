{"pretrained_model_name": "huggingtweets/ai_hexcrawl-gptmicrofic", "description": "---\nlanguage: en\nthumbnail: https://www.huggingtweets.com/ai_hexcrawl-gptmicrofic/1631934945678/predictions.png\ntags:\n- huggingtweets\nwidget:\n- text: \"My dream is\"\n---\n\n<div class=\"inline-flex flex-col\" style=\"line-height: 1.5;\">\n    <div class=\"flex\">\n        <div\n\t\t\tstyle=\"display:inherit; margin-left: 4px; margin-right: 4px; width: 92px; height:92px; border-radius: 50%; background-size: cover; background-image: url(&#39;https://pbs.twimg.com/profile_images/1391882949650440200/lmEKl2ZQ_400x400.jpg&#39;)\">\n        </div>\n        <div\n            style=\"display:inherit; margin-left: 4px; margin-right: 4px; width: 92px; height:92px; border-radius: 50%; background-size: cover; background-image: url(&#39;https://pbs.twimg.com/profile_images/1261895681561804800/r6vOZGoH_400x400.jpg&#39;)\">\n        </div>\n        <div\n            style=\"display:none; margin-left: 4px; margin-right: 4px; width: 92px; height:92px; border-radius: 50%; background-size: cover; background-image: url(&#39;&#39;)\">\n        </div>\n    </div>\n    <div style=\"text-align: center; margin-top: 3px; font-size: 16px; font-weight: 800\">\ud83e\udd16 AI CYBORG \ud83e\udd16</div>\n    <div style=\"text-align: center; font-size: 16px; font-weight: 800\">AI Hexcrawl & GPT2-Microfic</div>\n    <div style=\"text-align: center; font-size: 14px;\">@ai_hexcrawl-gptmicrofic</div>\n</div>\n\nI was made with [huggingtweets](https://github.com/borisdayma/huggingtweets).\n\nCreate your own bot based on your favorite user with [the demo](https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb)!\n\n## How does it work?\n\nThe model uses the following pipeline.\n\n![pipeline](https://github.com/borisdayma/huggingtweets/blob/master/img/pipeline.png?raw=true)\n\nTo understand how the model was developed, check the [W&B report](https://wandb.ai/wandb/huggingtweets/reports/HuggingTweets-Train-a-Model-to-Generate-Tweets--VmlldzoxMTY5MjI).\n\n## Training data\n\nThe model was trained on tweets from AI Hexcrawl & GPT2-Microfic.\n\n| Data | AI Hexcrawl | GPT2-Microfic |\n| --- | --- | --- |\n| Tweets downloaded | 737 | 1127 |\n| Retweets | 26 | 9 |\n| Short tweets | 1 | 9 |\n| Tweets kept | 710 | 1109 |\n\n[Explore the data](https://wandb.ai/wandb/huggingtweets/runs/2cmbpada/artifacts), which is tracked with [W&B artifacts](https://docs.wandb.com/artifacts) at every step of the pipeline.\n\n## Training procedure\n\nThe model is based on a pre-trained [GPT-2](https://huggingface.co/gpt2) which is fine-tuned on @ai_hexcrawl-gptmicrofic's tweets.\n\nHyperparameters and metrics are recorded in the [W&B training run](https://wandb.ai/wandb/huggingtweets/runs/5g9tts1o) for full transparency and reproducibility.\n\nAt the end of training, [the final model](https://wandb.ai/wandb/huggingtweets/runs/5g9tts1o/artifacts) is logged and versioned.\n\n## How to use\n\nYou can use this model directly with a pipeline for text generation:\n\n```python\nfrom transformers import pipeline\ngenerator = pipeline('text-generation',\n                     model='huggingtweets/ai_hexcrawl-gptmicrofic')\ngenerator(\"My dream is\", num_return_sequences=5)\n```\n\n## Limitations and bias\n\nThe model suffers from [the same limitations and bias as GPT-2](https://huggingface.co/gpt2#limitations-and-bias).\n\nIn addition, the data present in the user's tweets further affects the text generated by the model.\n\n## About\n\n*Built by Boris Dayma*\n\n[![Follow](https://img.shields.io/twitter/follow/borisdayma?style=social)](https://twitter.com/intent/follow?screen_name=borisdayma)\n\nFor more details, visit the project repository.\n\n[![GitHub stars](https://img.shields.io/github/stars/borisdayma/huggingtweets?style=social)](https://github.com/borisdayma/huggingtweets)\n", "size_bytes": "510403817", "downloads": 2}