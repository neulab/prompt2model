{"pretrained_model_name": "Norod78/hebrew-gpt_neo-xl", "description": "---\nlanguage: he\n\nthumbnail: https://avatars1.githubusercontent.com/u/3617152?norod.jpg\nwidget:\n- text: \"\u05e2\u05d5\u05d3 \u05d1\u05d9\u05de\u05d9 \u05e7\u05d3\u05dd\"\n- text: \"\u05e7\u05d5\u05e8\u05d0\u05d9\u05dd \u05dc\u05d9 \u05d3\u05d5\u05e8\u05d5\u05df \u05d5\u05d0\u05e0\u05d9 \u05de\u05e2\u05d5\u05e0\u05d9\u05d9\u05df \u05dc\"\n- text: \"\u05e7\u05d5\u05e8\u05d0\u05d9\u05dd \u05dc\u05d9 \u05d0\u05d9\u05e6\u05d9\u05e7 \u05d5\u05d0\u05e0\u05d9 \u05d7\u05d5\u05e9\u05d1 \u05e9\"\n- text: \"\u05d4\u05d7\u05ea\u05d5\u05dc \u05e9\u05dc\u05da \u05de\u05d0\u05d5\u05d3 \u05d7\u05de\u05d5\u05d3 \u05d5\"\n- text: \"\u05d5\u05d1\u05d3\u05e8\u05da \u05e8\u05d0\u05d9\u05e0\u05d5 \u05e9\u05d4\u05d2\u05df\"\n\nlicense: mit\n---\n\n# hebrew-gpt_neo-xl\n\nHebrew text generation model based on [EleutherAI's gpt-neo](https://github.com/EleutherAI/gpt-neo). Each was trained on a TPUv3-8 which was made avilable to me via the [TPU Research Cloud](https://sites.research.google/trc/) Program.\n\n## Datasets\n\n1. An assortment of various Hebrew corpuses - I have made it available [here](https://mega.nz/folder/CodSSA4R#4INvMes-56m_WUi7jQMbJQ)\n\n\n2. oscar / unshuffled_deduplicated_he - [Homepage](https://oscar-corpus.com) | [Dataset Permalink](https://huggingface.co/datasets/viewer/?dataset=oscar&config=unshuffled_deduplicated_he)\n\nThe Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\n\n3. CC100-Hebrew Dataset [Homepage](https://metatext.io/datasets/cc100-hebrew) \n\nCreated by Conneau & Wenzek et al. at 2020, the CC100-Hebrew This dataset is one of the 100 corpora of monolingual data that was processed from the January-December 2018 Commoncrawl snapshots from the CC-Net repository. The size of this corpus is 6.1G., in Hebrew language.\n\n## Training Config\n\nAvailable [here](https://github.com/Norod/hebrew-gpt_neo/tree/main/hebrew-gpt_neo-xl/configs) <BR>\n\n## Usage\n\n### Google Colab Notebook\n\nAvailable [here ](https://colab.research.google.com/github/Norod/hebrew-gpt_neo/blob/main/hebrew-gpt_neo-xl/Norod78_hebrew_gpt_neo_xl_Colab.ipynb) <BR>\n\n\n#### Simple usage sample code\n\n```python\n\n!pip install tokenizers==0.10.3 transformers==4.8.0\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n  \ntokenizer = AutoTokenizer.from_pretrained(\"Norod78/hebrew-gpt_neo-xl\")\nmodel = AutoModelForCausalLM.from_pretrained(\"Norod78/hebrew-gpt_neo-xl\", pad_token_id=tokenizer.eos_token_id)\n\nprompt_text = \"\u05d0\u05e0\u05d9 \u05d0\u05d5\u05d4\u05d1 \u05e9\u05d5\u05e7\u05d5\u05dc\u05d3 \u05d5\u05e2\u05d5\u05d2\u05d5\u05ea\"\nmax_len = 512\nsample_output_num = 3\nseed = 1000\n\nimport numpy as np\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = 0 if torch.cuda.is_available()==False else torch.cuda.device_count()\n\nprint(f\"device: {device}, n_gpu: {n_gpu}\")\n\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif n_gpu > 0:\n    torch.cuda.manual_seed_all(seed)\n\nmodel.to(device)\n\nencoded_prompt = tokenizer.encode(\n    prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n\nencoded_prompt = encoded_prompt.to(device)\n\nif encoded_prompt.size()[-1] == 0:\n        input_ids = None\nelse:\n        input_ids = encoded_prompt\n\nprint(\"input_ids = \" + str(input_ids))\n\nif input_ids != None:\n  max_len += len(encoded_prompt[0])\n  if max_len > 2048:\n    max_len = 2048\n\nprint(\"Updated max_len = \" + str(max_len))\n\nstop_token = \"<|endoftext|>\"\nnew_lines = \"\\\n\\\n\\\n\"\n\nsample_outputs = model.generate(\n    input_ids,\n    do_sample=True, \n    max_length=max_len, \n    top_k=50, \n    top_p=0.95, \n    num_return_sequences=sample_output_num\n)\n\nprint(100 * '-' + \"\\\n\\t\\tOutput\\\n\" + 100 * '-')\nfor i, sample_output in enumerate(sample_outputs):\n\n  text = tokenizer.decode(sample_output, skip_special_tokens=True)\n  \n  # Remove all text after the stop token\n  text = text[: text.find(stop_token) if stop_token else None]\n\n  # Remove all text after 3 newlines\n  text = text[: text.find(new_lines) if new_lines else None]\n\n  print(\"\\\n{}: {}\".format(i, text))\n  print(\"\\\n\" + 100 * '-')\n\n```\n", "size_bytes": "5312753707", "downloads": 131}