{"pretrained_model_name": "cedpsam/chatbot_fr", "description": "---\nlanguage: fr\ntags:\n- conversational\nwidget:\n- text: \"bonjour.\"\n- text: \"mais encore\"\n- text: \"est ce que l'argent achete le bonheur?\"\n---\n\n## a dialoggpt model trained on french opensubtitles with custom tokenizer\ntrained with this notebook\nhttps://colab.research.google.com/drive/1pfCV3bngAmISNZVfDvBMyEhQKuYw37Rl#scrollTo=AyImj9qZYLRi&uniqifier=3\n\nconfig from microsoft/DialoGPT-medium\ndataset generated from 2018 opensubtitle downloaded from opus folowing these guidelines\nhttps://github.com/PolyAI-LDN/conversational-datasets/tree/master/opensubtitles with this notebook\nhttps://colab.research.google.com/drive/1uyh3vJ9nEjqOHI68VD73qxt4olJzODxi#scrollTo=deaacv4XfLMk\n### How to use\n\nNow we are ready to try out how the model works as a chatting partner!\n\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\n\ntokenizer = AutoTokenizer.from_pretrained(\"cedpsam/chatbot_fr\")\n\nmodel = AutoModelWithLMHead.from_pretrained(\"cedpsam/chatbot_fr\")\n\nfor step in range(6):\n    # encode the new user input, add the eos_token and return a tensor in Pytorch\n    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n    # print(new_user_input_ids)\n\n    # append the new user input tokens to the chat history\n    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n\n    # generated a response while limiting the total chat history to 1000 tokens, \n    chat_history_ids = model.generate(\n        bot_input_ids, max_length=1000,\n        pad_token_id=tokenizer.eos_token_id,\n        top_p=0.92, top_k = 50\n    )\n    \n    # pretty print last ouput tokens from bot\n    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n", "size_bytes": "1444586111", "downloads": 116}