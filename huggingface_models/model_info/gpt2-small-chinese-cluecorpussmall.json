{"pretrained_model_name": "souljoy/gpt2-small-chinese-cluecorpussmall", "description": "---\nlanguage: zh\ndatasets:\n- clue\nwidget:\n- text: \u8fd9\u662f\u5f88\u4e45\u4e4b\u524d\u7684\u4e8b\u60c5\u4e86\npipeline_tag: text-generation\nlicense: apache-2.0\n---\n\n\n# Chinese GPT2 Model\n\n## Model description\n\nThe model is used to generate Chinese texts. \n## How to use\n\nYou can use the model directly with a pipeline for text generation:\n\n```python\n>>> from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n>>> tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n>>> model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n>>> text_generator = TextGenerationPipeline(model, tokenizer)   \n>>> text_generator(\"\u8fd9\u662f\u5f88\u4e45\u4e4b\u524d\u7684\u4e8b\u60c5\u4e86\", max_length=100, do_sample=True)\n    [{'generated_text': '\u8fd9\u662f\u5f88\u4e45\u4e4b\u524d\u7684\u4e8b\u60c5\u4e86 \u3002 \u81f3 \u4eca \u4ecd \u7559 \u5728 \u6211 \u8eab \u4e0a \uff0c \u6211 \u8bb0 \u5fc6 \u72b9 \u65b0 \u3002 \u5728 \u63a5 \u53d7 \u8bb0 \u8005 \u91c7 \u8bbf \u65f6 \uff0c \u6768 \u6770 \u8868 \u767d \u4e86 \uff0c \u5f53 \u521d \u6709 \u6ca1 \u6709 \u89c1 \u8fc7 \u6211 \uff0c \u6211 \u4e0d \u8ba4 \u4e3a \u4ed6 \u4eec \u662f \u4e0d \u5408 \u9002 \u7684 \u4eba \u3002 \u867d \u7136 \u5f53 \u65f6 \u4ed6 \u4eec \u4e0d \u4fe1 \u6211 \uff0c \u4f46 \u6768 \u6770 \u8868 \u793a \uff0c \u611f \u89c9 \u90a3 \u4e2a \u65f6 \u5019 \u611f \u89c9 \u662f \u597d \u60f3 \u542c \u4ed6 \u4eec \u8bf4 \u8bdd \uff0c'}]\n\n```\n\n## Training data\n\n[CLUECorpusSmall](https://github.com/CLUEbenchmark/CLUECorpus2020/) is used as training data.", "size_bytes": "244489903", "downloads": 11}