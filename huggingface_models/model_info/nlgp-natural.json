{"pretrained_model_name": "Nokia/nlgp-natural", "description": "---\nlanguage: \n  - en\n  - code\ntags:\n- code completion\n- code generation\nlicense: \"apache-2.0\"\n---\n\n# NLGP natural model\n\nThe NLGP natural model was introduced in the paper [Natural Language-Guided Programming](https://arxiv.org/abs/2108.05198).  The model was trained on a collection of Jupyter notebooks and can be used to synthesize Python code that addresses a natural language **intent** in a certain code **context** (see the example below). This work was carried out by a research team in Nokia Bell Labs.\n\n**Context**\n```py\nimport matplotlib.pyplot as plt\n\nvalues = [1, 2, 3, 4]\nlabels = [\"a\", \"b\", \"c\", \"d\"]\n```\n\n**Intent**\n```py\n# plot a bar chart\n```\n\n**Prediction**\n```py\nplt.bar(labels, values)\nplt.show()\n```\n\n## Usage\n\n```py\nimport re\nfrom transformers import GPT2LMHeadModel, GPT2TokenizerFast\n\n# load the model\ntok = GPT2TokenizerFast.from_pretrained(\"Nokia/nlgp-natural\")\nmodel = GPT2LMHeadModel.from_pretrained(\"Nokia/nlgp-natural\") \n\n# preprocessing functions\nnum_spaces = [2, 4, 6, 8, 10, 12, 14, 16, 18]\ndef preprocess(context, query):\n    \"\"\"\n    Encodes context + query as a single string and \n    replaces whitespace with special tokens <|2space|>, <|4space|>, ...\n    \"\"\"\n    input_str = f\"{context}\\n{query} <|endofcomment|>\\n\"\n    indentation_symbols = {n: f\"<|{n}space|>\" for n in num_spaces}\n    m = re.match(\"^[ ]+\", input_str)\n    if not m:\n        return input_str\n    leading_whitespace = m.group(0)\n    N = len(leading_whitespace)\n    for n in self.num_spaces:\n        leading_whitespace = leading_whitespace.replace(n * \" \", self.indentation_symbols[n])\n    return leading_whitespace + input_str[N:]\n    \ndetokenize_pattern = re.compile(fr\"<\\|(\\d+)space\\|>\")\ndef postprocess(output):\n    output = output.split(\"<|cell|>\")[0]\n    def insert_space(m):\n        num_spaces = int(m.group(1))\n        return num_spaces * \" \"\n    return detokenize_pattern.sub(insert_space, output)\n\n# inference\ncode_context = \"\"\"\nimport matplotlib.pyplot as plt\n\nvalues = [1, 2, 3, 4]\nlabels = [\"a\", \"b\", \"c\", \"d\"]\n\"\"\"\nquery = \"# plot a bar chart\"\n\ninput_str = preprocess(code_context, query)\ninput_ids = tok(input_str, return_tensors=\"pt\").input_ids\n\nmax_length = 150 # don't generate output longer than this length\ntotal_max_length = min(1024 - input_ids.shape[-1], input_ids.shape[-1] + 150) # total = input + output\n\ninput_and_output = model.generate(\n    input_ids=input_ids, \n    max_length=total_max_length,\n    min_length=10,\n    do_sample=False,\n    num_beams=4,\n    early_stopping=True,\n    eos_token_id=tok.encode(\"<|cell|>\")[0]\n)\n\noutput = input_and_output[:, input_ids.shape[-1]:] # remove the tokens that correspond to the input_str\noutput_str = tok.decode(output[0])\npostprocess(output_str)\n```\n\n## License and copyright\n\nCopyright 2021 Nokia\n\nLicensed under the Apache License 2.0\n\nSPDX-License-Identifier: Apache-2.0", "size_bytes": "1444630455", "downloads": 13}