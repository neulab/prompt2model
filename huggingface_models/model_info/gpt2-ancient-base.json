{"pretrained_model_name": "zhuimengshaonian/gpt2-ancient-base", "description": "---\nlanguage: zh\nwidget:\n- text: \"[CLS]\u5f53\u662f\u65f6\"\n\n---\n\n# Chinese Ancient GPT2 Model\n\n## Model description\n\nThe model is used to generate ancient Chinese. \nThe model uses the frame of GPT2-base.\nWe trained on 4 P100 for about 8 days.\uff08batch size = 16, steps = 1M\uff09\n\n## How to use\n\nYou can use the model directly with a pipeline for text generation:\n\n```python\nfrom transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\ntokenizer = BertTokenizer.from_pretrained(\"zhuimengshaonian/gpt2-ancient-base\")\nmodel = GPT2LMHeadModel.from_pretrained(\"zhuimengshaonian/gpt2-ancient-base\")\ntext_generator = TextGenerationPipeline(model, tokenizer)\ntext_generator(\"[CLS]\u738b\u4faf\u5c06\u76f8\", max_length=100, do_sample=True)\n```\n\n", "size_bytes": "478303885", "downloads": 10}