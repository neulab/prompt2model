{"pretrained_model_name": "TristanBehrens/js-fakes-4bars", "description": "---\n\ntags:\n- gpt2\n- text-generation\n- music-modeling\n- music-generation\n\nwidget:\n - text: \"PIECE_START\"\n - text: \"PIECE_START STYLE=JSFAKES GENRE=JSFAKES TRACK_START INST=48 BAR_START NOTE_ON=60\"\n - text: \"PIECE_START STYLE=JSFAKES GENRE=JSFAKES TRACK_START INST=48 BAR_START NOTE_ON=58\"\n\n---\n\n\n# GPT-2 for Music\n\nLanguage Models such as GPT-2 can be used for Music Generation. The idea is to represent pieces of music as texts, effectively reducing the task to Language Generation.\n\nThis model is a rather small instance of GPT-2 trained on [TristanBehrens/js-fakes-4bars](https://huggingface.co/datasets/TristanBehrens/js-fakes-4bars). The model generates 4 bars at a time of Bach-like chorales with four voices (soprano, alto, tenor, bass).\n\nIf you are contribute, if you want to say hello, if you want to know more, find me on [LinkedIn](https://www.linkedin.com/in/dr-tristan-behrens-734967a2/)\n\n## Model description\n\nThe model is GPT-2 with 6 decoders and 8 attention-heads each. The context length is 512. The embedding dimensions are 512 as well. The vocabulary size is 119.\n\n## Intended uses & limitations\n\nThis model is just a proof of concept. It shows that HuggingFace can be used to compose music.\n\n### How to use\n\nThere is a notebook in the repo that you can run on Google Colab.\n\n### Limitations and bias\n\nSince this model has been trained on a very small corpus of music, it is overfitting heavily. ", "size_bytes": "78557661", "downloads": 61}