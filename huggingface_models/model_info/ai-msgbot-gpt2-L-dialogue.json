{"pretrained_model_name": "ethzanalytics/ai-msgbot-gpt2-L-dialogue", "description": "# ai-msgbot GPT2-L + daily dialogues\n\n_NOTE: this model card is a WIP_\n\nGPT2-L (774M parameters) fine-tuned on the Wizard of Wikipedia dataset for 40k steps with 34/36 layers frozen using `aitextgen`. This model was then subsequently further fine-tuned on the [Daily Dialogues](http://yanran.li/dailydialog) dataset for an additional 40k steps, this time with **35** of 36 layers frozen.\n\nDesigned for use with [ai-msgbot](https://github.com/pszemraj/ai-msgbot) to create an open-ended chatbot (of course, if other use cases arise, have at it).\n\n\n## conversation data\n\nThe dataset was tokenized and fed to the model as a conversation between two speakers, whose names are below. This is relevant for writing prompts and filtering/extracting text from responses.\n\n`script_speaker_name` = `person alpha`\n\n`script_responder_name` = `person beta`\n\n\n## examples\n\n- the default inference API examples should work _okay_\n- an ideal test would be explicitly adding `person beta` to the **end** of the prompt text. The model is forced to respond to the entered chat prompt instead of adding to the entered prompt and then responding to that (which may cut off the response text due to the Inference API limits).\n\n### Example prompt:\n```\ndo you like to eat beans? \nperson beta:\n```\n### Resulting output\n\n```\ndo you like to eat beans? \n\nperson beta:\nno, i don't like\n```\n\n## citations \n```\n@inproceedings{dinan2019wizard,\n  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},\n  title={{W}izard of {W}ikipedia: Knowledge-powered Conversational Agents},\n  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},\n  year={2019},\n}\n\n@inproceedings{li-etal-2017-dailydialog,\n    title = \"{D}aily{D}ialog: A Manually Labelled Multi-turn Dialogue Dataset\",\n    author = \"Li, Yanran  and\n      Su, Hui  and\n      Shen, Xiaoyu  and\n      Li, Wenjie  and\n      Cao, Ziqiang  and\n      Niu, Shuzi\",\n    booktitle = \"Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = nov,\n    year = \"2017\",\n    address = \"Taipei, Taiwan\",\n    publisher = \"Asian Federation of Natural Language Processing\",\n    url = \"https://aclanthology.org/I17-1099\",\n    pages = \"986--995\",\n    abstract = \"We develop a high-quality multi-turn dialog dataset, \\textbf{DailyDialog}, which is intriguing in several aspects. The language is human-written and less noisy. The dialogues in the dataset reflect our daily communication way and cover various topics about our daily life. We also manually label the developed dataset with communication intention and emotion information. Then, we evaluate existing approaches on DailyDialog dataset and hope it benefit the research field of dialog systems. The dataset is available on \\url{http://yanran.li/dailydialog}\",\n}\n```", "size_bytes": "3134045897", "downloads": 1}