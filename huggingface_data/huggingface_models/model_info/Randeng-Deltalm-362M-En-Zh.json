{"pretrained_model_name": "IDEA-CCNL/Randeng-Deltalm-362M-En-Zh", "description": "---\nlanguage: \n- zh\n- en\n\ntags:\n- translation\ninference: False\n---\n\n# Randeng-Deltalm-362M-En-Zh\n\n- Main Page:[Fengshenbang](https://fengshenbang-lm.com/)\n- Github: [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)\n\n## \u7b80\u4ecb Brief Introduction\n\n\u4f7f\u7528\u5c01\u795e\u6846\u67b6\u57fa\u4e8e Detalm base \u8fdb\u884cfinetune \uff0c\u641c\u96c6\u7684\u4e2d\u82f1\u6570\u636e\u96c6\uff08\u51713\u5343\u4e07\u6761\uff09\u4ee5\u53ca iwslt\u7684\u4e2d\u82f1\u5e73\u884c\u6570\u636e\uff0820\u4e07\uff09\uff0c\u5f97\u5230 \u82f1-> \u4e2d\u65b9\u5411\u7684\u7ffb\u8bd1\u6a21\u578b\n\nUsing the Fengshen-LM framework and finetuning based on detalm , get a translation model in the English -> Chinese direction\n\n## \u6a21\u578b\u5206\u7c7b Model Taxonomy\n\n|  \u9700\u6c42 Demand  | \u4efb\u52a1 Task       | \u7cfb\u5217 Series      | \u6a21\u578b Model    | \u53c2\u6570 Parameter | \u989d\u5916 Extra |\n|  :----:  | :----:  | :----:  | :----:  | :----:  | :----:  |\n| \u901a\u7528 General | \u81ea\u7136\u8bed\u8a00\u8f6c\u6362 NLT | \u71c3\u706f Randeng | Deltalm |      362M      |    \u7ffb\u8bd1\u4efb\u52a1 En-Zh    |\n\n## \u6a21\u578b\u4fe1\u606f Model Information\n\n\u53c2\u8003\u8bba\u6587\uff1a[DeltaLM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders](https://arxiv.org/pdf/2106.13736v2.pdf)\n\n### \u4e0b\u6e38\u6548\u679c Performance\n\n| datasets | bleu|\n| ---- | ---- |\n| florse101-en-zh | 40.22 |\n\n## \u4f7f\u7528 Usage\n\n```python\n\n# Need to download modeling_deltalm.py from Fengshenbang-LM github repo in advance,\n# or you can download modeling_deltalm.py use wget https://huggingface.co/IDEA-CCNL/Randeng-Deltalm-362M-En-Zn/resolve/main/modeling_deltalm.py\n# Strongly recommend you git clone the Fengshenbang-LM repo:\n# 1. git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n# 2. cd Fengshenbang-LM/fengshen/\n\nfrom models.deltalm.modeling_deltalm import DeltalmForConditionalGeneration\nfrom transformers import AutoTokenizer\n\nmodel = DeltalmForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Deltalm-362M-En-Zn\")\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/infoxlm-base\")\n\ntext = \"In summer, especially, you'll need to watch out for mosquitoes if you decide to hike through the rainforest.\"\ninputs = tokenizer(text, max_length=512, return_tensors=\"pt\")\n\ngenerate_ids = model.generate(inputs[\"input_ids\"], max_length=512)\ntokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\n# model Output:\n# \u5982\u679c\u4f60\u51b3\u5b9a\u5f92\u6b65\u7a7f\u8d8a\u70ed\u5e26\u96e8\u6797,\u4f60\u9700\u8981\u5c0f\u5fc3\u868a\u5b50,\u5c24\u5176\u662f\u5728\u590f\u5929\u3002\n```\n\n## \u5f15\u7528 Citation\n\n\u5982\u679c\u60a8\u5728\u60a8\u7684\u5de5\u4f5c\u4e2d\u4f7f\u7528\u4e86\u6211\u4eec\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5f15\u7528\u6211\u4eec\u7684[\u8bba\u6587](https://arxiv.org/abs/2209.02970)\uff1a\n\nIf you are using the resource for your work, please cite the our [paper](https://arxiv.org/abs/2209.02970):\n\n```text\n@article{fengshenbang,\n  author    = {Jiaxing Zhang and Ruyi Gan and Junjie Wang and Yuxiang Zhang and Lin Zhang and Ping Yang and Xinyu Gao and Ziwei Wu and Xiaoqun Dong and Junqing He and Jianheng Zhuo and Qi Yang and Yongfeng Huang and Xiayu Li and Yanghan Wu and Junyu Lu and Xinyu Zhu and Weifeng Chen and Ting Han and Kunhao Pan and Rui Wang and Hao Wang and Xiaojun Wu and Zhongshen Zeng and Chongpei Chen},\n  title     = {Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence},\n  journal   = {CoRR},\n  volume    = {abs/2209.02970},\n  year      = {2022}\n}\n```\n\n\u4e5f\u53ef\u4ee5\u5f15\u7528\u6211\u4eec\u7684[\u7f51\u7ad9](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n\nYou can also cite our [website](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n\n```text\n@misc{Fengshenbang-LM,\n  title={Fengshenbang-LM},\n  author={IDEA-CCNL},\n  year={2021},\n  howpublished={\\url{https://github.com/IDEA-CCNL/Fengshenbang-LM}},\n}\n```\n", "size_bytes": "726358755", "downloads": 2101}