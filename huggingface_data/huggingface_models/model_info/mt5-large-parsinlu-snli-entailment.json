{"pretrained_model_name": "persiannlp/mt5-large-parsinlu-snli-entailment", "description": "---\nlanguage:\n- fa\n- multilingual\nthumbnail: https://upload.wikimedia.org/wikipedia/commons/a/a2/Farsi.svg\ntags:\n- entailment\n- mt5\n- persian\n- farsi\nlicense: cc-by-nc-sa-4.0\ndatasets:\n- parsinlu\n- snli\nmetrics:\n- accuracy\n---\n\n# Textual Entailment (\u0645\u062f\u0644 \u0628\u0631\u0627\u06cc \u067e\u0627\u0633\u062e \u0628\u0647 \u0627\u0633\u062a\u0644\u0632\u0627\u0645 \u0645\u0646\u0637\u0642\u06cc)\n\nThis is a model for textual entailment problems. \nHere is an example of how you can run this model: \n\n```python \nfrom transformers import MT5ForConditionalGeneration, MT5Tokenizer\n\nmodel_size=\"large\"\nmodel_name = f\"persiannlp/mt5-{model_size}-parsinlu-snli-entailment\"\ntokenizer = MT5Tokenizer.from_pretrained(model_name)\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name)\n\n\ndef run_model(premise, hypothesis, **generator_args):\n    input_ids = tokenizer.encode(f\"{premise}<sep>{hypothesis}\", return_tensors=\"pt\")\n    res = model.generate(input_ids, **generator_args)\n    output = tokenizer.batch_decode(res, skip_special_tokens=True)\n    print(output)\n    return output\n\n\nrun_model(\n    \"\u0627\u06cc\u0646 \u0645\u0633\u0627\u0628\u0642\u0627\u062a \u0628\u06cc\u0646 \u0622\u0648\u0631\u06cc\u0644 \u0648 \u062f\u0633\u0627\u0645\u0628\u0631 \u062f\u0631 \u0647\u06cc\u067e\u0648\u062f\u0631\u0648\u0645 \u0648\u0644\u06cc\u0641\u0646\u062f\u06cc \u062f\u0631 \u0646\u0632\u062f\u06cc\u06a9\u06cc \u0628\u0627\u06a9\u0631\u06a9\u06cc \u060c \u06f1\u06f5 \u06a9\u06cc\u0644\u0648\u0645\u062a\u0631\u06cc (\u06f9 \u0645\u0627\u06cc\u0644) \u063a\u0631\u0628 \u0627\u0633\u062a\u0627\u0646\u0628\u0648\u0644 \u0628\u0631\u06af\u0632\u0627\u0631 \u0645\u06cc \u0634\u0648\u062f.\",\n    \"\u062f\u0631 \u0648\u0644\u06cc\u0641\u0646\u062f\u06cc \u0647\u06cc\u067e\u0648\u062f\u0631\u0648\u0645\u060c \u0645\u0633\u0627\u0628\u0642\u0627\u062a\u06cc \u0627\u0632 \u0622\u0648\u0631\u06cc\u0644 \u062a\u0627 \u062f\u0633\u0627\u0645\u0628\u0631 \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f.\"\n)\n\nrun_model(\n\"\u0622\u06cc\u0627 \u06a9\u0648\u062f\u06a9\u0627\u0646\u06cc \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u0646\u062f \u06a9\u0647 \u0646\u06cc\u0627\u0632 \u0628\u0647 \u0633\u0631\u06af\u0631\u0645\u06cc \u062f\u0627\u0631\u0646\u062f\u061f\",\n    \"\u0647\u06cc\u0686 \u06a9\u0648\u062f\u06a9\u06cc \u0647\u0631\u06af\u0632 \u0646\u0645\u06cc \u062e\u0648\u0627\u0647\u062f \u0633\u0631\u06af\u0631\u0645 \u0634\u0648\u062f.\",\n)\n\nrun_model(\n    \"\u0645\u0627 \u0628\u0647 \u0633\u0641\u0631\u0647\u0627\u06cc\u06cc \u0631\u0641\u062a\u0647 \u0627\u06cc\u0645 \u06a9\u0647 \u062f\u0631 \u0646\u0647\u0631\u0647\u0627\u06cc\u06cc \u0634\u0646\u0627 \u06a9\u0631\u062f\u0647 \u0627\u06cc\u0645\",\n    \"\u0639\u0644\u0627\u0648\u0647 \u0628\u0631 \u0627\u0633\u062a\u062d\u0645\u0627\u0645 \u062f\u0631 \u0646\u0647\u0631\u0647\u0627 \u060c \u0645\u0627 \u0628\u0647 \u0627\u0633\u067e\u0627 \u0647\u0627 \u0648 \u0633\u0648\u0646\u0627 \u0647\u0627 \u0646\u06cc\u0632 \u0631\u0641\u062a\u0647 \u0627\u06cc\u0645.\"\n)\n```\n\n\nFor more details, visit this page: https://github.com/persiannlp/parsinlu/ \n", "size_bytes": "4918522339", "downloads": 7}