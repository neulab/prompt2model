{"pretrained_model_name": "marksverdhei/t5-base-define", "description": "---\nlanguage: en\nwidget:\n - text: 'define \"toecoin\": toecoin rose by 200% after Elon Musk mentioned it in his tweet'\ndatasets:\n- 'marksverdhei/wordnet-definitions-en-2021'\n---\n\n# T5-define  \n\n(This model is still a work in progress. If you use it for fine tuning, make sure to save a local copy)\n\nThis model is trained to generate word definitions based on the word and a context,\nusing a subset of wordnet for all words that have an example and definition.\nThe model uses task prompts on the format 'define \"[word]\": [example sentence]'\n\nThis model in particular is a one-shot learner for unseen words, as it has to infer the definition by only one example\n\nHow to run:\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\ntokenizer = T5Tokenizer.from_pretrained(\"marksverdhei/t5-base-define\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"marksverdhei/t5-base-define\")\n\nprompt = \"define \\\"noseplow\\\": The children hid as the noseplow drove across the street\"\n\nids = tokenizer(prompt, return_tensors=\"pt\").input_ids\ngenerated_tokens = model.generate(ids)[0][1:-1]\nprint(tokenizer.decode(generated_tokens))\n```\n\nSee the gist for the source code to used to train the model:\n\nhttps://gist.github.com/marksverdhei/0a13f67e65460b71c05fcf558a6a91ae", "size_bytes": "891730879", "downloads": 4}