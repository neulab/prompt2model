{"pretrained_model_name": "redadmiral/headlines_test_small_example", "description": "This Model is a fine-tuned version of T-systems [summarization model v1](https://huggingface.co/deutsche-telekom/mt5-small-sum-de-en-v1). \n\nWe used 1000 examples of headline-content pairs from BR24 articles for the fine-tuning process.\n\nDespite the small amount of training data, the tonality of the summarizations has changed significantly. Many of the resulting summaries do sound like a headline.\n\n## Training\n\nWe used the following parameters for training this model:\n\n+ base model: deutsche-telekom/mt5-small-sum-de-en-v1\n+ source_prefix: \"summarize: \"\n+ batch size: 4\n+ max_source_length: 400\n+ max_target_length: 35\n+ weight_decay: 0.01\n+ number of train epochs: 1\n+ learning rate: 5e-5\n\n## License\n\nSince the base model is trained on the MLSUM dataset, this model may not be used for commercial use.\n\n## Stats\n\n| Model                                   | Rouge1    | Rouge2   | RougeL    | RougeLSum |\n|-----------------------------------------|-----------|----------|-----------|-----------|\n| headlines_test_small_example            | 13.573500 | 3.694700 | 12.560600 | 12.60000  |\n| deutsche-telekom/mt5-small-sum-de-en-v1 | 10.6488   | 2.9313   | 10.0527   | 10.0523   |\n\n", "size_bytes": "1200743045", "downloads": 2}