{"pretrained_model_name": "svalabs/mt5-large-german-query-gen-v1", "description": "---\nlanguage:\n- de\ndatasets:\n- unicamp-dl/mmarco\n- deepset/germanquad\nwidget:\n- text: \"Python ist eine universelle, \u00fcblicherweise interpretierte, h\u00f6here Programmiersprache. Sie hat den Anspruch, einen gut lesbaren, knappen Programmierstil zu f\u00f6rdern. So werden beispielsweise Bl\u00f6cke nicht durch geschweifte Klammern, sondern durch Einr\u00fcckungen strukturiert.\"\n\n---\n# svalabs/mt5-large-german-query-gen-v1\nThis is a german [doc2query](https://arxiv.org/abs/1904.08375) model usable for document expansion to further boost search results by generating queries.\n## Usage (code from doc2query/msmarco-14langs-mt5-base-v1)\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\n\nmodel_name = 'svalabs/mt5-large-german-query-gen-v1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to('cuda:0')\n\ntext = \"qgen: Python ist eine universelle, \u00fcblicherweise interpretierte, h\u00f6here Programmiersprache. Sie hat den Anspruch, einen gut lesbaren, knappen Programmierstil zu f\u00f6rdern. So werden beispielsweise Bl\u00f6cke nicht durch geschweifte Klammern, sondern durch Einr\u00fcckungen strukturiert.\"\n\n\ndef create_queries(para):\n    input_ids = tokenizer.encode(para, return_tensors='pt').to('cuda:0')\n    with torch.no_grad():\n        # Here we use top_k / top_k random sampling. It generates more diverse queries, but of lower quality\n        sampling_outputs = model.generate(\n            input_ids=input_ids,\n            max_length=64,\n            do_sample=True,\n            top_p=0.95,\n            top_k=20, \n            num_return_sequences=10\n            )\n        \n        # Here we use Beam-search. It generates better quality queries, but with less diversity\n        beam_outputs = model.generate(\n            input_ids=input_ids, \n            max_length=64, \n            num_beams=10, \n            no_repeat_ngram_size=2, \n            num_return_sequences=10, \n            early_stopping=False\n        )\n\n    print(\"Paragraph:\")\n    print(para)\n    \n    print(\"\\nBeam Outputs:\")\n    for i in range(len(beam_outputs)):\n        query = tokenizer.decode(beam_outputs[i], skip_special_tokens=True)\n        print(f'{i + 1}: {query}')\n\n    print(\"\\nSampling Outputs:\")\n    for i in range(len(sampling_outputs)):\n        query = tokenizer.decode(sampling_outputs[i], skip_special_tokens=True)\n        print(f'{i + 1}: {query}')\n\ncreate_queries(text)\n```\n\n**Console Output**:\n```\nParagraph:\nqgen: Python ist eine universelle, \n\u00fcblicherweise interpretierte, \nh\u00f6here Programmiersprache.\nSie hat den Anspruch, einen gut lesbaren,\nknappen Programmierstil zu f\u00f6rdern. \nSo werden beispielsweise Bl\u00f6cke nicht durch geschweifte Klammern,\nsondern durch Einr\u00fcckungen strukturiert. \n\nBeam Outputs:\n1: ist Python eine universelle Programmiersprache\n2: Welche Art von Programmiersprache ist Python?\n3: Welche Programmiersprache ist Python?\n4: Was ist Python-Programmierung?\n5: welche sprache ist python\n6: Was ist der Unterschied zwischen Python und Perl?\n7: Was ist der Unterschied zwischen Python und Ruby?\n8: Was ist der Unterschied zwischen Python und Java?\n9: was ist python\n10: was ist der unterschied zwischen c++ und python?\n\nSampling Outputs:\n1: ist Python eine universelle Programmiersprache\n2: Was ist der Zweck der Python-Sprache?\n3: Was ist der Unterschied zwischen Python und Java?\n4: welche sprache ist python\n5: Was ist Python-Programmierung?\n6: welcher teil der sprache ist python\n7: Welche Art von Programmiersprache ist Python?\n8: ist Python eine universelle Programmiersprache\n9: warum Python eine universelle Programmiersprache ist\n10: ist Python-Programmierung universell\n```\n\n### References\n['Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks'](https://arxiv.org/abs/1908.10084).\n['MS MARCO: A Human Generated MAchine Reading COmprehension Dataset'](https://arxiv.org/abs/1611.09268).\n['GermanQuAD and GermanDPR: Improving Non-English Question Answering and Passage Retrieval'](https://arxiv.org/abs/2104.12741).\n[google/mt5-large](https://huggingface.co/google/mt5-large)\n[mMARCO dataset](https://github.com/unicamp-dl/mMARCO)\n[doc2query](https://arxiv.org/abs/1904.08375) ", "size_bytes": "4918515513", "downloads": 15}