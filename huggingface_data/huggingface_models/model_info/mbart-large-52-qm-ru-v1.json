{"pretrained_model_name": "TSjB/mbart-large-52-qm-ru-v1", "description": "---\nlanguage:\n- krc\n- ru\nlibrary_name: transformers\npipeline_tag: translation\nmetrics:\n- bleu\ntags:\n- code\n---\nAuthors: Bogdan Tewnalany, Ali Berberov\nGithub: https://github.com/TBSj/Qarachay_Malqar_translator_python\n\nAs a base we took mbart-50 model and trained it on 27235 parallel sentences from Qarachay-Malqar to russian language. It is not enough for good prediction, nevertheless, there is some result.\n\nNowdays, we are collecting more sentences to improve our result. And, I hope, it gives us opportunity to not use pre-trained models and realize translator on R instead of python.\n\nDataset: https://huggingface.co/datasets/TSjB/qm_ru_parallel\n\nWhere to use:\n\nhttps://huggingface.co/spaces/TSjB/QM_RU_translator\n\nhttps://tsjb-qm-ru-translator.hf.space/\n\nTelegram: https://t.me/QMKochBot", "size_bytes": "2453869853", "downloads": 13}