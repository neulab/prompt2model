{"pretrained_model_name": "Karim-Gamal/switch-base-8-finetuned-SemEval-2018-emojis-IID-Fed", "description": "---\nlicense: apache-2.0\nlanguage:\n- en\nmetrics:\n- f1\n---\n\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# switch-base-8-finetuned\n\nThis model is a fine-tuned version of [google/switch-base-8](https://huggingface.co/google/switch-base-8) on the SemEval-2018-Task-2 emojis english dataset with Federated Learning in IID setting.\nIt achieves the following results on the evaluation set:\n- Accuracy: 50.750 %\n- Mac-F1: 37.355 %\n\n\n# Model description\n\n## More information needed\n\n- **Model type:** Language model\n- **Language(s) (NLP):** English\n- **License:** Apache 2.0\n- **Related Models:** [All Switch Transformers Checkpoints](https://huggingface.co/models?search=switch)\n- **Original Checkpoints:** [All Original Switch Transformers Checkpoints](https://github.com/google-research/t5x/blob/main/docs/models.md#mixture-of-experts-moe-checkpoints)\n- **Resources for more information:**\n  - [Research paper](https://arxiv.org/pdf/2101.03961.pdf)\n  - [GitHub Repo](https://github.com/google-research/t5x)\n  - [Hugging Face Switch Transformers Docs (Similar to T5) ](https://huggingface.co/docs/transformers/model_doc/switch_transformers)\n\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 1e-4\n- train_batch_size: 464\n- eval_batch_size: 512\n- seed: 42\n- num_epochs: 30\n\n### Testing results\n\n\n|                 SemEval Testing Data                |   accuracy   |   Mac-F1   | \n|:---------------------------------------------------:|:------------:|:----------:|\n|        \"Tubingen-Oslo\" First SemEval Team           |    47.09%    |   35.99%   |\n| [switch-base-8-finetuned-SemEval-2018-emojis-cen-1](https://huggingface.co/Karim-Gamal/switch-base-8-finetuned-SemEval-2018-emojis-cen-1)   |    48.040%   |   33.239%  |\n| [switch-base-8-finetuned-SemEval-2018-emojis-cen-2](https://huggingface.co/Karim-Gamal/switch-base-8-finetuned-SemEval-2018-emojis-cen-2)   |    50.174%   |   36.660%  |\n| [switch-base-8-finetuned-SemEval-2018-emojis-IID-Fed](https://huggingface.co/Karim-Gamal/switch-base-8-finetuned-SemEval-2018-emojis-IID-Fed) |  50.750%      | 37.355%    |\n\n\n## Google colab to test the models on SemEval test dataset : [The Notebook](https://colab.research.google.com/drive/1CJWfCyT8ofz1xg6W_F5YCMyTpCs36_PP?usp=sharing)\n\n\n### Framework versions\n\n- Transformers 4.25.1\n- Pytorch 1.13.1+cu116\n- Tokenizers 0.13.2", "size_bytes": "1238827479", "downloads": 8}