{"pretrained_model_name": "j5ng/et5-formal-convertor", "description": "---\nlicense: apache-2.0\nlanguage:\n- ko\npipeline_tag: text2text-generation\n---\n\n# korean Formal Convertor Using Deep Learning\n\uc874\ub313\ub9d0\uacfc \ubc18\ub9d0\uc740 \ud55c\uad6d\uc5b4\uc5d0\uc11c\ub9cc \uc874\uc7ac\ud569\ub2c8\ub2e4, \ubcf8 \ubaa8\ub378\uc740 \ubc18\ub9d0(informal)\uc744 \uc874\ub313\ub9d0(formal)\ub85c \ubc14\uafd4\uc8fc\ub294 \ubcc0\ud658\uae30(convertor) \uc785\ub2c8\ub2e4. <br>\n*\ud655\ubcf4\ud55c \uc874\ub313\ub9d0 \ub370\uc774\ud130\uc14b\uc5d0\ub294 \"\ud574\uc694\uccb4\"\uc640 \"\ud569\uc1fc\uccb4\" \ub450 \uc885\ub958\uac00 \uc874\uc7ac\ud588\uc9c0\ub9cc \ubcf8 \ubaa8\ub378\uc740 \"\ud574\uc694\uccb4\"\ub85c \ud1b5\uc77c\ud558\uc5ec \ubcc0\ud658\ud558\uae30\ub85c \uacb0\uc815\ud588\uc2b5\ub2c8\ub2e4.\n\n|\ud569\uc1fc\uccb4|*\ud574\uc694\uccb4|\n|------|---|\n|\uc548\ub155\ud558\uc2ed\ub2c8\uae4c.|\uc548\ub155\ud558\uc138\uc694.|\n|\uc88b\uc740 \uc544\uce68\uc785\ub2c8\ub2e4.|\uc88b\uc740 \uc544\uce68\uc774\uc5d0\uc694.|\n|\ubc14\uc058\uc2dc\uc9c0 \uc54a\uc558\uc73c\uba74 \uc88b\uaca0\uc2b5\ub2c8\ub2e4.|\ubc14\uc058\uc2dc\uc9c0 \uc54a\uc558\uc73c\uba74 \uc88b\uaca0\uc5b4\uc694.|\n\n## \ubc30\uacbd\n- \uc774\uc804\uc5d0 \uc874\ub313\ub9d0\uacfc \ubc18\ub9d0\uc744 \uad6c\ubd84\ud558\ub294 \ubd84\ub958\uae30(https://github.com/jongmin-oh/korean-formal-classifier) \ub97c \ud559\uc2b5\ud588\uc2b5\ub2c8\ub2e4.<br>\n\ubd84\ub958\uae30\ub85c \ub9d0\ud22c\ub97c \ub098\ub220 \uc0ac\uc6a9\ud558\ub824\ud588\uc9c0\ub9cc, \uc0c1\ub300\uc801\uc73c\ub85c \uc874\ub313\ub9d0\uc758 \ube44\uc911\uc774 \uc801\uc5c8\uace0 \ubc18\ub9d0\uc744 \uc874\ub313\ub9d0\ub85c \ubc14\uafb8\uc5b4 \uc874\ub313\ub9d0 \ub370\uc774\ud130\uc758 \ube44\uc911\uc744 \ub298\ub9ac\uae30\uc704\ud574 \ub9cc\ub4e4\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n## \ud55c\uad6d\uc5b4 \uc874\ub313\ub9d0 \ubcc0\ud658\uae30\n- \uc874\ub313\ub9d0 \ubcc0\ud658\uae30\ub294 T5\ubaa8\ub378 \uc544\ud0a4\ud14d\uccd0\ub97c \uae30\ubc18\uc73c\ub85c\ud55c Text2Text generation Task\ub97c \uc218\ud589\ud568\uc73c\ub85c \ubc18\ub9d0\uc744 \uc874\ub313\ub9d0\ub85c \ubcc0\ud658\ud558\uc5ec \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n- \ubc14\ub85c \uc0ac\uc6a9\ud558\uc2e4 \ubd84\ub4e4\uc740 \ubc11\uc5d0 \uc608\uc81c \ucf54\ub4dc \ucc38\uace0\ud574\uc11c huggingFace \ubaa8\ub378('j5ng/et5-formal-convertor') \ub2e4\uc6b4\ubc1b\uc544 \uc0ac\uc6a9\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n## Base on PLM model(ET5)\n - ETRI(https://aiopen.etri.re.kr/et5Model)\n\n## Base on Dataset\n - AI\ud5c8\ube0c(https://www.aihub.or.kr/) : \ud55c\uad6d\uc5b4 \uc5b4\uccb4 \ubcc0\ud658 \ucf54\ud37c\uc2a4\n    1. KETI \uc77c\uc0c1\uc624\ud53c\uc2a4 \ub300\ud654 1,254 \ubb38\uc7a5\n    2. \uc218\ub3d9\ud0dc\uae45 \ubcd1\ub82c\ub370\uc774\ud130\n\n - \uc2a4\ub9c8\uc77c\uac8c\uc774\ud2b8 \ub9d0\ud22c \ub370\uc774\ud130 \uc14b(korean SmileStyle Dataset)\n\n### Preprocessing\n 1. \ubc18\ub9d0/\uc874\ub313\ub9d0 \ub370\uc774\ud130 \ubd84\ub9ac(\"\ud574\uc694\uccb4\"\ub9cc \ubd84\ub9ac)\n    - \uc2a4\ub9c8\uc77c\uac8c\uc774\ud2b8 \ub370\uc774\ud130\uc5d0\uc11c (['formal','informal']) \uce7c\ub7fc\ub9cc \uc0ac\uc6a9\n    - \uc218\ub3d9\ud0dc\uae45 \ubcd1\ub82c\ub370\uc774\ud130\uc5d0\uc11c [\"*.ban\", \"*.yo\"] txt \ud30c\uc77c\ub9cc \uc0ac\uc6a9\n    - KETI \uc77c\uc0c1\uc624\ud53c\uc2a4 \ub370\uc774\ud130\uc5d0\uc11c([\"\ubc18\ub9d0\",\"\ud574\uc694\uccb4\"]) \uce7c\ub7fc\ub9cc \uc0ac\uc6a9\n\n 2. \ub370\uc774\ud130 \uc14b \ubcd1\ud569(3\uac00\uc9c0 \ub370\uc774\ud130 \uc14b \ubcd1\ud569)\n 3. \ub9c8\uce68\ud45c(.)\uc640 \uc27c\ud45c(,)\uc81c\uac70\n 4. \ubc18\ub9d0(informal) \uce7c\ub7fc \uc911\ubcf5 \uc81c\uac70 : 1632\uac1c \uc911\ubcf5\ub370\uc774\ud130 \uc81c\uac70\n\n### \ucd5c\uc885 \ud559\uc2b5\ub370\uc774\ud130 \uc608\uc2dc\n|informal|formal|\n|------|---|\n|\uc751 \uace0\ub9c8\uc6cc|\ub124 \uac10\uc0ac\ud574\uc694|\n|\ub098\ub3c4 \uadf8 \ucc45 \uc77d\uc5c8\uc5b4 \uad49\uc7a5\ud788 \uc6c3\uae34 \ucc45\uc774\uc600\uc5b4|\uc800\ub3c4 \uadf8 \ucc45 \uc77d\uc5c8\uc2b5\ub2c8\ub2e4 \uad49\uc7a5\ud788 \uc6c3\uae34 \ucc45\uc774\uc600\uc5b4\uc694|\n|\ubbf8\uc138\uba3c\uc9c0\uac00 \ub9ce\uc740 \ub0a0\uc774\uc57c|\ubbf8\uc138\uba3c\uc9c0\uac00 \ub9ce\uc740 \ub0a0\uc774\ub124\uc694|\n|\uad1c\ucc2e\uaca0\uc5b4?|\uad1c\ucc2e\uc73c\uc2e4\uae4c\uc694?|\n|\uc544\ub2c8\uc57c \ud68c\uc758\uac00 \uc7a0\uc2dc \ub4a4\uc5d0 \uc788\uc5b4 \uc900\ube44\ud574\uc918|\uc544\ub2c8\uc5d0\uc694 \ud68c\uc758\uac00 \uc7a0\uc2dc \ub4a4\uc5d0 \uc788\uc5b4\uc694 \uc900\ube44\ud574\uc8fc\uc138\uc694|\n\n#### total : 14,992 \uc30d\n\n***\n\n## How to use\n```python\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\n# T5 \ubaa8\ub378 \ub85c\ub4dc\nmodel = T5ForConditionalGeneration.from_pretrained(\"j5ng/et5-formal-convertor\")\ntokenizer = T5Tokenizer.from_pretrained(\"j5ng/et5-formal-convertor\")\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n# device = \"mps:0\" if torch.cuda.is_available() else \"cpu\" # for mac m1\n\nmodel = model.to(device) \n\n# \uc608\uc2dc \uc785\ub825 \ubb38\uc7a5\ninput_text = \"\ub098 \uc9c4\uc9dc \ud654\ub0ac\uc5b4 \uc9c0\uae08\"\n\n# \uc785\ub825 \ubb38\uc7a5 \uc778\ucf54\ub529\ninput_encoding = tokenizer(\"\uc874\ub313\ub9d0\ub85c \ubc14\uafd4\uc8fc\uc138\uc694: \" + input_text, return_tensors=\"pt\")\n\ninput_ids = input_encoding.input_ids.to(device)\nattention_mask = input_encoding.attention_mask.to(device)\n\n# T5 \ubaa8\ub378 \ucd9c\ub825 \uc0dd\uc131\noutput_encoding = model.generate(\n    input_ids=input_ids,\n    attention_mask=attention_mask,\n    max_length=128,\n    num_beams=5,\n    early_stopping=True,\n)\n\n# \ucd9c\ub825 \ubb38\uc7a5 \ub514\ucf54\ub529\noutput_text = tokenizer.decode(output_encoding[0], skip_special_tokens=True)\n\n# \uacb0\uacfc \ucd9c\ub825\nprint(output_text) # \uc800 \uc9c4\uc9dc \ud654\ub0ac\uc2b5\ub2c8\ub2e4 \uc9c0\uae08.\n```\n\n***\n\n## With Transformer Pipeline\n```python\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n\nmodel = T5ForConditionalGeneration.from_pretrained('j5ng/et5-formal-convertor')\ntokenizer = T5Tokenizer.from_pretrained('j5ng/et5-formal-convertor')\n\ntypos_corrector = pipeline(\n    \"text2text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    device=0 if torch.cuda.is_available() else -1,\n    framework=\"pt\",\n)\n\ninput_text = \"\ub110 \uac00\uc9c8 \uc218 \uc788\uc744\uac70\ub77c \uc0dd\uac01\ud588\uc5b4\"\noutput_text = typos_corrector(\"\uc874\ub313\ub9d0\ub85c \ubc14\uafd4\uc8fc\uc138\uc694: \" + input_text,\n            max_length=128,\n            num_beams=5,\n            early_stopping=True)[0]['generated_text']\n\nprint(output_text) # \ub2f9\uc2e0\uc744 \uac00\uc9c8 \uc218 \uc788\uc744\uac70\ub77c \uc0dd\uac01\ud588\uc2b5\ub2c8\ub2e4.\n```\n\n## Thanks to\n\uc874\ub313\ub9d0 \ubcc0\ud658\uae30\uc758 \ud559\uc2b5\uc740 \uc778\uacf5\uc9c0\ub2a5\uc0b0\uc5c5\uc735\ud569\uc0ac\uc5c5\ub2e8(AICA)\uc758 GPU \ub9ac\uc18c\uc2a4\ub97c \uc9c0\uc6d0\ubc1b\uc544 \ud559\uc2b5\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n\n\n", "size_bytes": "1296601269", "downloads": 63}