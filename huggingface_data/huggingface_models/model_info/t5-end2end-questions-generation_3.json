{"pretrained_model_name": "Gayathri142214002/t5-end2end-questions-generation_3", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\nmodel-index:\n- name: t5-end2end-questions-generation_3\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# t5-end2end-questions-generation_3\n\nThis model is a fine-tuned version of [Gayathri142214002/t5-end2end-questions-generation_2](https://huggingface.co/Gayathri142214002/t5-end2end-questions-generation_2) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.3733\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 0.0001\n- train_batch_size: 1\n- eval_batch_size: 1\n- seed: 42\n- gradient_accumulation_steps: 4\n- total_train_batch_size: 4\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 7\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss |\n|:-------------:|:-----:|:----:|:---------------:|\n| 0.6874        | 0.05  | 10   | 0.5152          |\n| 0.5855        | 0.11  | 20   | 0.4873          |\n| 0.5778        | 0.16  | 30   | 0.4874          |\n| 0.5322        | 0.21  | 40   | 0.4939          |\n| 0.5852        | 0.27  | 50   | 0.4955          |\n| 0.5046        | 0.32  | 60   | 0.5046          |\n| 0.3833        | 0.37  | 70   | 0.5042          |\n| 0.459         | 0.42  | 80   | 0.5073          |\n| 0.4129        | 0.48  | 90   | 0.5082          |\n| 0.5371        | 0.53  | 100  | 0.5053          |\n| 0.4841        | 0.58  | 110  | 0.5015          |\n| 0.4994        | 0.64  | 120  | 0.4695          |\n| 0.4129        | 0.69  | 130  | 0.4582          |\n| 0.4524        | 0.74  | 140  | 0.4540          |\n| 0.4908        | 0.8   | 150  | 0.4424          |\n| 0.5084        | 0.85  | 160  | 0.4244          |\n| 0.4423        | 0.9   | 170  | 0.4048          |\n| 0.4426        | 0.96  | 180  | 0.3875          |\n| 0.3701        | 1.01  | 190  | 0.4059          |\n| 0.4315        | 1.06  | 200  | 0.3965          |\n| 0.3846        | 1.12  | 210  | 0.4089          |\n| 0.3511        | 1.17  | 220  | 0.4195          |\n| 0.3644        | 1.22  | 230  | 0.4303          |\n| 0.3706        | 1.27  | 240  | 0.4264          |\n| 0.3325        | 1.33  | 250  | 0.4291          |\n| 0.4266        | 1.38  | 260  | 0.4280          |\n| 0.3983        | 1.43  | 270  | 0.4209          |\n| 0.4121        | 1.49  | 280  | 0.4144          |\n| 0.386         | 1.54  | 290  | 0.4140          |\n| 0.4533        | 1.59  | 300  | 0.4128          |\n| 0.3978        | 1.65  | 310  | 0.4182          |\n| 0.38          | 1.7   | 320  | 0.4248          |\n| 0.3818        | 1.75  | 330  | 0.4194          |\n| 0.3957        | 1.81  | 340  | 0.3931          |\n| 0.3409        | 1.86  | 350  | 0.3859          |\n| 0.3619        | 1.91  | 360  | 0.3973          |\n| 0.388         | 1.97  | 370  | 0.4041          |\n| 0.377         | 2.02  | 380  | 0.4017          |\n| 0.3645        | 2.07  | 390  | 0.3985          |\n| 0.3268        | 2.12  | 400  | 0.3987          |\n| 0.3389        | 2.18  | 410  | 0.3990          |\n| 0.3405        | 2.23  | 420  | 0.3985          |\n| 0.3677        | 2.28  | 430  | 0.3972          |\n| 0.333         | 2.34  | 440  | 0.4131          |\n| 0.3641        | 2.39  | 450  | 0.4188          |\n| 0.3568        | 2.44  | 460  | 0.4132          |\n| 0.3443        | 2.5   | 470  | 0.4266          |\n| 0.337         | 2.55  | 480  | 0.4321          |\n| 0.3562        | 2.6   | 490  | 0.4271          |\n| 0.3411        | 2.66  | 500  | 0.4131          |\n| 0.3386        | 2.71  | 510  | 0.4078          |\n| 0.3307        | 2.76  | 520  | 0.3912          |\n| 0.3293        | 2.82  | 530  | 0.3931          |\n| 0.3647        | 2.87  | 540  | 0.3893          |\n| 0.3555        | 2.92  | 550  | 0.3781          |\n| 0.3588        | 2.97  | 560  | 0.3730          |\n| 0.3088        | 3.03  | 570  | 0.3639          |\n| 0.2886        | 3.08  | 580  | 0.3604          |\n| 0.2834        | 3.13  | 590  | 0.3723          |\n| 0.3154        | 3.19  | 600  | 0.3817          |\n| 0.319         | 3.24  | 610  | 0.3847          |\n| 0.298         | 3.29  | 620  | 0.3844          |\n| 0.3443        | 3.35  | 630  | 0.3821          |\n| 0.3418        | 3.4   | 640  | 0.3800          |\n| 0.3606        | 3.45  | 650  | 0.3774          |\n| 0.3668        | 3.51  | 660  | 0.3667          |\n| 0.3331        | 3.56  | 670  | 0.3593          |\n| 0.3045        | 3.61  | 680  | 0.3561          |\n| 0.3307        | 3.67  | 690  | 0.3524          |\n| 0.3409        | 3.72  | 700  | 0.3528          |\n| 0.3783        | 3.77  | 710  | 0.3558          |\n| 0.3288        | 3.82  | 720  | 0.3622          |\n| 0.3248        | 3.88  | 730  | 0.3728          |\n| 0.3115        | 3.93  | 740  | 0.3714          |\n| 0.3374        | 3.98  | 750  | 0.3712          |\n| 0.2982        | 4.04  | 760  | 0.3734          |\n| 0.2636        | 4.09  | 770  | 0.3749          |\n| 0.3035        | 4.14  | 780  | 0.3787          |\n| 0.3041        | 4.2   | 790  | 0.3782          |\n| 0.3112        | 4.25  | 800  | 0.3791          |\n| 0.332         | 4.3   | 810  | 0.3789          |\n| 0.2698        | 4.36  | 820  | 0.3822          |\n| 0.277         | 4.41  | 830  | 0.3808          |\n| 0.3357        | 4.46  | 840  | 0.3800          |\n| 0.3224        | 4.52  | 850  | 0.3770          |\n| 0.3358        | 4.57  | 860  | 0.3731          |\n| 0.2973        | 4.62  | 870  | 0.3743          |\n| 0.2815        | 4.67  | 880  | 0.3776          |\n| 0.3233        | 4.73  | 890  | 0.3768          |\n| 0.3034        | 4.78  | 900  | 0.3728          |\n| 0.2978        | 4.83  | 910  | 0.3718          |\n| 0.2692        | 4.89  | 920  | 0.3700          |\n| 0.3294        | 4.94  | 930  | 0.3710          |\n| 0.3022        | 4.99  | 940  | 0.3733          |\n| 0.3036        | 5.05  | 950  | 0.3706          |\n| 0.3134        | 5.1   | 960  | 0.3673          |\n| 0.2808        | 5.15  | 970  | 0.3643          |\n| 0.2728        | 5.21  | 980  | 0.3661          |\n| 0.3201        | 5.26  | 990  | 0.3697          |\n| 0.2873        | 5.31  | 1000 | 0.3710          |\n| 0.2709        | 5.37  | 1010 | 0.3716          |\n| 0.2758        | 5.42  | 1020 | 0.3728          |\n| 0.2695        | 5.47  | 1030 | 0.3759          |\n| 0.2734        | 5.52  | 1040 | 0.3758          |\n| 0.2993        | 5.58  | 1050 | 0.3747          |\n| 0.2697        | 5.63  | 1060 | 0.3756          |\n| 0.3017        | 5.68  | 1070 | 0.3772          |\n| 0.299         | 5.74  | 1080 | 0.3782          |\n| 0.2834        | 5.79  | 1090 | 0.3795          |\n| 0.3069        | 5.84  | 1100 | 0.3782          |\n| 0.3309        | 5.9   | 1110 | 0.3764          |\n| 0.3041        | 5.95  | 1120 | 0.3750          |\n| 0.3047        | 6.0   | 1130 | 0.3743          |\n| 0.2717        | 6.06  | 1140 | 0.3738          |\n| 0.2108        | 6.11  | 1150 | 0.3749          |\n| 0.2637        | 6.16  | 1160 | 0.3764          |\n| 0.2972        | 6.22  | 1170 | 0.3748          |\n| 0.2818        | 6.27  | 1180 | 0.3735          |\n| 0.2934        | 6.32  | 1190 | 0.3729          |\n| 0.3049        | 6.37  | 1200 | 0.3726          |\n| 0.2389        | 6.43  | 1210 | 0.3727          |\n| 0.2831        | 6.48  | 1220 | 0.3742          |\n| 0.3017        | 6.53  | 1230 | 0.3751          |\n| 0.2869        | 6.59  | 1240 | 0.3755          |\n| 0.2719        | 6.64  | 1250 | 0.3749          |\n| 0.2754        | 6.69  | 1260 | 0.3744          |\n| 0.3138        | 6.75  | 1270 | 0.3738          |\n| 0.2772        | 6.8   | 1280 | 0.3734          |\n| 0.2952        | 6.85  | 1290 | 0.3733          |\n| 0.2746        | 6.91  | 1300 | 0.3733          |\n| 0.2918        | 6.96  | 1310 | 0.3733          |\n\n\n### Framework versions\n\n- Transformers 4.29.2\n- Pytorch 2.0.1+cu117\n- Datasets 2.12.0\n- Tokenizers 0.13.3\n", "size_bytes": "891702929", "downloads": 2}