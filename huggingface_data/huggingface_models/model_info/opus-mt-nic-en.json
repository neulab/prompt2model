{"pretrained_model_name": "Helsinki-NLP/opus-mt-nic-en", "description": "---\nlanguage: \n- sn\n- rw\n- wo\n- ig\n- sg\n- ee\n- zu\n- lg\n- ts\n- ln\n- ny\n- yo\n- rn\n- xh\n- nic\n- en\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### nic-eng\n\n* source group: Niger-Kordofanian languages \n* target group: English \n*  OPUS readme: [nic-eng](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/nic-eng/README.md)\n\n*  model: transformer\n* source language(s): bam_Latn ewe fuc fuv ibo kin lin lug nya run sag sna swh toi_Latn tso umb wol xho yor zul\n* target language(s): eng\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus2m-2020-08-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/nic-eng/opus2m-2020-08-01.zip)\n* test set translations: [opus2m-2020-08-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/nic-eng/opus2m-2020-08-01.test.txt)\n* test set scores: [opus2m-2020-08-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/nic-eng/opus2m-2020-08-01.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| Tatoeba-test.bam-eng.bam.eng \t| 2.4 \t| 0.090 |\n| Tatoeba-test.ewe-eng.ewe.eng \t| 10.3 \t| 0.384 |\n| Tatoeba-test.ful-eng.ful.eng \t| 1.2 \t| 0.114 |\n| Tatoeba-test.ibo-eng.ibo.eng \t| 7.5 \t| 0.197 |\n| Tatoeba-test.kin-eng.kin.eng \t| 30.7 \t| 0.481 |\n| Tatoeba-test.lin-eng.lin.eng \t| 3.1 \t| 0.185 |\n| Tatoeba-test.lug-eng.lug.eng \t| 3.1 \t| 0.261 |\n| Tatoeba-test.multi.eng \t| 21.3 \t| 0.377 |\n| Tatoeba-test.nya-eng.nya.eng \t| 31.6 \t| 0.502 |\n| Tatoeba-test.run-eng.run.eng \t| 24.9 \t| 0.420 |\n| Tatoeba-test.sag-eng.sag.eng \t| 5.2 \t| 0.231 |\n| Tatoeba-test.sna-eng.sna.eng \t| 20.1 \t| 0.374 |\n| Tatoeba-test.swa-eng.swa.eng \t| 4.6 \t| 0.191 |\n| Tatoeba-test.toi-eng.toi.eng \t| 4.8 \t| 0.122 |\n| Tatoeba-test.tso-eng.tso.eng \t| 100.0 \t| 1.000 |\n| Tatoeba-test.umb-eng.umb.eng \t| 9.0 \t| 0.246 |\n| Tatoeba-test.wol-eng.wol.eng \t| 14.0 \t| 0.212 |\n| Tatoeba-test.xho-eng.xho.eng \t| 38.2 \t| 0.558 |\n| Tatoeba-test.yor-eng.yor.eng \t| 21.2 \t| 0.364 |\n| Tatoeba-test.zul-eng.zul.eng \t| 42.3 \t| 0.589 |\n\n\n### System Info: \n- hf_name: nic-eng\n\n- source_languages: nic\n\n- target_languages: eng\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/nic-eng/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['sn', 'rw', 'wo', 'ig', 'sg', 'ee', 'zu', 'lg', 'ts', 'ln', 'ny', 'yo', 'rn', 'xh', 'nic', 'en']\n\n- src_constituents: {'bam_Latn', 'sna', 'kin', 'wol', 'ibo', 'swh', 'sag', 'ewe', 'zul', 'fuc', 'lug', 'tso', 'lin', 'nya', 'yor', 'run', 'xho', 'fuv', 'toi_Latn', 'umb'}\n\n- tgt_constituents: {'eng'}\n\n- src_multilingual: True\n\n- tgt_multilingual: False\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/nic-eng/opus2m-2020-08-01.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/nic-eng/opus2m-2020-08-01.test.txt\n\n- src_alpha3: nic\n\n- tgt_alpha3: eng\n\n- short_pair: nic-en\n\n- chrF2_score: 0.377\n\n- bleu: 21.3\n\n- brevity_penalty: 1.0\n\n- ref_len: 15228.0\n\n- src_name: Niger-Kordofanian languages\n\n- tgt_name: English\n\n- train_date: 2020-08-01\n\n- src_alpha2: nic\n\n- tgt_alpha2: en\n\n- prefer_old: False\n\n- long_pair: nic-eng\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "305089689", "downloads": 11}