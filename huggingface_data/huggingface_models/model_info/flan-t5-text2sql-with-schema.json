{"pretrained_model_name": "juierror/flan-t5-text2sql-with-schema", "description": "---\nlanguage: en\ndatasets:\n- wikisql\nwidget:\n- text: 'question: get people name with age equal 25 table: id, name, age'\nlicense: apache-2.0\n---\nThere are an upgraded version that support multiple tables and support \"<\" sign [here](https://huggingface.co/juierror/flan-t5-text2sql-with-schema-v2).\n\n# How to use\n```python\nfrom typing import List\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"juierror/flan-t5-text2sql-with-schema\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"juierror/flan-t5-text2sql-with-schema\")\n\ndef prepare_input(question: str, table: List[str]):\n    table_prefix = \"table:\"\n    question_prefix = \"question:\"\n    join_table = \",\".join(table)\n    inputs = f\"{question_prefix} {question} {table_prefix} {join_table}\"\n    input_ids = tokenizer(inputs, max_length=512, return_tensors=\"pt\").input_ids\n    return input_ids\n\ndef inference(question: str, table: List[str]) -> str:\n    input_data = prepare_input(question=question, table=table)\n    input_data = input_data.to(model.device)\n    outputs = model.generate(inputs=input_data, num_beams=10, top_k=10, max_length=700)\n    result = tokenizer.decode(token_ids=outputs[0], skip_special_tokens=True)\n    return result\n\nprint(inference(question=\"get people name with age equal 25\", table=[\"id\", \"name\", \"age\"]))\n```", "size_bytes": "990408885", "downloads": 2855}