{"pretrained_model_name": "vocabtrimmer/mbart-large-cc25-trimmed-en", "description": "# Vocabulary Trimmed [facebook/mbart-large-cc25](https://huggingface.co/facebook/mbart-large-cc25): `vocabtrimmer/mbart-large-cc25-trimmed-en` \nThis model is a trimmed version of [facebook/mbart-large-cc25](https://huggingface.co/facebook/mbart-large-cc25) by [`vocabtrimmer`](https://github.com/asahi417/lm-vocab-trimmer), a tool for trimming vocabulary of language models to compress the model size.\nFollowing table shows a summary of the trimming process.\n\n|                            | facebook/mbart-large-cc25   | vocabtrimmer/mbart-large-cc25-trimmed-en   |\n|:---------------------------|:----------------------------|:-------------------------------------------|\n| parameter_size_full        | 610,851,840                 | 532,244,480                                |\n| parameter_size_embedding   | 512,055,296                 | 354,840,576                                |\n| vocab_size                 | 250,027                     | 173,262                                    |\n| compression_rate_full      | 100.0                       | 87.13                                      |\n| compression_rate_embedding | 100.0                       | 69.3                                       |\n\n\nFollowing table shows the parameter used to trim vocabulary.\n\n | language   | dataset                     | dataset_column   | dataset_name   | dataset_split   | target_vocab_size   |   min_frequency |\n|:-----------|:----------------------------|:-----------------|:---------------|:----------------|:--------------------|----------------:|\n| en         | vocabtrimmer/mc4_validation | text             | en             | validation      |                     |               2 |", "size_bytes": "2129839517", "downloads": 2}