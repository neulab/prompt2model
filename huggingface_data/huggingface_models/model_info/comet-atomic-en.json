{"pretrained_model_name": "svjack/comet-atomic-en", "description": "---\nlanguage:\n- en\npipeline_tag: text2text-generation\n---\n\n```python\nfrom transformers import T5ForConditionalGeneration\nfrom transformers import T5TokenizerFast as T5Tokenizer\nimport pandas as pd\nmodel = \"svjack/comet-atomic-en\"\ndevice = \"cpu\"\n#device = \"cuda:0\"\ntokenizer = T5Tokenizer.from_pretrained(model)\nmodel = T5ForConditionalGeneration.from_pretrained(model).to(device).eval()\n\nNEED_PREFIX = 'What are the necessary preconditions for the next event?'\nEFFECT_PREFIX = 'What could happen after the next event?'\nINTENT_PREFIX = 'What is the motivation for the next event?'\nREACT_PREFIX = 'What are your feelings after the following event?'\n\n\nevent = \"X had a big meal.\"\nfor prefix in [NEED_PREFIX, EFFECT_PREFIX, INTENT_PREFIX, REACT_PREFIX]:\n    prompt = \"{}{}\".format(prefix, event)\n    encode = tokenizer(prompt, return_tensors='pt').to(device)\n    answer = model.generate(encode.input_ids,\n                           max_length = 128,\n        num_beams=2,\n        top_p = 0.95,\n        top_k = 50,\n        repetition_penalty = 2.5,\n        length_penalty=1.0,\n        early_stopping=True,\n                           )[0]\n    decoded = tokenizer.decode(answer, skip_special_tokens=True)\n    print(prompt, \"\\n---Answer\uff1a\", decoded, \"----\\n\")\n```\n\n</br>\n\n```json\nWhat are the necessary preconditions for the next event?X had a big meal. \n---Answer\uff1a X goes shopping at the supermarket ----\n\nWhat could happen after the next event?X had a big meal. \n---Answer\uff1a X gets fat ----\n\nWhat is the motivation for the next event?X had a big meal. \n---Answer\uff1a X wants to eat ----\n\nWhat are your feelings after the following event?X had a big meal. \n---Answer\uff1a X tastes good ----\n```", "size_bytes": "990438349", "downloads": 59}