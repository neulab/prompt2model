{"pretrained_model_name": "lmqg/mt5-small-frquad-qg-ae", "description": "\n---\nlicense: cc-by-4.0\nmetrics:\n- bleu4\n- meteor\n- rouge-l\n- bertscore\n- moverscore\nlanguage: fr\ndatasets:\n- lmqg/qg_frquad\npipeline_tag: text2text-generation\ntags:\n- question generation\n- answer extraction\nwidget:\n- text: \"generate question: Cr\u00e9ateur \u00bb (Maker), lui aussi au singulier, \u00ab <hl> le Supr\u00eame Berger <hl> \u00bb (The Great Shepherd) ; de l'autre, des r\u00e9miniscences de la th\u00e9ologie de l'Antiquit\u00e9 : le tonnerre, voix de Jupiter, \u00ab Et souvent ta voix gronde en un tonnerre terrifiant \u00bb, etc.\"\n  example_title: \"Question Generation Example 1\" \n- text: \"generate question: Ce black dog peut \u00eatre li\u00e9 \u00e0 des \u00e9v\u00e8nements traumatisants issus du monde ext\u00e9rieur, tels que son renvoi de l'Amiraut\u00e9 apr\u00e8s la catastrophe des Dardanelles, lors de la <hl> Grande Guerre <hl> de 14-18, ou son rejet par l'\u00e9lectorat en juillet 1945.\"\n  example_title: \"Question Generation Example 2\" \n- text: \"generate question: contre <hl> Normie Smith <hl> et 15 000 dollars le 28 novembre 1938.\"\n  example_title: \"Question Generation Example 3\" \n- text: \"extract answers: Pourtant, la strophe spens\u00e9rienne, utilis\u00e9e cinq fois avant que ne commence le ch\u0153ur, constitue en soi un vecteur dont les r\u00e9p\u00e9titions structurelles, selon Ricks, rel\u00e8vent du pur lyrisme tout en constituant une menace potentielle. Apr\u00e8s les huit sages pentam\u00e8tres iambiques, l'alexandrin final <hl> permet une pause <hl>, \u00ab v\u00e9ritable illusion d'optique \u00bb qu'accentuent les nombreuses expressions archa\u00efsantes telles que did swoon, did seem, did go, did receive, did make, qui doublent le pr\u00e9t\u00e9rit en un temps compos\u00e9 et paraissent \u00e0 la fois \u00ab tr\u00e8s pr\u00e9cautionneuses et tr\u00e8s peu press\u00e9es \u00bb.\"\n  example_title: \"Answer Extraction Example 1\" \n- text: \"extract answers: N\u00e9anmoins, une fois encore, l'arithm\u00e9tique modulaire est insuffisante pour venir \u00e0 bout du th\u00e9or\u00e8me. Dirichlet utilise de nombreuses techniques analytiques, comme les s\u00e9ries enti\u00e8res et l'analyse complexe. Le fruit de ces travaux donne naissance \u00e0 une nouvelle branche des math\u00e9matiques : la th\u00e9orie analytique des nombres. L'un des points cruciaux de cette th\u00e9orie provient de l'unique article de <hl> Bernhard Riemann <hl> en th\u00e9orie des nombres : Sur le nombre de nombres premiers inf\u00e9rieurs \u00e0 une taille donn\u00e9e. Il conjecture une localisation des racines de sa fonction \u03b6. La recherche de la position des racines, initi\u00e9e par Dirichlet, devient une pr\u00e9occupation centrale et reste l'une des conjectures pressenties comme les plus difficiles des math\u00e9matiques de notre \u00e9poque.\"\n  example_title: \"Answer Extraction Example 2\" \nmodel-index:\n- name: lmqg/mt5-small-frquad-qg-ae\n  results:\n  - task:\n      name: Text2text Generation\n      type: text2text-generation\n    dataset:\n      name: lmqg/qg_frquad\n      type: default\n      args: default\n    metrics:\n    - name: BLEU4 (Question Generation)\n      type: bleu4_question_generation\n      value: 7.75\n    - name: ROUGE-L (Question Generation)\n      type: rouge_l_question_generation\n      value: 28.06\n    - name: METEOR (Question Generation)\n      type: meteor_question_generation\n      value: 17.62\n    - name: BERTScore (Question Generation)\n      type: bertscore_question_generation\n      value: 79.9\n    - name: MoverScore (Question Generation)\n      type: moverscore_question_generation\n      value: 56.44\n    - name: QAAlignedF1Score-BERTScore (Question & Answer Generation (with Gold Answer))\n      type: qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer\n      value: 79.7\n    - name: QAAlignedRecall-BERTScore (Question & Answer Generation (with Gold Answer))\n      type: qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer\n      value: 82.36\n    - name: QAAlignedPrecision-BERTScore (Question & Answer Generation (with Gold Answer))\n      type: qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer\n      value: 77.29\n    - name: QAAlignedF1Score-MoverScore (Question & Answer Generation (with Gold Answer))\n      type: qa_aligned_f1_score_moverscore_question_answer_generation_with_gold_answer\n      value: 54.22\n    - name: QAAlignedRecall-MoverScore (Question & Answer Generation (with Gold Answer))\n      type: qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer\n      value: 55.76\n    - name: QAAlignedPrecision-MoverScore (Question & Answer Generation (with Gold Answer))\n      type: qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer\n      value: 52.84\n    - name: BLEU4 (Answer Extraction)\n      type: bleu4_answer_extraction\n      value: 28.71\n    - name: ROUGE-L (Answer Extraction)\n      type: rouge_l_answer_extraction\n      value: 43.93\n    - name: METEOR (Answer Extraction)\n      type: meteor_answer_extraction\n      value: 37.9\n    - name: BERTScore (Answer Extraction)\n      type: bertscore_answer_extraction\n      value: 87.84\n    - name: MoverScore (Answer Extraction)\n      type: moverscore_answer_extraction\n      value: 76.45\n    - name: AnswerF1Score (Answer Extraction)\n      type: answer_f1_score__answer_extraction\n      value: 67.44\n    - name: AnswerExactMatch (Answer Extraction)\n      type: answer_exact_match_answer_extraction\n      value: 46.96\n---\n\n# Model Card of `lmqg/mt5-small-frquad-qg-ae`\nThis model is fine-tuned version of [google/mt5-small](https://huggingface.co/google/mt5-small) for question generation and answer extraction jointly on the [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) (dataset_name: default) via [`lmqg`](https://github.com/asahi417/lm-question-generation).\n\n\n### Overview\n- **Language model:** [google/mt5-small](https://huggingface.co/google/mt5-small)   \n- **Language:** fr  \n- **Training data:** [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) (default)\n- **Online Demo:** [https://autoqg.net/](https://autoqg.net/)\n- **Repository:** [https://github.com/asahi417/lm-question-generation](https://github.com/asahi417/lm-question-generation)\n- **Paper:** [https://arxiv.org/abs/2210.03992](https://arxiv.org/abs/2210.03992)\n\n### Usage\n- With [`lmqg`](https://github.com/asahi417/lm-question-generation#lmqg-language-model-for-question-generation-)\n```python\nfrom lmqg import TransformersQG\n\n# initialize model\nmodel = TransformersQG(language=\"fr\", model=\"lmqg/mt5-small-frquad-qg-ae\")\n\n# model prediction\nquestion_answer_pairs = model.generate_qa(\"Cr\u00e9ateur \u00bb (Maker), lui aussi au singulier, \u00ab le Supr\u00eame Berger \u00bb (The Great Shepherd) ; de l'autre, des r\u00e9miniscences de la th\u00e9ologie de l'Antiquit\u00e9 : le tonnerre, voix de Jupiter, \u00ab Et souvent ta voix gronde en un tonnerre terrifiant \u00bb, etc.\")\n\n```\n\n- With `transformers`\n```python\nfrom transformers import pipeline\n\npipe = pipeline(\"text2text-generation\", \"lmqg/mt5-small-frquad-qg-ae\")\n\n# answer extraction\nanswer = pipe(\"generate question: Cr\u00e9ateur \u00bb (Maker), lui aussi au singulier, \u00ab <hl> le Supr\u00eame Berger <hl> \u00bb (The Great Shepherd) ; de l'autre, des r\u00e9miniscences de la th\u00e9ologie de l'Antiquit\u00e9 : le tonnerre, voix de Jupiter, \u00ab Et souvent ta voix gronde en un tonnerre terrifiant \u00bb, etc.\")\n\n# question generation\nquestion = pipe(\"extract answers: Pourtant, la strophe spens\u00e9rienne, utilis\u00e9e cinq fois avant que ne commence le ch\u0153ur, constitue en soi un vecteur dont les r\u00e9p\u00e9titions structurelles, selon Ricks, rel\u00e8vent du pur lyrisme tout en constituant une menace potentielle. Apr\u00e8s les huit sages pentam\u00e8tres iambiques, l'alexandrin final <hl> permet une pause <hl>, \u00ab v\u00e9ritable illusion d'optique \u00bb qu'accentuent les nombreuses expressions archa\u00efsantes telles que did swoon, did seem, did go, did receive, did make, qui doublent le pr\u00e9t\u00e9rit en un temps compos\u00e9 et paraissent \u00e0 la fois \u00ab tr\u00e8s pr\u00e9cautionneuses et tr\u00e8s peu press\u00e9es \u00bb.\")\n\n```\n\n## Evaluation\n\n\n- ***Metric (Question Generation)***: [raw metric file](https://huggingface.co/lmqg/mt5-small-frquad-qg-ae/raw/main/eval/metric.first.sentence.paragraph_answer.question.lmqg_qg_frquad.default.json) \n\n|            |   Score | Type    | Dataset                                                          |\n|:-----------|--------:|:--------|:-----------------------------------------------------------------|\n| BERTScore  |   79.9  | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_1     |   27.6  | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_2     |   16.31 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_3     |   11    | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_4     |    7.75 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| METEOR     |   17.62 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| MoverScore |   56.44 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| ROUGE_L    |   28.06 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n\n\n- ***Metric (Question & Answer Generation)***:  [raw metric file](https://huggingface.co/lmqg/mt5-small-frquad-qg-ae/raw/main/eval/metric.first.answer.paragraph.questions_answers.lmqg_qg_frquad.default.json)\n\n|                                 |   Score | Type    | Dataset                                                          |\n|:--------------------------------|--------:|:--------|:-----------------------------------------------------------------|\n| QAAlignedF1Score (BERTScore)    |   79.7  | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| QAAlignedF1Score (MoverScore)   |   54.22 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| QAAlignedPrecision (BERTScore)  |   77.29 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| QAAlignedPrecision (MoverScore) |   52.84 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| QAAlignedRecall (BERTScore)     |   82.36 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| QAAlignedRecall (MoverScore)    |   55.76 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n\n\n- ***Metric (Answer Extraction)***: [raw metric file](https://huggingface.co/lmqg/mt5-small-frquad-qg-ae/raw/main/eval/metric.first.answer.paragraph_sentence.answer.lmqg_qg_frquad.default.json)\n\n|                  |   Score | Type    | Dataset                                                          |\n|:-----------------|--------:|:--------|:-----------------------------------------------------------------|\n| AnswerExactMatch |   46.96 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| AnswerF1Score    |   67.44 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| BERTScore        |   87.84 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_1           |   40.67 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_2           |   35.92 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_3           |   32.1  | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| Bleu_4           |   28.71 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| METEOR           |   37.9  | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| MoverScore       |   76.45 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n| ROUGE_L          |   43.93 | default | [lmqg/qg_frquad](https://huggingface.co/datasets/lmqg/qg_frquad) |\n\n\n\n## Training hyperparameters\n\nThe following hyperparameters were used during fine-tuning:\n - dataset_path: lmqg/qg_frquad\n - dataset_name: default\n - input_types: ['paragraph_answer', 'paragraph_sentence']\n - output_types: ['question', 'answer']\n - prefix_types: ['qg', 'ae']\n - model: google/mt5-small\n - max_length: 512\n - max_length_output: 32\n - epoch: 18\n - batch: 64\n - lr: 0.0005\n - fp16: False\n - random_seed: 1\n - gradient_accumulation_steps: 1\n - label_smoothing: 0.15\n\nThe full configuration can be found at [fine-tuning config file](https://huggingface.co/lmqg/mt5-small-frquad-qg-ae/raw/main/trainer_config.json).\n\n## Citation\n```\n@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}\n\n```\n", "size_bytes": "1200723013", "downloads": 294}