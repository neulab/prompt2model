{"pretrained_model_name": "bond005/ruT5-ASR", "description": "---\nlanguage: ru\ntags:\n  - audio\n  - automatic-speech-recognition\n  - speech\n  - PyTorch\n  - Transformers\nlicense: apache-2.0\nwidget:\n- text: \u0443\u043b\u0430\u0441\u043d\u044b \u0432 \u043c\u043e\u0441\u043a\u0432\u0435 \u0438\u043d\u0442\u0435\u0440\u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u0433\u043e\u0434\u0443 \u0447\u0442\u043e \u043b\u0435\u043f\u0440\u043e\u0432\u0435\u043b\u0438\n---\n\n# ruT5-ASR\n\nModel was trained by [bond005](https://research.nsu.ru/en/persons/ibondarenko) to correct errors in the ASR output (in particular, output of [Wav2Vec2-Large-Ru-Golos](https://huggingface.co/bond005/wav2vec2-large-ru-golos)). The model is based on [ruT5-base](https://huggingface.co/ai-forever/ruT5-base).\n\n## Usage\n\nTo correct ASR outputs the model can be used as a standalone sequence-to-sequence model as follows:\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\n\n\ndef rescore(text: str, tokenizer: T5Tokenizer,\n            model: T5ForConditionalGeneration) -> str:\n    if len(text) == 0:  # if an input text is empty, then we return an empty text too\n        return ''\n    ru_letters = set('\u0430\u043e\u0443\u044b\u044d\u044f\u0435\u0451\u044e\u0438\u0431\u0432\u0433\u0434\u0439\u0436\u0437\u043a\u043b\u043c\u043d\u043f\u0440\u0441\u0442\u0444\u0445\u0446\u0447\u0448\u0449\u044c\u044a')\n    punct = set('.,:/\\\\?!()[]{};\"\\'-')\n    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n    max_size = int(x.input_ids.shape[1] * 1.5 + 10)\n    min_size = 3\n    if x.input_ids.shape[1] <= min_size:\n        return text  # we don't rescore a very short text\n    out = model.generate(**x, do_sample=False, num_beams=5,\n                         max_length=max_size, min_length=min_size)\n    res = tokenizer.decode(out[0], skip_special_tokens=True).lower().strip()\n    res = ' '.join(res.split())\n    postprocessed = ''\n    for cur in res:\n        if cur.isspace() or (cur in punct):\n            postprocessed += ' '\n        elif cur in ru_letters:\n            postprocessed += cur\n    return (' '.join(postprocessed.strip().split())).replace('\u0451', '\u0435')\n\n\n# load model and tokenizer\ntokenizer_for_rescoring = T5Tokenizer.from_pretrained('bond005/ruT5-ASR')\nmodel_for_rescoring = T5ForConditionalGeneration.from_pretrained('bond005/ruT5-ASR')\nif torch.cuda.is_available():\n    model_for_rescoring = model_for_rescoring.cuda()\n\ninput_examples = [\n    '\u0443\u043b\u0430\u0441\u043d\u044b \u0432 \u043c\u043e\u0441\u043a\u0432\u0435 \u0438\u043d\u0442\u0435\u0440\u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u0433\u043e\u0434\u0443 \u0447\u0442\u043e \u043b\u0435\u043f\u0440\u043e\u0432\u0435\u043b\u0438',\n    '\u043c\u043e\u0440\u043e\u0437 \u0438 \u0441\u043e\u043b\u043d\u0446\u0435 \u0434\u0435\u043d\u044c \u0447\u0443\u0434\u0435\u0441\u043d\u044b\u0439',\n    '\u043d\u0435\u0439\u0440\u043e \u0441\u0435\u0442\u0438 \u044d\u0442\u0430 \u0445\u0430\u0440\u043e\u0448\u043e',\n    '\u0434\u0430'\n]\n\nfor src in input_examples:\n    rescored = rescore(src, tokenizer_for_rescoring, model_for_rescoring)\n    print(f'{src} -> {rescored}')\n```\n\n```text\n\u0443\u043b\u0430\u0441\u043d\u044b \u0432 \u043c\u043e\u0441\u043a\u0432\u0435 \u0438\u043d\u0442\u0435\u0440\u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u0433\u043e\u0434\u0443 \u0447\u0442\u043e \u043b\u0435\u043f\u0440\u043e\u0432\u0435\u043b\u0438 -> \u0443 \u043d\u0430\u0441 \u0432 \u043c\u043e\u0441\u043a\u0432\u0435 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u043f\u0440\u043e\u0448\u043b\u043e\u043c \u0433\u043e\u0434\u0443 \u0447\u0442\u043e \u043b\u0438 \u043f\u0440\u043e\u0432\u0435\u043b\u0438\n\u043c\u043e\u0440\u043e\u0437 \u0438 \u0441\u043e\u043b\u043d\u0446\u0435 \u0434\u0435\u043d\u044c \u0447\u0443\u0434\u0435\u0441\u043d\u044b\u0439 -> \u043c\u043e\u0440\u043e\u0437 \u0438 \u0441\u043e\u043b\u043d\u0446\u0435 \u0434\u0435\u043d\u044c \u0447\u0443\u0434\u0435\u0441\u043d\u044b\u0439\n\u043d\u0435\u0439\u0440\u043e \u0441\u0435\u0442\u0438 \u044d\u0442\u0430 \u0445\u0430\u0440\u043e\u0448\u043e -> \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 \u044d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e\n\u0434\u0430 -> \u0434\u0430\n```\n\n## Evaluation\nThis model was evaluated on the test subsets of [SberDevices Golos](https://huggingface.co/datasets/SberDevices/Golos), [Common Voice 6.0](https://huggingface.co/datasets/common_voice) (Russian part), and [Russian Librispeech](https://huggingface.co/datasets/bond005/rulibrispeech), but it was trained on the training subset of SberDevices Golos only. You can see the evaluation script on other datasets, including Russian Librispeech and SOVA RuDevices, on my Kaggle web-page https://www.kaggle.com/code/bond005/wav2vec2-t5-ru-eval\n\n*Comparison with \"pure\" Wav2Vec2-Large-Ru-Golos (WER, %)*:\n\n|        dataset name | pure ASR | ASR with rescoring |\n|---------------------|----------|--------------------|\n|         Voxforge Ru |    **27.08** |              40.48 |\n| Russian LibriSpeech |    **21.87** |              23.77 |\n|      Sova RuDevices |    25.41 |              **20.13** |\n|         Golos Crowd |    10.14 |               **9.42** |\n|      Golos Farfield |    20.35 |              **17.99** |\n|      CommonVoice Ru |    18.55 |              **11.60** |\n", "size_bytes": "891730879", "downloads": 124}