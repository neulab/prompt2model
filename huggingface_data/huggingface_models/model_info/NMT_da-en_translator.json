{"pretrained_model_name": "MichaelHarborg/NMT_da-en_translator", "description": "---\nlicense: mit\n---\nTransformer model based on Vaswani et al., 2017 for Danish-English Neural Machine Translation. \n\nIt has ~74M parameters and is a fine-tuned version of Helsinki-Opus-NLP da-en.\n\n\nThe model achieves a BLEU score of 49.16 on a hold-out test set for the TED2020 dataset (in-domain dataset).\n\nThe model achieves a BLEU score of 44.16 on a hold-out test set for the for CCAligned and Wikimatrix (out-of-domain dataset).\n\n\nThis outperforms the baseline Opus model, which achieved BLEU scores of 46.74 and 42.31 on the in-domain and out-of-domain data respectively.\n\n\nNote: When running inference \"_\" characters can sometimes replace spaces.", "size_bytes": "297563333", "downloads": 2}