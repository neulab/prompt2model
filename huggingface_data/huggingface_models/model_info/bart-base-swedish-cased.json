{"pretrained_model_name": "KBLab/bart-base-swedish-cased", "description": "---\nlanguage: sv\n\nwidget:\n    - text: \"Jag har \u00e4tit en <mask>\"\n---\n\n## KB-BART\n\nA [BART](https://arxiv.org/abs/1910.13461) model trained on a Swedish corpus consisting of 15 billion tokens (about 80GB of text). The model was trained with [Fairseq](https://github.com/pytorch/fairseq), and converted to be compatible with Huggingface. \n\nTraining code can be found [here](https://github.com/kb-labb/kb_bart).\n\n## Usage\n\n```python\nfrom transformers import BartForConditionalGeneration, PreTrainedTokenizerFast, AutoTokenizer\n\nmodel = BartForConditionalGeneration.from_pretrained(\"KBLab/bart-base-swedish-cased\")\ntok = AutoTokenizer.from_pretrained(\"KBLab/bart-base-swedish-cased\")\n\nmodel.eval()\n\ninput_ids = tok.encode(\n    \"Jag har \u00e4tit en uts\u00f6kt <mask> p\u00e5 restaurang vid <mask> .\", return_tensors=\"pt\"\n)\n\n# Simple greedy search\noutput_ids = model.generate(\n    input_ids,\n    min_length=15,\n    max_length=25,\n    num_beams=1,\n    do_sample=False,\n)\ntok.decode(output_ids[0])\n# '</s><s> Jag har \u00e4tit en uts\u00f6kt middag p\u00e5 restaurang vid havet p\u00e5 restaurang vid havet p\u00e5 restaurang vid havet.</s>'\n\n\n# Sampling\noutput_ids = model.generate(\n    input_ids,\n    min_length=15,\n    max_length=20,\n    num_beams=1,\n    do_sample=True,\n)\ntok.decode(output_ids[0])\n#'</s><s> Jag har \u00e4tit en uts\u00f6kt god mat som de tagit in p\u00e5 restaurang vid avr\u00f6jda</s>'\n\n\n# Beam search\noutput_ids = model.generate(\n    input_ids,\n    min_length=15,\n    max_length=25,\n    no_repeat_ngram_size=3,\n    num_beams=8,\n    early_stopping=True,\n    do_sample=True,\n    num_return_sequences=6\n)\ntok.decode(output_ids[0])\n# '</s><s> Jag har \u00e4tit en uts\u00f6kt middag p\u00e5 restaurang vid havet. Jag har varit ute och g\u00e5tt en sv\u00e4ng.</s><pad><pad>'\n\n\n# Diverse beam generation\noutput_ids = model.generate(\n    input_ids,\n    min_length=50,\n    max_length=100,\n    no_repeat_ngram_size=3,\n    num_beams=8,\n    early_stopping=True,\n    do_sample=False,\n    num_return_sequences=6,\n    num_beam_groups=8,\n    diversity_penalty=2.0,\n)\ntok.decode(output_ids[0])\n# '</s><s> Jag har \u00e4tit en uts\u00f6kt middag p\u00e5 restaurang vid havet p\u00e5 restaurang. Jag har varit p\u00e5 restaurang i tv\u00e5 dagar... Jag..,..!!!.. S\u00e5.. Nu.. Hej.. Vi.. H\u00e4r.</s>'\n\n```\n\n\n## Acknowledgements\n\nWe gratefully acknowledge the HPC RIVR consortium ([www.hpc-rivr.si](https://www.hpc-rivr.si/)) and EuroHPC JU ([eurohpc-ju.europa.eu/](https://eurohpc-ju.europa.eu/)) for funding this research by providing computing resources of the HPC system Vega at the Institute of Information Science ([www.izum.si](https://www.izum.si/)).", "size_bytes": "557735955", "downloads": 28}