{"pretrained_model_name": "KES/T5-KES", "description": "---\n\nlanguage: en\n\ntags:\n\n- sentence correction\n\n- text2text-generation\n\nlicense: cc-by-nc-sa-4.0\n\ndatasets:\n\n- jfleg\n\n---\n\n# Model\nThis model utilises T5-base pre-trained model. It was fine tuned using a modified version of the [JFLEG](https://arxiv.org/abs/1702.04066) dataset and [Happy Transformer framework](https://github.com/EricFillion/happy-transformer). This model was fine-tuned for sentence correction on normal English translations and positional English translations of local Caribbean English Creole. This model will be updated periodically as more data is compiled. For more on the Caribbean English Creole checkout the library [Caribe](https://pypi.org/project/Caribe/).\n\n___\n\n\n# Re-training/Fine Tuning\n\nThe results of fine-tuning resulted in a final accuracy of 92%\n\n\n# Usage \n\n\n\n```python\n\nfrom happytransformer import HappyTextToText, TTSettings\n\npre_trained_model=\"T5\"\nmodel = HappyTextToText(pre_trained_model, \"KES/T5-KES\")\n\narguments = TTSettings(num_beams=4, min_length=1)\nsentence = \"Wat iz your nam\"\n\ncorrection = model.generate_text(\"grammar: \"+sentence, args=arguments)\nif(correction.text.find(\" .\")):\n    correction.text=correction.text.replace(\" .\", \".\")\n\nprint(correction.text) # Correction: \"What is your name?\".\n\n```\n___\n# Usage with Transformers\n\n```python\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"KES/T5-KES\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"KES/T5-KES\")\n\ntext = \"I am lived with my parenmts \"\ninputs = tokenizer(\"grammar:\"+text, truncation=True, return_tensors='pt')\n\noutput = model.generate(inputs['input_ids'], num_beams=4, max_length=512, early_stopping=True)\ncorrection=tokenizer.batch_decode(output, skip_special_tokens=True)\nprint(\"\".join(correction)) #Correction: I am living with my parents.\n\n```\n___\n", "size_bytes": "891700799", "downloads": 18105}