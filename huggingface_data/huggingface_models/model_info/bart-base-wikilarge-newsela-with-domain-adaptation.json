{"pretrained_model_name": "bogdancazan/bart-base-wikilarge-newsela-with-domain-adaptation", "description": "training_args = TrainingArguments(\n    output_dir='bart-base-wikilarge-newsela-with-domain-adaptation',\n    num_train_epochs=20,\n    warmup_steps=250,\n    per_device_train_batch_size=BATCH_SIZE,\n    weight_decay=0.01,\n    learning_rate=2e-4,\n    fp16=True,\n    optim=\"adafactor\",\n)\n\nStep\tTraining Loss\n500\t5.111300\n1000\t3.064000\n1500\t2.899200\n2000\t2.779200\n2500\t2.710700\n3000\t2.608300\n3500\t2.546900\n4000\t2.491100\n4500\t2.404400\n5000\t2.374700\n5500\t2.324800\n6000\t2.257300\n6500\t2.239900\n7000\t2.173400\n7500\t2.134500\n8000\t2.115700\n8500\t2.046100\n9000\t2.025600\n9500\t1.989900\n10000\t1.953900\n10500\t1.940900\n11000\t1.894000\n11500\t1.872400\n12000\t1.854300\n12500\t1.823300\n13000\t1.811900\n13500\t1.789700\n14000\t1.764800\n14500\t1.753300\n15000\t1.735000\n15500\t1.727400\n16000\t1.719900\nTrainOutput(global_step=16060, training_loss=2.2460614238848278, metrics={'train_runtime': 5541.9227, 'train_samples_per_second': 370.669, 'train_steps_per_second': 2.898, 'total_flos': 0.0, 'train_loss': 2.2460614238848278, 'epoch': 20.0})", "size_bytes": "557971229", "downloads": 3}