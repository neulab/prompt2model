{"pretrained_model_name": "NlpHUST/t5-vi-en-base", "description": "---\nlanguage:\n- vi\n\ntags:\n- t5\n- seq2seq\n\n# Machine translation for vietnamese\n## Model Description\nT5-vi-en-base is a transformer model for vietnamese machine translation designed using T5 architecture.\n## Training data\nT5-vi-en-base was trained on 4M sentence pairs (english,vietnamese)\n### How to use\n\n```py\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"NlpHUST/t5-vi-en-base\")\ntokenizer = T5Tokenizer.from_pretrained(\"NlpHUST/t5-vi-en-base\")\nmodel.to(device)\n\nsrc = \"Theo l\u00e3nh \u0111\u1ea1o S\u1edf Y t\u1ebf, 3 ng\u01b0\u1eddi n\u00e0y kh\u00f4ng c\u00f3 tri\u1ec7u ch\u1ee9ng s\u1ed1t, ho, kh\u00f3 th\u1edf, \u0111\u00e3 \u0111\u01b0\u1ee3c l\u1ea5y m\u1eabu x\u00e9t nghi\u1ec7m v\u00e0 c\u00e1ch ly t\u1eadp trung.\"\ntokenized_text = tokenizer.encode(src, return_tensors=\"pt\").to(device)\nmodel.eval()\nsummary_ids = model.generate(\n                    tokenized_text,\n                    max_length=256, \n                    num_beams=5,\n                    repetition_penalty=2.5, \n                    length_penalty=1.0, \n                    early_stopping=True\n                )\noutput = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\nprint(output)\n\nAccording to the head of the Department of Health, the three people had no symptoms of fever, cough, shortness of breath, were taken samples for testing and concentrated quarantine.\n```", "size_bytes": "2329734527", "downloads": 12}