{"pretrained_model_name": "Isotonic/informal_to_formal", "description": "---\nlanguage: \"en\"\ntags:\n- style-transfer\n- text2text-generation\n- seq2seq\ninference: true\n---\n\u200b\n# Formality Style Transfer\n## Model description\u200b\nT5 Model for Formality Style Transfer. Trained on the GYAFC dataset.\u200b\n\n## How to use\n\u200bPyTorch model available\u200b.\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\u200b\ntokenizer = AutoTokenizer.from_pretrained(\"Isotonic/informal_to_formal\")  \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Isotonic/informal_to_formal\")\n\u200b\nsentence = \"will you look into these two deals and let me know\"\n\ntext =  \"Make the following sentence Formal: \" + sentence + \" </s>\"\n\nencoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\ninput_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n\n\noutputs = model.generate(\n    input_ids=input_ids, attention_mask=attention_masks,\n    max_length=256,\n    do_sample=True,\n    top_k=120,\n    top_p=0.95,\n    early_stopping=True,\n    num_return_sequences=5\n)\n\nfor output in outputs:\n    line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    print(line)\n\n\u200bOutput: \"Would you look into the two deals in question, then let me know?\"\n```", "size_bytes": "2950837703", "downloads": 58}