{"pretrained_model_name": "potsawee/t5-large-generation-squad-QuestionAnswer", "description": "---\nlicense: apache-2.0\ndatasets:\n- squad\nlanguage:\n- en\nlibrary_name: transformers\npipeline_tag: text2text-generation\n---\n# t5-large fine-tuned to SQuAD for Generating Question+Answer\n- Input: `context` (e.g. news article)\n- Output: `question <sep> answer`\n\nThe answers in the training data (SQuAD) are highly extractive; therefore, this model will generate **extractive** answers. If you would like to have **abstractive** questions/answers, you can use our model trained on the RACE dataset: https://huggingface.co/potsawee/t5-large-generation-race-QuestionAnswer. \n\n## Model Details\n\nt5-large model is fine-tuned to the SQuAD dataset where the input is the context/passage and the output is the question followed by the answer. This is the first component in the question generation pipeline (i.e. `g1`) in our [MQAG paper](https://arxiv.org/abs/2301.12307), \nor please refer to the GitHub repo of this project: https://github.com/potsawee/mqag0.\n\n## How to Use the Model\n\nUse the code below to get started with the model. You can also set ```do_sample=True``` in ```generate()``` to obtain different question-answer pairs.\n\n```python\n>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n\n>>> context = r\"\"\"Chelsea's mini-revival continued with a third victory in a row as they consigned struggling Leicester City to a fifth consecutive defeat.\nBuoyed by their Champions League win over Borussia Dortmund, Chelsea started brightly and Ben Chilwell volleyed in from a tight angle against his old club.\nChelsea's Joao Felix and Leicester's Kiernan Dewsbury-Hall hit the woodwork in the space of two minutes, then Felix had a goal ruled out by the video assistant referee for offside.\nPatson Daka rifled home an excellent equaliser after Ricardo Pereira won the ball off the dawdling Felix outside the box.\nBut Kai Havertz pounced six minutes into first-half injury time with an excellent dinked finish from Enzo Fernandez's clever aerial ball.\nMykhailo Mudryk thought he had his first goal for the Blues after the break but his effort was disallowed for offside.\nMateo Kovacic sealed the win as he volleyed in from Mudryk's header.\nThe sliding Foxes, who ended with 10 men following Wout Faes' late dismissal for a second booking, now just sit one point outside the relegation zone.\n\"\"\".replace('\\n', ' ')\n\n>>> inputs = tokenizer(context, return_tensors=\"pt\")\n>>> outputs = model.generate(**inputs, max_length=100)\n>>> question_answer = tokenizer.decode(outputs[0], skip_special_tokens=False)\n>>> question_answer = question_answer.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n>>> question, answer = question_answer.split(tokenizer.sep_token)\n\n>>> print(\"question:\", question)\nquestion:  Who scored the winner for Chelsea?\n>>> print(\"answer:\", answer)\nanswer:  Mateo Kovacic\n\n```\n\n## Generating Distractors (other options in a multiple-choice setup)\n\n```Context ---> Question + (A) Answer (B) Distractor1 (C) Distractor2 (D) Distractor3```\n\nPlease refer to our distractor generation model, e.g. https://huggingface.co/potsawee/t5-large-generation-race-Distractor\n\n## Citation\n\n```bibtex\n@article{manakul2023mqag,\n  title={MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization},\n  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark JF},\n  journal={arXiv preprint arXiv:2301.12307},\n  year={2023}\n}\n```", "size_bytes": "2950837703", "downloads": 1930}