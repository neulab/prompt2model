{"pretrained_model_name": "lmqg/mt5-base-koquad-ae", "description": "\n---\nlicense: cc-by-4.0\nmetrics:\n- bleu4\n- meteor\n- rouge-l\n- bertscore\n- moverscore\nlanguage: ko\ndatasets:\n- lmqg/qg_koquad\npipeline_tag: text2text-generation\ntags:\n- answer extraction\nwidget:\n- text: \"\ub610\ud55c \uc2a4\ud53c\uc5b4\uc2a4\ub294 \ub9ce\uc740 \uc0c8\ub85c\uc6b4 \uc5ec\uc131 \uc544\ud2f0\uc2a4\ud2b8\ub4e4\uc5d0\uac8c \uc601\ud5a5\uc744 \ub07c\ucce4\ub294\ub370, \ub300\ud45c\uc801\uc73c\ub85c \ub370\ubbf8 \ub85c\ubc14\ud1a0, \ucf00\uc774\ud2f0 \ud398\ub9ac, \ud06c\ub9ac\uc2a4\ud2f0\ub2c8\uc544 \ub4dc\ubc14\uc9c0, \ub808\uc774\ub514 \uac00\uac00, \ub9ac\ud2c0 \ubd80\uce20, \uc140\ub808\ub098 \uace0\uba54\uc988 & \ub354\uc52c, \ud53d\uc2dc \ub85c\ud2b8 \uc774 \uc788\ub2e4. 2007\ub144 \ube44\uc698\uc138 \ub180\uc2a4\ub294 Total Request Live\uc640\uc758 \uc778\ud130\ubdf0\uc5d0\uc11c '\ub098\ub294 \ube0c\ub9ac\ud2b8\ub2c8\ub97c \uc0ac\ub791\ud558\uace0 \ud32c\uc774\uc5d0\uc694. \ud2b9\ud788 \uc0c8 \uc568\ubc94 Blackout\uc744 \uc88b\uc544\ud574\uc694'\ub77c\uace0 \ub9d0\ud588\ub2e4. \ub9b0\uc81c\uc774 \ub85c\ud55c\uc740 '\uc5b8\uc81c\ub098 \ube0c\ub9ac\ud2b8\ub2c8 \uc2a4\ud53c\uc5b4\uc2a4\uc5d0\uac8c \uc601\uac10\uc744 \ubc1b\ub294\ub2e4. \ud559\ucc3d\uc2dc\uc808 \uadf8\ub140\ucc98\ub7fc \ud0c0\ube14\ub85c\uc774\ub4dc\uc5d0 \uc624\ub974\uae30\ub97c \uafc8\uafd4\uc654\ub2e4'\uace0 \ub9d0\ud558\uba70 \ub864 \ubaa8\ub378\ub85c \uaf3d\uc558\ub2e4. \uc2a4\ud53c\uc5b4\uc2a4\ub294 \ud604\ub300 \uc74c\uc545\uac00\ub4e4\uc5d0\uac8c \uc74c\uc545\uc801 \uc601\uac10\uc73c\ub85c \uc5b8\uae09\ub418\uae30\ub3c4 \ud588\ub2e4. <hl> \ub9c8\uc77c\ub9ac \uc0ac\uc774\ub7ec\uc2a4\ub294 \uc790\uc2e0\uc758 \ud788\ud2b8\uace1 Party in the U.S.A. \uac00 \ube0c\ub9ac\ud2b8\ub2c8\uc5d0\uac8c \uc601\uac10\uacfc \uc601\ud5a5\uc744 \ubc1b\uc740 \uace1\uc774\ub77c\uace0 \ubc1d\ud614\ub2e4. <hl> \ubca0\ub9ac \ub9e4\ub2d0\ub85c\uc6b0\uc758 \uc568\ubc94 15 Minutes \uc5ed\uc2dc \ube0c\ub9ac\ud2b8\ub2c8\uc5d0\uac8c \uc601\uac10\uc744 \uc5bb\uc5c8\ub2e4\uace0 \uc5b8\uae09\ub418\uc5c8\ub2e4.\"\n  example_title: \"Answering Extraction Example 1\" \n- text: \"\uc9c0\ub09c 22\uc77c \uc544\ud504\ub9ac\uce74TV\ub294 BJ \ucca0\uad6c\uac00 \uc11c\ube44\uc2a4 \uc815\uc9c0 \ucc98\ubd84\uc744 \ubc1b\uc558\uc74c\uc744 \ubc1d\ud614\ub2e4. \uc11c\ube44\uc2a4 \uc815\uc9c0 \ucc98\ubd84\uc744 \uc0ac\uc720\ub294 \ucca0\uad6c\uac00 10\ub300 \uccad\uc18c\ub144\uc5d0\uac8c \uc720\ud574\ud55c \uc7a5\uba74\uc744 \ubc29\uc1a1\uc73c\ub85c \ub0b4\ubcf4\ub0c8\uae30 \ub54c\ubb38\uc774\uc5c8\ub2e4. \ubb38\uc81c\uac00 \ub41c \uc7a5\uba74\uc740 BJ \ucca0\uad6c\uac00 \ubbf8\uc131\ub144\uc790\ub294 \uc2dc\uccad\ud560 \uc218 \uc5c6\uac8c \ud558\ub294 19\uc138 \uc2dc\uccad \uac00\ub2a5 \uc124\uc815\uc744 \ud558\uc9c0 \uc54a\uc740 \ucc44 \ud761\uc5f0\ud558\ub294 \ubaa8\uc2b5\uc744 \uc5ec\uacfc \uc5c6\uc774 \ub4dc\ub7ec\ub0b8 \uc7a5\uba74\uc774\ub2e4. \uc544\ud504\ub9ac\uce74TV\ub294 \uccad\uc18c\ub144 \ubcf4\ud638 \uc815\ucc45\uc758 '\uccad\uc18c\ub144\ub4e4\uc774 \ud574\ub85c\uc6b4 \ud658\uacbd\uc73c\ub85c\ubd80\ud130 \ubcf4\ud638\ubc1b\uc744 \uc218 \uc788\ub3c4\ub85d \uc870\uce58\ud55c\ub2e4'\ub77c\uace0 \uc870\ud56d\uc744 \uadfc\uac70\ub85c \ucca0\uad6c\uc5d0\uac8c \uc11c\ube44\uc2a4 \uc815\uc9c0 \ucc98\ubd84\uc744 \ub0b4\ub838\ub2e4. \ud761\uc5f0 \uc774\uc678\uc5d0 \uc74c\uc8fc \ubc29\uc1a1 \ub4f1\ub3c4 19\uc138 \uc2dc\uccad \uac00\ub2a5 \uc124\uc815\uc744 \ud574\uc57c\ub9cc \ubc29\uc1a1\ud560 \uc218 \uc788\ub2e4. <hl> \uac8c\ub2e4\uac00 \ucca0\uad6c\uc758 \ubc29\uc1a1 \uc815\uc9c0 \ucc98\ubd84\uc740 \uc774\ubc88\uc5d0 \ucc98\uc74c\uc774 \uc544\ub2c8\ub77c 16\ubc88 \uc9f8\uae30 \ub54c\ubb38\uc5d0 \ub354\uc6b1\ub354 \ub17c\ub780\uc774 \ub418\uace0 \uc788\ub2e4. <hl>\"\n  example_title: \"Answering Extraction Example 2\" \nmodel-index:\n- name: lmqg/mt5-base-koquad-ae\n  results:\n  - task:\n      name: Text2text Generation\n      type: text2text-generation\n    dataset:\n      name: lmqg/qg_koquad\n      type: default\n      args: default\n    metrics:\n    - name: BLEU4 (Answer Extraction)\n      type: bleu4_answer_extraction\n      value: 20.6\n    - name: ROUGE-L (Answer Extraction)\n      type: rouge_l_answer_extraction\n      value: 72.57\n    - name: METEOR (Answer Extraction)\n      type: meteor_answer_extraction\n      value: 51.78\n    - name: BERTScore (Answer Extraction)\n      type: bertscore_answer_extraction\n      value: 91.76\n    - name: MoverScore (Answer Extraction)\n      type: moverscore_answer_extraction\n      value: 90.78\n    - name: AnswerF1Score (Answer Extraction)\n      type: answer_f1_score__answer_extraction\n      value: 77.32\n    - name: AnswerExactMatch (Answer Extraction)\n      type: answer_exact_match_answer_extraction\n      value: 69.49\n---\n\n# Model Card of `lmqg/mt5-base-koquad-ae`\nThis model is fine-tuned version of [google/mt5-base](https://huggingface.co/google/mt5-base) for answer extraction on the [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) (dataset_name: default) via [`lmqg`](https://github.com/asahi417/lm-question-generation).\n\n\n### Overview\n- **Language model:** [google/mt5-base](https://huggingface.co/google/mt5-base)   \n- **Language:** ko  \n- **Training data:** [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) (default)\n- **Online Demo:** [https://autoqg.net/](https://autoqg.net/)\n- **Repository:** [https://github.com/asahi417/lm-question-generation](https://github.com/asahi417/lm-question-generation)\n- **Paper:** [https://arxiv.org/abs/2210.03992](https://arxiv.org/abs/2210.03992)\n\n### Usage\n- With [`lmqg`](https://github.com/asahi417/lm-question-generation#lmqg-language-model-for-question-generation-)\n```python\nfrom lmqg import TransformersQG\n\n# initialize model\nmodel = TransformersQG(language=\"ko\", model=\"lmqg/mt5-base-koquad-ae\")\n\n# model prediction\nanswers = model.generate_a(\"1990\ub144 \uc601\ud654 \u300a \ub0a8\ubd80\uad70 \u300b\uc5d0\uc11c \ub2e8\uc5ed\uc73c\ub85c \uc601\ud654\ubc30\uc6b0 \uccab \ub370\ubdd4\uc5d0 \uc774\uc5b4 \uac19\uc740 \ud574 KBS \ub4dc\ub77c\ub9c8 \u300a\uc9c0\uad6c\uc778\u300b\uc5d0\uc11c \ub2e8\uc5ed\uc73c\ub85c \ucd9c\uc5f0\ud558\uc600\uace0 \uc774\ub4ec\ud574 MBC \u300a\uc5ec\uba85\uc758 \ub208\ub3d9\uc790\u300b\ub97c \ud1b5\ud574 \ub2e8\uc5ed\uc73c\ub85c \ucd9c\uc5f0\ud558\uc600\ub2e4.\")\n\n```\n\n- With `transformers`\n```python\nfrom transformers import pipeline\n\npipe = pipeline(\"text2text-generation\", \"lmqg/mt5-base-koquad-ae\")\noutput = pipe(\"\ub610\ud55c \uc2a4\ud53c\uc5b4\uc2a4\ub294 \ub9ce\uc740 \uc0c8\ub85c\uc6b4 \uc5ec\uc131 \uc544\ud2f0\uc2a4\ud2b8\ub4e4\uc5d0\uac8c \uc601\ud5a5\uc744 \ub07c\ucce4\ub294\ub370, \ub300\ud45c\uc801\uc73c\ub85c \ub370\ubbf8 \ub85c\ubc14\ud1a0, \ucf00\uc774\ud2f0 \ud398\ub9ac, \ud06c\ub9ac\uc2a4\ud2f0\ub2c8\uc544 \ub4dc\ubc14\uc9c0, \ub808\uc774\ub514 \uac00\uac00, \ub9ac\ud2c0 \ubd80\uce20, \uc140\ub808\ub098 \uace0\uba54\uc988 & \ub354\uc52c, \ud53d\uc2dc \ub85c\ud2b8 \uc774 \uc788\ub2e4. 2007\ub144 \ube44\uc698\uc138 \ub180\uc2a4\ub294 Total Request Live\uc640\uc758 \uc778\ud130\ubdf0\uc5d0\uc11c '\ub098\ub294 \ube0c\ub9ac\ud2b8\ub2c8\ub97c \uc0ac\ub791\ud558\uace0 \ud32c\uc774\uc5d0\uc694. \ud2b9\ud788 \uc0c8 \uc568\ubc94 Blackout\uc744 \uc88b\uc544\ud574\uc694'\ub77c\uace0 \ub9d0\ud588\ub2e4. \ub9b0\uc81c\uc774 \ub85c\ud55c\uc740 '\uc5b8\uc81c\ub098 \ube0c\ub9ac\ud2b8\ub2c8 \uc2a4\ud53c\uc5b4\uc2a4\uc5d0\uac8c \uc601\uac10\uc744 \ubc1b\ub294\ub2e4. \ud559\ucc3d\uc2dc\uc808 \uadf8\ub140\ucc98\ub7fc \ud0c0\ube14\ub85c\uc774\ub4dc\uc5d0 \uc624\ub974\uae30\ub97c \uafc8\uafd4\uc654\ub2e4'\uace0 \ub9d0\ud558\uba70 \ub864 \ubaa8\ub378\ub85c \uaf3d\uc558\ub2e4. \uc2a4\ud53c\uc5b4\uc2a4\ub294 \ud604\ub300 \uc74c\uc545\uac00\ub4e4\uc5d0\uac8c \uc74c\uc545\uc801 \uc601\uac10\uc73c\ub85c \uc5b8\uae09\ub418\uae30\ub3c4 \ud588\ub2e4. <hl> \ub9c8\uc77c\ub9ac \uc0ac\uc774\ub7ec\uc2a4\ub294 \uc790\uc2e0\uc758 \ud788\ud2b8\uace1 Party in the U.S.A. \uac00 \ube0c\ub9ac\ud2b8\ub2c8\uc5d0\uac8c \uc601\uac10\uacfc \uc601\ud5a5\uc744 \ubc1b\uc740 \uace1\uc774\ub77c\uace0 \ubc1d\ud614\ub2e4. <hl> \ubca0\ub9ac \ub9e4\ub2d0\ub85c\uc6b0\uc758 \uc568\ubc94 15 Minutes \uc5ed\uc2dc \ube0c\ub9ac\ud2b8\ub2c8\uc5d0\uac8c \uc601\uac10\uc744 \uc5bb\uc5c8\ub2e4\uace0 \uc5b8\uae09\ub418\uc5c8\ub2e4.\")\n\n```\n\n## Evaluation\n\n\n- ***Metric (Answer Extraction)***: [raw metric file](https://huggingface.co/lmqg/mt5-base-koquad-ae/raw/main/eval/metric.first.answer.paragraph_sentence.answer.lmqg_qg_koquad.default.json) \n\n|                  |   Score | Type    | Dataset                                                          |\n|:-----------------|--------:|:--------|:-----------------------------------------------------------------|\n| AnswerExactMatch |   69.49 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| AnswerF1Score    |   77.32 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| BERTScore        |   91.76 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| Bleu_1           |   59.38 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| Bleu_2           |   48.34 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| Bleu_3           |   34.11 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| Bleu_4           |   20.6  | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| METEOR           |   51.78 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| MoverScore       |   90.78 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n| ROUGE_L          |   72.57 | default | [lmqg/qg_koquad](https://huggingface.co/datasets/lmqg/qg_koquad) |\n\n\n\n## Training hyperparameters\n\nThe following hyperparameters were used during fine-tuning:\n - dataset_path: lmqg/qg_koquad\n - dataset_name: default\n - input_types: ['paragraph_sentence']\n - output_types: ['answer']\n - prefix_types: None\n - model: google/mt5-base\n - max_length: 512\n - max_length_output: 32\n - epoch: 5\n - batch: 8\n - lr: 0.0005\n - fp16: False\n - random_seed: 1\n - gradient_accumulation_steps: 8\n - label_smoothing: 0.15\n\nThe full configuration can be found at [fine-tuning config file](https://huggingface.co/lmqg/mt5-base-koquad-ae/raw/main/trainer_config.json).\n\n## Citation\n```\n@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}\n\n```\n", "size_bytes": "2329634869", "downloads": 2}