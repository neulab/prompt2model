{"pretrained_model_name": "bananaspectre/marian-finetuned-tgl-eng-netspeak-trial9", "description": "---\nlicense: apache-2.0\ntags:\n- translation\n- generated_from_trainer\nmetrics:\n- bleu\nmodel-index:\n- name: marian-finetuned-tgl-eng-netspeak-trial9\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# marian-finetuned-tgl-eng-netspeak-trial9\n\nThis model is a fine-tuned version of [Helsinki-NLP/opus-mt-tl-en](https://huggingface.co/Helsinki-NLP/opus-mt-tl-en) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 2.3568\n- Bleu: 29.1370\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 2e-05\n- train_batch_size: 32\n- eval_batch_size: 32\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 200\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Bleu    |\n|:-------------:|:-----:|:----:|:---------------:|:-------:|\n| 5.6316        | 1.0   | 57   | 4.1183          | 4.6005  |\n| 4.8654        | 2.0   | 114  | 3.8581          | 5.9435  |\n| 4.5642        | 3.0   | 171  | 3.6865          | 6.6312  |\n| 4.3364        | 4.0   | 228  | 3.5646          | 7.3157  |\n| 4.1474        | 5.0   | 285  | 3.4686          | 8.6700  |\n| 4.0044        | 6.0   | 342  | 3.3852          | 8.6733  |\n| 3.8862        | 7.0   | 399  | 3.3257          | 8.3894  |\n| 3.7676        | 8.0   | 456  | 3.2528          | 9.2599  |\n| 3.6633        | 9.0   | 513  | 3.2005          | 9.7922  |\n| 3.5594        | 10.0  | 570  | 3.1615          | 10.9836 |\n| 3.4683        | 11.0  | 627  | 3.1055          | 11.0111 |\n| 3.3897        | 12.0  | 684  | 3.0527          | 11.0658 |\n| 3.3165        | 13.0  | 741  | 3.0106          | 11.3570 |\n| 3.2338        | 14.0  | 798  | 2.9819          | 12.4296 |\n| 3.1626        | 15.0  | 855  | 2.9395          | 13.0279 |\n| 3.1127        | 16.0  | 912  | 2.9088          | 13.2959 |\n| 3.0224        | 17.0  | 969  | 2.8760          | 13.9185 |\n| 2.9523        | 18.0  | 1026 | 2.8420          | 14.7849 |\n| 2.9036        | 19.0  | 1083 | 2.8059          | 15.3255 |\n| 2.8449        | 20.0  | 1140 | 2.7830          | 15.8899 |\n| 2.7851        | 21.0  | 1197 | 2.7654          | 15.3016 |\n| 2.7182        | 22.0  | 1254 | 2.7422          | 15.9169 |\n| 2.683         | 23.0  | 1311 | 2.7171          | 15.4695 |\n| 2.6016        | 24.0  | 1368 | 2.6860          | 17.2504 |\n| 2.5688        | 25.0  | 1425 | 2.6800          | 17.4693 |\n| 2.511         | 26.0  | 1482 | 2.6523          | 17.8363 |\n| 2.4627        | 27.0  | 1539 | 2.6247          | 18.6818 |\n| 2.4259        | 28.0  | 1596 | 2.6038          | 19.2026 |\n| 2.3814        | 29.0  | 1653 | 2.5946          | 18.9046 |\n| 2.3368        | 30.0  | 1710 | 2.5720          | 19.6498 |\n| 2.2639        | 31.0  | 1767 | 2.5564          | 18.7972 |\n| 2.2366        | 32.0  | 1824 | 2.5432          | 20.1555 |\n| 2.1884        | 33.0  | 1881 | 2.5369          | 19.9048 |\n| 2.143         | 34.0  | 1938 | 2.5215          | 19.3706 |\n| 2.122         | 35.0  | 1995 | 2.5102          | 20.2954 |\n| 2.0819        | 36.0  | 2052 | 2.4966          | 20.5785 |\n| 2.0333        | 37.0  | 2109 | 2.4939          | 20.8078 |\n| 1.9972        | 38.0  | 2166 | 2.4852          | 21.6624 |\n| 1.9596        | 39.0  | 2223 | 2.4724          | 21.3380 |\n| 1.9386        | 40.0  | 2280 | 2.4550          | 21.7399 |\n| 1.8881        | 41.0  | 2337 | 2.4539          | 21.8201 |\n| 1.8488        | 42.0  | 2394 | 2.4494          | 22.8561 |\n| 1.8344        | 43.0  | 2451 | 2.4436          | 22.0001 |\n| 1.8005        | 44.0  | 2508 | 2.4353          | 21.5060 |\n| 1.7703        | 45.0  | 2565 | 2.4314          | 22.6523 |\n| 1.7321        | 46.0  | 2622 | 2.4258          | 22.9500 |\n| 1.6897        | 47.0  | 2679 | 2.4202          | 23.0767 |\n| 1.6822        | 48.0  | 2736 | 2.4115          | 23.3565 |\n| 1.6392        | 49.0  | 2793 | 2.4056          | 24.4669 |\n| 1.621         | 50.0  | 2850 | 2.4071          | 25.7900 |\n| 1.6075        | 51.0  | 2907 | 2.3930          | 25.8570 |\n| 1.5558        | 52.0  | 2964 | 2.3835          | 26.0207 |\n| 1.5335        | 53.0  | 3021 | 2.3848          | 24.5089 |\n| 1.5091        | 54.0  | 3078 | 2.3870          | 26.7579 |\n| 1.4904        | 55.0  | 3135 | 2.3791          | 26.2250 |\n| 1.4645        | 56.0  | 3192 | 2.3760          | 26.1819 |\n| 1.4628        | 57.0  | 3249 | 2.3811          | 25.9747 |\n| 1.4297        | 58.0  | 3306 | 2.3659          | 26.4407 |\n| 1.4011        | 59.0  | 3363 | 2.3650          | 27.1145 |\n| 1.3649        | 60.0  | 3420 | 2.3597          | 27.6616 |\n| 1.3419        | 61.0  | 3477 | 2.3601          | 28.6248 |\n| 1.3278        | 62.0  | 3534 | 2.3670          | 27.2075 |\n| 1.3106        | 63.0  | 3591 | 2.3588          | 27.3917 |\n| 1.2855        | 64.0  | 3648 | 2.3508          | 27.8277 |\n| 1.2732        | 65.0  | 3705 | 2.3622          | 28.3032 |\n| 1.259         | 66.0  | 3762 | 2.3603          | 28.0315 |\n| 1.2397        | 67.0  | 3819 | 2.3551          | 27.9452 |\n| 1.2285        | 68.0  | 3876 | 2.3597          | 28.5887 |\n| 1.1898        | 69.0  | 3933 | 2.3599          | 28.5675 |\n| 1.181         | 70.0  | 3990 | 2.3642          | 29.7412 |\n| 1.1748        | 71.0  | 4047 | 2.3577          | 29.2003 |\n| 1.146         | 72.0  | 4104 | 2.3609          | 28.3760 |\n| 1.1274        | 73.0  | 4161 | 2.3519          | 29.2015 |\n| 1.1138        | 74.0  | 4218 | 2.3568          | 29.1370 |\n\n\n### Framework versions\n\n- Transformers 4.25.1\n- Pytorch 1.13.0+cu116\n- Datasets 2.8.0\n- Tokenizers 0.13.2\n", "size_bytes": "294010757", "downloads": 4}