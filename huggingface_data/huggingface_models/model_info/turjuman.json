{"pretrained_model_name": "UBC-NLP/turjuman", "description": "  \n  <p align=\"center\">\n    <br>\n    <img src=\"https://github.com/UBC-NLP/turjuman/raw/master//images/turjuman_logo.png\"/>\n    <br>\n<p>\n  \n  <img src=\"https://github.com/UBC-NLP/turjuman/raw/master/images/turjuman.png\" alt=\"AraT5\" width=\"50%\" height=\"50%\" align=\"right\"/>\n\n\n\nTurjuman is a neural machine translation toolkit. It translates from 20 languages into Modern Standard Arabic (MSA). Turjuman is described in this paper: \n[**TURJUMAN: A Public Toolkit for Neural Arabic Machine Translation**](https://arxiv.org/abs/2206.03933).\n\nTurjuman exploits our [AraT5 model](https://github.com/UBC-NLP/araT5). This endows Turjuman with a powerful ability to decode into Arabic. The toolkit offers the possibility of employing a number of diverse decoding methods, making it suited for acquiring paraphrases for the MSA translations as an added value.\n\n\n**Github**: [https://github.com/UBC-NLP/turjuman](https://github.com/UBC-NLP/turjuman)\n\n**Demo**: [https://demos.dlnlp.ai/turjuman](https://demos.dlnlp.ai/turjuman)\n\n**Paper**: [https://arxiv.org/abs/2206.03933](https://arxiv.org/abs/2206.03933)\n\n## License\nturjuman(-py) is Apache-2.0 licensed. The license applies to the pre-trained models as well.\n\n## Citation\nIf you use TURJUMAN toolkit or the pre-trained models for your scientific publication, or if you find the resources in this repository useful, please cite our paper as follows (to be updated):\n```\n@inproceedings{nagoudi-osact5-2022-turjuman,\n  title={TURJUMAN: A Public Toolkit for Neural Arabic Machine Translation},\n  author={Nagoudi, El Moatez Billah and Elmadany, AbdelRahim and Abdul-Mageed, Muhammad},\n  booktitle = \"Proceedings of the 5th Workshop on Open-Source Arabic Corpora and Processing Tools (OSACT5)\",\n  month = \"June\",\n  year = \"2022\",\n  address = \"Marseille, France\",\n  publisher = \"European Language Resource Association\",\n}\n\n```\n\n", "size_bytes": "1131179919", "downloads": 28531}