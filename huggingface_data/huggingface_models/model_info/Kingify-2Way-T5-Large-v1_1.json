{"pretrained_model_name": "swcrazyfan/Kingify-2Way-T5-Large-v1_1", "description": "---\nlanguage: english\ntags:\n- t5\nwidget:\n- text: \"dekingify: \"\n  example_title: \"Translate 17th-century English to modern English\"\n- text: \"kingify: \"\n  example_title: \"Translate modern English to  17th-century English\"\n---\n# Kingify 2Way\nThis is a custom AI model that translates modern English into 17th-century English or \"King James\" English.\n\n## Details of the model\n\nThis model is a fine-tuned version of [google/t5-v1_1-large] on a dataset of a modern Bible translation with matching King James Bible verses.\n\n## Intended uses & limitations\n\nAt times, despite sharing the same language and general grammatical rules, English from previous centuries can be easily misunderstood. The purpose of this was to explore ways to understand texts from the 17th-century more clearly.\n\n#### How to use\n\n```python\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\n\ntokenizer = AutoTokenizer.from_pretrained(\"swcrazyfan/Kingify-2Way\")\n\nmodel = AutoModelWithLMHead.from_pretrained(\"swcrazyfan/Kingify-2Way\")\n```\n\n#### Limitations and bias\n\n- The model is trained on the King James Version of the Bible, so it will work best with Christian-style language (or even clich\u00e9s).\n- Before the 18th and 19th centuries, English spelling was inconsistent. Because of this, the model often does not recognize spellings different from those in the KJV.\n- The model was trained on a relatively small amount of data, so it will not be as accurate as a model trained on a larger data set.\n\n## Training data\n\nThe data used to train this model is from the New English Translation and the King James Version of the Bible.\n\n## Training procedure\n\nThe model was trained on Kaggle using the Hugging Face Transformers library.\n\n### Training hyperparameters\nThe following hyperparameters were used during training:\n- num_train_epochs: 4\n- learning_rate: 5e-04\n- train_batch_size: 2\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n\n## Eval results\n\nThe model was evaluated using a human test. A human was asked to evaluate the translation quality of the model. The human was not told which sentences were translated by the model and which sentences were written by a human.\n\n## BibTeX entry and citation info\n\n```bibtex\n@inproceedings{,\n  title={Kingify 2Way},\n  author={Joshua Kaufmann},\n  year={2022},\n  url={https://huggingface.co/swcrazyfan/Kingify-2Way-T5-Large-v1_1}\n}\n```", "size_bytes": "3132852901", "downloads": 2}