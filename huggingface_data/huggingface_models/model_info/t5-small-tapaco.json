{"pretrained_model_name": "hetpandya/t5-small-tapaco", "description": "---\nlanguage: en\ndatasets:\n- tapaco\n---\n# T5-small for paraphrase generation\n\nGoogle's T5 small fine-tuned on [TaPaCo](https://huggingface.co/datasets/tapaco) dataset for paraphrasing.\n\n## Model in Action \ud83d\ude80\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\ntokenizer = T5Tokenizer.from_pretrained(\"hetpandya/t5-small-tapaco\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"hetpandya/t5-small-tapaco\")\n\ndef get_paraphrases(sentence, prefix=\"paraphrase: \", n_predictions=5, top_k=120, max_length=256,device=\"cpu\"):\n        text = prefix + sentence + \" </s>\"\n        encoding = tokenizer.encode_plus(\n            text, pad_to_max_length=True, return_tensors=\"pt\"\n        )\n        input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\n            \"attention_mask\"\n        ].to(device)\n\n        model_output = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_masks,\n            do_sample=True,\n            max_length=max_length,\n            top_k=top_k,\n            top_p=0.98,\n            early_stopping=True,\n            num_return_sequences=n_predictions,\n        )\n\n        outputs = []\n        for output in model_output:\n            generated_sent = tokenizer.decode(\n                output, skip_special_tokens=True, clean_up_tokenization_spaces=True\n            )\n            if (\n                generated_sent.lower() != sentence.lower()\n                and generated_sent not in outputs\n            ):\n                outputs.append(generated_sent)\n        return outputs\n\nparaphrases = get_paraphrases(\"The house will be cleaned by me every Saturday.\")\n\nfor sent in paraphrases:\n  print(sent)\n```\n\n## Output\n```\nThe house is cleaned every Saturday by me.\nThe house will be cleaned on Saturday.\nI will clean the house every Saturday.\nI get the house cleaned every Saturday.\nI will clean this house every Saturday.\n```\n\n## Model fine-tuning\nPlease find my guide on fine-tuning the model here:\n\nhttps://towardsdatascience.com/training-t5-for-paraphrase-generation-ab3b5be151a2\n\n\nCreated by [Het Pandya/@hetpandya](https://github.com/hetpandya) | [LinkedIn](https://www.linkedin.com/in/het-pandya)\n\nMade with <span style=\"color: red;\">&hearts;</span> in India", "size_bytes": "242085627", "downloads": 515}