{"pretrained_model_name": "CLAck/indo-pure", "description": "---\nlanguage:\n- en\n- id\ntags:\n- translation\nlicense: apache-2.0\ndatasets:\n- ALT\nmetrics:\n- sacrebleu\n---\nPure fine-tuning version of MarianMT en-zh on Indonesian Language\n\n### Example\n```\n%%capture\n!pip install transformers transformers[sentencepiece]\n\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n# Download the pretrained model for English-Vietnamese available on the hub\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"CLAck/indo-pure\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"CLAck/indo-pure\")\n# Download a tokenizer that can tokenize English since the model Tokenizer doesn't know anymore how to do it\n# We used the one coming from the initial model\n# This tokenizer is used to tokenize the input sentence\ntokenizer_en = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-zh')\n# These special tokens are needed to reproduce the original tokenizer\ntokenizer_en.add_tokens([\"<2zh>\", \"<2indo>\"], special_tokens=True)\n\nsentence = \"The cat is on the table\"\n# This token is needed to identify the target language\ninput_sentence = \"<2indo> \" + sentence \ntranslated = model.generate(**tokenizer_en(input_sentence, return_tensors=\"pt\", padding=True))\noutput_sentence = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n```\n\n### Training results\n\n| Epoch | Bleu    |\n|:-----:|:-------:|\n| 1.0   | 15.9336 |\n| 2.0   | 28.0175 |\n| 3.0   | 31.6603 |\n| 4.0   | 33.9151 |\n| 5.0   | 35.0472 |\n| 6.0   | 35.8469 |\n| 7.0   | 36.1180 |\n| 8.0   | 36.6018 |\n| 9.0   | 37.1973 |\n| 10.0  | 37.2738 |", "size_bytes": "337379461", "downloads": 19}