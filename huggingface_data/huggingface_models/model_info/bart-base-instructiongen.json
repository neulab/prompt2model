{"pretrained_model_name": "pszemraj/bart-base-instructiongen", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\n- alpaca\n- self-instruct\n- instruction generation\n- instructiongen\ndatasets:\n- pszemraj/fleece2instructions\nmetrics:\n- rouge\nmodel-index:\n- name: bart-base-instructiongen\n  results:\n  - task:\n      name: Sequence-to-sequence Language Modeling\n      type: text2text-generation\n    dataset:\n      name: pszemraj/fleece2instructions\n      type: pszemraj/fleece2instructions\n      split: validation\n    metrics:\n    - name: Rouge1\n      type: rouge\n      value: 61.7209\nwidget:\n- text: >-\n    You'll need to start by choosing the right venue. Consider the type of\n    atmosphere and the size of the area that will be suitable for the number of\n    guests you plan to invite. Choose the right decorations based on your\n    brother's interests, such as balloons in his favorite colors, banners, and\n    streamers. Next, decide on the food and drinks, making sure they are tasty\n    and appropriate for the occasion. Then decide on the other games, music, and\n    entertainment that will make the party memorable. Finally, involve your\n    brother's friends and family to help create the perfect surprise.\n  example_title: birthday party\n- text: 1) cookies and cream 2) chocolate chip 3) mint chip 4) oreo\n  example_title: ice cream\n- text: >-\n    Start by selecting a scale model of a building that fits the theme. Use a\n    hobby knife and glue to cut and assemble the model into a ruined or\n    abandoned version of itself, adding details like broken windows and\n    graffiti. Create a base for the diorama using foam, plaster, or other\n    materials, and paint it to resemble a ruined street or sidewalk. Add\n    miniature vehicles, debris, and figures to complete the scene, and use\n    weathering techniques like dry brushing and rust washes to add realism.\n    Display the diorama in a shadow box or other protective case to showcase\n    your work.\n  example_title: Miniature diorama creation\n- text: >-\n    Start by selecting clothing that is futuristic and edgy, such as leather\n    jackets, neon-colored accessories, and tech-inspired patterns. Add\n    accessories like goggles, cybernetic implants, and LED lights to enhance the\n    cyberpunk vibe. Use makeup and body paint to create a futuristic look, such\n    as metallic skin or neon makeup. Consider adding functional elements to your\n    costume, such as a built-in backpack or hidden pockets for your tech\n    gadgets. Finally, practice your confident walk and embrace your inner\n    cyberpunk for a memorable and immersive costume experience.\n  example_title: Cyberpunk costume design\n- text: >-\n    Start by creating a base terrain with mountains, valleys, and other natural\n    features. Use fractal noise and displacement mapping to add texture and\n    detail to the terrain, and experiment with different materials like rock,\n    grass, and water. Add surreal elements like floating islands, giant\n    mushrooms, or impossible geometry to create a dreamlike atmosphere. Use\n    lighting and color grading to enhance the mood and tone of the scene, and\n    render the final image at a high resolution for maximum impact. Share your\n    surreal landscape with the world and inspire others to explore the\n    possibilities of 3D art.\n  example_title: Surreal 3D landscape creation\n- text: >-\n    Start by setting a realistic goal and creating a training plan. Build up\n    your mileage gradually over time, and incorporate cross-training and\n    strength exercises to prevent injury and improve endurance. Be sure to stay\n    hydrated and properly fuel your body with nutritious foods. Listen to your\n    body and adjust your training as needed to avoid overexertion or burnout.\n    Finally, taper your training in the weeks leading up to the race to give\n    your body time to rest and recover before the big day.\n  example_title: Marathon training\ninference:\n  parameters:\n    max_length: 96\n    num_beams: 4\n---\n\n\n# bart-base-instructiongen\n\nInstead of generating questions from text, generate instructions for LLMs! \n\n- Check out a [basic demo on Spaces](https://huggingface.co/spaces/pszemraj/generate-instructions)\n- An example of how to use instructiongen models in a CLI script can be found [here](https://gist.github.com/pszemraj/8b0213e700763106074d3ac15d041c14)\n- You can find other models fine-tuned for instruction generation by [searching for the instructiongen tag](https://huggingface.co/models?other=instructiongen).\n\n\n## About\n\n**Hypothesis:** Apply text-to-text models to unlabeled domain-specific text to generate appropriate LLM instructions. Consequently, this may enable domain adaptation of instruction-tuned LLMs, making them more versatile for specific domains.\n\nThis model is a fine-tuned version of the [facebook/bart-base](https://huggingface.co/facebook/bart-base) model, fine-tuned using the `pszemraj/fleece2instructions` dataset. \n\nIt achieves the following results on the evaluation set:\n- Loss: 1.0034\n- Rouge1: 61.7209\n- Rouge2: 45.0116\n- Rougel: 59.8188\n- Rougelsum: 59.8931\n- Gen Len: 14.3179\n\n## Intended uses & limitations\n\nThis is just a base model/example. There is likely to be even better performance with larger models (click [here to see other checkpoints](https://huggingface.co/models?other=instructiongen))\n\nAdditionally, this was trained on a dataset of **only** instructions+outputs, with the `inputs` filtered out. This means that text of *1) cookies and cream 2) chocolate chip 3) mint chip 4) oreo* will **not** get you *\"Rank the following ice cream flavors: oreo, mint chip, chocolate chip, cookies and cream\"*.\n\n## Training and evaluation data\n\nSee the linked dataset `pszemraj/fleece2instructions` - it is a filtered/formatted version of `tatsu-lab/alpaca` to generate instructions for arbitrary text.\n\n- Some of the API examples are intentionally weird to demonstrate the generalizability of the model.\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 8e-05\n- train_batch_size: 8\n- eval_batch_size: 1\n- seed: 42\n- distributed_type: multi-GPU\n- gradient_accumulation_steps: 8\n- total_train_batch_size: 64\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: cosine\n- lr_scheduler_warmup_ratio: 0.02\n- num_epochs: 2.0\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Rouge1  | Rouge2  | Rougel  | Rougelsum | Gen Len |\n|:-------------:|:-----:|:----:|:---------------:|:-------:|:-------:|:-------:|:---------:|:-------:|\n| 1.2723        | 1.0   | 362  | 1.0325          | 61.6206 | 45.1199 | 59.6467 | 59.7534   | 14.0443 |\n| 1.0157        | 2.0   | 724  | 1.0034          | 62.4433 | 46.0114 | 60.5355 | 60.6392   | 14.1807 |", "size_bytes": "557971229", "downloads": 6}