{"pretrained_model_name": "JulianS/distilbart-cnn-6-6-finetuned-summscreen", "description": "---\nwidget:\n - text: \"DOCTOR: We have to get to Triton, destroy all the Morpheus machines. End this. This is how we get home?\\nCLARA: I've never been so pleased to see\\n(Sandmen move between them and the Tardis. More approach from behind.)\\nDOCTOR: Nagata!\\n(He turns Nagata round and uses her helmet schematic projector on a copper sheet.)\\nCLARA: Doctor, quickly!\\n(The Doctor taps the projection of the anti-grav shield generators.)\\nNAGATA: What did you just do?\\nDOCTOR: Self-destructed the grav-shields.\\nNAGATA: What?\\n(The spacestation tilts. The women cry out.)\\nDOCTOR: It's working!\\n(Clara uses her key to open the Tardis door. The Sandmen are stationary, falling to pieces.)\\nDOCTOR: Neptune's gravity is pulling them apart, bit by bit! It doesn't make sense. None of this makes any sense.\\n(They run inside the Tardis and it dematerialises.)\"\n - text: \"Michael: I'm starting my own paper company. \\nAndy: No way!? \\nMichael: Yeah. \\nAndy: In this climate? \\nMichael: Yeah. In all climates. It's going to be worldwide. And I'm looking for some talented salesmen to join me. That's where you come in. \\nAndy: Ehh... [in accent] well it's a very intriguing concept, isn't it? Um... hmmm..\\n[makes weird noises to stall, Dwight enters] Michael is starting his own paper company. What do you think about that? \\nDwight: Your own paper company. \\nMichael: Can you believe it? Well, we'll see, we'll see. It's just a, just a nugget of an idea right now so \\nDwight: Right... \\nMichael: Potential, lots of potential. yes. \\nDwight: What a courageous venture. \\nMichael: It's... it's very courageous, very exciting. Um... \\nDwight: Location is hard for me, with the farm and the responsibilities... \\nMichael: That's what I was thinking, with the farm, so... You getting to wherever I'm gonna put my thing. \\nDwight: Okay. So yeah. \\nMichael: So think about it. Lets put a pin in it for now. \\nDwight: You know, I would love to put a pin in that.\"\n - text: \"Penny: This is great. What\u2019s the occasion? \\nLeonard: No occasion. You know, things have been a little weird between us, so I wanted to throw together a fun night just for you. \\nPenny: That is so sweet. \\nLeonard: I got all your favourites. Beer, wings, sliders. We can watch the football game. I even painted my stomach. \\nPenny: Go Sports? \\nLeonard: Well, in case you were in the mood for baseball, I didn\u2019t want to look ridiculous. \\nPenny: This is awesome. I love it! \\nLeonard: Good, I\u2019m glad. \\nPenny: Gosh, I worked my ass off today. This is exactly what I needed. \\nLeonard: Great. Just relax and enjoy. Tonight is all about you. \\nPenny: Ah, thank you! \\nLeonard: So, where exactly are we in this relationship? \\nPenny: Oh, come on. I just told you I had a hard day. \\nLeonard: You\u2019re right, I\u2019m sorry. Let\u2019s watch the game. \\nPenny: Great.\"\nlicense: apache-2.0\ntags:\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: distilbart-cnn-6-6-finetuned-summscreen-10-epochs\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# distilbart-cnn-6-6-finetuned-summscreen-10-epochs\n\nThis model is a fine-tuned version of [sshleifer/distilbart-cnn-6-6](https://huggingface.co/sshleifer/distilbart-cnn-6-6) on the SummScreen dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 3.4962\n- Rouge1: 26.3499\n- Rouge2: 7.3999\n- Rougel: 18.6087\n- Rougelsum: 23.17\n- Gen Len: 49.8609\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 1e-05\n- train_batch_size: 1\n- eval_batch_size: 1\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 10\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Rouge1  | Rouge2 | Rougel  | Rougelsum | Gen Len |\n|:-------------:|:-----:|:-----:|:---------------:|:-------:|:------:|:-------:|:---------:|:-------:|\n| 3.1229        | 1.0   | 3673  | 3.1271          | 26.6959 | 7.4401 | 18.8303 | 23.7132   | 49.9763 |\n| 2.8872        | 2.0   | 7346  | 3.0482          | 26.6447 | 7.5599 | 18.5921 | 23.2786   | 49.8195 |\n| 2.5733        | 3.0   | 11019 | 3.0292          | 27.425  | 7.9963 | 19.3544 | 24.1281   | 49.8757 |\n| 2.3886        | 4.0   | 14692 | 3.0625          | 27.1291 | 7.5541 | 18.9375 | 23.8729   | 49.8905 |\n| 2.215         | 5.0   | 18365 | 3.1118          | 27.1773 | 7.551  | 19.0524 | 24.1015   | 49.9142 |\n| 2.0377        | 6.0   | 22038 | 3.2086          | 27.2237 | 7.8821 | 19.2136 | 24.0477   | 49.784  |\n| 1.9358        | 7.0   | 25711 | 3.3405          | 26.7555 | 7.6628 | 18.8609 | 23.5264   | 49.8343 |\n| 1.8292        | 8.0   | 29384 | 3.4124          | 26.7741 | 7.4529 | 18.9276 | 23.5827   | 49.8757 |\n| 1.7702        | 9.0   | 33057 | 3.4457          | 26.6281 | 7.4415 | 18.7932 | 23.4608   | 49.8639 |\n| 1.7443        | 10.0  | 36730 | 3.4962          | 26.3499 | 7.3999 | 18.6087 | 23.17     | 49.8609 |\n\n\n### Framework versions\n\n- Transformers 4.26.0\n- Pytorch 1.13.1\n- Datasets 2.9.0\n- Tokenizers 0.13.2\n", "size_bytes": "920021789", "downloads": 3}