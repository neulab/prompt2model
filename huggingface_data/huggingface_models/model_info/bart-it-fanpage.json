{"pretrained_model_name": "morenolq/bart-it-fanpage", "description": "---\nlanguage: \"it\"\nlicense: mit\ndatasets:\n- ARTeLab/fanpage\ntags:\n- bart\n- pytorch\npipeline:\n- summarization\n---\n\n# BART-IT - FanPage\n\nBART-IT is a sequence-to-sequence model, based on the BART architecture that is specifically tailored to the Italian language. The model is pre-trained on a [large corpus of Italian text](https://huggingface.co/datasets/gsarti/clean_mc4_it), and can be fine-tuned on a variety of tasks.\n\n## Model description\n\nThe model is a `base-`sized BART model, with a vocabulary size of 52,000 tokens. It has 140M parameters and can be used for any task that requires a sequence-to-sequence model. It is trained from scratch on a large corpus of Italian text, and can be fine-tuned on a variety of tasks.\n\n\n## Pre-training\n\nThe code used to pre-train BART-IT together with additional information on model parameters can be found [here](https://github.com/MorenoLaQuatra/bart-it).\n\n## Fine-tuning\n\nThe model has been fine-tuned for the abstractive summarization task on 3 different Italian datasets:\n\n- **This model** [FanPage](https://huggingface.co/datasets/ARTeLab/fanpage) - finetuned model [here](https://huggingface.co/morenolq/bart-it-fanpage)\n- [IlPost](https://huggingface.co/datasets/ARTeLab/ilpost) - finetuned model [here](https://huggingface.co/morenolq/bart-it-ilpost)\n- [WITS](https://huggingface.co/datasets/Silvia/WITS) - finetuned model [here](https://huggingface.co/morenolq/bart-it-WITS)\n\n## Usage\n\nIn order to use the model, you can use the following code:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"morenolq/bart-it-fanpage\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"morenolq/bart-it-fanpage\")\n\ninput_ids = tokenizer.encode(\"Il modello BART-IT \u00e8 stato pre-addestrato su un corpus di testo italiano\", return_tensors=\"pt\")\noutputs = model.generate(input_ids, max_length=40, num_beams=4, early_stopping=True)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n```\n\n# Citation\n\nIf you find this model useful for your research, please cite the following paper:\n\n```bibtex\n@Article{BARTIT,\n\tAUTHOR = {La Quatra, Moreno and Cagliero, Luca},\n\tTITLE = {BART-IT: An Efficient Sequence-to-Sequence Model for Italian Text Summarization},\n\tJOURNAL = {Future Internet},\n\tVOLUME = {15},\n\tYEAR = {2023},\n\tNUMBER = {1},\n\tARTICLE-NUMBER = {15},\n\tURL = {https://www.mdpi.com/1999-5903/15/1/15},\n\tISSN = {1999-5903},\n\tDOI = {10.3390/fi15010015}\n}\n```\n", "size_bytes": "563305977", "downloads": 192}