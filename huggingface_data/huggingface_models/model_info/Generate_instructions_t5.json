{"pretrained_model_name": "priyank/Generate_instructions_t5", "description": "\n```\nimport torch\nfrom transformers import T5ForConditionalGeneration,T5Tokenizer\n\n\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    \n    set_seed(42)\n\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"priyank/Generate_instructions_t5\")\ntokenizer = T5Tokenizer.from_pretrained(\"priyank/Generate_instructions_t5\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n\nsentence = \"ask user to provide his date of birth\"\ntext =  \"paraphrase: \" + sentence + \" </s>\"\n\n\nmax_len = 256\n\nencoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\ninput_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n\n\n# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\nbeam_outputs = model.generate(\n    input_ids=input_ids, attention_mask=attention_masks,\n    do_sample=True,\n    max_length=256,\n    top_k=120,\n    top_p=0.98,\n    early_stopping=True,\n    num_return_sequences=10\n)\n\n\nprint (\"\\\\\nApprentice Query ::\")\nprint (sentence)\nprint (\"\\\\\nAuto Generated Instruction ::\")\nfinal_outputs =[]\nfor beam_output in beam_outputs:\n    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    if sent.lower() != sentence.lower() and sent not in final_outputs:\n        final_outputs.append(sent)\n\nfor i, final_output in enumerate(final_outputs):\n    print(\"{}: {}\".format(i, final_output))\n\n\nApprentice Query ::\nif balance is greater than $100, then tell the user he needs more balance\n\nAuto Generated Instruction ::\n0: IF (assert(user.balance > $100)) THEN (say you need more balance)\n\n```\n\nReference: https://github.com/ramsrigouthamg/Paraphrase-any-question-with-T5-Text-To-Text-Transfer-Transformer-", "size_bytes": "891692459", "downloads": 6}