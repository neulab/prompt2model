{"pretrained_model_name": "Suchinthana/MT5-Sinhala-Wikigen-Experimental", "description": "---\nlicense: apache-2.0\nlanguage:\n- si\n---\n### Fine tuned MT5 base model with Sinhala Wikipedia Dataset (Experimentally continues training)\n\nThis model is fine tuned with articles from Sinhala Wikipedia for article generation. Used around 10,000 articles for training and fine tuned arround 100 times.\n\n### How to use\n\nWe have to use **\"writeWiki: \"** part at the begining of each prompt.\n\nYou can use this model with a pipeline for text generation.\n\nFirst you might need to install required libraries and import them.\n```py\n!pip uninstall transformers -y\n!pip install transformers\n\npip install tokenizers sentencepiece\n```\n\nThen we might need to restart the runtime either manually or use the below code to end it. \n```py\nimport os\nos.kill(os.getpid(), 9)\n```\n\nThen we just have to import the tokenizer and run the pipeline:\n\n```py\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('google/mt5-small')\n\nfrom transformers import pipeline\ngenerator = pipeline(model='Suchinthana/MT5-Sinhala-Wikigen-Experimental', tokenizer=tokenizer)\ngenerator(\"writeWiki: \u0db8\u0dcf\u0db1\u0dc0 \u0d86\u0dc4\u0dcf\u0dbb\", do_sample=True, max_length=180)\n```", "size_bytes": "1200775901", "downloads": 7}