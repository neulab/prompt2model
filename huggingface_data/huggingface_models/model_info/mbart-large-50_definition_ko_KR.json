{"pretrained_model_name": "PoeticPaper/mbart-large-50_definition_ko_KR", "description": "The model can generate definition in Korean. Usage:\n```python\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n\ncheckpoint = 'PoeticPaper/mbart-large-50_definition_ko_KR'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint, src_lang=\"ko_KR\", tgt_lang=\"ko_KR\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\ngenerator = pipeline(\n    task='text2text-generation',\n    model=model,\n    tokenizer=tokenizer,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"ko_KR\"],\n)\n\ninput = \"define: \ud798\uc4f0\ub2e4 context: \uc6b0\ub9ac \uc5f0\uad6c\uc2e4\uc740 \ub300\uae30\uc624\uc5fc\uc744 \uc904\uc77c \uc218 \uc788\ub294 \uc790\ub3d9\ucc28 \uac1c\ubc1c\uc5d0 \ud798\uc4f0\uace0 \uc788\ub2e4. \uafb8\uc900\ud55c \ud64d\ubcf4\uc5d0 \ud798\uc4f4 \uacb0\uacfc \ub9ce\uc740 \uc0ac\ub78c\ub4e4\uc774 \uc6b0\ub9ac \ud68c\uc0ac\uc758 \uc0c1\ud488\uc744 \uc54c\uac8c \ub418\uc5c8\ub2e4. definition:\"\noutput = generator(input) # output will be: \"\uc5b4\ub5a4 \uc77c\uc744 \uc774\ub8e8\ub824\uace0 \ub178\ub825\ud558\ub2e4.\"\n```", "size_bytes": "2444683129", "downloads": 2}