{"pretrained_model_name": "inseq/wmt20-mlqe-en-de", "description": "---\nlanguage:\n- en\n- de\n- multilingual\nlicense: cc-by-sa-4.0\ntags:\n- translation\n- wmt20\ndatasets:\n- wmt/europarl\n- para_crawl\n- german-nlp-group/german_common_crawl\n- wmt/news-commentary\n- wmt/wikititles\n---\n\n# Fairseq En-De NMT WMT20 MLQE\n\nThis repository contains the English-German model trained with the [fairseq toolkit](https://github.com/pytorch/fairseq) that was used to produce translations used in the WMT20 shared task on quality estimation (QE) on the [MLQE dataset](https://github.com/facebookresearch/mlqe).\n\nThe checkpoint was converted from the original fairseq checkpoint available [here](https://github.com/facebookresearch/mlqe/tree/master/nmt_models) using the `convert_fsmt_original_pytorch_checkpoint_to_pytorch.py` script from the \ud83e\udd17 Transformers library (v4.26.0).\n\nPlease refer to the repositories linked above for additional information on usage, parameters and training data.\n", "size_bytes": "434204421", "downloads": 15}