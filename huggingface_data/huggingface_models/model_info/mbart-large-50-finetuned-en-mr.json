{"pretrained_model_name": "shivam/mbart-large-50-finetuned-en-mr", "description": "---\nLanguage Pair Finetuned:\n- en-mr\n\nMetrics:\n- sacrebleu\n  - WAT 2021: 16.11\n\n# mbart-large-finetuned-en-mr\n \n## Model Description\n This is the mbart-large-50 model finetuned on En-Mr corpus.\n  \n## Intended uses and limitations\n Mostly useful for English to Marathi translation but the mbart-large-50 model also supports other language pairs\n \n### How to use\n```python\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\nmodel = MBartForConditionalGeneration.from_pretrained(\"shivam/mbart-large-50-finetuned-en-mr\")\ntokenizer = MBart50TokenizerFast.from_pretrained(\"shivam/mbart-large-50-finetuned-en-mr\", src_lang=\"en_XX\", tgt_lang=\"mr_IN\")\n\nenglish_input_sentence = \"The Prime Minister said that cleanliness, or Swachhta, is one of the most important aspects of preventive healthcare.\"\nmodel_inputs = tokenizer(english_input_sentence, return_tensors=\"pt\")\ngenerated_tokens = model.generate(\n    **model_inputs,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"mr_IN\"]\n)\nmarathi_output_sentence = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\nprint(marathi_output_sentence)\n#\u0938\u094d\u0935\u091a\u094d\u091b\u0924\u093e \u0939\u093e \u092a\u094d\u0930\u0924\u093f\u092c\u0902\u0927\u093e\u0924\u094d\u092e\u0915 \u0906\u0930\u094b\u0917\u094d\u092f \u0938\u0947\u0935\u0947\u0924\u0940\u0932 \u0938\u0930\u094d\u0935\u093e\u0924 \u092e\u0939\u0924\u094d\u0924\u094d\u0935\u093e\u091a\u093e \u092a\u0948\u0932\u0942 \u0906\u0939\u0947, \u0905\u0938\u0947 \u092a\u0902\u0924\u092a\u094d\u0930\u0927\u093e\u0928 \u092e\u094d\u0939\u0923\u093e\u0932\u0947.\n```\n#### Limitations\n The model was trained on Google Colab and as the training takes a lot of time the model was trained for small time and small number of epochs.\n\n## Eval results \n WAT 2021: 16.11 ", "size_bytes": "2444714899", "downloads": 4}