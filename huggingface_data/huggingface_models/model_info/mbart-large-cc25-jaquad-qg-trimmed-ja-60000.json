{"pretrained_model_name": "vocabtrimmer/mbart-large-cc25-jaquad-qg-trimmed-ja-60000", "description": "# Vocabulary Trimmed [lmqg/mbart-large-cc25-jaquad-qg](https://huggingface.co/lmqg/mbart-large-cc25-jaquad-qg): `vocabtrimmer/mbart-large-cc25-jaquad-qg-trimmed-ja-60000` \nThis model is a trimmed version of [lmqg/mbart-large-cc25-jaquad-qg](https://huggingface.co/lmqg/mbart-large-cc25-jaquad-qg) by [`vocabtrimmer`](https://github.com/asahi417/lm-vocab-trimmer), a tool for trimming vocabulary of language models to compress the model size.\nFollowing table shows a summary of the trimming process.\n\n|                            | lmqg/mbart-large-cc25-jaquad-qg   | vocabtrimmer/mbart-large-cc25-jaquad-qg-trimmed-ja-60000   |\n|:---------------------------|:----------------------------------|:-----------------------------------------------------------|\n| parameter_size_full        | 610,852,864                       | 416,268,288                                                |\n| parameter_size_embedding   | 512,057,344                       | 122,888,192                                                |\n| vocab_size                 | 250,028                           | 60,004                                                     |\n| compression_rate_full      | 100.0                             | 68.15                                                      |\n| compression_rate_embedding | 100.0                             | 24.0                                                       |\n\n\nFollowing table shows the parameter used to trim vocabulary.\n\n | language   | dataset                     | dataset_column   | dataset_name   | dataset_split   |   target_vocab_size |   min_frequency |\n|:-----------|:----------------------------|:-----------------|:---------------|:----------------|--------------------:|----------------:|\n| ja         | vocabtrimmer/mc4_validation | text             | ja             | validation      |               60000 |               2 |", "size_bytes": "1665478137", "downloads": 2}