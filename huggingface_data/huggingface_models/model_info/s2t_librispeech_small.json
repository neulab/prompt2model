{"pretrained_model_name": "valhalla/s2t_librispeech_small", "description": "---\nlanguage: en\ndatasets:\n- librispeech_asr\ntags:\n- audio\n- automatic-speech-recognition\nlicense: apache-2.0\n---\n\nTODO: [To be filled]\n\n\n## Evaluation on LibriSpeech Test\n\nThe following script shows how to evaluate this model on the [LibriSpeech](https://huggingface.co/datasets/librispeech_asr) *\"clean\"* and *\"other\"* test dataset.\n\n```python\nfrom datasets import load_dataset\nfrom transformers import Speech2TextTransformerForConditionalGeneration, Speech2TextTransformerTokenizer\nimport soundfile as sf\nfrom jiwer import wer\n\nlibrispeech_eval = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\")  # change to \"other\" for other test dataset\n\nmodel = Speech2TextTransformerForConditionalGeneration.from_pretrained(\"valhalla/s2t_librispeech_small\").to(\"cuda\")\ntokenizer = Speech2TextTransformerTokenizer.from_pretrained(\"valhalla/s2t_librispeech_small\", do_upper_case=True)\n\ndef map_to_array(batch):\n    speech, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech\n    return batch\n\nlibrispeech_eval = librispeech_eval.map(map_to_array)\n\ndef map_to_pred(batch):\n    features = tokenizer(batch[\"speech\"], sample_rate=16000, padding=True, return_tensors=\"pt\")\n    input_features = features.input_features.to(\"cuda\")\n    attention_mask = features.attention_mask.to(\"cuda\")\n\n    gen_tokens = model.generate(input_ids=input_features, attention_mask=attention_mask)\n    batch[\"transcription\"] = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n    return batch\n\nresult = librispeech_eval.map(map_to_pred, batched=True, batch_size=8, remove_columns=[\"speech\"])\n\nprint(\"WER:\", wer(result[\"text\"], result[\"transcription\"]))\n```\n\n*Result (WER)*:\n\n| \"clean\" | \"other\" |\n|---|---|\n| 4.3 | 9.0 |", "size_bytes": "118281550", "downloads": 6}