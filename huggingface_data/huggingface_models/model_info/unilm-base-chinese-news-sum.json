{"pretrained_model_name": "Yuang/unilm-base-chinese-news-sum", "description": "---\nlanguage:\n  - zh\ntags:\n  - unilm\nlicense: apache-2.0\n---\n\n# unilm-base-chinese-news-sum\n\n```sh\npip install git+https://github.com/Liadrinz/transformers-unilm  # \u5b89\u88c5\u517c\u5bb9HuggingFace\u7684UniLM\u6a21\u578b\u4ee3\u7801\n```\n\n```py\nfrom unilm import UniLMTokenizer, UniLMForConditionalGeneration\n\n\nnews_article = (\n    \"12\u670823\u65e5\uff0c\u6cb3\u5317\u77f3\u5bb6\u5e84\u30028\u5c81\u54e5\u54e5\u8f7b\u8f66\u719f\u8def\u54c4\u7761\u5f1f\u5f1f\uff0c\u59ff\u52bf\u6807\u51c6\u52a8\u4f5c\u719f\u7ec3\u3002\"\n    \"\u5988\u5988\u6768\u5973\u58eb\u8868\u793a\uff1a\u54e5\u54e5\u5f88\u559c\u6b22\u5f1f\u5f1f\uff0c\u56e0\u4e3a\u5fc3\u601d\u6bd4\u8f83\u7ec6\uff0c\u81ea\u5df1\u5e73\u65f6\u5e26\u5b69\u5b50\u7684\u4e60\u60ef\u4ed6\u90fd\u4f1a\u8ddf\u7740\u5b66\u4e60\uff0c\"\n    \"\u54c4\u7761\u5b69\u5b50\u4e5f\u90fd\u4f1a\u4e89\u7740\u6765\uff0c\u6280\u5de7\u5f88\u5a34\u719f\uff0c\u4e24\u4eba\u5728\u4e00\u5757\u5f88\u6709\u7231\uff0c\u81ea\u5df1\u611f\u5230\u5f88\u5e78\u798f\uff0c\u5e73\u65f6\u5e2e\u4e86\u81ea\u5df1\u5f88\u5927\u7684\u5fd9\uff0c\u611f\u6069\u6709\u8fd9\u4e48\u4e56\u7684\u5b9d\u5b9d\u3002\"\n)\n\ntokenizer = UniLMTokenizer.from_pretrained(\"Yuang/unilm-base-chinese-news-sum\")\nmodel = UniLMForConditionalGeneration.from_pretrained(\"Yuang/unilm-base-chinese-news-sum\")\n\ninputs = tokenizer(news_article, return_tensors=\"pt\")\noutput_ids = model.generate(**inputs, max_new_tokens=16)\noutput_text = tokenizer.decode(output_ids[0])\nprint(output_text)  # \"[CLS] <news_article> [SEP] <news_summary> [SEP]\"\nnews_summary = output_text.split(\"[SEP]\")[1].strip()\nprint(news_summary)\n```\n", "size_bytes": "411608167", "downloads": 36}