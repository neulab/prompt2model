{"pretrained_model_name": "minhtoan/t5-translation-vietnamese-nom", "description": "---\nlanguage:\n- vi\ntags:\n- translation\nlicense: mit\nwidget:\n- text: \"\ud846\udd82\u624d\ud846\udd82\u547d\u7a96\udb81\udc7c\u6044\u9952\"\ninference:\n  parameters:\n    max_length: 48\npipeline_tag: translation\nlibrary_name: transformers\n---\n# Bidirectional Vietnamese N\u00f4m Transliteration\n\nVietnamese N\u00f4m, or Ch\u1eef N\u00f4m, was an ancient writing system in Vietnam before the 20th century. It evolved from Chinese characters but adapted to Vietnamese sounds and vocabulary. N\u00f4m was used by scholars for literature and communication. The script visually differed from Chinese characters and expressed Vietnamese concepts with semantic and phonetic components. Today, N\u00f4m is a specialized field, and efforts are made to preserve its knowledge. Though modern Vietnamese uses the Latin alphabet, N\u00f4m remains an integral part of Vietnam's cultural heritage.\n\n## State-of-the-art lightweights pretrained Transformer-based encoder-decoder model for Vietnamese Nom translation.\n\nModel trained on dataset Luc-Van- Tien\u2019s book, Tale Of Kieu book, \u201cHistory of Greater Vietnam\u201d book, \u201cChinh Phu Ngam Khuc\u201d poems, \u201cHo Xuan Huong\u201d poems, Corpus documents from chunom.org, sample texts coming from 130 different books (Tu-Dien-Chu-Nom-Dan Giai). \n\n\n## The model is trained and supports bidirectional translation between Vietnamese N\u00f4m script and Vietnamese Latin script, enabling the translation from N\u00f4m to Vietnamese Latin script and vice versa.\n\n## How to use\n\n\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ntokenizer = AutoTokenizer.from_pretrained(\"minhtoan/t5-translation-vietnamese-nom\")  \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"minhtoan/t5-translation-vietnamese-nom\")\nmodel.cuda()\nsrc = \"\u5982\u6885\u65e9\u674f\u9072\u7ba1\"\ntokenized_text = tokenizer.encode(src, return_tensors=\"pt\").cuda()\nmodel.eval()\ntranslate_ids = model.generate(tokenized_text, max_length=48)\noutput = tokenizer.decode(translate_ids[0], skip_special_tokens=True)\noutput\n```\n'nh\u01b0 mai t\u1ea3o h\u1ea1nh tr\u00ec qu\u00e1n'\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ntokenizer = AutoTokenizer.from_pretrained(\"minhtoan/t5-translation-vietnamese-nom\")  \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"minhtoan/t5-translation-vietnamese-nom\")\nmodel.cuda()\nsrc = \"nh\u01b0 mai t\u1ea3o h\u1ea1nh tr\u00ec qu\u00e1n\"\ntokenized_text = tokenizer.encode(src, return_tensors=\"pt\").cuda()\nmodel.eval()\ntranslate_ids = model.generate(tokenized_text, max_length=48)\noutput = tokenizer.decode(translate_ids[0], skip_special_tokens=True)\noutput\n```\n'\u5982\u6885\u65e9\u674f\u9072\u8218'\n\n\n\n## Author\n`\nPhan Minh Toan \n`", "size_bytes": "139421401", "downloads": 167}