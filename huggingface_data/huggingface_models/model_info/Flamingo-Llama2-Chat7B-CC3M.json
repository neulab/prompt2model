{"pretrained_model_name": "luodian/Flamingo-Llama2-Chat7B-CC3M", "description": "---\nlicense: mit\n---\n\n**TLDR**: We trained a Flamingo with Llama2-Chat7B as LLM on CC3M in less than 5 hours using just 4 A100s. \n\nThe model showed promising zero-shot captioning skills. High-quality captioning data really helps fast alignment.\n\nYou could test it via following code. Be sure to visit [Otter](https://github.com/Luodian/Otter) to get necessary Flamingo/Otter models.\n\n```python\nfrom flamingo.modeling_flamingo import FlamingoForConditionalGeneration\nflamingo_model = FlamingoForConditionalGeneration.from_pretrained(\"luodian/Flamingo-Llama2-Chat7B-CC3M\", device_map=auto)\nprompt = \"<image>an image of\"\nsimple_prompt = \"<image>\"\n```", "size_bytes": 32881829960, "downloads": 128}