{"pretrained_model_name": "mjk0618/mt-ko-en-scitech", "description": "---\nlanguage:\n- ko\n- en\nmetrics:\n- bleu\npipeline_tag: translation\ntags:\n- science\n- technology\n---\n\n# Model Overview\nThis model is fine-tuned model of \"Helsinki-NLP/opus-mt-ko-en\" <br/>\nThe model has been trained with 1,198,943 Korean, Enlgish sentence pairs which mainly contains science, technology terms. \n\n# Load Model\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"mjk0618/mt-ko-en-scitech\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"mjk0618/mt-ko-en-scitech\")\n```\n\n# How to use\n```python\n# After loading model\nsentence = \"\uc778\uacf5\uc9c0\ub2a5\uc740 \uc778\uac04\uc758 \ud559\uc2b5\ub2a5\ub825, \ucd94\ub860\ub2a5\ub825, \uc9c0\uac01\ub2a5\ub825\uc744 \uc778\uacf5\uc801\uc73c\ub85c \uad6c\ud604\ud558\ub824\ub294 \ucef4\ud4e8\ud130 \uacfc\ud559\uc758 \uc138\ubd80\ubd84\uc57c \uc911 \ud558\ub098\uc774\ub2e4\"\n\ninputs = tokenizer(sentence, return_tensors=\"pt\").input_ids\noutputs = model.generate(inputs)[0]\ntranslated_sentence = tokenizer.decode(outputs, skip_special_tokens=True)\n\nprint(translated_sentence)\n# Artificial intelligence is one of the details of computer science that artifically implements human learning ability, reasoning ability, and perception ability.\n```", "size_bytes": "310022533", "downloads": 16}