{"pretrained_model_name": "Hariharavarshan/Cover_genie", "description": "---\nlicense: apache-2.0\nlanguage:\n- en\nmetrics:\n- rouge\nlibrary_name: transformers\n---\n# Model Card for CoverGenie\n\n<!-- Provide a quick summary of what the model is/does. -->\n\nThe goal of this project is to build a fine-grained mini-ChatGPT (named \u201cCoverGenie\u201d) , which is designed to generate resumes and cover letters based on job descriptions from the tech field. \nBy nature,it is a language generation task, and it takes the job description as input to a sequence of text and turns it into a structured, certain style of resumes and cover letters.\nThis might involve parameter efficient finetuning, reinforcement learning and prompting engineering to some extent.\n\n## Model Details\n\n### Model Description\n\n<!-- Provide a longer summary of what this model is. -->\n\n- **Model type:** T5 (Text-to-Text-Transfer-Transformer)\n- **Language(s) (NLP):** [More Information Needed]\n- **License:** Apache-2.0\n- **Finetuned from model:** FlanT5 Large \n\n### Model Sources [optional]\n\n<!-- Provide the basic links for the model. -->\n\n- **Repository:** [More Information Needed]\n- **Paper [optional]:** https://arxiv.org/pdf/2210.11416.pdf\n\n\n## Uses\n\nIt Can Generate Cover letter if we are able to input the **Job description** and **Resume** of a candidate.\n\n# How to Get Started with the Model\n\nUse the code below to get started with the model.\n\n<details>\n<summary> Click to expand </summary>\n\n```python\nfrom transformers import GenerationConfig\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom transformers import GenerationConfig\nimport nltk\nnltk.download('punkt')\nmax_source_length=512 \ntokenizer = AutoTokenizer.from_pretrained(\"Hariharavarshan/Cover_genie\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Hariharavarshan/Cover_genie\")\nJD='''<Job description Text>'''\nresume_text= '''<Resume Text>'''\nfinal_text=\"give me a cover letter based on the a job description and a resume. Job description:\"+JD +\" Resume:\"+ resume_text\ngeneration_config = GenerationConfig.from_pretrained(\"google/flan-t5-large\",temperature=2.0)\ninputs = tokenizer(final_text, max_length=max_source_length, truncation=True, return_tensors=\"pt\")\noutput = model.generate(**inputs, num_beams=3, do_sample=True, min_length=1000,\n                               max_length=10000,generation_config=generation_config,num_return_sequences=3)\ndecoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\ngenerated_Coverletter = nltk.sent_tokenize(decoded_output.strip())\n```\n\n**Developed by:** Hariharavarshan,Jayathilaga,Sara,Meiyu\n", "size_bytes": "3132785797", "downloads": 8}