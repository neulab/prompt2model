{"pretrained_model_name": "ihgn/gpt3-paraphrase", "description": "---\nlanguage:\n- en\nmetrics:\n- bleu\n- rouge\npipeline_tag: text2text-generation\n---\n\n    def paraphrase(\n        question,\n        num_beams=5,\n        num_beam_groups=5,\n        num_return_sequences=1,\n        repetition_penalty=10.0,\n        diversity_penalty=3.0,\n        no_repeat_ngram_size=2,\n        temperature=0.7,\n        max_length=128\n    ):\n      input_ids = tokenizer(\n          f'paraphrase: {question}',\n          return_tensors=\"pt\", \n          padding=\"longest\",\n          max_length=max_length,\n          truncation=True,\n      ).input_ids\n      \n      outputs = model.generate(\n          input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n          num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n          num_beams=num_beams, num_beam_groups=num_beam_groups,\n          max_length=max_length, diversity_penalty=diversity_penalty\n      )\n  \n      res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n  \n      return res", "size_bytes": "891702929", "downloads": 57}