{"pretrained_model_name": "bogdancazan/t5-small-wikilarge-newsela-with-domain-adaptation", "description": "training_args = TrainingArguments(\n    output_dir='t5-small-wikilarge-newsela-with-domain-adaptation',\n    num_train_epochs=20,\n    warmup_steps=250,\n    per_device_train_batch_size=BATCH_SIZE,\n    weight_decay=0.01,\n    learning_rate=2e-4,\n    # fp16=True,\n    optim=\"adafactor\",\n)\n\nStep\tTraining Loss\n500\t3.313300\n1000\t2.914200\n1500\t2.848100\n2000\t2.811700\n2500\t2.789700\n3000\t2.771400\n3500\t2.761500\n4000\t2.749600\n4500\t2.732300\n5000\t2.729400\n5500\t2.717600\n6000\t2.703000\n6500\t2.699100\n7000\t2.686200\n7500\t2.681000\n8000\t2.679300\n8500\t2.667100\n9000\t2.656400\n9500\t2.656200\n10000\t2.645100\n10500\t2.648600\n11000\t2.638400\n11500\t2.636200\n12000\t2.633500\n12500\t2.632400\n13000\t2.622300\n13500\t2.624400\n14000\t2.618200\n14500\t2.614300\n15000\t2.616600\n15500\t2.610700\n16000\t2.613600\nTrainOutput(global_step=16060, training_loss=2.709684318266948, metrics={'train_runtime': 3869.7584, 'train_samples_per_second': 530.839, 'train_steps_per_second': 4.15, 'total_flos': 0.0, 'train_loss': 2.709684318266948, 'epoch': 20.0})\n\n\tsari\tbleu\n0\t36.778905\t38.143843", "size_bytes": "242071641", "downloads": 3}