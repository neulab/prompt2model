{"pretrained_model_name": "allegro/plt5-small", "description": "---\nlanguage: pl\ntags:\n- T5\n- translation\n- summarization\n- question answering\n- reading comprehension\ndatasets:\n- ccnet\n- nkjp\n- wikipedia\n- open subtitles\n- free readings\nlicense: cc-by-4.0\n---\n\n# plT5 Small\n**plT5** models are T5-based language models trained on Polish corpora. The models were optimized for the original T5 denoising target.\n\n## Corpus\nplT5 was trained on six different corpora available for Polish language:\n\n| Corpus | Tokens | Documents |\n| :------ | ------: | ------: |\n| [CCNet Middle](https://github.com/facebookresearch/cc_net) | 3243M  | 7.9M |\n| [CCNet Head](https://github.com/facebookresearch/cc_net) | 2641M  | 7.0M |\n| [National Corpus of Polish](http://nkjp.pl/index.php?page=14&lang=1)| 1357M  | 3.9M |\n| [Open Subtitles](http://opus.nlpl.eu/OpenSubtitles-v2018.php) | 1056M  | 1.1M \n| [Wikipedia](https://dumps.wikimedia.org/) | 260M  | 1.4M |\n| [Wolne Lektury](https://wolnelektury.pl/) | 41M  | 5.5k |\n\n## Tokenizer\nThe training dataset was tokenized into subwords using a sentencepiece unigram model with\nvocabulary size of 50k tokens. \n\n## Usage\nExample code:\n```python\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"allegro/plt5-small\")\nmodel = AutoModel.from_pretrained(\"allegro/plt5-small\")\n```\n\n## License\nCC BY 4.0\n\n## Citation\nIf you use this model, please cite the following paper:\n```\n@article{chrabrowa2022evaluation,\n  title={Evaluation of Transfer Learning for Polish with a Text-to-Text Model},\n  author={Chrabrowa, Aleksandra and Dragan, {\\L}ukasz and Grzegorczyk, Karol and Kajtoch, Dariusz and Koszowski, Miko{\\l}aj and Mroczkowski, Robert and Rybak, Piotr},\n  journal={arXiv preprint arXiv:2205.08808},\n  year={2022}\n}\n```\n\n## Authors\nThe model was trained by [**Machine Learning Research Team at Allegro**](https://ml.allegro.tech/) and [**Linguistic Engineering Group at Institute of Computer Science, Polish Academy of Sciences**](http://zil.ipipan.waw.pl/).\n\nYou can contact us at: <a href=\"mailto:klejbenchmark@allegro.pl\">klejbenchmark@allegro.pl</a>", "size_bytes": "381332827", "downloads": 98}