{"pretrained_model_name": "nielsr/codet5-small-code-summarization-ruby", "description": "---\nlicense: apache-2.0\ntags:\n- codet5\ndatasets:\n- code_x_glue_ct_code_to_text\nwidget:\n- text: 'def pad(tensor, paddings, mode: \"CONSTANT\", name: nil) _op(:pad, tensor, paddings, mode: mode, name: name) end </s>'\n---\n\n# Description\n\nCodeT5-small model, fine-tuned on the code summarization subtask of CodeXGLUE (Ruby programming language). This model can generate a docstring of a given function written in Ruby.\n\n# Notebook\n\nThe notebook that I used to fine-tune CodeT5 can be found [here](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tune_CodeT5_for_generating_docstrings_from_Ruby_code.ipynb).\n\n# Usage\n\nHere's how to use this model: \n\n```python\nfrom transformers import RobertaTokenizer, T5ForConditionalGeneration\n\nmodel_name = \"nielsr/codet5-small-code-summarization-ruby\"\ntokenizer = RobertaTokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\ncode = \"\"\"\ndef update_with_file_contents(digest, filename)\n      File.open(filename) do |io|\n        while (chunk = io.read(1024 * 8))\n          digest.update(chunk)\n        end\n      end\n    end\n\"\"\"\n\ninput_ids = tokenizer(code, return_tensors=\"pt\").input_ids\noutputs = model.generate(input_ids)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n# Update the digest with the contents of the given file\n```", "size_bytes": "242026427", "downloads": 14}