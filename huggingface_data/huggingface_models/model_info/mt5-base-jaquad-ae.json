{"pretrained_model_name": "lmqg/mt5-base-jaquad-ae", "description": "\n---\nlicense: cc-by-4.0\nmetrics:\n- bleu4\n- meteor\n- rouge-l\n- bertscore\n- moverscore\nlanguage: ja\ndatasets:\n- lmqg/qg_jaquad\npipeline_tag: text2text-generation\ntags:\n- answer extraction\nwidget:\n- text: \"\u300e\u30af\u30de\u306e\u30d7\u30fc\u3055\u3093\u300f\u306e\u7269\u8a9e\u306f\u307e\u305a1925\u5e7412\u670824\u65e5\u3001\u300e\u30a4\u30f4\u30cb\u30f3\u30b0\u30fb\u30cb\u30e5\u30fc\u30b9\u300f\u7d19\u306e\u30af\u30ea\u30b9\u30de\u30b9\u7279\u96c6\u53f7\u306b\u77ed\u7de8\u4f5c\u54c1\u3068\u3057\u3066\u63b2\u8f09\u3055\u308c\u305f\u3002\u3053\u308c\u306f\u300e\u30af\u30de\u306e\u30d7\u30fc\u3055\u3093\u300f\u306e\u7b2c\u4e00\u7ae0\u306b\u3042\u305f\u308b\u4f5c\u54c1\u3067\u3001\u3053\u306e\u3068\u304d\u3060\u3051\u306f\u633f\u7d75\u3092J.H.\u30c0\u30a6\u30c9\u304c\u3064\u3051\u3066\u3044\u308b\u3002\u305d\u306e\u5f8c\u4f5c\u54c110\u8a71\u3068\u633f\u7d75\u304c\u6574\u3044\u3001\u520a\u884c\u306b\u5148\u99c6\u3051\u3066\u300c\u30a4\u30fc\u30e8\u30fc\u306e\u8a95\u751f\u65e5\u300d\u306e\u30a8\u30d4\u30bd\u30fc\u30c9\u304c1926\u5e748\u6708\u306b\u300e\u30ed\u30a4\u30e4\u30eb\u30de\u30ac\u30b8\u30f3\u300f\u306b\u3001\u540c\u5e7410\u67089\u65e5\u306b\u300e\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u30fb\u30a4\u30f4\u30cb\u30f3\u30b0\u30fb\u30dd\u30b9\u30c8\u300f\u7d19\u306b\u63b2\u8f09\u3055\u308c\u305f\u3042\u3068\u3001\u540c\u5e7410\u670814\u65e5\u306b\u30ed\u30f3\u30c9\u30f3\u3067(\u30e1\u30b7\u30e5\u30a8\u30f3\u793e)\u300121\u65e5\u306b\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u3067(\u30c0\u30c3\u30c8\u30f3\u793e)\u300e\u30af\u30de\u306e\u30d7\u30fc\u3055\u3093\u300f\u304c\u520a\u884c\u3055\u308c\u305f\u3002<hl>\u524d\u8457\u300e\u307c\u304f\u305f\u3061\u304c\u3068\u3066\u3082\u3061\u3044\u3055\u304b\u3063\u305f\u3053\u308d\u300f\u304c\u3059\u3067\u306b\u5927\u304d\u306a\u6210\u529f\u3092\u53ce\u3081\u3066\u3044\u305f\u3053\u3068\u3082\u3042\u308a\u3001\u30a4\u30ae\u30ea\u30b9\u3067\u306f\u521d\u7248\u306f\u524d\u8457\u306e7\u500d\u306b\u5f53\u305f\u308b3\u4e075000\u90e8\u304c\u5237\u3089\u308c\u305f\u3002<hl>\u4ed6\u65b9\u306e\u30a2\u30e1\u30ea\u30ab\u3067\u3082\u305d\u306e\u5e74\u306e\u7d42\u308f\u308a\u307e\u3067\u306b15\u4e07\u90e8\u3092\u58f2\u308a\u4e0a\u3052\u3066\u3044\u308b\u3002\u305f\u3060\u3057\u4f9d\u7136\u3068\u3057\u3066\u4eba\u6c17\u306e\u3042\u3063\u305f\u524d\u8457\u3092\u58f2\u308a\u4e0a\u3052\u3067\u8ffd\u3044\u8d8a\u3059\u306b\u306f\u6570\u5e74\u306e\u6642\u9593\u3092\u8981\u3057\u305f\u3002\"\n  example_title: \"Answering Extraction Example 1\" \n- text: \"\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u3067\u306f\u300117\u4e16\u7d00\u306e\u30aa\u30e9\u30f3\u30c0\u306e\u753b\u5bb6\u3001\u30e8\u30cf\u30cd\u30b9\u30fb\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u306b\u3064\u3044\u3066\u8a18\u8ff0\u3059\u308b\u3002\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u306f\u3001\u7591\u554f\u4f5c\u3082\u542b\u308130\u6570\u70b9\u3057\u304b\u73fe\u5b58\u3057\u306a\u3044\u3002<hl>\u73fe\u5b58\u4f5c\u54c1\u306f\u3059\u3079\u3066\u6cb9\u5f69\u753b\u3067\u3001\u7248\u753b\u3001\u4e0b\u7d75\u3001\u7d20\u63cf\u306a\u3069\u306f\u6b8b\u3063\u3066\u3044\u306a\u3044\u3002\u4ee5\u4e0b\u306b\u306f\u82e5\u5e72\u306e\u7591\u554f\u4f5c\u3082\u542b\u3081\u300137\u70b9\u306e\u57fa\u672c\u60c5\u5831\u3092\u8a18\u8f09\u3057\u3001\u5404\u4f5c\u54c1\u306b\u3064\u3044\u3066\u7565\u8aac\u3059\u308b\u3002<hl>\u53ce\u9332\u9806\u5e8f\u3001\u63a8\u5b9a\u5236\u4f5c\u5e74\u4ee3\u306f\u300e\u300c\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u3068\u305d\u306e\u6642\u4ee3\u5c55\u300d\u56f3\u9332\u300f\u306b\u3088\u308b\u3002\u65e5\u672c\u8a9e\u306e\u4f5c\u54c1\u30bf\u30a4\u30c8\u30eb\u306b\u3064\u3044\u3066\u306f\u3001\u4e0a\u63b2\u56f3\u9332\u306e\u307b\u304b\u3001\u300e\u300c\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u5c55\u300d\u56f3\u9332\u300f\u3001\u300e\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u751f\u6daf\u3068\u4f5c\u54c1\u300f\u306b\u3088\u308b\u3002\u4fbf\u5b9c\u4e0a\u300c1650\u5e74\u4ee3\u306e\u4f5c\u54c1\u300d\u300c1660\u5e74\u4ee3\u306e\u4f5c\u54c1\u300d\u300c1670\u5e74\u4ee3\u306e\u4f5c\u54c1\u300d\u306e3\u3064\u306e\u7bc0\u3092\u8a2d\u3051\u305f\u304c\u3001\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u306b\u306f\u5236\u4f5c\u5e74\u4ee3\u4e0d\u660e\u306e\u3082\u306e\u304c\u591a\u304f\u3001\u63a8\u5b9a\u5236\u4f5c\u5e74\u4ee3\u306b\u3064\u3044\u3066\u306f\u7814\u7a76\u8005\u3084\u6587\u732e\u306b\u3088\u3063\u3066\u82e5\u5e72\u306e\u5dee\u304c\u3042\u308b\u3002\"\n  example_title: \"Answering Extraction Example 2\" \nmodel-index:\n- name: lmqg/mt5-base-jaquad-ae\n  results:\n  - task:\n      name: Text2text Generation\n      type: text2text-generation\n    dataset:\n      name: lmqg/qg_jaquad\n      type: default\n      args: default\n    metrics:\n    - name: BLEU4 (Answer Extraction)\n      type: bleu4_answer_extraction\n      value: 26.48\n    - name: ROUGE-L (Answer Extraction)\n      type: rouge_l_answer_extraction\n      value: 35.58\n    - name: METEOR (Answer Extraction)\n      type: meteor_answer_extraction\n      value: 25.61\n    - name: BERTScore (Answer Extraction)\n      type: bertscore_answer_extraction\n      value: 77.33\n    - name: MoverScore (Answer Extraction)\n      type: moverscore_answer_extraction\n      value: 64.96\n    - name: AnswerF1Score (Answer Extraction)\n      type: answer_f1_score__answer_extraction\n      value: 28.33\n    - name: AnswerExactMatch (Answer Extraction)\n      type: answer_exact_match_answer_extraction\n      value: 28.33\n---\n\n# Model Card of `lmqg/mt5-base-jaquad-ae`\nThis model is fine-tuned version of [google/mt5-base](https://huggingface.co/google/mt5-base) for answer extraction on the [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) (dataset_name: default) via [`lmqg`](https://github.com/asahi417/lm-question-generation).\n\n\n### Overview\n- **Language model:** [google/mt5-base](https://huggingface.co/google/mt5-base)   \n- **Language:** ja  \n- **Training data:** [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) (default)\n- **Online Demo:** [https://autoqg.net/](https://autoqg.net/)\n- **Repository:** [https://github.com/asahi417/lm-question-generation](https://github.com/asahi417/lm-question-generation)\n- **Paper:** [https://arxiv.org/abs/2210.03992](https://arxiv.org/abs/2210.03992)\n\n### Usage\n- With [`lmqg`](https://github.com/asahi417/lm-question-generation#lmqg-language-model-for-question-generation-)\n```python\nfrom lmqg import TransformersQG\n\n# initialize model\nmodel = TransformersQG(language=\"ja\", model=\"lmqg/mt5-base-jaquad-ae\")\n\n# model prediction\nanswers = model.generate_a(\"\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u3067\u306f\u300117\u4e16\u7d00\u306e\u30aa\u30e9\u30f3\u30c0\u306e\u753b\u5bb6\u3001\u30e8\u30cf\u30cd\u30b9\u30fb\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u306b\u3064\u3044\u3066\u8a18\u8ff0\u3059\u308b\u3002\u30d5\u30a7\u30eb\u30e1\u30fc\u30eb\u306e\u4f5c\u54c1\u306f\u3001\u7591\u554f\u4f5c\u3082\u542b\u308130\u6570\u70b9\u3057\u304b\u73fe\u5b58\u3057\u306a\u3044\u3002\u73fe\u5b58\u4f5c\u54c1\u306f\u3059\u3079\u3066\u6cb9\u5f69\u753b\u3067\u3001\u7248\u753b\u3001\u4e0b\u7d75\u3001\u7d20\u63cf\u306a\u3069\u306f\u6b8b\u3063\u3066\u3044\u306a\u3044\u3002\")\n\n```\n\n- With `transformers`\n```python\nfrom transformers import pipeline\n\npipe = pipeline(\"text2text-generation\", \"lmqg/mt5-base-jaquad-ae\")\noutput = pipe(\"\u300e\u30af\u30de\u306e\u30d7\u30fc\u3055\u3093\u300f\u306e\u7269\u8a9e\u306f\u307e\u305a1925\u5e7412\u670824\u65e5\u3001\u300e\u30a4\u30f4\u30cb\u30f3\u30b0\u30fb\u30cb\u30e5\u30fc\u30b9\u300f\u7d19\u306e\u30af\u30ea\u30b9\u30de\u30b9\u7279\u96c6\u53f7\u306b\u77ed\u7de8\u4f5c\u54c1\u3068\u3057\u3066\u63b2\u8f09\u3055\u308c\u305f\u3002\u3053\u308c\u306f\u300e\u30af\u30de\u306e\u30d7\u30fc\u3055\u3093\u300f\u306e\u7b2c\u4e00\u7ae0\u306b\u3042\u305f\u308b\u4f5c\u54c1\u3067\u3001\u3053\u306e\u3068\u304d\u3060\u3051\u306f\u633f\u7d75\u3092J.H.\u30c0\u30a6\u30c9\u304c\u3064\u3051\u3066\u3044\u308b\u3002\u305d\u306e\u5f8c\u4f5c\u54c110\u8a71\u3068\u633f\u7d75\u304c\u6574\u3044\u3001\u520a\u884c\u306b\u5148\u99c6\u3051\u3066\u300c\u30a4\u30fc\u30e8\u30fc\u306e\u8a95\u751f\u65e5\u300d\u306e\u30a8\u30d4\u30bd\u30fc\u30c9\u304c1926\u5e748\u6708\u306b\u300e\u30ed\u30a4\u30e4\u30eb\u30de\u30ac\u30b8\u30f3\u300f\u306b\u3001\u540c\u5e7410\u67089\u65e5\u306b\u300e\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u30fb\u30a4\u30f4\u30cb\u30f3\u30b0\u30fb\u30dd\u30b9\u30c8\u300f\u7d19\u306b\u63b2\u8f09\u3055\u308c\u305f\u3042\u3068\u3001\u540c\u5e7410\u670814\u65e5\u306b\u30ed\u30f3\u30c9\u30f3\u3067(\u30e1\u30b7\u30e5\u30a8\u30f3\u793e)\u300121\u65e5\u306b\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u3067(\u30c0\u30c3\u30c8\u30f3\u793e)\u300e\u30af\u30de\u306e\u30d7\u30fc\u3055\u3093\u300f\u304c\u520a\u884c\u3055\u308c\u305f\u3002<hl>\u524d\u8457\u300e\u307c\u304f\u305f\u3061\u304c\u3068\u3066\u3082\u3061\u3044\u3055\u304b\u3063\u305f\u3053\u308d\u300f\u304c\u3059\u3067\u306b\u5927\u304d\u306a\u6210\u529f\u3092\u53ce\u3081\u3066\u3044\u305f\u3053\u3068\u3082\u3042\u308a\u3001\u30a4\u30ae\u30ea\u30b9\u3067\u306f\u521d\u7248\u306f\u524d\u8457\u306e7\u500d\u306b\u5f53\u305f\u308b3\u4e075000\u90e8\u304c\u5237\u3089\u308c\u305f\u3002<hl>\u4ed6\u65b9\u306e\u30a2\u30e1\u30ea\u30ab\u3067\u3082\u305d\u306e\u5e74\u306e\u7d42\u308f\u308a\u307e\u3067\u306b15\u4e07\u90e8\u3092\u58f2\u308a\u4e0a\u3052\u3066\u3044\u308b\u3002\u305f\u3060\u3057\u4f9d\u7136\u3068\u3057\u3066\u4eba\u6c17\u306e\u3042\u3063\u305f\u524d\u8457\u3092\u58f2\u308a\u4e0a\u3052\u3067\u8ffd\u3044\u8d8a\u3059\u306b\u306f\u6570\u5e74\u306e\u6642\u9593\u3092\u8981\u3057\u305f\u3002\")\n\n```\n\n## Evaluation\n\n\n- ***Metric (Answer Extraction)***: [raw metric file](https://huggingface.co/lmqg/mt5-base-jaquad-ae/raw/main/eval/metric.first.answer.paragraph_sentence.answer.lmqg_qg_jaquad.default.json) \n\n|                  |   Score | Type    | Dataset                                                          |\n|:-----------------|--------:|:--------|:-----------------------------------------------------------------|\n| AnswerExactMatch |   28.33 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| AnswerF1Score    |   28.33 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| BERTScore        |   77.33 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| Bleu_1           |   33.75 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| Bleu_2           |   30.74 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| Bleu_3           |   28.29 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| Bleu_4           |   26.48 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| METEOR           |   25.61 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| MoverScore       |   64.96 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n| ROUGE_L          |   35.58 | default | [lmqg/qg_jaquad](https://huggingface.co/datasets/lmqg/qg_jaquad) |\n\n\n\n## Training hyperparameters\n\nThe following hyperparameters were used during fine-tuning:\n - dataset_path: lmqg/qg_jaquad\n - dataset_name: default\n - input_types: ['paragraph_sentence']\n - output_types: ['answer']\n - prefix_types: None\n - model: google/mt5-base\n - max_length: 512\n - max_length_output: 32\n - epoch: 9\n - batch: 8\n - lr: 0.0005\n - fp16: False\n - random_seed: 1\n - gradient_accumulation_steps: 8\n - label_smoothing: 0.15\n\nThe full configuration can be found at [fine-tuning config file](https://huggingface.co/lmqg/mt5-base-jaquad-ae/raw/main/trainer_config.json).\n\n## Citation\n```\n@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}\n\n```\n", "size_bytes": "2329634869", "downloads": 11}