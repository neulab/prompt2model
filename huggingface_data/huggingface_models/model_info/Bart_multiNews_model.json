{"pretrained_model_name": "usakha/Bart_multiNews_model", "description": "---\ndatasets:\n- multi_news\nmetrics:\n- bleu\n- rouge\npipeline_tag: summarization\n---\n# Hyperparameters\n    learning_rate=2e-5\n    per_device_train_batch_size=14\n    per_device_eval_batch_size=14\n    weight_decay=0.01\n    save_total_limit=3\n    num_train_epochs=3\n    predict_with_generate=True\n    fp16=True\n\n# Training Output\n    global_step=7710\n    training_loss=2.1297076629757417\n    metrics={'train_runtime': 6059.0418, \n    'train_samples_per_second': 17.813, \n    'train_steps_per_second': 1.272, \n    'total_flos': 2.3389776681055027e+17, \n    'train_loss': 2.1297076629757417, \n    'epoch': 3.0}\n\n# Training Results\n\n| Epoch\t| Training Loss | Validation Loss |  Rouge1  |  Rouge2\t|  Rougel  | Rougelsum |   Bleu\t  |  Gen Len  |\n|:----- |:------------  |:--------------- |:-------- | :------- |:-------- |:--------- |:-------- |:--------- |\n|  1    |    2.223100   |     2.038599    | 0.147400 | 0.054800 | 0.113500 |  0.113500 | 0.001400 | 20.000000 |\n|  2\t|    2.078100   |     2.009619    | 0.152900 | 0.057800 | 0.117000 |  0.117000 | 0.001600 | 20.000000 |\n|  3\t|    1.989000   |     2.006006    | 0.152900 | 0.057300 | 0.116700 |  0.116700 | 0.001700 | 20.000000 |", "size_bytes": "1625541389", "downloads": 29}