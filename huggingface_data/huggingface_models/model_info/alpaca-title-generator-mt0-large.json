{"pretrained_model_name": "theblackcat102/alpaca-title-generator-mt0-large", "description": "---\nlicense: mit\nlanguage:\n- en\n- zh\n- de\n- fr\n- ja\n- ko\n- es\nwidget:\n- text: Hi assistant How can I help you\n- text: Guten Morgen! Wie kann ich Ihnen helfen?\n- text: \u3069\u3046\u3059\u308c\u3070\u904b\u52d5\u3092\u7d9a\u3051\u3089\u308c\u307e\u3059\u304b\uff1f \u904b\u52d5\u3092\u7d9a\u3051\u308b\u3053\u3068\u306f\u3001\u5065\u5eb7\u7684\u306a\u751f\u6d3b\u3092\u7dad\u6301\u3059\u308b\u4e0a\u3067\u975e\u5e38\u306b\u91cd\u8981\u3067\u3059\u304c\u3001\u30e2\u30c1\u30d9\u30fc\u30b7\u30e7\u30f3\u3092\u7dad\u6301\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u4ee5\u4e0b\u306b\u3044\u304f\u3064\u304b\u306e\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n- text: \uc138\uacc4 1\ucc28 \ub300\uc804\uc740 1914\ub144\ubd80\ud130 1918\ub144\uae4c\uc9c0 \uc804 \uc138\uacc4\uc801\uc73c\ub85c \ubc8c\uc5b4\uc9c4 \ub300\uaddc\ubaa8 \uc804\uc7c1\uc785\ub2c8\ub2e4. \uc8fc\uc694\ud55c \ucc38\uc804\uad6d\uc73c\ub85c\ub294 \ub3c5\uc77c, \uc624\uc2a4\ud2b8\ub9ac\uc544-\ud5dd\uac00\ub9ac \uc81c\uad6d, \uc601\uad6d, \ud504\ub791\uc2a4, \ub7ec\uc2dc\uc544, \uc774\ud0c8\ub9ac\uc544, \ubbf8\uad6d \ub4f1\uc774 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.\n- text: \u3053\u3093\u306b\u3061\u306f\uff01\u304a\u5143\u6c17\u3067\u3059\u304b\uff1f\u4f55\u304b\u304a\u624b\u4f1d\u3044\u3067\u304d\u308b\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u304b\uff1f\n- text: user&#58; Python \u548c C++ \u54ea\u4e2a\u66f4\u597d\u5b66\uff1f\u54ea\u4e2a\u66f4\u5f3a\u5927\uff1f\u6211\u8be5\u600e\u4e48\u9009\u62e9\uff1f\n- text: \u5728\u5927\u71b1\u5929\u88e1\uff0c\u58a8\u93e1\u7684\u92b7\u552e\u8207\u51b0\u6dc7\u6dcb\u7684\u92b7\u552e\u6709\u8457\u9ad8\u5ea6\u76f8\u95dc\u6027\u3002\u7576\u5929\u6c23\u5f88\u71b1\u7684\u6642\u5019\uff0c\u5169\u500b\u90fd\u5341\u5206\u71b1\u8ce3\uff0c\u800c\u5929\u6c23\u8f49\u6dbc\u4ee5\u5f8c\u5169\u8005\u7684\u92b7\u552e\u5c31\u5e95\u843d\u8c37\u5e95\u3002\u7576\u6709\u4e00\u5929\uff0c\u58a8\u93e1\u6279\u767c\u5546\u8eca\u8f1b\u5728\u4e0a\u73ed\u9014\u4e2d\u62cb\u9328\uff0c\u56e0\u6b64\u7121\u6cd5\u958b\u696d\uff0c\u5c0e\u81f4\u58a8\u93e1\u92b7\u552e\u8b8a 0 \u3002\u8acb\u554f\u7576\u5929\u51b0\u6dc7\u6dcb\u7684\u92b7\u552e\u5982\u4f55\uff1f\n- text: >-\n    user&#58; Good morning\\n assistant&#58; Good morning! How can I assist you\n    today?\npipeline_tag: text2text-generation\ntags:\n- text-generation-inference\n---\n\n# Generate title for conversation\n\n## How to use\n\n```python\nmodel_name = \"theblackcat102/alpaca-title-generator-mt0-large\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\nquestion = 'Hi\\nHow can I help you?'\nencodes = tokenizer(question, return_tensors='pt')\noutputs = model.generate(encodes.input_ids, \n    max_length=512,\n    do_sample=True,\n    repetition_penalty=1.2,\n    top_k=50,\n    num_return_sequences=1,\n    early_stopping=True\n)\nfor i, beam_output in enumerate(outputs):\n    print('-----')\n    print(\"{}\".format(tokenizer.decode(beam_output, skip_special_tokens=True)))\n# > Help requested.\n```\n\n## Generate title data\n\ndata was generated using response pair from `yahma/alpaca-cleaned` and use openai turbo model for title.\n\n```\n\"\"\nuser: {}\nassistant: {}\n\"\"\n\nGenerate a very short title within 5 words of the conversation above, title must be as relevant as possible. Title language must be same as the context\n\nTITLE: \n```", "size_bytes": "2459242663", "downloads": 282}