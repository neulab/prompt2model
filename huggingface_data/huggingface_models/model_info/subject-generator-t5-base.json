{"pretrained_model_name": "Chirayu/subject-generator-t5-base", "description": "# What does this model do?\nThis model generates a subject line for the email, given the whole email as input. It is fine-tuned T5-Base\n\nHere is how to use this model\n\n```python\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Chirayu/subject-generator-t5-base\")\ntokenizer = AutoTokenizer.from_pretrained(\"Chirayu/subject-generator-t5-base\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ndef get_subject(content, num_beams=5,max_length=512, repetition_penalty=2.5, length_penalty=1, early_stopping=True,top_p=.95, top_k=50, num_return_sequences=3):\n  \n  text =  \"title: \" + content + \" </s>\"\n  \n  input_ids = tokenizer.encode(\n    text, return_tensors=\"pt\", add_special_tokens=True\n  )\n  \n  input_ids = input_ids.to(device)\n  generated_ids = model.generate(\n      input_ids=input_ids,\n     \n      num_beams=num_beams,\n      max_length=max_length,\n      repetition_penalty=repetition_penalty,\n      length_penalty=length_penalty,\n      early_stopping=early_stopping,\n      top_p=top_p,\n      top_k=top_k,\n      num_return_sequences=num_return_sequences,\n  )\n  subjects = [tokenizer.decode(generated_id,skip_special_tokens=True,clean_up_tokenization_spaces=True,) for generated_id in generated_ids]\n  return subjects\n```\n\n\n", "size_bytes": "891730879", "downloads": 14}