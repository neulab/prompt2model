{"pretrained_model_name": "SZTAKI-HLT/Bert2Bert-HunSum-1", "description": "---\ndatasets:\n- SZTAKI-HLT/HunSum-1\nlanguage:\n- hu\nmetrics:\n- rouge\npipeline_tag: text2text-generation\ninference:\n  parameters:\n    num_beams: 5\n    length_penalty: 2\n    max_length: 128\n    no_repeat_ngram_size: 3\n    early_stopping: True\ntags:\n- hubert\n- bert\n- summarization\n---\n\n# Model Card for Bert2Bert-HunSum-1\n\nThe Bert2Bert-HunSum-1 is a Hungarian abstractive summarization model, which was trained on the [SZTAKI-HLT/HunSum-1 dataset](https://huggingface.co/datasets/SZTAKI-HLT/HunSum-1).\nThe model is based on [SZTAKI-HLT/hubert-base-cc](https://huggingface.co/SZTAKI-HLT/hubert-base-cc).\n\n## Intended uses & limitations\n\n- **Model type:** Text Summarization\n- **Language(s) (NLP):** Hungarian\n- **Resource(s) for more information:**\n  - [GitHub Repo](https://github.com/dorinapetra/summarization)\n \n## Parameters\n\n- **Batch Size:** 13\n- **Learning Rate:** 5e-5\n- **Weight Decay:** 0.01\n- **Warmup Steps:** 16000\n- **Epochs:** 15\n- **no_repeat_ngram_size:** 3\n- **num_beams:** 5\n- **early_stopping:** True\n\n## Results\n\n| Metric        | Value                                       |\n| :------------ | :------------------------------------------ |\n| ROUGE-1       | 28.52                                       |\n| ROUGE-2       | 10.35                                       |\n| ROUGE-L       | 20.07                                       |\n\n## Citation\n\nIf you use our model, please cite the following paper:\n```\n@inproceedings {HunSum-1,\n    title = {{HunSum-1: an Abstractive Summarization Dataset for Hungarian}},\n\tbooktitle = {XIX. Magyar Sz\u00e1m\u00edt\u00f3g\u00e9pes Nyelv\u00e9szeti Konferencia (MSZNY 2023)},\n\tyear = {2023},\n\tpublisher = {Szegedi Tudom\u00e1nyegyetem, Informatikai Int\u00e9zet},\n\taddress = {Szeged, Magyarorsz\u00e1g},\n\tauthor = {Barta, Botond and Lakatos, Dorina and Nagy, Attila and Nyist, Mil{\\'{a}}n Konor and {\\'{A}}cs, Judit},\n\tpages = {231--243}\n}\n```", "size_bytes": "998739090", "downloads": 23}