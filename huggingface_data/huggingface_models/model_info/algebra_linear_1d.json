{"pretrained_model_name": "dbernsohn/algebra_linear_1d", "description": "# algebra_linear_1d\n---\nlanguage: en\ndatasets:\n- algebra_linear_1d\n---\n\nThis is a [t5-small](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) fine-tuned version on the [math_dataset/algebra_linear_1d](https://www.tensorflow.org/datasets/catalog/math_dataset#mathdatasetalgebra_linear_1d_default_config) for solving **algebra 1d equations** mission.\n\nTo load the model:\n(necessary packages: !pip install transformers sentencepiece)\n```python\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\ntokenizer = AutoTokenizer.from_pretrained(\"dbernsohn/algebra_linear_1d\")\nmodel = AutoModelWithLMHead.from_pretrained(\"dbernsohn/algebra_linear_1d\")\n```\n\nYou can then use this model to solve algebra 1d equations into numbers.\n\n```python\nquery = \"Solve 0 = 1026*x - 2474 + 46592 for x\"\ninput_text = f\"{query} </s>\"\nfeatures = tokenizer([input_text], return_tensors='pt')\nmodel.to('cuda')\noutput = model.generate(input_ids=features['input_ids'].cuda(), \n                        attention_mask=features['attention_mask'].cuda())\n\ntokenizer.decode(output[0])\n# <pad> -41</s>\n```\n\nAnother examples:\n\n+ Solve 1112*r + 1418*r - 5220 = 587*r - 28536 for r. \n+ Answer:  -12 Pred:  -12\n----\n+ Solve -119*k + 6*k - 117 - 352 = 322 for k. \n+ Answer:  -7 Pred:  -7\n----\n+ Solve -547 = -62*t + 437 - 798 for t. \n+ Answer:  3 Pred:  3\n----\n+ Solve 3*j - 3*j + 0*j - 4802 = 98*j for j. \n+ Answer:  -49 Pred:  -49\n----\n+ Solve 3047*n - 6130*n - 1700 = -3049*n for n. \n+ Answer:  -50 Pred:  -50\n----\n+ Solve 121*i + 1690 = 76*i - 128*i + 133 for i. \n+ Answer:  -9 Pred:  -9\n\nThe whole training process and hyperparameters are in my [GitHub repo](https://github.com/DorBernsohn/CodeLM/tree/main/MathLM)\n> Created by [Dor Bernsohn](https://www.linkedin.com/in/dor-bernsohn-70b2b1146/)\n", "size_bytes": "242088059", "downloads": 3}