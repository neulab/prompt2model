{"pretrained_model_name": "Helsinki-NLP/opus-mt-en-urj", "description": "---\nlanguage: \n- en\n- se\n- fi\n- hu\n- et\n- urj\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### eng-urj\n\n* source group: English \n* target group: Uralic languages \n*  OPUS readme: [eng-urj](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-urj/README.md)\n\n*  model: transformer\n* source language(s): eng\n* target language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)\n* download original weights: [opus2m-2020-08-02.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-urj/opus2m-2020-08-02.zip)\n* test set translations: [opus2m-2020-08-02.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-urj/opus2m-2020-08-02.test.txt)\n* test set scores: [opus2m-2020-08-02.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-urj/opus2m-2020-08-02.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| newsdev2015-enfi-engfin.eng.fin \t| 18.3 \t| 0.519 |\n| newsdev2018-enet-engest.eng.est \t| 19.3 \t| 0.520 |\n| newssyscomb2009-enghun.eng.hun \t| 15.4 \t| 0.471 |\n| newstest2009-enghun.eng.hun \t| 15.7 \t| 0.468 |\n| newstest2015-enfi-engfin.eng.fin \t| 20.2 \t| 0.534 |\n| newstest2016-enfi-engfin.eng.fin \t| 20.7 \t| 0.541 |\n| newstest2017-enfi-engfin.eng.fin \t| 23.6 \t| 0.566 |\n| newstest2018-enet-engest.eng.est \t| 20.8 \t| 0.535 |\n| newstest2018-enfi-engfin.eng.fin \t| 15.8 \t| 0.499 |\n| newstest2019-enfi-engfin.eng.fin \t| 19.9 \t| 0.518 |\n| newstestB2016-enfi-engfin.eng.fin \t| 16.6 \t| 0.509 |\n| newstestB2017-enfi-engfin.eng.fin \t| 19.4 \t| 0.529 |\n| Tatoeba-test.eng-chm.eng.chm \t| 1.3 \t| 0.127 |\n| Tatoeba-test.eng-est.eng.est \t| 51.0 \t| 0.692 |\n| Tatoeba-test.eng-fin.eng.fin \t| 34.6 \t| 0.597 |\n| Tatoeba-test.eng-fkv.eng.fkv \t| 2.2 \t| 0.302 |\n| Tatoeba-test.eng-hun.eng.hun \t| 35.6 \t| 0.591 |\n| Tatoeba-test.eng-izh.eng.izh \t| 5.7 \t| 0.211 |\n| Tatoeba-test.eng-kom.eng.kom \t| 3.0 \t| 0.012 |\n| Tatoeba-test.eng-krl.eng.krl \t| 8.5 \t| 0.230 |\n| Tatoeba-test.eng-liv.eng.liv \t| 2.7 \t| 0.077 |\n| Tatoeba-test.eng-mdf.eng.mdf \t| 2.8 \t| 0.007 |\n| Tatoeba-test.eng.multi \t| 35.1 \t| 0.588 |\n| Tatoeba-test.eng-myv.eng.myv \t| 1.3 \t| 0.014 |\n| Tatoeba-test.eng-sma.eng.sma \t| 1.8 \t| 0.095 |\n| Tatoeba-test.eng-sme.eng.sme \t| 6.8 \t| 0.204 |\n| Tatoeba-test.eng-udm.eng.udm \t| 1.1 \t| 0.121 |\n\n\n### System Info: \n- hf_name: eng-urj\n\n- source_languages: eng\n\n- target_languages: urj\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-urj/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['en', 'se', 'fi', 'hu', 'et', 'urj']\n\n- src_constituents: {'eng'}\n\n- tgt_constituents: {'izh', 'mdf', 'vep', 'vro', 'sme', 'myv', 'fkv_Latn', 'krl', 'fin', 'hun', 'kpv', 'udm', 'liv_Latn', 'est', 'mhr', 'sma'}\n\n- src_multilingual: False\n\n- tgt_multilingual: True\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-urj/opus2m-2020-08-02.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-urj/opus2m-2020-08-02.test.txt\n\n- src_alpha3: eng\n\n- tgt_alpha3: urj\n\n- short_pair: en-urj\n\n- chrF2_score: 0.588\n\n- bleu: 35.1\n\n- brevity_penalty: 0.943\n\n- ref_len: 59664.0\n\n- src_name: English\n\n- tgt_name: Uralic languages\n\n- train_date: 2020-08-02\n\n- src_alpha2: en\n\n- tgt_alpha2: urj\n\n- prefer_old: False\n\n- long_pair: eng-urj\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "299608797", "downloads": 18}