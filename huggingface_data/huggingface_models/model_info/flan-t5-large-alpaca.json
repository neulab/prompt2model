{"pretrained_model_name": "VMware/flan-t5-large-alpaca", "description": "---\ndatasets:\n- tatsu-lab/alpaca\nlanguage:\n- en\npipeline_tag: text2text-generation\nlibrary_name: transformers\nlicense: other\n---\n\n\n# Model Details\n\n- **Model name:** Flan-T5-Large-Alpaca\n- **Model type:** - Text2Text Generation\n- **Parent Model:** [google/flan-t5-large](https://huggingface.co/google/flan-t5-large)\n- **Training dataset:** [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) \n- **Language:** English\n- **Framework:** PyTorch\n- **Model version:** 1.0\n\n\nWe take the instruction-tuned Flan models (trained on Academic datasets) and perform style transfer using the Alpaca dataset \n\n# License\n- Parent model ([google/flan-t5-large](https://huggingface.co/google/flan-t5-large)): Apache 2.0\n- Dataset ([Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca)) : cc-by-4.0\n- Text-Davinci-3 (Used to generate Alpaca): [OpenAI License](https://openai.com/policies/terms-of-use)\n\n\n\n# How to Use\n\n```\nfrom transformers import pipeline\nmodel = pipeline(model=\"vmware/flan-t5-large-alpaca\",device_map = 'auto')\n\nprompt = \"Give me the recipe for making a caramel flan\"\noutput = model(prompt, max_length=256, do_sample=True)\n\n\n\n\n'''\n[{'generated_text': 'Recipe for making caramel flan: 2 cups all-purpose flour 3 cups butter 6 tablespoons sugar 2 tablespoons melted dark chocolate 2 cups milk Instructions: 1.\nPreheat oven to 350\u00b0F (180\u00b0C). 2. Grease 9 inch round cake pan. 3. In a large bowl, whisk together flour, baking powder, cocoa powder, salt and salt.\n4. Beat until fluffy. 5. Add the melted chocolate, vanilla and sugar and beat until blended. 6. Pour batter into the prepared pan and bake for 45 minutes.\n7. Remove the pan from the oven and let cool before serving.'}]\n\n\n'''\n\n\n```\n\n\nUsing Alpaca prompt template might generate better outputs for certain prompts as the model was trained using the template.\n\n```\nfrom transformers import pipeline\nmodel = pipeline(model=\"vmware/flan-t5-large-alpaca\",device_map = 'auto')\n\nprompt_template = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\"\n\nprompt = \"YOUR PROMPT HERE\"\n\noutput = model(prompt_template.format(instruction= prompt), max_length=256, do_sample=True)\n\nprint(output)\n\n\n\n```\n\n# Training Details\n\nThe model was trained on 3xV100 GPUs\n\n* Hyperparameters:\n* learning_rate = 5e-5\n* batch_size = 128\n*  epochs = 3\n\n\n```\n\n\n\n# Limitations and Bias\n\nThe model is based on a large and diverse dataset, but it may still have limitations and biases in certain areas. Some limitations include:\n\n- Language: The model is designed to work with English text only and may not perform as well in other languages.\n\n\nIn addition, the model may have some bias in terms of the data it was trained on. The dataset includes questions from a variety of sources, but it may not be representative of all populations or perspectives. As a result, the model may perform better or worse for certain types of questions or on certain types of texts.", "size_bytes": "3132789733", "downloads": 31}