{"pretrained_model_name": "Ife/BM-FR", "description": "---\nlanguage:\n- bm\n- fr\n---\n@inproceedings{adebara-abdul-mageed-2021-improving,\n    title = \"Improving Similar Language Translation With Transfer Learning\",\n    author = \"Adebara, Ife  and\n      Abdul-Mageed, Muhammad\",\n    booktitle = \"Proceedings of the Sixth Conference on Machine Translation\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.wmt-1.27\",\n    pages = \"273--278\",\n    abstract = \"We investigate transfer learning based on pre-trained neural machine translation models to translate between (low-resource) similar languages. This work is part of our contribution to the WMT 2021 Similar Languages Translation Shared Task where we submitted models for different language pairs, including French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions. Our models for Catalan-Spanish (82.79 BLEU)and Portuguese-Spanish (87.11 BLEU) rank top 1 in the official shared task evaluation, and we are the only team to submit models for the French-Bambara pairs.\",\n}", "size_bytes": "298723871", "downloads": 2}