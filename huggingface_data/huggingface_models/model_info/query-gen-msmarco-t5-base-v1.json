{"pretrained_model_name": "BeIR/query-gen-msmarco-t5-base-v1", "description": "# Query Generation\nThis model is the t5-base model from [docTTTTTquery](https://github.com/castorini/docTTTTTquery).\n\nThe T5-base model was trained on the [MS MARCO Passage Dataset](https://github.com/microsoft/MSMARCO-Passage-Ranking), which consists of about 500k real search queries from Bing together with the relevant passage.\n\nThe model can be used for query generation to learn semantic search models without requiring annotated training data: [Synthetic Query Generation](https://github.com/UKPLab/sentence-transformers/tree/master/examples/unsupervised_learning/query_generation).\n\n\n## Usage\n\n```python\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained('model-name')\nmodel = T5ForConditionalGeneration.from_pretrained('model-name')\n\npara = \"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\"\n\ninput_ids = tokenizer.encode(para, return_tensors='pt')\noutputs = model.generate(\n\tinput_ids=input_ids,\n\tmax_length=64,\n\tdo_sample=True,\n\ttop_p=0.95,\n\tnum_return_sequences=3)\n\nprint(\"Paragraph:\")\nprint(para)\n\nprint(\"\\nGenerated Queries:\")\nfor i in range(len(outputs)):\n\tquery = tokenizer.decode(outputs[i], skip_special_tokens=True)\n\tprint(f'{i + 1}: {query}')\n```", "size_bytes": "891733816", "downloads": 1034}