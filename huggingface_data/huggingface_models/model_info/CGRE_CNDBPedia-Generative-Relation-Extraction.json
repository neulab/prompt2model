{"pretrained_model_name": "fanxiao/CGRE_CNDBPedia-Generative-Relation-Extraction", "description": "  CGRE is a generation-based relation extraction model\n\n  \u00b7a SOTA chinese end-to-end relation extraction model,using bart as backbone.\n\n  \u00b7using the Distant-supervised data from cndbpedia,pretrained from the checkpoint of fnlp/bart-base-chinese.\n  \n  \u00b7can perform SOTA in many chinese relation extraction dataset,such as DuIE~1.0,DuIE~2.0,HacRED,etc.\n  \n  \u00b7easy to use,just like normal generation task.\n  \n  \u00b7input is sentence,and output is linearlize triples,such as input:\u59da\u660e\u662f\u4e00\u540dNBA\u7bee\u7403\u8fd0\u52a8\u5458 output:[subj]\u59da\u660e[obj]NBA[rel]\u516c\u53f8[obj]\u7bee\u7403\u8fd0\u52a8\u5458[rel]\u804c\u4e1a\n\n\nusing model\uff1a\n\nfrom transformers import BertTokenizer, BartForConditionalGeneration\n\nmodel_name = 'fnlp/bart-base-chinese'\n\ntokenizer_kwargs = {\n    \"use_fast\": True,\n    \"additional_special_tokens\": ['<rel>', '<obj>', '<subj>'],\n} # if cannot see tokens in model card please open readme file\n\ntokenizer = BertTokenizer.from_pretrained(model_name, **tokenizer_kwargs)\n\nmodel = BartForConditionalGeneration.from_pretrained('./CGRE_CNDBPedia-Generative-Relation-Extraction')\n\ninputs = tokenizer(sent, max_length=max_source_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n\nparams = {\"decoder_start_token_id\":0,\"early_stopping\":False,\"no_repeat_ngram_size\":0,\"length_penalty\": 0,\"num_beams\":20,\"use_cache\":True}\n\nout_id = model.generate(inputs[\"input_ids\"], attention_mask = inputs[\"attention_mask\"], max_length=max_target_length, **params)\n", "size_bytes": "465217273", "downloads": 55}