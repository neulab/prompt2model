{"pretrained_model_name": "facebook/mbart-large-cc25", "description": "---\ntags:\n- translation\n\nlanguage:\n- en\n- ar\n- cs\n- de\n- et\n- fi\n- fr\n- gu\n- hi\n- it\n- ja\n- kk\n- ko\n- lt\n- lv\n- my\n- ne\n- nl\n- ro \n- ru\n- si\n- tr\n- vi\n- zh\n- multilingual\n\n---\n#### mbart-large-cc25\n\nPretrained (not finetuned) multilingual mbart model.\nOriginal Languages\n```\nexport langs=ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\n```\n\nOriginal Code: https://github.com/pytorch/fairseq/tree/master/examples/mbart\nDocs:  https://huggingface.co/transformers/master/model_doc/mbart.html\nFinetuning Code: examples/seq2seq/finetune.py (as of Aug 20, 2020)\n\nCan also be finetuned for summarization.", "size_bytes": "2444517405", "downloads": 22215}