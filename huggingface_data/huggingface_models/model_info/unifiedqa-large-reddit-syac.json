{"pretrained_model_name": "marksverdhei/unifiedqa-large-reddit-syac", "description": "---\nlanguage: en\n---\n# UnifiedQA-Reddit-SYAC  \n\nThis is an abstractive title answering (TA) / clickbait spoiling model.  \nThis is a variant of [allenai/unifiedqa-t5-large](https://huggingface.co/allenai/unifiedqa-t5-large), fine-tuned on the Reddit SYAC dataset.  \nThe model was trained as part of my masters thesis:\n\n_Abstractive title answering for clickbait content_  \n\n\n### Disinformation  \nThis model has the proven capability of generating, and hallucinating false information.  \nAny use of a TA system such as this one should be with knowledge of this risk.\n\n\n## Performance  \n\n### Intrinsic  \n\nThe following scores is the result of intrinsic evaluation on the Reddit SYAC test set.  \nWe used a max input length of 2048 and truncated the tokens exceeding this limit.  \n\n| rouge1    | rouge2    | rougeL    | bleu      | meteor   |\n|:----------|:----------|:----------|:----------|:---------|\n| **44.58** | **23.89** | **43.45** | 17.46     | 36.22    |\n\n\n### Qualtiy  \nUsing human evaluation, we measured model performance by asking the evaluators to rate the models\non a scale from 1 to 5 on how good their generated answer was for a given clickbait article.  \n\nMean quality = 4.065  \n\n### Factuality  \nWe included a factuality assessment to address the issue of generating false information.  \nHuman raters were asked to place each output in the categories \"True\", \"Irrelevant\", and \"False\".  \n\n| True    | Irrelevant | False    |\n|:-------:|:----------:|:--------:|\n|   85%   |    7.5%    | 7.5%     |\n\n## Cite  \n\nIf you use this model, please cite my master's thesis\n\n```\n@mastersthesis{heiervang2022AbstractiveTA\n  title={Abstractive title answering for clickbait content},\n  author={Markus Sverdvik Heiervang},\n  publisher={University of Oslo, Department of Informatics},\n  year={2022}\n}\n```", "size_bytes": "2950844807", "downloads": 4}