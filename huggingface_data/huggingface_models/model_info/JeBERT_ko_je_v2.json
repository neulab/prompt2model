{"pretrained_model_name": "kompactss/JeBERT_ko_je_v2", "description": "---\nlicense: afl-3.0\n---\n\n# \ud83c\udf4a \uc81c\uc8fc \ubc29\uc5b8 \ubc88\uc5ed \ubaa8\ub378 \ud83c\udf4a\n  -  \ud45c\uc900\uc5b4 -> \uc81c\uc8fc\uc5b4\n  -  Made by. \uad6c\ub984 \uc790\uc5f0\uc5b4\ucc98\ub9ac \uacfc\uc815 3\uae30 3\uc870!!\n  - github link : https://github.com/Goormnlpteam3/JeBERT\n  \n## 1. Seq2Seq Transformer Model\n  -  encoder :  BertConfig\n  -  decoder :  BertConfig\n  -  Tokenizer :  WordPiece Tokenizer\n  \n## 2. Dataset\n  -  Jit Dataset\n  -  AI HUB(+\uc544\ub798\uc544 \ubb38\uc790)_v2\n\n## 3. Hyper Parameters\n  -  Epoch :  10 epochs(best at 7 epoch)\n  -  Random Seed :  42\n  -  Learning Rate :  5e-5\n  -  Warm up Ratio :  0.1\n  -  Batch Size :  32\n\n## 4. BLEU Score\n  -  Jit + AI HUB(+\uc544\ub798\uc544 \ubb38\uc790) Dataset :  67.6\n---\n### CREDIT\n  - \uc8fc\ud615\uc900 : wngudwns2798@gmail.com\n  - \uac15\uac00\ub78c : 1st9aram@gmail.com\n  - \uace0\uad11\uc5f0 : rhfprl11@gmail.com\n  - \uae40\uc218\uc5f0 : s01090445778@gmail.com\n  - \uc774\uc6d0\uacbd : hjtwin2@gmail.com\n  - \uc870\uc131\uc740 : eun102476@gmail.com", "size_bytes": "989641131", "downloads": 2}