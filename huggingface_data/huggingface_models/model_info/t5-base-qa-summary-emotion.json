{"pretrained_model_name": "kiri-ai/t5-base-qa-summary-emotion", "description": "---\nlanguage:\n- en\ntags:\n- question-answering\n- emotion-detection\n- summarisation\nlicense: apache-2.0\ndatasets:\n- coqa\n- squad_v2\n- go_emotions\n- cnn_dailymail\nmetrics:\n- f1\npipeline_tag: text2text-generation\nwidget:\n- text: 'q: Who is Elon Musk? a: an entrepreneur q: When was he born? c: Elon Musk\n    is an entrepreneur born in 1971. </s>'\n- text: 'emotion: I hope this works! </s>'\n---\n# T5 Base with QA + Summary + Emotion\n\n## Dependencies\n\nRequires transformers>=4.0.0\n\n## Description\n\nThis model was finetuned on the CoQa, Squad 2, GoEmotions and CNN/DailyMail.\n\nIt achieves a score of **F1 79.5** on the Squad 2 dev set and a score of **F1 70.6** on the CoQa dev set.\n\nSummarisation and emotion detection has not been evaluated yet.\n\n## Usage\n\n### Question answering\n\n#### With Transformers\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\ntokenizer = T5Tokenizer.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\n\ndef get_answer(question, prev_qa, context):\n    input_text = [f\"q: {qa[0]} a: {qa[1]}\" for qa in prev_qa]\n    input_text.append(f\"q: {question}\")\n    input_text.append(f\"c: {context}\")\n    input_text = \" \".join(input_text)\n    features = tokenizer([input_text], return_tensors='pt')\n    tokens = model.generate(input_ids=features['input_ids'], \n            attention_mask=features['attention_mask'], max_length=64)\n    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n\nprint(get_answer(\"Why is the moon yellow?\", \"I'm not entirely sure why the moon is yellow.\")) # unknown\n\ncontext = \"Elon Musk left OpenAI to avoid possible future conflicts with his role as CEO of Tesla.\"\n\nprint(get_answer(\"Why not?\", [(\"Does Elon Musk still work with OpenAI\", \"No\")], context)) # to avoid possible future conflicts with his role as CEO of Tesla\n```\n\n#### With Kiri\n\n```python\nfrom kiri.models import T5QASummaryEmotion\n\ncontext = \"Elon Musk left OpenAI to avoid possible future conflicts with his role as CEO of Tesla.\"\nprev_qa = [(\"Does Elon Musk still work with OpenAI\", \"No\")]\nmodel = T5QASummaryEmotion()\n\n# Leave prev_qa blank for non conversational question-answering\nmodel.qa(\"Why not?\", context, prev_qa=prev_qa)\n> \"to avoid possible future conflicts with his role as CEO of Tesla\"\n```\n\n### Summarisation\n\n#### With Transformers\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\ntokenizer = T5Tokenizer.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\n\ndef summary(context):\n    input_text = f\"summarize: {context}\"\n    features = tokenizer([input_text], return_tensors='pt')\n    tokens = model.generate(input_ids=features['input_ids'], \n            attention_mask=features['attention_mask'], max_length=64)\n    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n```\n\n#### With Kiri\n\n```python\nfrom kiri.models import T5QASummaryEmotion\n\nmodel = T5QASummaryEmotion()\n\nmodel.summarise(\"Long text to summarise\")\n> \"Short summary of long text\"\n```\n\n### Emotion detection\n\n#### With Transformers\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\ntokenizer = T5Tokenizer.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\n\ndef emotion(context):\n    input_text = f\"emotion: {context}\"\n    features = tokenizer([input_text], return_tensors='pt')\n    tokens = model.generate(input_ids=features['input_ids'], \n            attention_mask=features['attention_mask'], max_length=64)\n    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n```\n\n#### With Kiri\n\n```python\nfrom kiri.models import T5QASummaryEmotion\n\nmodel = T5QASummaryEmotion()\n\nmodel.emotion(\"I hope this works!\")\n> \"optimism\"\n```\n\n## About us\n\nKiri makes using state-of-the-art models easy, accessible and scalable.\n\n[Website](https://kiri.ai) | [Natural Language Engine](https://github.com/kiri-ai/kiri)\n", "size_bytes": "891734842", "downloads": 158}