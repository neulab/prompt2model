{"pretrained_model_name": "cardiffnlp/flan-t5-base-tweet-qg", "description": "\n---\nwidget:\n- text: \"context: I would hope that Phylicia Rashad would apologize now that @missjillscott has! You cannot discount 30 victims who come with similar stories.\u2014 JDWhitner (@JDWhitner) July 7, 2015, answer: apologize\"\n  example_title: example 1\n- text: \"context: I would hope that Phylicia Rashad would apologize now that @missjillscott has! You cannot discount 30 victims who come with similar stories.\u2014 JDWhitner (@JDWhitner) July 7, 2015, answer: 30\"\n  example_title: example 2\n- text: \"context: The news about Vegas is devastating. Sending all our love to the people there right now \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f\u2014 HAIM (@HAIMtheband) October 2, 2017, answer: vegas\"\n  example_title: example 3\n---\n\n# cardiffnlp/flan-t5-base-tweet-qg\n\nThis is [google/flan-t5-base](https://huggingface.co/google/flan-t5-base) fine-tuned on [cardiffnlp/super_tweeteval (tweet_qg)](https://huggingface.co/datasets/cardiffnlp/super_tweeteval).\n\n### Usage\n\n```python\nfrom transformers import pipeline\n\npipe = pipeline('text2text-generation', model=\"cardiffnlp/flan-t5-base-tweet-qg\")\noutput = pipe(\"context: I would hope that Phylicia Rashad would apologize now that @missjillscott has! You cannot discount 30 victims who come with similar stories.\u2014 JDWhitner (@JDWhitner) July 7, 2015, answer: apologize\")\n```\n        ", "size_bytes": "990402637", "downloads": 3}