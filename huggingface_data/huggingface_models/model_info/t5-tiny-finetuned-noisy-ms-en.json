{"pretrained_model_name": "mesolitica/t5-tiny-finetuned-noisy-ms-en", "description": "---\ntags:\n- generated_from_keras_callback\nmodel-index:\n- name: t5-tiny-finetuned-noisy-ms-en\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information Keras had access to. You should\nprobably proofread and complete it, then remove this comment. -->\n\n# t5-tiny-finetuned-noisy-ms-en\n\nThis model was finetuned from https://github.com/huseinzol05/malaya/tree/master/pretrained-model/t5, t5-tiny-social-media-2021-11-15.tar.gz, on https://huggingface.co/datasets/mesolitica/ms-en and https://huggingface.co/datasets/mesolitica/noisy-ms-en-augmentation\n\n## Evaluation\n\n### evaluation set\n\nIt achieves the following results on the evaluation set using SacreBLEU from [t5-tiny-noisy-ms-en-huggingface.ipynb](t5-tiny-noisy-ms-en-huggingface.ipynb):\n\n```\n{'name': 'BLEU',\n 'score': 65.9069151371865,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '83.0/69.3/60.7/54.1 (BP = 1.000 ratio = 1.001 hyp_len = 2003273 ref_len = 2001100)',\n 'bp': 1.0,\n 'counts': [1662910, 1327225, 1108852, 941870],\n 'totals': [2003273, 1915678, 1828247, 1741231],\n 'sys_len': 2003273,\n 'ref_len': 2001100,\n 'precisions': [83.00965470008332,\n  69.28225933585915,\n  60.651104582695886,\n  54.09219109928551],\n 'prec_str': '83.0/69.3/60.7/54.1',\n 'ratio': 1.0010859027534855}\n```\n\n**The test set is from a semisupervised model, this model might generate better results than the semisupervised model**.\n\n### FLORES200\n\nIt achieved the following results on the [NLLB 200 test set](https://github.com/facebookresearch/flores/tree/main/flores200) using SacreBLEU from [sacrebleu-mesolitica-t5-tiny-finetuned-noisy-ms-en-flores200.ipynb](sacrebleu-mesolitica-t5-tiny-finetuned-noisy-ms-en-flores200.ipynb),\n\n```\nchrF2++ = 59.91\n```\n\n### Framework versions\n\n- Transformers 4.19.0\n- TensorFlow 2.6.0\n- Datasets 2.1.0\n- Tokenizers 0.12.1", "size_bytes": "139068250", "downloads": 2}