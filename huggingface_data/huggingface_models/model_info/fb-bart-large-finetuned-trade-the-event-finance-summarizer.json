{"pretrained_model_name": "nickmuchi/fb-bart-large-finetuned-trade-the-event-finance-summarizer", "description": "---\ntags:\n- summarization\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: fb-bart-large-finetuned-trade-the-event-finance-summarizer\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# fb-bart-large-finetuned-trade-the-event-finance-summarizer\n\nThis model was trained from scratch on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.5103\n- Rouge1: 57.6289\n- Rouge2: 53.0421\n- Rougel: 56.54\n- Rougelsum: 56.5636\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 5.6e-05\n- train_batch_size: 8\n- eval_batch_size: 8\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 8\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Rouge1  | Rouge2  | Rougel  | Rougelsum |\n|:-------------:|:-----:|:-----:|:---------------:|:-------:|:-------:|:-------:|:---------:|\n| 1.8188        | 1.0   | 1688  | 1.7495          | 37.9629 | 22.0496 | 32.2942 | 32.4631   |\n| 1.2551        | 2.0   | 3376  | 1.7559          | 38.5548 | 22.7487 | 32.9304 | 33.0737   |\n| 0.8629        | 3.0   | 5064  | 1.9539          | 39.3912 | 22.8503 | 33.2043 | 33.4378   |\n| 0.5661        | 4.0   | 6752  | 2.1153          | 39.1514 | 22.8104 | 33.1306 | 33.2955   |\n| 0.3484        | 5.0   | 8440  | 2.3289          | 39.0093 | 22.4364 | 32.5868 | 32.7545   |\n| 0.2009        | 6.0   | 10128 | 2.5754          | 39.0874 | 22.4444 | 32.6894 | 32.8413   |\n| 0.1105        | 7.0   | 11816 | 2.8093          | 39.0905 | 22.4051 | 32.597  | 32.8183   |\n| 0.0609        | 8.0   | 13504 | 0.5103          | 57.6289 | 53.0421 | 56.54   | 56.5636   |\n\n\n### Framework versions\n\n- Transformers 4.16.2\n- Pytorch 1.10.0+cu111\n- Datasets 1.18.3\n- Tokenizers 0.11.0\n", "size_bytes": "1625553217", "downloads": 293}