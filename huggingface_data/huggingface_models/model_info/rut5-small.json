{"pretrained_model_name": "cointegrated/rut5-small", "description": "---\nlanguage: \"ru\"\ntags:\n- paraphrasing\n- russian\nlicense: mit\n---\n\nThis is a small Russian paraphraser based on the [google/mt5-small](https://huggingface.co/google/mt5-small) model. \nIt has rather poor paraphrasing performance, but can be fine tuned for this or other tasks.\n\nThis model was created by taking the [alenusch/mt5small-ruparaphraser](https://huggingface.co/alenusch/mt5small-ruparaphraser) model and stripping 96% of its vocabulary which is unrelated to the Russian language or infrequent.\n\n* The original model has 300M parameters, with 256M of them being input and output embeddings. \n* After shrinking the `sentencepiece` vocabulary from 250K to 20K the number of model parameters reduced to 65M parameters, and model size reduced from 1.1GB to 246MB.\n   * The first 5K tokens in the new vocabulary are taken from the original `mt5-small`.\n   * The next 15K tokens are the most frequent tokens obtained by tokenizing a Russian web corpus from the [Leipzig corpora collection](https://wortschatz.uni-leipzig.de/en/download/Russian).\n\nThe model can be used as follows:\n```\n# !pip install transformers sentencepiece\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\ntokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small\")\n\ntext = '\u0415\u0445\u0430\u043b \u0413\u0440\u0435\u043a\u0430 \u0447\u0435\u0440\u0435\u0437 \u0440\u0435\u043a\u0443, \u0432\u0438\u0434\u0438\u0442 \u0413\u0440\u0435\u043a\u0430 \u0432 \u0440\u0435\u043a\u0435 \u0440\u0430\u043a. '\ninputs = tokenizer(text, return_tensors='pt')\nwith torch.no_grad():\n    hypotheses = model.generate(\n        **inputs, \n        do_sample=True, top_p=0.95, num_return_sequences=10, \n        repetition_penalty=2.5,\n        max_length=32,\n    )\nfor h in hypotheses:\n    print(tokenizer.decode(h, skip_special_tokens=True))\n```\n", "size_bytes": "258644061", "downloads": 315}