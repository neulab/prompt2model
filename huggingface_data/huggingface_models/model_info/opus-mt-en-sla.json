{"pretrained_model_name": "Helsinki-NLP/opus-mt-en-sla", "description": "---\nlanguage: \n- en\n- be\n- hr\n- mk\n- cs\n- ru\n- pl\n- bg\n- uk\n- sl\n- sla\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### eng-sla\n\n* source group: English \n* target group: Slavic languages \n*  OPUS readme: [eng-sla](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-sla/README.md)\n\n*  model: transformer\n* source language(s): eng\n* target language(s): bel bel_Latn bos_Latn bul bul_Latn ces csb_Latn dsb hrv hsb mkd orv_Cyrl pol rue rus slv srp_Cyrl srp_Latn ukr\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)\n* download original weights: [opus2m-2020-08-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-sla/opus2m-2020-08-01.zip)\n* test set translations: [opus2m-2020-08-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-sla/opus2m-2020-08-01.test.txt)\n* test set scores: [opus2m-2020-08-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-sla/opus2m-2020-08-01.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| newssyscomb2009-engces.eng.ces \t| 20.1 \t| 0.484 |\n| news-test2008-engces.eng.ces \t| 17.7 \t| 0.461 |\n| newstest2009-engces.eng.ces \t| 19.1 \t| 0.479 |\n| newstest2010-engces.eng.ces \t| 19.3 \t| 0.483 |\n| newstest2011-engces.eng.ces \t| 20.4 \t| 0.486 |\n| newstest2012-engces.eng.ces \t| 18.3 \t| 0.461 |\n| newstest2012-engrus.eng.rus \t| 27.4 \t| 0.551 |\n| newstest2013-engces.eng.ces \t| 21.5 \t| 0.489 |\n| newstest2013-engrus.eng.rus \t| 20.9 \t| 0.490 |\n| newstest2015-encs-engces.eng.ces \t| 21.1 \t| 0.496 |\n| newstest2015-enru-engrus.eng.rus \t| 24.5 \t| 0.536 |\n| newstest2016-encs-engces.eng.ces \t| 23.6 \t| 0.515 |\n| newstest2016-enru-engrus.eng.rus \t| 23.0 \t| 0.519 |\n| newstest2017-encs-engces.eng.ces \t| 19.2 \t| 0.474 |\n| newstest2017-enru-engrus.eng.rus \t| 25.0 \t| 0.541 |\n| newstest2018-encs-engces.eng.ces \t| 19.3 \t| 0.479 |\n| newstest2018-enru-engrus.eng.rus \t| 22.3 \t| 0.526 |\n| newstest2019-encs-engces.eng.ces \t| 20.4 \t| 0.486 |\n| newstest2019-enru-engrus.eng.rus \t| 24.0 \t| 0.506 |\n| Tatoeba-test.eng-bel.eng.bel \t| 22.9 \t| 0.489 |\n| Tatoeba-test.eng-bul.eng.bul \t| 46.7 \t| 0.652 |\n| Tatoeba-test.eng-ces.eng.ces \t| 42.7 \t| 0.624 |\n| Tatoeba-test.eng-csb.eng.csb \t| 1.4 \t| 0.210 |\n| Tatoeba-test.eng-dsb.eng.dsb \t| 1.4 \t| 0.165 |\n| Tatoeba-test.eng-hbs.eng.hbs \t| 40.3 \t| 0.616 |\n| Tatoeba-test.eng-hsb.eng.hsb \t| 14.3 \t| 0.344 |\n| Tatoeba-test.eng-mkd.eng.mkd \t| 44.1 \t| 0.635 |\n| Tatoeba-test.eng.multi \t| 41.0 \t| 0.610 |\n| Tatoeba-test.eng-orv.eng.orv \t| 0.3 \t| 0.014 |\n| Tatoeba-test.eng-pol.eng.pol \t| 42.0 \t| 0.637 |\n| Tatoeba-test.eng-rue.eng.rue \t| 0.3 \t| 0.012 |\n| Tatoeba-test.eng-rus.eng.rus \t| 40.5 \t| 0.612 |\n| Tatoeba-test.eng-slv.eng.slv \t| 18.8 \t| 0.357 |\n| Tatoeba-test.eng-ukr.eng.ukr \t| 38.8 \t| 0.600 |\n\n\n### System Info: \n- hf_name: eng-sla\n\n- source_languages: eng\n\n- target_languages: sla\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-sla/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['en', 'be', 'hr', 'mk', 'cs', 'ru', 'pl', 'bg', 'uk', 'sl', 'sla']\n\n- src_constituents: {'eng'}\n\n- tgt_constituents: {'bel', 'hrv', 'orv_Cyrl', 'mkd', 'bel_Latn', 'srp_Latn', 'bul_Latn', 'ces', 'bos_Latn', 'csb_Latn', 'dsb', 'hsb', 'rus', 'srp_Cyrl', 'pol', 'rue', 'bul', 'ukr', 'slv'}\n\n- src_multilingual: False\n\n- tgt_multilingual: True\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-sla/opus2m-2020-08-01.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-sla/opus2m-2020-08-01.test.txt\n\n- src_alpha3: eng\n\n- tgt_alpha3: sla\n\n- short_pair: en-sla\n\n- chrF2_score: 0.61\n\n- bleu: 41.0\n\n- brevity_penalty: 0.976\n\n- ref_len: 64809.0\n\n- src_name: English\n\n- tgt_name: Slavic languages\n\n- train_date: 2020-08-01\n\n- src_alpha2: en\n\n- tgt_alpha2: sla\n\n- prefer_old: False\n\n- long_pair: eng-sla\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "299524665", "downloads": 625}