{"pretrained_model_name": "heack/HeackMT5-ZhSum100k", "description": "---\nlicense: cc-by-nc-sa-4.0\nlanguage:\n- zh\npipeline_tag: summarization\ntags:\n- mT5\n- summarization\n---\n\n# HeackMT5-ZhSum100k: A Summarization Model for Chinese Texts\n\nThis model, `heack/HeackMT5-ZhSum100k`, is a fine-tuned mT5 model for Chinese text summarization tasks. It was trained on a diverse set of Chinese datasets and is able to generate coherent and concise summaries for a wide range of texts.\n\n## Model Details\n\n- Model: mT5\n- Language: Chinese\n- Training data: Mainly Chinese Financial News Sources, NO BBC or CNN source. Training data contains 100k lines.\n- Finetuning epochs: 10\n\n## Evaluation Results\n\nThe model achieved the following results:\n\n- ROUGE-1: 56.46\n- ROUGE-2: 45.81\n- ROUGE-L: 52.98\n- ROUGE-Lsum: 20.22\n\n## Usage\n\nHere is how you can use this model for text summarization:\n\n```python\nfrom transformers import MT5ForConditionalGeneration, T5Tokenizer\n\nmodel = MT5ForConditionalGeneration.from_pretrained(\"heack/HeackMT5-ZhSum100k\")\ntokenizer = T5Tokenizer.from_pretrained(\"heack/HeackMT5-ZhSum100k\")\n\nchunk = \"\"\"\n\u8d22\u8054\u793e5\u670822\u65e5\u8baf\uff0c\u636e\u5e73\u5b89\u5305\u5934\u5fae\u4fe1\u516c\u4f17\u53f7\u6d88\u606f\uff0c\u8fd1\u65e5\uff0c\u5305\u5934\u8b66\u65b9\u53d1\u5e03\u4e00\u8d77\u5229\u7528\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5b9e\u65bd\u7535\u4fe1\u8bc8\u9a97\u7684\u5178\u578b\u6848\u4f8b\uff0c\u798f\u5dde\u5e02\u67d0\u79d1\u6280\u516c\u53f8\u6cd5\u4eba\u4ee3\u8868\u90ed\u5148\u751f10\u5206\u949f\u5185\u88ab\u9a97430\u4e07\u5143\u3002\n4\u670820\u65e5\u4e2d\u5348\uff0c\u90ed\u5148\u751f\u7684\u597d\u53cb\u7a81\u7136\u901a\u8fc7\u5fae\u4fe1\u89c6\u9891\u8054\u7cfb\u4ed6\uff0c\u81ea\u5df1\u7684\u670b\u53cb\u5728\u5916\u5730\u7ade\u6807\uff0c\u9700\u8981430\u4e07\u4fdd\u8bc1\u91d1\uff0c\u4e14\u9700\u8981\u516c\u5bf9\u516c\u8d26\u6237\u8fc7\u8d26\uff0c\u60f3\u8981\u501f\u90ed\u5148\u751f\u516c\u53f8\u7684\u8d26\u6237\u8d70\u8d26\u3002\n\u57fa\u4e8e\u5bf9\u597d\u53cb\u7684\u4fe1\u4efb\uff0c\u52a0\u4e0a\u5df2\u7ecf\u89c6\u9891\u804a\u5929\u6838\u5b9e\u4e86\u8eab\u4efd\uff0c\u90ed\u5148\u751f\u6ca1\u6709\u6838\u5b9e\u94b1\u6b3e\u662f\u5426\u5230\u8d26\uff0c\u5c31\u5206\u4e24\u7b14\u628a430\u4e07\u8f6c\u5230\u4e86\u597d\u53cb\u670b\u53cb\u7684\u94f6\u884c\u5361\u4e0a\u3002\u90ed\u5148\u751f\u62e8\u6253\u597d\u53cb\u7535\u8bdd\uff0c\u624d\u77e5\u9053\u88ab\u9a97\u3002\u9a97\u5b50\u901a\u8fc7\u667a\u80fdAI\u6362\u8138\u548c\u62df\u58f0\u6280\u672f\uff0c\u4f6f\u88c5\u597d\u53cb\u5bf9\u4ed6\u5b9e\u65bd\u4e86\u8bc8\u9a97\u3002\n\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u9a97\u5b50\u5e76\u6ca1\u6709\u4f7f\u7528\u4e00\u4e2a\u4eff\u771f\u7684\u597d\u53cb\u5fae\u4fe1\u6dfb\u52a0\u90ed\u5148\u751f\u4e3a\u597d\u53cb\uff0c\u800c\u662f\u76f4\u63a5\u7528\u597d\u53cb\u5fae\u4fe1\u53d1\u8d77\u89c6\u9891\u804a\u5929\uff0c\u8fd9\u4e5f\u662f\u90ed\u5148\u751f\u88ab\u9a97\u7684\u539f\u56e0\u4e4b\u4e00\u3002\u9a97\u5b50\u6781\u6709\u53ef\u80fd\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u76d7\u7528\u4e86\u90ed\u5148\u751f\u597d\u53cb\u7684\u5fae\u4fe1\u3002\u5e78\u8fd0\u7684\u662f\uff0c\u63a5\u5230\u62a5\u8b66\u540e\uff0c\u798f\u5dde\u3001\u5305\u5934\u4e24\u5730\u8b66\u94f6\u8fc5\u901f\u542f\u52a8\u6b62\u4ed8\u673a\u5236\uff0c\u6210\u529f\u6b62\u4ed8\u62e6\u622a336.84\u4e07\u5143\uff0c\u4f46\u4ecd\u670993.16\u4e07\u5143\u88ab\u8f6c\u79fb\uff0c\u76ee\u524d\u6b63\u5728\u5168\u529b\u8ffd\u7f34\u4e2d\u3002\n\"\"\"\ninputs = tokenizer.encode(\"summarize: \" + chunk, return_tensors='pt', max_length=512, truncation=True)\nsummary_ids = model.generate(inputs, max_length=150, num_beams=4, length_penalty=1.5, no_repeat_ngram_size=2)\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\nprint(summary)\n\n\u5305\u5934\u8b66\u65b9\u53d1\u5e03\u4e00\u8d77\u5229\u7528AI\u5b9e\u65bd\u7535\u4fe1\u8bc8\u9a97\u5178\u578b\u6848\u4f8b:\u6cd5\u4eba\u4ee3\u886810\u5206\u949f\u5185\u88ab\u9a97430\u4e07\u5143\n```\n\n## If you need a longer abbreviation, refer to the following code \u5982\u679c\u9700\u8981\u66f4\u957f\u7684\u7f29\u7565\u8bed\uff0c\u53c2\u8003\u5982\u4e0b\u4ee3\u7801\uff1a\n\n```python\nfrom transformers import MT5ForConditionalGeneration, T5Tokenizer\n\nmodel_heack = MT5ForConditionalGeneration.from_pretrained(\"heack/HeackMT5-ZhSum100k\")\ntokenizer_heack = T5Tokenizer.from_pretrained(\"heack/HeackMT5-ZhSum100k\")\n\n\ndef _split_text(text, length):\n    chunks = []\n    start = 0\n    while start < len(text):\n        if len(text) - start > length:\n            pos_forward = start + length\n            pos_backward = start + length\n            pos = start + length\n            while (pos_forward < len(text)) and (pos_backward >= 0) and (pos_forward < 20 + pos) and  (pos_backward + 20 > pos) and text[pos_forward] not in {'.', '\u3002','\uff0c',','} and text[pos_backward] not in {'.', '\u3002','\uff0c',','}:\n                pos_forward += 1\n                pos_backward -= 1\n            if pos_forward - pos >= 20 and pos_backward <= pos - 20:\n                pos = start + length\n            elif text[pos_backward] in {'.', '\u3002','\uff0c',','}:\n                pos = pos_backward\n            else:\n                pos = pos_forward\n            chunks.append(text[start:pos+1])\n            start = pos + 1\n        else:\n            chunks.append(text[start:])\n            break\n    # Combine last chunk with previous one if it's too short\n    if len(chunks) > 1 and len(chunks[-1]) < 100:\n        chunks[-2] += chunks[-1]\n        chunks.pop()\n    return chunks\n\ndef get_summary_heack(text, each_summary_length=150):\n    chunks = _split_text(text, 300)\n    summaries = []\n    for chunk in chunks:\n        inputs = tokenizer_heack.encode(\"summarize: \" + chunk, return_tensors='pt', max_length=512, truncation=True)\n        summary_ids = model_heack.generate(inputs, max_length=each_summary_length, num_beams=4, length_penalty=1.5, no_repeat_ngram_size=2)\n        summary = tokenizer_heack.decode(summary_ids[0], skip_special_tokens=True)\n        summaries.append(summary)\n    return \" \".join(summaries)\n\n\n```\n\n## Credits\nThis model is trained and maintained by KongYang from Shanghai Jiao Tong University. For any questions, please reach out to me at my WeChat ID: kongyang.\n\n## License\nThis model is released under the CC BY-NC-SA 4.0 license.\n\n## Citation\n\nIf you use this model in your research, please cite:\n\n```bibtex\n@misc{kongyang2023heackmt5zhsum100k,\n    title={HeackMT5-ZhSum100k: A Large-Scale Multilingual Abstractive Summarization for Chinese Texts},\n    author={Kong Yang},\n    year={2023}\n}\n", "size_bytes": "2329706751", "downloads": 371}