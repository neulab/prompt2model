{"pretrained_model_name": "mehnaazasad/bart-large-finetuned-arxiv-co-ga-latest", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: bart-large-finetuned-arxiv-co-ga-latest\n  results: []\ndatasets:\n- mehnaazasad/arxiv_astro_co_ga\n---\n\n# bart-large-finetuned-arxiv-co-ga-latest\n\n## Model description\n\nThis model (v1.0) is a fine-tuned version of [facebook/bart-large](https://huggingface.co/facebook/bart-large). The purpose of this model is \nto generate titles given an abstract. It was trained on Astronomy arXiv papers tagged 'CO' (Cosmology and Nongalactic Astrophysics) \nas well as 'GA' (Astrophysics of Galaxies).\n\nCode for this project can be found on [GitHub](https://github.com/MehnaazAsad/NLP_summarization_bart). \n\n\ud83d\udc49\ud83c\udffd Feel free to interact with the model [here](https://huggingface.co/spaces/mehnaazasad/give-me-a-title) and use it to generate a title given your abstract! \ud83d\udc48\ud83c\udffd\n\n<!-- ## Intended uses & limitations\n\nMore information needed -->\n\n## Training and evaluation data\n\nThe dataset used for training consists of abstract+title pairs from arXiv and was obtained from \n[Kaggle](https://www.kaggle.com/datasets/Cornell-University/arxiv/code). Training was performed on 79,727 abstract+title pairs and \nvalidation was done on 9966 abstract+title pairs.\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 2e-05\n- train_batch_size: 8\n- eval_batch_size: 8\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 1\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Rouge1  | Rouge2  | Rougel | Rougelsum |\n|:-------------:|:-----:|:----:|:---------------:|:-------:|:-------:|:------:|:---------:|\n| 1.7752        | 1.0   | 9966 | 1.7190          | 43.8916 | 23.6296 | 38.229 | 39.3519   |\n\n\n### Framework versions\n\n- Transformers 4.28.0\n- Pytorch 2.0.1+cu118\n- Datasets 2.12.0\n- Tokenizers 0.13.3", "size_bytes": "1625541389", "downloads": 12}