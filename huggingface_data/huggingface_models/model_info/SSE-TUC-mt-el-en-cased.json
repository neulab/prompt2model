{"pretrained_model_name": "lighteternal/SSE-TUC-mt-el-en-cased", "description": "---\nlanguage:\n- en\n- el\ntags:\n- translation\n\nwidget:\n- text: \"\u039f \u03cc\u03c1\u03bf\u03c2 \u03c4\u03b5\u03c7\u03bd\u03b7\u03c4\u03ae \u03bd\u03bf\u03b7\u03bc\u03bf\u03c3\u03cd\u03bd\u03b7 \u03b1\u03bd\u03b1\u03c6\u03ad\u03c1\u03b5\u03c4\u03b1\u03b9 \u03c3\u03c4\u03bf\u03bd \u03ba\u03bb\u03ac\u03b4\u03bf \u03c4\u03b7\u03c2 \u03c0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 \u03bf \u03bf\u03c0\u03bf\u03af\u03bf\u03c2 \u03b1\u03c3\u03c7\u03bf\u03bb\u03b5\u03af\u03c4\u03b1\u03b9 \u03bc\u03b5 \u03c4\u03b7 \u03c3\u03c7\u03b5\u03b4\u03af\u03b1\u03c3\u03b7 \u03ba\u03b1\u03b9 \u03c4\u03b7\u03bd \u03c5\u03bb\u03bf\u03c0\u03bf\u03af\u03b7\u03c3\u03b7 \u03c5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03b9\u03ba\u03ce\u03bd \u03c3\u03c5\u03c3\u03c4\u03b7\u03bc\u03ac\u03c4\u03c9\u03bd \u03c0\u03bf\u03c5 \u03bc\u03b9\u03bc\u03bf\u03cd\u03bd\u03c4\u03b1\u03b9 \u03c3\u03c4\u03bf\u03b9\u03c7\u03b5\u03af\u03b1 \u03c4\u03b7\u03c2 \u03b1\u03bd\u03b8\u03c1\u03ce\u03c0\u03b9\u03bd\u03b7\u03c2 \u03c3\u03c5\u03bc\u03c0\u03b5\u03c1\u03b9\u03c6\u03bf\u03c1\u03ac\u03c2. \"\nlicense: apache-2.0\nmetrics:\n- bleu\n---\n\n\n## Greek to English NMT \n## By the Hellenic Army Academy (SSE) and the Technical University of Crete (TUC)\n\n* source languages: el\n* target languages: en\n* licence: apache-2.0\n* dataset: Opus, CCmatrix\n* model: transformer(fairseq)\n* pre-processing: tokenization + BPE segmentation\n* metrics: bleu, chrf\n\n### Model description\n\nTrained using the Fairseq framework, transformer_iwslt_de_en architecture.\\\\\nBPE segmentation (20k codes).\\\\\nMixed-case model. \n\n### How to use\n\n```\nfrom transformers import FSMTTokenizer, FSMTForConditionalGeneration\n\nmname = \"lighteternal/SSE-TUC-mt-el-en-cased\"\n\ntokenizer = FSMTTokenizer.from_pretrained(mname)\nmodel = FSMTForConditionalGeneration.from_pretrained(mname)\n\ntext = \"\u039f \u03cc\u03c1\u03bf\u03c2 \u03c4\u03b5\u03c7\u03bd\u03b7\u03c4\u03ae \u03bd\u03bf\u03b7\u03bc\u03bf\u03c3\u03cd\u03bd\u03b7 \u03b1\u03bd\u03b1\u03c6\u03ad\u03c1\u03b5\u03c4\u03b1\u03b9 \u03c3\u03c4\u03bf\u03bd \u03ba\u03bb\u03ac\u03b4\u03bf \u03c4\u03b7\u03c2 \u03c0\u03bb\u03b7\u03c1\u03bf\u03c6\u03bf\u03c1\u03b9\u03ba\u03ae\u03c2 \u03bf \u03bf\u03c0\u03bf\u03af\u03bf\u03c2 \u03b1\u03c3\u03c7\u03bf\u03bb\u03b5\u03af\u03c4\u03b1\u03b9 \u03bc\u03b5 \u03c4\u03b7 \u03c3\u03c7\u03b5\u03b4\u03af\u03b1\u03c3\u03b7 \u03ba\u03b1\u03b9 \u03c4\u03b7\u03bd \u03c5\u03bb\u03bf\u03c0\u03bf\u03af\u03b7\u03c3\u03b7 \u03c5\u03c0\u03bf\u03bb\u03bf\u03b3\u03b9\u03c3\u03c4\u03b9\u03ba\u03ce\u03bd \u03c3\u03c5\u03c3\u03c4\u03b7\u03bc\u03ac\u03c4\u03c9\u03bd \u03c0\u03bf\u03c5 \u03bc\u03b9\u03bc\u03bf\u03cd\u03bd\u03c4\u03b1\u03b9 \u03c3\u03c4\u03bf\u03b9\u03c7\u03b5\u03af\u03b1 \u03c4\u03b7\u03c2 \u03b1\u03bd\u03b8\u03c1\u03ce\u03c0\u03b9\u03bd\u03b7\u03c2 \u03c3\u03c5\u03bc\u03c0\u03b5\u03c1\u03b9\u03c6\u03bf\u03c1\u03ac\u03c2 .\"\n\nencoded = tokenizer.encode(text, return_tensors='pt')\n\noutputs = model.generate(encoded, num_beams=5, num_return_sequences=5, early_stopping=True)\nfor i, output in enumerate(outputs):\n    i += 1\n    print(f\"{i}: {output.tolist()}\")\n    \n    decoded = tokenizer.decode(output, skip_special_tokens=True)\n    print(f\"{i}: {decoded}\")\n```\n\n\n## Training data\n\nConsolidated corpus from Opus and CC-Matrix (~6.6GB in total)\n\n\n## Eval results\n\n\nResults on Tatoeba testset (EL-EN): \n\n| BLEU | chrF  |\n| ------ | ------ |\n| 79.3 |  0.795 |\n\n\nResults on XNLI parallel (EL-EN): \n\n| BLEU | chrF  |\n| ------ | ------ |\n| 66.2 |  0.623 |\n\n### BibTeX entry and citation info\n\nDimitris Papadopoulos, et al. \"PENELOPIE: Enabling Open Information Extraction for the Greek Language through Machine Translation.\" (2021). Accepted at EACL 2021 SRW\n \n\n### Acknowledgement\n\nThe research work was supported by the Hellenic Foundation for Research and Innovation (HFRI) under the HFRI PhD Fellowship grant (Fellowship Number:50, 2nd call)\n", "size_bytes": "205089118", "downloads": 13}