{"pretrained_model_name": "Gabriel/bart-base-cnn-xsum-swe", "description": "---\nlanguage: sv\nlicense: mit\ntags:\n- summarization\ndatasets:\n- Gabriel/xsum_swe\nwidget:\n- text: 'Jordan Hill, Bretagne Covington och Tesfaye Cooper, alla 18, och Tanishia\n    Covington, 24, d\u00f6k upp i en Chicagodomstol p\u00e5 fredag. De fyra har \u00e5talats f\u00f6r\n    hatbrott och grov kidnappning och misshandel, bland annat. En insamling p\u00e5 n\u00e4tet\n    till deras offer har hittills samlat in $51.000 (=42.500 pund). Domare Maria Kuriakos\n    Ciesil f\u00f6rnekade borgen och fr\u00e5gade: Var fanns din anst\u00e4ndighetsk\u00e4nsla? \u00c5klagarna\n    ber\u00e4ttade f\u00f6r domstolen att misshandeln b\u00f6rjade i en sk\u00e5pbil och fortsatte i ett\n    hus, d\u00e4r de misst\u00e4nkta p\u00e5st\u00e5s ha tvingat det 18-\u00e5riga vita offret, som lider av\n    schizofreni och problem med uppm\u00e4rksamhetsbrist, att dricka toalettvatten och\n    kyssa golvet. Polisen h\u00e4vdar att sk\u00e5pbilen tidigare stals av Mr Hill, som ocks\u00e5\n    anklagas f\u00f6r att ha kr\u00e4vt 300 dollar av offrets mor medan de h\u00f6ll honom f\u00e5ngen,\n    enligt Chicago Tribune. R\u00e4tten fick ocks\u00e5 veta att de misst\u00e4nkta stoppade en strumpa\n    i munnen, tejpade igen munnen och band h\u00e4nderna med ett b\u00e4lte. I en video gjord\n    f\u00f6r Facebook Live som har setts miljontals g\u00e5nger, kan angriparna h\u00f6ras g\u00f6ra neds\u00e4ttande\n    uttalanden mot vita m\u00e4nniskor och Donald Trump. Offret hade sl\u00e4ppts av p\u00e5 en McDonalds\n    f\u00f6r att tr\u00e4ffa Mr Hill - som var en av hans v\u00e4nner - den 31 december. Han hittades\n    av en polis tisdagen den 3 januari, en dag efter att han anm\u00e4ldes saknad av sina\n    f\u00f6r\u00e4ldrar. \u00c5klagarna s\u00e4ger att de misst\u00e4nkta m\u00f6ter tv\u00e5 hatbrott r\u00e4knas, en p\u00e5\n    grund av offrets ras och den andra p\u00e5 grund av hans funktionshinder.'\ninference:\n  parameters:\n    temperature: 0.7\n    min_length: 30\n    max_length: 120\ntrain-eval-index:\n- config: Gabriel--xsum_swe\n  task: summarization\n  task_id: summarization\n  splits:\n    eval_split: test\n  col_mapping:\n    document: text\n    summary: target\nco2_eq_emissions:\n  emissions: 0.0334\n  source: Google Colab\n  training_type: fine-tuning\n  geographical_location: Fredericia, Denmark\n  hardware_used: Tesla P100-PCIE-16GB\nmodel-index:\n- name: bart-base-cnn-xsum-swe\n  results:\n  - task:\n      type: summarization\n      name: summarization\n    dataset:\n      name: Gabriel/xsum_swe\n      type: Gabriel/xsum_swe\n      split: validation\n    metrics:\n    - type: rouge-1\n      value: 30.9467\n      name: Validation ROGUE-1.\n      verified: true\n      verifyToken: eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiNWJmOWRhNjgzNjNhY2U3Y2VjY2Y0MzU3MmQyNzVlNzE0NmZjY2YxM2EzZmUxMzA3YTQ1MjU0ZGI3ZjU2OTllNCIsInZlcnNpb24iOjF9.vs305ofbXaHXU-APAdgvvMjJgI7Eb2xpNih3yt9lgFzG5EhDmVm2la62vLgiW_ypvc3v-95CFw2RDvX4GjqQDA\n    - type: rouge-2\n      value: 12.2589\n      name: Validation ROGUE-2\n      verified: true\n      verifyToken: eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiNGI4NzFhZDBjZmJhYmFhMmYwZTQ3ZTdkYTY3OWU1MDk2MDNjNDAyODg3Yzc2YjY0MmE1ZGZlYjIyODdiYTZjZCIsInZlcnNpb24iOjF9.Xm9uAyUR_QsOKtw7GM0J6jduoL1-qUVra07cpIGQve8au8T8r94pzvb_r5f5YFKioa1rsG8fT8xCHecV2yPjAg\n    - type: rouge-l\n      value: 25.4487\n      name: Validation ROGUE-L\n      verified: true\n      verifyToken: eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiNDdmMjEyNDRhODI5MWJmNGYyMGRiMzlkOGMwODIyZjgyNDg2M2NjMTAwZTlkYWVkZjUxNjRmNzgzZWU0MGMyNCIsInZlcnNpb24iOjF9.Wx0RQwcx4-rJ2K3EG-RwWxvfTpSYii-DW2Wi9TTre6HkByDHNImzesP7sPJ3AcIoHZzt1kw30652nUpmMW5zDg\n    - type: rouge-l-sum\n      value: 25.4792\n      name: Validation ROGUE-L-SUM\n      verified: true\n      verifyToken: eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiNTFiMDE5YThmNGM5YjMwNThkNzQ1MWUzMGFjNmNiNzE0ZWU0N2I2OTk0MTU4YzkwNzhlNzkzZjI0MjcxNTQ4OSIsInZlcnNpb24iOjF9.uU9p925R6K3m9w-SrfTFb7pbXEfP8T38tsOG9iKiLiLPexQ1sJTTold1oTTWiYOs8oDBIqF1w2eRit4Q7U90Dg\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# bart-base-cnn-xsum-swe\n\nThis model is a fine-tuned version of [Gabriel/bart-base-cnn-swe](https://huggingface.co/Gabriel/bart-base-cnn-swe) on the None dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 2.1027\n- Rouge1: 30.9467\n- Rouge2: 12.2589\n- Rougel: 25.4487\n- Rougelsum: 25.4792\n- Gen Len: 19.7379\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 4e-05\n- train_batch_size: 16\n- eval_batch_size: 16\n- seed: 42\n- gradient_accumulation_steps: 2\n- total_train_batch_size: 32\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- lr_scheduler_warmup_steps: 500\n- num_epochs: 4\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Rouge1  | Rouge2  | Rougel  | Rougelsum | Gen Len |\n|:-------------:|:-----:|:-----:|:---------------:|:-------:|:-------:|:-------:|:---------:|:-------:|\n| 2.3076        | 1.0   | 6375  | 2.1986          | 29.7041 | 10.9883 | 24.2149 | 24.2406   | 19.7193 |\n| 2.0733        | 2.0   | 12750 | 2.1246          | 30.4521 | 11.8107 | 24.9519 | 24.9745   | 19.6592 |\n| 1.8933        | 3.0   | 19125 | 2.0989          | 30.9407 | 12.2682 | 25.4135 | 25.4378   | 19.7195 |\n| 1.777         | 4.0   | 25500 | 2.1027          | 30.9467 | 12.2589 | 25.4487 | 25.4792   | 19.7379 |\n\n\n### Framework versions\n\n- Transformers 4.22.2\n- Pytorch 1.12.1+cu113\n- Datasets 2.5.1\n- Tokenizers 0.12.1\n", "size_bytes": "557723065", "downloads": 32}