{"pretrained_model_name": "gotutiyan/gec-bart-base", "description": "---\nlicense: mit\n---\n\nThis is a reproduction of the following paper:\n```\n@inproceedings{katsumata-komachi-2020-stronger,\n    title = \"Stronger Baselines for Grammatical Error Correction Using a Pretrained Encoder-Decoder Model\",\n    author = \"Katsumata, Satoru  and\n      Komachi, Mamoru\",\n    booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\",\n    month = dec,\n    year = \"2020\",\n    address = \"Suzhou, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.aacl-main.83\",\n    pages = \"827--832\",\n}\n```\n\nThis model achieves the following results:\n|Data|Metric|gotutiyan/gec-bart-base|\n|:--|:--|:--|\n|CoNLL-2014|M2 (P/R/F0.5)|70.0 / 38.5 / 60.2|\n|BEA19-test|ERRANT (P/R/F0.5)|67.7 / 50.1 / 63.3|\n|JFLEG-test|GLEU|55.2|\n\nThe details can be found in the [GitHub repository](https://github.com/gotutiyan/GEC-BART).", "size_bytes": "557969145", "downloads": 49}