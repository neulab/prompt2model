{"pretrained_model_name": "morenolq/distilbart-bbc", "description": "This model is a fine-tuned version of [sshleifer/distilbart-cnn-12-6](https://huggingface.co/sshleifer/distilbart-cnn-12-6) on the BBC News Summary dataset (https://www.kaggle.com/pariza/bbc-news-summary).\n\nThe model has been generated as part of the in-lab practice of **Deep NLP course** currently held at Politecnico di Torino.\n\nTraining parameters:\n- `num_train_epochs=2`\n- `fp16=True`\n- `per_device_train_batch_size=1`\n- `warmup_steps=10`\n- `weight_decay=0.01`\n- `max_seq_length=100`", "size_bytes": "1222369657", "downloads": 2}