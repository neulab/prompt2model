{"pretrained_model_name": "shibing624/t5-chinese-couplet", "description": "---\nlanguage: \n- zh\ntags:\n- t5\n- pytorch\n- zh\n- Text2Text-Generation\nlicense: \"apache-2.0\"\nwidget:\n- text: \"\u5bf9\u8054\uff1a\u4e39\u67ab\u6c5f\u51b7\u4eba\u521d\u53bb\"\n\n---\n\n# T5 for Chinese Couplet(t5-chinese-couplet) Model\nT5\u4e2d\u6587\u5bf9\u8054\u751f\u6210\u6a21\u578b\n\n`t5-chinese-couplet` evaluate couplet test data\uff1a\n\nThe overall performance of T5 on couplet **test**:\n\n|prefix|input_text|target_text|pred|\n|:-- |:--- |:--- |:-- |\n|\u5bf9\u8054\uff1a|\u6625\u56de\u5927\u5730\uff0c\u5bf9\u5bf9\u9ec4\u83ba\u9e23\u6696\u6811|\u65e5\u7167\u795e\u5dde\uff0c\u7fa4\u7fa4\u7d2b\u71d5\u8854\u65b0\u6ce5|\u798f\u81f3\u4eba\u95f4,\u5bb6\u5bb6\u7d2b\u71d5\u821e\u548c\u98ce|\n\n\u5728Couplet\u6d4b\u8bd5\u96c6\u4e0a\u751f\u6210\u7ed3\u679c\u6ee1\u8db3\u5b57\u6570\u76f8\u540c\u3001\u8bcd\u6027\u5bf9\u9f50\u3001\u8bcd\u9762\u5bf9\u9f50\u3001\u5f62\u4f3c\u8981\u6c42\uff0c\u800c\u8bed\u4e49\u5bf9\u4ed7\u5de5\u6574\u548c\u5e73\u4ec4\u5408\u5f8b\u8fd8\u4e0d\u6ee1\u8db3\u3002\n\nT5\u7684\u7f51\u7edc\u7ed3\u6784(\u539f\u751fT5)\uff1a\n\n![arch](t5.png)\n\n## Usage\n\n\u672c\u9879\u76ee\u5f00\u6e90\u5728\u6587\u672c\u751f\u6210\u9879\u76ee\uff1a[textgen](https://github.com/shibing624/textgen)\uff0c\u53ef\u652f\u6301T5\u6a21\u578b\uff0c\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u8c03\u7528\uff1a\n\nInstall package:\n```shell\npip install -U textgen\n```\n\n```python\nfrom textgen import T5Model\nmodel = T5Model(\"t5\", \"shibing624/t5-chinese-couplet\")\nr = model.predict([\"\u5bf9\u8054\uff1a\u4e39\u67ab\u6c5f\u51b7\u4eba\u521d\u53bb\"])\nprint(r) # ['\u767d\u77f3\u77f6\u5bd2\u5ba2\u4e0d\u5f52']\n```\n\n## Usage (HuggingFace Transformers)\nWithout [textgen](https://github.com/shibing624/textgen), you can use the model like this: \n\nFirst, you pass your input through the transformer model, then you get the generated sentence.\n\nInstall package:\n```\npip install transformers \n```\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\ntokenizer = T5Tokenizer.from_pretrained(\"shibing624/t5-chinese-couplet\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"shibing624/t5-chinese-couplet\")\n\n\ndef batch_generate(input_texts, max_length=64):\n    features = tokenizer(input_texts, return_tensors='pt')\n    outputs = model.generate(input_ids=features['input_ids'],\n                             attention_mask=features['attention_mask'],\n                             max_length=max_length)\n    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n\nr = batch_generate([\"\u5bf9\u8054\uff1a\u4e39\u67ab\u6c5f\u51b7\u4eba\u521d\u53bb\"])\nprint(r)\n```\n\noutput:\n```shell\n['\u767d\u77f3\u77f6\u5bd2\u5ba2\u4e0d\u5f52']\n```\n\n\u6a21\u578b\u6587\u4ef6\u7ec4\u6210\uff1a\n```\nt5-chinese-couplet\n    \u251c\u2500\u2500 config.json\n    \u251c\u2500\u2500 model_args.json\n    \u251c\u2500\u2500 pytorch_model.bin\n    \u251c\u2500\u2500 special_tokens_map.json\n    \u251c\u2500\u2500 tokenizer_config.json\n    \u251c\u2500\u2500 spiece.model\n    \u2514\u2500\u2500 vocab.txt\n```\n\n\n### \u8bad\u7ec3\u6570\u636e\u96c6\n#### \u4e2d\u6587\u5bf9\u8054\u6570\u636e\u96c6\n\n- \u6570\u636e\uff1a[\u5bf9\u8054github](https://github.com/wb14123/couplet-dataset)\u3001[\u6e05\u6d17\u8fc7\u7684\u5bf9\u8054github](https://github.com/v-zich/couplet-clean-dataset)\n- \u76f8\u5173\u5185\u5bb9\n  - [Huggingface](https://huggingface.co/)\n  - LangZhou Chinese [MengZi T5 pretrained Model](https://huggingface.co/Langboat/mengzi-t5-base) and [paper](https://arxiv.org/pdf/2110.06696.pdf)\n  - [textgen](https://github.com/shibing624/textgen)\n  \n  \n\u6570\u636e\u683c\u5f0f\uff1a\n\n```text\nhead -n 1 couplet_files/couplet/train/in.txt\n\u665a \u98ce \u6447 \u6811 \u6811 \u8fd8 \u633a \n\nhead -n 1 couplet_files/couplet/train/out.txt\n\u6668 \u9732 \u6da6 \u82b1 \u82b1 \u66f4 \u7ea2 \n```\n\n\n\u5982\u679c\u9700\u8981\u8bad\u7ec3T5\u6a21\u578b\uff0c\u8bf7\u53c2\u8003[https://github.com/shibing624/textgen/blob/main/docs/%E5%AF%B9%E8%81%94%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.md](https://github.com/shibing624/textgen/blob/main/docs/%E5%AF%B9%E8%81%94%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.md)\n\n\n## Citation\n\n```latex\n@software{textgen,\n  author = {Xu Ming},\n  title = {textgen: Implementation of Text Generation models},\n  year = {2022},\n  url = {https://github.com/shibing624/textgen},\n}\n```\n\n", "size_bytes": "990406605", "downloads": 20}