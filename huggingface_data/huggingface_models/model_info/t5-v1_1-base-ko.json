{"pretrained_model_name": "team-lucid/t5-v1_1-base-ko", "description": "---\nlanguage: ko\nlicense: apache-2.0\n---\n\n# hyunwoo3235/t5-v1_1-base-ko\n\n[Google's T5](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) Version 1.1 that trained on korean corpus\n\nt5-v1_1-base-ko\uc740 \ud55c\uad6d\uc5b4 \ucf54\ud37c\uc2a4\uc5d0\uc11c \ud559\uc2b5\ub41c t5 v1.1 \ubaa8\ub378\uc785\ub2c8\ub2e4.\n\nOOV\uc744 \ub9c9\uae30 \uc704\ud574 BBPE\ub97c \uc0ac\uc6a9\ud558\uc600\uc73c\uba70, HyperCLOVA\uc5d0\uc11c \ud615\ud0dc\uc18c \ubd84\uc11d\uc774 \uc131\ub2a5\uc744 \ub192\ud788\ub294\ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \uac83\uc744 \ubcf4\uace0 \ud1a0\ud06c\ub098\uc774\uc800 \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c MeCab\uc744 \uc774\uc6a9\ud574 \ud615\ud0dc\uc18c\uac00 \uc774\uc0c1\ud558\uac8c \ud1a0\ud070\ud654 \ub418\uc9c0 \uc54a\ub3c4\ub85d \ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n## Usage\n```python\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration\n\ntokenizer = AutoTokenizer.from_pretrained('hyunwoo3235/t5-v1_1-base-ko')\nmodel = T5ForConditionalGeneration.from_pretrained('hyunwoo3235/t5-v1_1-base-ko')\n```", "size_bytes": "990402637", "downloads": 37}