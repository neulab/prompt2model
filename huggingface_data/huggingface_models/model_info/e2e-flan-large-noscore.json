{"pretrained_model_name": "divers/e2e-flan-large-noscore", "description": "<table>\n  <thead>\n    <tr>\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n    <td>45</td>\n    <td>0.354900</td>\n    <td>0.269528</td>\n    <td>0.576800</td>\n    <td>0.401800</td>\n    <td>0.459100</td>\n    <td>0.568700</td>\n    <td>477.000000</td>\n  </tr>\n  <tr>\n    <td>46</td>\n    <td>0.336500</td>\n    <td>0.266415</td>\n    <td>0.589300</td>\n    <td>0.407500</td>\n    <td>0.462300</td>\n    <td>0.578900</td>\n    <td>531.588200</td>\n  </tr>\n  <tr>\n    <td>47</td>\n    <td>0.330200</td>\n    <td>0.264836</td>\n    <td>0.527300</td>\n    <td>0.359300</td>\n    <td>0.419800</td>\n    <td>0.519300</td>\n    <td>602.764700</td>\n  </tr>\n  <tr>\n    <td>49</td>\n    <td>0.326100</td>\n    <td>0.263734</td>\n    <td>0.562700</td>\n    <td>0.399900</td>\n    <td>0.458800</td>\n    <td>0.556100</td>\n    <td>562.941200</td>\n  </tr>\n  <tr>\n    <td>49</td>\n    <td>0.326700</td>\n    <td>0.262347</td>\n    <td>0.585700</td>\n    <td>0.413500</td>\n    <td>0.474000</td>\n    <td>0.577500</td>\n    <td>545.882400</td>\n  </tr>\n  <tr>\n    <td>50</td>\n    <td>0.319400</td>\n    <td>0.261993</td>\n    <td>0.581300</td>\n    <td>0.411200</td>\n    <td>0.471100</td>\n    <td>0.570000</td>\n    <td>555.941200</td>\n  </tr>\n  <tr>\n    <td>51</td>\n    <td>0.314700</td>\n    <td>0.261653</td>\n    <td>0.586700</td>\n    <td>0.415300</td>\n    <td>0.473400</td>\n    <td>0.578600</td>\n    <td>543.529400</td>\n  </tr>\n  <tr>\n    <td>53</td>\n    <td>0.311900</td>\n    <td>0.261087</td>\n    <td>0.617900</td>\n    <td>0.433900</td>\n    <td>0.489800</td>\n    <td>0.608700</td>\n    <td>525.647100</td>\n  </tr>\n  <tr>\n    <td>53</td>\n    <td>0.315600</td>\n    <td>0.260690</td>\n    <td>0.616000</td>\n    <td>0.434500</td>\n    <td>0.492100</td>\n    <td>0.606800</td>\n    <td>529.588200</td>\n  </tr>\n  <tr>\n    <td>54</td>\n    <td>0.315400</td>\n    <td>0.260348</td>\n    <td>0.615600</td>\n    <td>0.432100</td>\n    <td>0.489000</td>\n    <td>0.605500</td>\n    <td>535.411800</td>\n  </tr>\n  <tr>\n    <td>55</td>\n    <td>0.307700</td>\n    <td>0.259774</td>\n    <td>0.622600</td>\n    <td>0.443800</td>\n    <td>0.497700</td>\n    <td>0.613200</td>\n    <td>529.647100</td>\n  </tr>\n  <tr>\n    <td>56</td>\n    <td>0.306800</td>\n    <td>0.259790</td>\n    <td>0.620900</td>\n    <td>0.438100</td>\n    <td>0.493000</td>\n    <td>0.610600</td>\n    <td>515.058800</td>\n  </tr>\n  <tr>\n    <td>58</td>\n    <td>0.305700</td>\n    <td>0.259624</td>\n    <td>0.618500</td>\n    <td>0.434000</td>\n    <td>0.489200</td>\n    <td>0.607800</td>\n    <td>506.352900</td>\n  </tr>\n  <tr>\n    <td>58</td>\n    <td>0.310700</td>\n    <td>0.259519</td>\n    <td>0.618800</td>\n    <td>0.434700</td>\n    <td>0.489100</td>\n    <td>0.608000</td>\n    <td>506.529400</td>\n  </tr>\n  <tr>\n    <td>59</td>\n    <td>0.300900</td>\n    <td>0.259501</td>\n    <td>0.618800</td>\n    <td>0.434700</td>\n    <td>0.489100</td>\n    <td>0.608000</td>\n    <td>506.529400</td>\n  </tr>\n</table>\n\n", "size_bytes": "3132793669", "downloads": 2}