{"pretrained_model_name": "kaiyuy/leandojo-lean4-sst-byt5-small", "description": "---\nlicense: mit\ninference:\n  parameters:\n    max_length: 1024\nwidget:\n  - text: \"before\\n\u03b1 : Type?u.60285\\n\u03b2 : Type?u.60288\\nG : Type u_1\\ninst\u271d : Group G\\na b c d : G\\n\u22a2 b / a = c / a \u2194 b = c\\n\\nafter\\n\u03b1 : Type?u.60285\\n\u03b2 : Type?u.60288\\nG : Type u_1\\ninst\u271d : Group G\\na b c d : G\\n\u22a2 b * a\u207b\u00b9 = c * a\u207b\u00b9 \u2194 b = c\"\n    example_title: Example\n---\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean4-sst-byt5-small\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"kaiyuy/leandojo-lean4-sst-byt5-small\")\n\nstate_pair = \"\"\"before\n\u03b1 : Type?u.60285\n\u03b2 : Type?u.60288\nG : Type u_1\ninst\u271d : Group G\na b c d : G\n\u22a2 b / a = c / a \u2194 b = c\n\nafter\n\u03b1 : Type?u.60285\n\u03b2 : Type?u.60288\nG : Type u_1\ninst\u271d : Group G\na b c d : G\n\u22a2 b * a\u207b\u00b9 = c * a\u207b\u00b9 \u2194 b = c\"\"\"\ntokenized_state_pair = tokenizer(state_pair, return_tensors=\"pt\")\n\n# Generate a single tactic.\ntactic_ids = model.generate(tokenized_state_pair.input_ids, max_length=1024)\ntactic = tokenizer.decode(tactic_ids[0], skip_special_tokens=True)\nprint(tactic, end=\"\\n\\n\")\n\n# Generate multiple tactics via beam search.\ntactic_candidates_ids = model.generate(\n    tokenized_state_pair.input_ids,\n    max_length=1024,\n    num_beams=4,\n    length_penalty=0.0,\n    do_sample=False,\n    num_return_sequences=4,\n    early_stopping=False,\n)\ntactic_candidates = tokenizer.batch_decode(\n    tactic_candidates_ids, skip_special_tokens=True\n)\nfor tac in tactic_candidates:\n    print(tac)\n```", "size_bytes": "1198607221", "downloads": 30}