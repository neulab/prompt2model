{"pretrained_model_name": "jed351/bart-zh-hk-wiki", "description": "---\nlanguage:\n- yue\ntags:\n- bart\n- cantonese\n- fill-mask\nlicense: other\n\n---\n\n# bart-base-cantonese\n\nThis is the Cantonese model of BART base. It is based on another model created by: https://huggingface.co/Ayaka/bart-base-cantonese\n\n\n\n## Usage\n\n```python\nfrom transformers import BertTokenizer, BartForConditionalGeneration, Text2TextGenerationPipeline\ntokenizer = BertTokenizer.from_pretrained('jed351/bart-zh-hk-wiki')\nmodel = BartForConditionalGeneration.from_pretrained('jed351/bart-zh-hk-wiki')\ntext2text_generator = Text2TextGenerationPipeline(model, tokenizer)  \noutput = text2text_generator('\u807d\u65e5\u5c31\u8981\u8fd4\u9999\u6e2f\uff0c\u6211\u6fc0\u52d5\u5230[MASK]\u5514\u7740', max_length=50, do_sample=False)\nprint(output[0]['generated_text'].replace(' ', ''))\n```\n\n**Note**: Please use the `BertTokenizer` for the model vocabulary. DO NOT use the original `BartTokenizer`.\n\n\n", "size_bytes": "439152541", "downloads": 10}