{"pretrained_model_name": "yuyijiong/mt0-xl-bf16-sentiment-quadruple", "description": "---\nlanguage:\n- zh\n- en\nlibrary_name: transformers\npipeline_tag: text2text-generation\n---\n\n\u62bd\u53d6\u60c5\u611f\u56db\u5143\u7ec4\u3001\u4e09\u5143\u7ec4\u3001\u4e8c\u5143\u7ec4\u7b49\n```python\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"yuyijiong/mt0-xl-bf16-sentiment-quadruple\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"yuyijiong/mt0-xl-bf16-sentiment-quadruple\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n\ntext = '\u60c5\u611f\u56db\u5143\u7ec4(\u5bf9\u8c61,\u89c2\u70b9,\u65b9\u9762,\u6781\u6027)\u62bd\u53d6\u4efb\u52a1 (\u8865\u5168null): \u3010\u5df2\u7ecf\u5f00\u4e864\u888b,\u666e\u904d\u51fa\u73b0\u7c73\u6cbe\u5728\u5305\u88c5\u4e0a\u4e86,\u770b\u8d77\u6765\u653e\u4e86\u5f88\u4e45\u7684\u6837\u5b50\u3011'\ninput_ids = tokenizer(text,return_tensors=\"pt\", padding=True)['input_ids'].cuda(0)\nwith torch.no_grad():\n    with torch.autocast('cuda'):\n        output = model.generate(input_ids=input_ids)\noutput_str = tokenizer.batch_decode(output, skip_special_tokens=True)\nprint(output_str)\n\n```", "size_bytes": "7485435201", "downloads": 14}