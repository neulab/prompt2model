{"pretrained_model_name": "svjack/gpt-daliy-dialogue", "description": "---\nlanguage:\n- zh\nlibrary_name: transformers\npipeline_tag: text2text-generation\n---\n\n```python\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"svjack/gpt-daliy-dialogue\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\"svjack/gpt-daliy-dialogue\")\n\ntokenizer.decode(\nmodel.generate(\n    tokenizer.encode(\n            \"\u4eca\u5929\u5929\u6c14\u4e0d\u9519\u3002\", return_tensors=\"pt\", add_special_tokens=True\n        ), max_length = 128)[0],\nskip_special_tokens = True\n)\n\n'''\n'\u4eca \u5929 \u5929 \u6c14 \u4e0d \u9519 \u3002 \u771f \u597d \uff0c \u4e0d \u662f \u5417 \uff1f\n\u662f \u7684 \uff0c \u73b0 \u5728 \u7684 \u5929 \u6c14 \u5f88 \u597d \u6211 \u4eec \u53bb \u516c \u56ed \u91cc \u7684 \u90a3 \u4e2a \u98ce \u666f \u533a \u770b \u770b \u5427 \u6211 \u89c9 \u5f97 \u90a3 \u4e2a \u98ce \u666f \u5f88 \u4e0d \u9519 \u3002\n\u90a3 \u662f \u4ec0 \u4e48 \u6837 \u5b50 \u7684 \u516c \u56ed \uff1f \u90a3 \u662f \u4e00 \u4e2a \u4ee5 \u81ea \u7136 \u98ce \u5149 \u800c \u95fb \u540d \u7684 \u516c \u56ed \u3002\n\u6211 \u60f3 \u53bb \u90a3 \u91cc \u722c \u5c71 \u3002 \u6211 \u4eec \u53ef \u4ee5 \u5728 \u90a3 \u91cc \u5403 \u70b9 \u4e1c \u897f \u3002\n\u597d \u554a \u6211 \u4eec \u53ef \u4ee5 \u5728 \u516c \u56ed \u7684 \u505c \u8f66 \u697c \u505c \u4e00 \u4e0b \u3002 \u6211 \u60f3 \u6211'\n'''\n\n```", "size_bytes": "420912233", "downloads": 8}