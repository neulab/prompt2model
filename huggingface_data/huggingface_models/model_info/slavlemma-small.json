{"pretrained_model_name": "amu-cai/slavlemma-small", "description": "---\nlanguage: \n  - pl\n  - cs\n  - ru\ntags:\n  - mT5\n  - lemmatization\nlicense: apache-2.0\n---\n\n\n# SlavLemma Small\n\nSlavLemma models are intended for lemmatization of named entities and multi-word expressions in Polish, Czech and Russian languages.\n\nThey were fine-tuned from the google/mT5 models, e.g.: [google/mt5-small](https://huggingface.co/google/mt5-small).\n\n## Usage\n\nWhen using the model, prepend one of the language tokens (`>>pl<<`, `>>cs<<`, `>>ru<<`) to the input, based on the language of the phrase you want to lemmatize.\n\nSample usage:\n\n```\nfrom transformers import pipeline\n\npipe = pipeline(task=\"text2text-generation\", model=\"amu-cai/slavlemma-small\", tokenizer=\"amu-cai/slavlemma-small\")\nhyp = [res['generated_text'] for res in pipe([\">>pl<< federalnego urz\u0119du statystycznego\"], clean_up_tokenization_spaces=True, num_beams=5)][0]\n```\n\n\n## Evaluation results\n\nLemmatization Exact Match was computed on the SlavNER 2021 test sets (COVID-19 and USA 2020 Elections).\n\n\nCOVID-19:\n| Model | pl | cs | ru |\n| :------ | ------: | ------: | ------: |\n| [slavlemma-large](https://huggingface.co/amu-cai/slavlemma-large) | 93.76 | 89.80 | 77.30\n| [slavlemma-base](https://huggingface.co/amu-cai/slavlemma-base) | 91.00 |86.29| 76.10\n| [slavlemma-small](https://huggingface.co/amu-cai/slavlemma-small)| 86.80 |80.98| 73.83\n\nUSA 2020 Elections:\n| Model | pl | cs | ru |\n| :------ | ------: | ------: | ------: |\n| [slavlemma-large](https://huggingface.co/amu-cai/slavlemma-large) | 89.12 | 87.27| 82.50\n| [slavlemma-base](https://huggingface.co/amu-cai/slavlemma-base) | 84.19 |81.97| 80.27\n| [slavlemma-small](https://huggingface.co/amu-cai/slavlemma-small)| 78.85 |75.86| 76.18\n\n\n## Citation\n\nIf you use the model, please cite the following paper:\n\n```\n@inproceedings{palka-nowakowski-2023-exploring,\n    title = \"Exploring the Use of Foundation Models for Named Entity Recognition and Lemmatization Tasks in {S}lavic Languages\",\n    author = \"Pa{\\l}ka, Gabriela  and\n      Nowakowski, Artur\",\n    booktitle = \"Proceedings of the 9th Workshop on Slavic Natural Language Processing 2023 (SlavicNLP 2023)\",\n    month = may,\n    year = \"2023\",\n    address = \"Dubrovnik, Croatia\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bsnlp-1.19\",\n    pages = \"165--171\",\n    abstract = \"This paper describes Adam Mickiewicz University{'}s (AMU) solution for the 4th Shared Task on SlavNER. The task involves the identification, categorization, and lemmatization of named entities in Slavic languages. Our approach involved exploring the use of foundation models for these tasks. In particular, we used models based on the popular BERT and T5 model architectures. Additionally, we used external datasets to further improve the quality of our models. Our solution obtained promising results, achieving high metrics scores in both tasks. We describe our approach and the results of our experiments in detail, showing that the method is effective for NER and lemmatization in Slavic languages. Additionally, our models for lemmatization will be available at: https://huggingface.co/amu-cai.\",\n}\n```\n\n### Framework versions\n\n- Transformers 4.26.0\n- Pytorch 1.13.1.post200\n- Datasets 2.9.0\n- Tokenizers 0.13.2\n", "size_bytes": "1200772485", "downloads": 4}