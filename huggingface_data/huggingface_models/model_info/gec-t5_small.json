{"pretrained_model_name": "Unbabel/gec-t5_small", "description": "---\nlanguage:\n- en\ntags:\n- grammatical error correction\n- text2text\n- t5\nlicense: apache-2.0\ndatasets:\n- clang-8\n- conll-14\n- conll-13\nmetrics:\n- f0.5\n---\n\nThis model is an implementation of the paper [A Simple Recipe for Multilingual Grammatical Error Correction](https://arxiv.org/pdf/2106.03830.pdf) from Google where they report the State of the art score in the task of Grammatical Error Correction (GEC).\nWe implement the version with the T5-small with the reported F_0.5 score in the paper (60.70).\n\nTo effectively use the \"Hosted inference API\", write \"gec: [YOUR SENTENCE HERE]\".\n\nIn order to use the model, look at the following snippet:\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"Unbabel/gec-t5_small\")\ntokenizer = T5Tokenizer.from_pretrained('t5-small')\n\nsentence = \"I like to swimming\"\ntokenized_sentence = tokenizer('gec: ' + sentence, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\ncorrected_sentence = tokenizer.decode(\n    model.generate(\n        input_ids = tokenized_sentence.input_ids,\n        attention_mask = tokenized_sentence.attention_mask, \n        max_length=128,\n        num_beams=5,\n        early_stopping=True,\n    )[0],\n    skip_special_tokens=True, \n    clean_up_tokenization_spaces=True\n)\nprint(corrected_sentence) # -> I like swimming.\n```", "size_bytes": "242083771", "downloads": 428}