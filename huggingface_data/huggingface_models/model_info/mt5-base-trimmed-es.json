{"pretrained_model_name": "research-backup/mt5-base-trimmed-es", "description": "# Vocabulary Trimmed [google/mt5-base](https://huggingface.co/google/mt5-base): `vocabtrimmer/mt5-base-trimmed-es` \nThis model is a trimmed version of [google/mt5-base](https://huggingface.co/google/mt5-base) by [`vocabtrimmer`](https://github.com/asahi417/lm-vocab-trimmer), a tool for trimming vocabulary of language models to compress the model size.\nFollowing table shows a summary of the trimming process.\n\n|                            | google/mt5-base   | vocabtrimmer/mt5-base-trimmed-es   |\n|:---------------------------|:------------------|:-----------------------------------|\n| parameter_size_full        | 582,401,280       | 399,606,528                        |\n| parameter_size_embedding   | 384,172,032       | 201,377,280                        |\n| vocab_size                 | 250,112           | 131,105                            |\n| compression_rate_full      | 100.0             | 68.61                              |\n| compression_rate_embedding | 100.0             | 52.42                              |\n\n\nFollowing table shows the parameter used to trim vocabulary.\n\n | language   | dataset                     | dataset_column   | dataset_name   | dataset_split   | target_vocab_size   |   min_frequency |\n|:-----------|:----------------------------|:-----------------|:---------------|:----------------|:--------------------|----------------:|\n| es         | vocabtrimmer/mc4_validation | text             | es             | validation      |                     |               2 |", "size_bytes": "1598519477", "downloads": 2}