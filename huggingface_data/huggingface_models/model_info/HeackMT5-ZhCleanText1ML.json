{"pretrained_model_name": "heack/HeackMT5-ZhCleanText1ML", "description": "---\npipeline_tag: text2text-generation\n---\n\n# HeackMT5-ZhCleanText1ML: A Text Cleaning Model for Chinese Texts\n\nThis model, `heack/HeackMT5-ZhCleanText1ML`, is a fine-tuned mT5 model for Chinese text cleaning tasks. It is designed to remove gibberish, clean up the text, retain original information as much as possible, and does not process large sections of non-Chinese text (such as English text).\n\n\u6b64\u6a21\u5757\uff0c\u4e3b\u8981\u89e3\u51b3\u56f0\u6270\u4e2d\u56fd\u4e92\u8054\u7f51\u591a\u5e74\u7684\u4e71\u7801\u95ee\u9898\uff0c\u540c\u65f6\u501f\u52a9Transformer\u5927\u6a21\u578b\uff0c\u53ef\u4ee5\u5bf9\u6587\u5b57\u8fdb\u884c\u63d0\u70bc\uff08\u5f88\u5c11\u7684\u60c5\u51b5\u4e0b\u4ee5\u53ca\n\u6a21\u578b\u975e\u5e38\u786e\u4fe1\u7684\u60c5\u51b5\u4e0b\uff09\uff0c\u8fdb\u884c\u6587\u5b57\u6e05\u7406\u3002\u4f60\u5927\u53ef\u4ee5\u76f8\u4fe1\u6b64\u6a21\u578b\uff0c\u5b83\u4e0d\u4f1a\u5bf9\u4f60\u7684\u6587\u672c\u8fdb\u884c\u4efb\u610f\u7684\u6539\u52a8\u3002\u5bf9\u4e8e\u975e\u4e2d\u6587\u5b57\u7b26\u7684\u6587\u672c\uff0c\n\u672c\u6a21\u578b\u4e0d\u505a\u5904\u7406\u3002\n\n\u6b64\u6a21\u578b\u57fa\u4e8e100\u4e07\u884c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u5f97\u5230\uff0c\u8bad\u7ec3\u7ed3\u679c\uff1a\n\n\n|  step    | epoch | learning_rate          | loss   | eval_loss         \n|------|-------|------------------------|--------|--------\n| 129000   | 3.73  | 1e-05  | 1.714 | 1.706  \n\n\n## Model Details\n\n- Model: mT5\n- Language: Chinese (multiple languages supported)\n\n## Usage\n\nHere is how you can use this model for text cleaning:\n\n```python\nfrom transformers import MT5ForConditionalGeneration, T5Tokenizer\nmodel = MT5ForConditionalGeneration.from_pretrained(\"heack/HeackMT5-ZhCleanText1ML\")\ntokenizer = T5Tokenizer.from_pretrained(\"heack/HeackMT5-ZhCleanText1ML\")\ntext = \"\"\"\n\u5927\u4f17\u6c7d\u8f66\u96c6\u56e2\u5728\u7b2c\u4e94\u5c4a\u4e2d\u56fd\u56fd\u9645\u8fdb\u53e3\u535a\u89c8\u4f1a\u643a\u65d7\u4e0b\u5927\u4f17\u6c7d\u8f66\u54c1\u724c\u3001\u5965\u7076\u6db2\u5f0a\u80c0\u6f14\u8e42\u7a77\u8e6d\u9f7f\u6e2f\u545b\u5978\u6000\u752b\u78c1\u6d12\u66ae\u70c2\u7281\u6295\u8fea\u54c1\u724c\u548c\u4fdd\u65f6\u6377\u54c1\u724c\u4eae\u76f8\uff0c\u5171\u5c55\u51fa5\u6b3e\u7eaf\u7535\u52a8\u8f66\n\u578b\u3002\u5176\u4e2d\uff0c\u5927\u4f17\u6c7d\u8f66\u5f79\u7edc\u89c2\u793a\u60d1\u89c9\u9ad3\u54c1\u724c\u5c55\u51fa\u4e86ID.\u5bb6\u65cf\u6700\u65b0\u6210\u5458\u2014\u2014ID.AERO\u6982\u5ff5\u8f66\uff0c\u5c06\u4e8e2023\u5e74\u4e0a\u5e02\uff1b\u5965\u8fea\u5c55\u51fa\u4e86\u4e24\u6b3e\u8c6a\u534e\u8fd0\u52a8\u7eaf\u7535\u52a8\u8f66\u5965\u8feaRS e-tro???Mission GT\u548c\u9996\u6b3e\u201cRoadjet\n\u9646\u5730\u4e13\u673a\u201d\u5965\u8feaQ5e-t\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u01b7\ufffd2022\ufffd\ufffd\u05e3\ufffd\ufffd\u00b5\u03fdron\u3002\u52302022\u5e74\u5e95\uff0c\u5965\u8fea\u5c06\u5728\u4e2d\u56fdD\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u5e02\u573a\u63d0\u4f9b7\u6b3e\u65b0\u80fd\u6e90\u8f66\u578b\u3002\u4fdd\u65f6\u6377\u5219\u5c55\u51fa\u4e86\u4e24\u6b3e\u7eaf\u7535\u52a8\u8f66\uff0c\u5176\u4e2d\u4fdd\u65f6\u6377Mission R\u6982\u5ff5\u8f66\u4e3a\u4e9a\u6d32\u9996\u79c0\u3002\u4fdd\u65f6\u6377\u5c06\u8fdb\u4e00\u6b65\u5728\u7535\u6c14\u5316\u9886\u57df\u6301\u7eed\u53d1\u529b\uff0c\u5927\u91cf\u521b\u65b0\u6280\n\u672f\u8424\u6052\u6254\u526a\u79c6\u4ec1\u5fd9\u6b83\u6389\u96c4\u505c\u9075\u5192\u59d1\u53ea\u8138\u7389\u5323\u6709\u671b\u5e94\u7528\u4e8e\u672a\u6765\u7684\u91cf\u4ea7\u8f66\u4e2d\uff0c\u5305\u62ec\u5168\u65b0\u7684\u7535\u6c60\u7ec4\u548c\u51b7\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u5374\u7cfb\u7edf\u7b49\u3002\u201c\u81ea2015\u5e74\u4ee5\u6765\uff0c\u4e2d\u56fd\u5728\u667a\u80fd\u6c7d\u8f66\u9886\u57df\u5df2\u9010\u6e10\u5728\u4e16\u754c\u4e0a\u9886\u5148\u3002\u5728\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\uff0c\u6ca1\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u6280\u672f\u521b\u65b0\u548c\u5b9e\u65bd\u901f\u5ea6\u73b0\u5728\u80fd\u591f\u8d85\u8d8a\u4e2d\u56fd\u3002\u201d\u5927\u4f17\u6c7d\u8f66\u96c6d\n\u56e2\u6267\u884c\u526f\u603b\u88c1\u5218\u4e91\u5cf0\u8bf4\uff0c\u4ed6\u6307\u51fa\uff0c\u4e2d\u5fb7\u53cc\u65b9\u7684\u52a1\u5b9e\u5408\u4f5c\u5e7f\u6cdb\u800c\u6df1\u5165\uff0c\u5176\u4e2d\u7ecf\u8d38\u5408\u4f5c\u53d1\u6325\u4e86\u538b\u8231\u77f3\u4f5c\u9473\u85c9\u5bf2\u675e\ufffd\u9368\u5b2c\u6b91\u6d93\u7ed8\u57ac\u9366\u8f70\u7ba3\u6d93\ufffd\u9286\u7528\uff0c\u7279\u522b\u662f\u5728\u638f\u50bb\u6c7d\u8f66\u884c\u4e1a\u3002\u5927\u4f17\u6c7d\u8f66\u96c6\u56e2\u6709\u5173\u4eba\u58eb\u4ecb\u7ecd\uff0c\u5927\u4f17\u6b63\u79ef\u6781\u4e3b\u52a8\u5730\u63a8\u8fdb\u8f6c\u578b\uff0c\u521b\u65b0\u6c42\u53d8\uff0coYFb\u800c\u4e2d\u56fd\u662f\u5927\u4f17\u6c7d\u8f66\u5411\u7535\u52a8\u5316\u548c\u4ea4\u667a\u80fd\u5316\n\u8f6c\u578b\u7684\u4e3b\u6218\u573a\u4e4b\u4e00\u3002\u9664\u4e86\u4ee3\u8868\u5927\u4f17\u8fc4\u67d1\u5c45\u6627\u61e6\u6c7d\u8f66\u7535\u52a8\u5316\u653b\u52bf\u7684\u591a\u6b3e\u7eaf\u7535\u8f66\u578b\u548c\u521b\u65b0\u6280\u672f\u5916\uff0c\u5927\u4f17\u6c7d\u8f66\u8fd8\u5728\u672c\u5c4a\u8fdb\u535a<script\u4f1a\u901a\u8fc7\u4e92\u52a8\u5f62\u5f0f\u5c55\u793a\u4e86\u65d7\u4e0b\u8f6f\u4ef6\u516c\u53f8CARIAD\u7684\u6700\u65b0\u8f6f\u4ef6\u7814\u53d1\u6210\u679c\u3002\u6309\u8ba1\u5212\uff0c\u5728\u4e2d\u56fd\uff0c\u5927\u4f17\u6c7d\u8f66\u54c1\u724cID.\u5bb6\u65cf\u6d74\u5c4b??????????????\u8042\u65e5\u7968\u7ee2\u7f00\u90c1\u787c\u9b4f\u6316\u4e24\n\u88d9\u5feb\u6e29\u5c4e\u68e0\u8650\u60e8\u9047\u7684\u4ea7\u54c1\u9635\u5bb9\u5c06\u62d3\u5c55\u81f3\u7eaf\u7535\u4e2d\u578b\u8f7f\u8f66\u7ec6\u5206\u5e02\u573a\u3002\n\"\"\"\ninputs = tokenizer(\"filter:\"+text, return_tensors=\"pt\")\noutputs = model.generate(inputs.input_ids, max_new_tokens=512)\nfiltered_text = tokenizer.decode(outputs[0], skip_special_tokens=True, num_beams=4, length_penalty=0.8)\nprint(filtered_text)\n======================\n\"\"\"\n\u5927\u4f17\u6c7d\u8f66\u96c6\u56e2\u5728\u7b2c\u4e94\u5c4a\u4e2d\u56fd\u56fd\u9645\u8fdb\u53e3\u535a\u89c8\u4f1a\u643a\u65d7\u4e0b\u5927\u4f17\u6c7d\u8f66\u54c1\u724c\u3001\u5965\u8fea\u54c1\u724c\u548c\u4fdd\u65f6\u6377\u54c1\u724c\u4eae\u76f8,\u5171\u5c55\u51fa5\u6b3e\u7eaf\u7535\u52a8\u8f66\n\u578b\u3002\u5176\u4e2d,\u5927\u4f17\u6c7d\u8f66\u54c1\u724c\u5c55\u51fa\u4e86ID.\u5bb6\u65cf\u6700\u65b0\u6210\u5458\u2014\u2014ID.AERO\u6982\u5ff5\u8f66,\u5c06\u4e8e2023\u5e74\u4e0a\u5e02;\u5965\u8fea\u5c55\u51fa\u4e86\u4e24\u6b3e\u8c6a\u534e\u8fd0\u52a8\u7eaf\u7535\u52a8\u8f66\u5965\u8feaRS e-tronMission GT\u548c\u9996\u6b3e\u201cRoadjet \n\u9646\u5730\u4e13\u673a\u201d\u5965\u8feaQ5e-tron\u3002\u52302022\u5e74\u5e95,\u5965\u8fea\u5c06\u5728\u4e2d\u56fd\u5e02\u573a\u63d0\u4f9b7\u6b3e\u65b0\u80fd\u6e90\u8f66\u578b\u3002\u4fdd\u65f6\u6377\u5219\u5c55\u51fa\u4e86\u4e24\u6b3e\u7eaf\u7535\u52a8\u8f66,\u5176\u4e2d\u4fdd\u65f6\u6377Mission R\u6982\u5ff5\u8f66\u4e3a\u4e9a\u6d32\u9996\u79c0\u3002\u4fdd\u65f6\u6377\u5c06\u8fdb\u4e00\u6b65\u5728\u7535\u6c14\u5316\u9886\u57df\u6301\u7eed\u53d1\u529b,\u5927\u91cf\u521b\u65b0\u6280\n\u672f\u6709\u671b\u5e94\u7528\u4e8e\u672a\u6765\u7684\u91cf\u4ea7\u8f66\u4e2d,\u5305\u62ec\u5168\u65b0\u7684\u7535\u6c60\u7ec4\u548c\u51b7\u5374\u7cfb\u7edf\u7b49\u3002\u201c\u81ea2015\u5e74\u4ee5\u6765,\u4e2d\u56fd\u5728\u667a\u80fd\u6c7d\u8f66\u9886\u57df\u5df2\u9010\u6e10\u5728\u4e16\u754c\u4e0a\u9886\u5148\u3002\u5728\u81ea\u52a8\u9a7e\u9a76\u9886\u57df,\u6ca1\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u6280\u672f\u521b\u65b0\u548c\u5b9e\u65bd\u901f\u5ea6\u73b0\u5728\u80fd\u591f\u8d85\u8d8a\u4e2d\u56fd\u3002\u201d\u5927\u4f17\u6c7d\u8f66\u96c6\n\u56e2\u6267\u884c\u526f\u603b\u88c1\u5218\u4e91\u5cf0\u8bf4,\u4ed6\u6307\u51fa,\u4e2d\u5fb7\u53cc\u65b9\u7684\u52a1\u5b9e\u5408\u4f5c\u5e7f\u6cdb\u800c\u6df1\u5165,\u5176\u4e2d\u7ecf\u8d38\u5408\u4f5c\u53d1\u6325\u4e86\u538b\u8231\u77f3\u4f5c\u7528,\u7279\u522b\u662f\u5728\u6c7d\u8f66\u884c\u4e1a\u3002\u5927\u4f17\u6c7d\u8f66\u96c6\u56e2\u6709\u5173\u4eba\u58eb\u4ecb\u7ecd,\u5927\u4f17\u6b63\u79ef\u6781\u4e3b\u52a8\u5730\u63a8\u8fdb\u8f6c\u578b,\u521b\u65b0\u6c42\u53d8,\u800c\u4e2d\u56fd\u662f\u5927\u4f17\u6c7d\u8f66\u5411\u7535\u52a8\u5316\u548c\u4ea4\u667a\u80fd\u5316 \n\u8f6c\u578b\u7684\u4e3b\u6218\u573a\u4e4b\u4e00\u3002\u9664\u4e86\u4ee3\u8868\u5927\u4f17\u6c7d\u8f66\u7535\u52a8\u5316\u653b\u52bf\u7684\u591a\u6b3e\u7eaf\u7535\u8f66\u578b\u548c\u521b\u65b0\u6280\u672f\u5916,\u5927\u4f17\u6c7d\u8f66\u8fd8\u5728\u672c\u5c4a\u8fdb\u535a\u4f1a\u901a\u8fc7\u4e92\u52a8\u5f62\u5f0f\u5c55\u793a\u4e86\u65d7\u4e0b\u8f6f\u4ef6\u516c\u53f8CARIAD\u7684\u6700\u65b0\u8f6f\u4ef6\u7814\u53d1\u6210\u679c\u3002\u6309\u8ba1\u5212,\u5728\u4e2d\u56fd,\u5927\u4f17\u6c7d\u8f66\u54c1\u724cID.\u5bb6\u65cf\u7684\u4ea7\u54c1\u9635\u5bb9\u5c06\u62d3\u5c55\u81f3\u7eaf\u7535\u4e2d\u578b\u8f7f\u8f66\u7ec6\u5206\u5e02\u573a\u3002\n\"\"\"\n```\n## For long text(more than 512 tokens)\n\n```python\nfrom transformers import MT5ForConditionalGeneration, T5Tokenizer\n\ndef split_text(text, tokenizer, length):\n    chunks = []\n    chunk = \"\"\n    for char in text:\n        chunk = chunk + char\n        if len(tokenizer.encode(chunk, truncation=False)) >= length:\n            if char in {'.', '\u3002', '\uff0c', ',', '\\n'}:\n                chunks.append(chunk)\n                chunk = \"\"\n            else:\n                for i in range(1, 21):\n                    if chunk[-i] in {'.', '\u3002', '\uff0c', ',', '\\n'}:\n                        break\n                else:\n                    i = 0\n                if i == 0:\n                    chunks.append(chunk)\n                    chunk = \"\"\n                else:\n                    chunks.append(chunk[:-i])\n                    chunk = chunk[-i:]\n    chunks.append(chunk)\n\n    assert \"\".join(chunks) == text\n    return chunks\n\ndef filter_luanma_text(text, model, tokenizer):\n    chunks = split_text(text, tokenizer,500)\n    filter_texts = []\n    for chunk in chunks:\n        inputs = tokenizer(\"filter:\" + chunk, return_tensors=\"pt\")\n        outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=500)\n        filter_text = tokenizer.decode(outputs[0], max_length=500, skip_special_tokens=True, num_beams=4, length_penalty=0.8)\n        filter_texts.append(filter_text)\n    return \" \".join(filter_texts)\n\nmodel = MT5ForConditionalGeneration.from_pretrained(\"heack/HeackMT5-ZhCleanText1ML\")\ntokenizer = T5Tokenizer.from_pretrained(\"heack/HeackMT5-ZhCleanText1ML\")\n\nfiltered_text = filter_luanma_text(\"\u9700\u8981df\u8fc7\u6ee4\u7684\u6587=\u672c\", model, tokenizer)\nprint(filtered_text)\n======================================\n\"\"\"\n\u9700\u8981\u8fc7\u6ee4\u7684\u6587\u672c\n\"\"\"\n```\n\n\n\n## Credits\nThis model is trained and maintained by KongYang from Shanghai Jiao Tong University. For any questions, please reach out to me at my WeChat ID: kongyang.\n\n## License\nThis model is released under the CC BY-NC-SA 4.0 license.\n\n## Citation\n\nIf you use this model in your research, please cite:\n\n## Citation\n\nIf you use this model in your research, please cite:\n\n```bibtex\n@misc{kongyang2023heackmt5ZhCleanText1ML,\n    title={heack/HeackMT5-ZhCleanText1ML: A Large-Scale Multilingual Abstractive Summarization for Chinese Texts},\n    author={Kong Yang},\n    year={2023}\n}\n\n", "size_bytes": "2329696205", "downloads": 30}