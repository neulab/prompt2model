{"pretrained_model_name": "akhooli/mbart-large-cc25-ar-en", "description": "---\ntags:\n- translation\n\nlanguage:\n- ar\n- en\n\nlicense: mit\n---\n### mbart-large-ar-en\nThis is mbart-large-cc25, finetuned on a subset of the OPUS corpus for ar_en.   \nUsage: see [example notebook](https://colab.research.google.com/drive/1I6RFOWMaTpPBX7saJYjnSTddW0TD6H1t?usp=sharing)  \nNote: model has limited training set, not fully trained (do not use for production).   \nOther models by me: [Abed Khooli](https://huggingface.co/akhooli)  \n", "size_bytes": "2444523612", "downloads": 33}