{"pretrained_model_name": "valhalla/m2m100_tiny_random", "description": "---\nlanguage: \n- multilingual\n\ntags:\n- text-2-text-generation\n- m2m_100\n---\n\n# Model Card for KeywordIdentifier  \n \n# Model Details\n \n## Model Description\n \nMore information needed\n \n- **Developed by:** Facebook\n- **Shared by [Optional]:** Suraj Patil\n- **Model type:** Text2Text Generation\n- **Language(s) (NLP):** More information needed\n- **License:** More information needed\n- **Parent Model:** [M2M100]https://huggingface.co/facebook/m2m100_418M)\n- **Resources for more information:** \n    - [M2M100 Associated Paper](https://arxiv.org/abs/2010.11125)\n\n# Uses\n \n\n## Direct Use\nThis model can be used for the task of Text2Text Generation. \n \n## Downstream Use [Optional]\n \nMore information needed.\n \n## Out-of-Scope Use\n \nThe model should not be used to intentionally create hostile or alienating environments for people. \n \n# Bias, Risks, and Limitations\n \n \nSignificant research has explored bias and fairness issues with language models (see, e.g., [Sheng et al. (2021)](https://aclanthology.org/2021.acl-long.330.pdf) and [Bender et al. (2021)](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)). Predictions generated by the model may include disturbing and harmful stereotypes across protected classes; identity characteristics; and sensitive, social, and occupational groups.\n\n\n\n## Recommendations\n \n \nUsers (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.\n\n# Training Details\n \n## Training Data\n \nMore information needed \n \n## Training Procedure\n\n \n### Preprocessing\n \nMore information needed \n\n\n \n### Speeds, Sizes, Times\n \nMore information needed \n\n\n \n# Evaluation\n \n \n## Testing Data, Factors & Metrics\n \n### Testing Data\n \nMore information needed\n \n### Factors\nMore information needed\n \n### Metrics\n \nMore information needed\n \n \n## Results \n \nMore information needed\n\n \n# Model Examination\n \nMore information needed\n \n# Environmental Impact\n \nCarbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).\n \n- **Hardware Type:** More information needed\n- **Hours used:** More information needed\n- **Cloud Provider:** More information needed\n- **Compute Region:** More information needed\n- **Carbon Emitted:** More information needed\n \n# Technical Specifications [optional]\n \n## Model Architecture and Objective\n \nMore information needed\n \n## Compute Infrastructure\n \nMore information needed\n \n### Hardware\n \n \nMore information needed\n \n### Software\n \nMore information needed.\n \n# Citation\n\n \n**BibTeX:**\n \nMore information needed\n```bibtex \n@misc{fan2020englishcentric,\n      title={Beyond English-Centric Multilingual Machine Translation}, \n      author={Angela Fan and Shruti Bhosale and Holger Schwenk and Zhiyi Ma and Ahmed El-Kishky and Siddharth Goyal and Mandeep Baines and Onur Celebi and Guillaume Wenzek and Vishrav Chaudhary and Naman Goyal and Tom Birch and Vitaliy Liptchinsky and Sergey Edunov and Edouard Grave and Michael Auli and Armand Joulin},\n      year={2020},\n      eprint={2010.11125},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\n\n\n**APA:**\n\nMore information needed\n  \n# Glossary [optional]\n \nMore information needed\n\n# More Information [optional]\nSee the [model hub](https://huggingface.co/models?filter=m2m_100) for more fine-tuned versions.\n\n# Model Card Authors [optional]\n \nSuraj Patil  in collaboration with Ezi Ozoani and the Hugging Face team\n\n# Model Card Contact\n \nMore information needed\n \n# How to Get Started with the Model\n \nUse the code below to get started with the model.\n \n<details>\n<summary> Click to expand </summary>\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"valhalla/m2m100_tiny_random\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"valhalla/m2m100_tiny_random\")\n \n ```\n</details>\n", "size_bytes": "12917483", "downloads": 5}