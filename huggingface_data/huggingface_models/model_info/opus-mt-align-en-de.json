{"pretrained_model_name": "silsever/opus-mt-align-en-de", "description": "---\nlanguage:\n- en\n- de\ntags:\n- translation\n- opus-mt\nlicense: cc-by-4.0\nmodel-index:\n- name: opus-mt-tc-big-eng-deu\n  results:\n  - task:\n      name: Translation eng-deu\n      type: translation\n      args: eng-deu\n    dataset:\n      name: Tatoeba-test.eng-deu\n      type: tatoeba_mt\n      args: eng-deu\n    metrics:\n    - name: BLEU\n      type: bleu\n      value: 45.7\t\n---\n\n# Opus Tatoeba English-German\n\n*This model was obtained by running the script [convert_marian_to_pytorch.py](https://github.com/huggingface/transformers/blob/master/src/transformers/models/marian/convert_marian_to_pytorch.py) - [Instruction available here](https://github.com/huggingface/transformers/tree/main/scripts/tatoeba). The original models were trained by [J\u00f6rg Tiedemann](https://blogs.helsinki.fi/tiedeman/) using the [MarianNMT](https://marian-nmt.github.io/) library. See all available `MarianMTModel` models on the profile of the [Helsinki NLP](https://huggingface.co/Helsinki-NLP) group.\n\nThis is the conversion of checkpoint [opus+bt-2021-04-13.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus+bt-2021-04-13.zip)\n*\n\n\n---\n\n### eng-deu\n\n* source language name: English\n* target language name: German\n* OPUS readme: [README.md](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/README.md)\n\n* model: transformer-align\n* source language code: en\n* target language code: de\n* dataset: opus+bt \n* release date: 2021-02-22\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus+bt-2021-04-13.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus+bt-2021-04-13.zip)\n* Test set translations data: [opus+bt-2021-04-13.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus+bt-2021-04-13.test.txt)\n* test set scores file: [opus+bt-2021-04-13.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus+bt-2021-04-13.eval.txt)\n* Benchmarks\n|Test set|BLEU|chr-F|\n|---|---|---|\n|newssyscomb2009.eng-deu|22.8|0.538|\n|news-test2008.eng-deu|23.7|0.533|\t\n|newstest2009.eng-deu|22.6|0.532|\t\n|newstest2010.eng-deu|25.5|0.552|\t\n|newstest2011.eng-deu|22.6|0.527|\t\n|newstest2012.eng-deu|23.4|0.530|\t\n|newstest2013.eng-deu|27.1|0.556|\t\n|newstest2014-deen.eng-deu|29.6|0.599|\t\n|newstest2015-ende.eng-deu|31.6|0.600|\t\n|newstest2016-ende.eng-deu|37.2|0.644|\t\n|newstest2017-ende.eng-deu|30.6|0.595|\t\n|newstest2018-ende.eng-deu|45.6|0.696|\t\n|newstest2019-ende.eng-deu|41.3|0.659|\t\n|Tatoeba-test.eng-deu|45.7|0.654|\t\n", "size_bytes": "221612169", "downloads": 12}