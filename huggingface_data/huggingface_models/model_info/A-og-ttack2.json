{"pretrained_model_name": "ogtal/A-og-ttack2", "description": "---\nlanguage:\n- no\n- da\nlibrary_name: transformers\nmetrics:\n- f1-score (Danish): 0.87\n- f1-score (Norwegian): 0.76\n---\n# Model Card for A&ttack2\n\nA text classification model for determining if a social media post in Danish or Norwegian contains a verbal attack.\n\n# Model Description\n\nThe model is based on the north/t5_large_scand (by Per E. Kummervold, not publicly available) which is a Scandinavian language pretrained for 1.700.000 steps starting with the mT5 checkpoint on a Scandinavian corpus (Bokm\u00e5l, Nynorsk, Danish, Swedish and Icelandic (+ a tiny bit Faeroyish)).\n\nThe model is finetuned for 20.000 steps in batches of 8. The data consists of ~70k Norwegian and ~67k Danish social media posts which have been classified as either 'verbal attack' or 'nothing', making it a text-to-text model restricted to do classification. The model is described in Danish in [this report](https://www.ogtal.dk/assets/files/230403-Analyse-Tall-Angrep-hat-i-den-offentlige-debatten-paa-Facebook.pdf).\n\n\n- **Developed by:** The development team at Analyse & Tal\n- **Model type:** Language model restricted to classification\n- **Language(s) (NLP):** Danish and Norwegian\n- **License:** [More Information Needed]\n- **Finetuned from model:** north/t5_large_scand (by Per E. Kummervold, not publicly available)\n\n\n# Direct Use\nThis model can be used for classifying Danish and Norwegian social media posts (or other texts) as either 'verbal attack' or 'nothing'.\n\n# Training Data\nA collection of ~70k Norwegian and ~67k Danish social media posts have been manually annotated as 'verbal attack' or 'nothing' by annotators. 5% of the posts have been annotated by more then one annotator, with the annotators in agreement for 83% of annotations.\n\nNorwegian data are split  in 70% training, 20% validation and 10% test. The Danish data are split in 70% training, 15% validation and 15% test. \n\n# Evaluation Metrics\n\nMacro-averaged f1-score for Danish data: 0.87\nMacro-averaged f1-score for Norwegian data: 0.76\n\n\n# Model Card Authors\nThis model card was written by the developer team at Analyse & Tal. Contact: oyvind@ogtal.dk.\n\n# How to Get Started with the Model\n\nUse the code below to get started with the model.\n\n```\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Download/load tokenizer and language model\ntokenizer = AutoTokenizer.from_pretrained(\"ogtal/A-og-ttack2\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"ogtal/A-og-ttack2\")\n\n# Give sample text. The example is from a social media comment.\nsample_text = \"Velbekomme dit klamme usle l\u00f8gnersvin!\"\ninput_ids = tokenizer(sample_text, return_tensors=\"pt\").input_ids\n\n# Forward pass and print the output\noutputs = model.generate(input_ids)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n```\n\nRunning the above code will print \"angreb\" (attack in Danish).", "size_bytes": "4918515513", "downloads": 166}