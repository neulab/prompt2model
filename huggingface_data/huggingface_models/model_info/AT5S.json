{"pretrained_model_name": "huawei-noah/AT5S", "description": "---\nlicense: apache-2.0\n---\n\n# Overview\n\n<p align=\"center\">\n  <img src=\"https://avatars.githubusercontent.com/u/12619994?s=200&v=4\" width=\"150\">\n</p>\n\n<!-- -------------------------------------------------------------------------------- -->\n\nAT5S is an Arabic T5-small model. It's is **only compatible** with the code in [this github repo](https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch) (not supported by the [Transformers](https://github.com/huggingface/transformers) library)\n \n## Citation\n\nPlease cite the following [paper](https://arxiv.org/pdf/2205.10687.pdf) when using our code and model:\n\n``` bibtex\n@article{ghaddar2022revisiting,\n  title={Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Understanding},\n  author={Ghaddar, Abbas and Wu, Yimeng and Bagga, Sunyam and Rashid, Ahmad and Bibi, Khalil and Rezagholizadeh, Mehdi and Xing, Chao and Wang, Yasheng and Xinyu, Duan and Wang, Zhefeng and others},\n  journal={arXiv preprint arXiv:2205.10687},\n  year={2022}\n}\n```\n\n", "size_bytes": "438482461", "downloads": 2}