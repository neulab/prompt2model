{"pretrained_model_name": "jannatul17/squad-bn-qgen-banglat5", "description": "---\ntags:\n- generated_from_trainer\ndatasets:\n- squad_bn\nmetrics:\n- sacrebleu\nmodel-index:\n- name: squad-bn-qgen-banglat5\n  results:\n  - task:\n      name: Sequence-to-sequence Language Modeling\n      type: text2text-generation\n    dataset:\n      name: squad_bn\n      type: squad_bn\n      args: squad_bn\n    metrics:\n    - name: Sacrebleu\n      type: sacrebleu\n      value: 8.0898\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# squad-bn-qgen-banglat5\n\nThis model is a fine-tuned version of [csebuetnlp/banglat5](https://huggingface.co/csebuetnlp/banglat5) on the squad_bn dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.4808\n- Rouge1 Precision: 37.7366\n- Rouge1 Recall: 34.2712\n- Rouge1 Fmeasure: 34.8738\n- Rouge2 Precision: 16.2055\n- Rouge2 Recall: 14.568\n- Rouge2 Fmeasure: 14.852\n- Rougel Precision: 35.4241\n- Rougel Recall: 32.2011\n- Rougel Fmeasure: 32.7617\n- Rougelsum Precision: 35.4167\n- Rougelsum Recall: 32.1978\n- Rougelsum Fmeasure: 32.7572\n- Sacrebleu: 8.0898\n- Meteor: 0.1782\n- Gen Len: 9.8299\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 5e-05\n- train_batch_size: 4\n- eval_batch_size: 4\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 5\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Rouge1 Precision | Rouge1 Recall | Rouge1 Fmeasure | Rouge2 Precision | Rouge2 Recall | Rouge2 Fmeasure | Rougel Precision | Rougel Recall | Rougel Fmeasure | Rougelsum Precision | Rougelsum Recall | Rougelsum Fmeasure | Sacrebleu | Meteor | Gen Len |\n|:-------------:|:-----:|:-----:|:---------------:|:----------------:|:-------------:|:---------------:|:----------------:|:-------------:|:---------------:|:----------------:|:-------------:|:---------------:|:-------------------:|:----------------:|:------------------:|:---------:|:------:|:-------:|\n| 0.5208        | 1.0   | 16396 | 0.4683          | 38.566           | 35.5094       | 35.9216         | 17.0701          | 15.3916       | 15.6829         | 36.4433          | 33.5298       | 33.958          | 36.4637             | 33.5496          | 33.9913            | 8.6055    | 0.1799 | 9.8340  |\n| 0.479         | 2.0   | 32792 | 0.4815          | 40.7475          | 35.8163       | 37.0498         | 17.9002          | 15.2742       | 15.9601         | 38.6977          | 33.8607       | 35.1258         | 38.7261             | 33.8717          | 35.1537            | 9.0561    | 0.1835 | 9.4338  |\n| 0.4577        | 3.0   | 49188 | 0.4879          | 40.6712          | 36.2763       | 37.2775         | 18.5942          | 16.0689       | 16.7206         | 38.8546          | 34.5013       | 35.5491         | 38.8633             | 34.5255          | 35.5682            | 9.7947    | 0.1879 | 9.6324  |\n| 0.4389        | 4.0   | 65584 | 0.4881          | 41.4251          | 36.2873       | 37.6272         | 18.561           | 15.7067       | 16.5358         | 39.434           | 34.3496       | 35.7457         | 39.533              | 34.4702          | 35.8347            | 9.7612    | 0.1881 | 9.3944  |\n| 0.4321        | 5.0   | 81980 | 0.4937          | 41.1197          | 36.0568       | 37.4121         | 18.7179          | 15.8348       | 16.6644         | 39.3386          | 34.3177       | 35.7088         | 39.3171             | 34.3015          | 35.6748            | 9.8263    | 0.1887 | 9.4040  |\n\n\n### Framework versions\n\n- Transformers 4.20.1\n- Pytorch 1.11.0\n- Datasets 2.1.0\n- Tokenizers 0.12.1\n", "size_bytes": "990406605", "downloads": 3}