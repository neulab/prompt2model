{"pretrained_model_name": "alimoezzi/ReportQL-base", "description": "---\ndatasets:\n- pubmed\nlanguage:\n- en\nmetrics:\n- bleu\n- exact_match\n- sacrebleu\n- rouge\ntags:\n- medical\n- dialog\n- arxiv:2209.12177\nwidget:\n- text: >-\n    The liver is normal in size and with normal parenchymal echogenicity with no\n    sign of space-occupying lesion or bile ducts dilatation. GB is well\n    distended with no stone or wall thickening. The spleen is normal in size and\n    parenchymal echogenicity with no sign of space-occupying lesion. visualized\n    parts of the pancreas and para-aortic area are unremarkable. Both kidneys\n    are normal in size with normal cortical parenchymal echogenicity with no\n    sign of the stone, stasis, or perinephric collection. ureters are not\n    dilated. The urinary bladder is empty so evaluation of pelvic organs is not\n    possible. no free fluid is seen in the abdominopelvic cavity.\n  example_title: Sample 1\n- text: >-\n    Liver is normal in size, with normal echogenicity with no sign of space\n    occupying lesion. GB is semi distended with two stones up to 8mm in size\n    with a rim of pericholecystic fluid and positive murphy sign. CBD is normal.\n    Spleen is moderately enlarged with normal parenchymal echo with no S.O.L.\n    Pancreas cannot be evaluated due to severe gas shadow. RT. and LT. kidneys\n    are normal in size with increase parenchymal echogenicity with no sign of\n    stone, stasis or perinephric collection with two cortical cystsin the upper\n    pole of left kidney. Urinary bladder is mildly distended. Moderate free\n    fluid is seen in the abdominopelvic cavity at present time.\n  example_title: Sample 2\ninference:\n  parameters:\n    repetition_penalty: 1\n    num_beams: 5\n    early_stopping: true\n    max_length: 350\nlicense: mit\n---\n# ReportQL \u2014 Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique\n\n*[Seyed Ali Reza Moezzi](https://scholar.google.com/citations?hl=en&user=JIZgcjAAAAAJ)*,\n*[Abdolrahman Ghaedi]()*,\n*[Mojdeh Rahmanian](https://scholar.google.com/citations?user=2ZtVfnUAAAAJ)*,\n*[Seyedeh Zahra Mousavi](https://www.researchgate.net/scientific-contributions/Seyedeh-Zahra-Mousavi-2176375936)*,\n*[Ashkan Sami](https://scholar.google.com/citations?user=zIh9AvIAAAAJ)*\n<html>\n<div><sub><sup>*Submitted: 16 November 2021*</sup></sub></div>\n<div><sub><sup>*Revised: 20 June 2022*</sup></sub></div>\n<sub><sup>*Accepted: 27 July 2022*</sup></sub>\n</html>\n\n[[paper](https://link.springer.com/article/10.1007/s10278-022-00692-x)] [[arXiv](https://arxiv.org/abs/2209.12177)] [[dataset](https://www.kaggle.com/datasets/sarme77/reportql)] [[project page](https://realsarm.github.io/ReportQL/)]\n\n## Introduction\n\nThis repository is code release for **Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique**\n\n<p align=\"center\"> <img src='https://raw.githubusercontent.com/realsarm/ReportQL/main/assets/overview.png' align=\"center\" height=\"320px\"> </p>\n\nSince radiology reports needed for clinical practice and research are written and stored in free-text narrations, extraction of relative information for further analysis is difficult. In these circumstances, natural language processing (NLP) techniques can facilitate automatic information extraction and transformation of free-text formats to structured data. In recent years, deep learning (DL)-based models have been adapted for NLP experiments with promising results. Despite the significant potential of DL models based on artificial neural networks (ANN) and convolutional neural networks (CNN), the models face some limitations to implement in clinical practice. Transformers, another new DL architecture, have been increasingly applied to improve the process. Therefore, in this study, we propose a transformer-based fine-grained named entity recognition (NER) architecture for clinical information extraction. We collected 88 abdominopelvic sonography reports in free-text formats and annotated them based on our developed information schema. The text-to-text transfer transformer model (T5) and Scifive, a pre-trained domain-specific adaptation of the T5 model, were applied for fine-tuning to extract entities and relations and transform the input into a structured format. Our transformer-based model in this study outperformed previously applied approaches such as ANN and CNN models based on ROUGE-1, ROUGE-2, ROUGE-L, and BLEU scores of 0.816, 0.668, 0.528, and 0.743, respectively, while providing an interpretable structured report.\n\n## Dataset\n\nOur annotated [dataset](https://doi.org/10.5281/zenodo.7072374) used in the paper is hosted in this repository and in [Kaggle Datasets](https://www.kaggle.com/datasets/sarme77/reportql).\n\nThe data is structured as follows:\n\n```\ndata/\n\u251c\u2500\u2500 trialReport\n\u2502   \u2514\u2500\u2500 ReportQL\n\u2502       \u251c\u2500\u2500 Schemas\n\u2502       \u2502   \u2514\u2500\u2500 organs\n\u2502       \u2502       \u2514\u2500\u2500 simpleSchema.json\n\u2502       \u2514\u2500\u2500 dataset\n\u2502           \u251c\u2500\u2500 test.csv\n\u2502           \u251c\u2500\u2500 train_orig.csv\n\u2502           \u2514\u2500\u2500 training.csv\n```\n\nThe `train_orig.csv` is our original training set. You can find our synthetic dataset and test set in `training.csv` and `test.csv` file.\n\nInformation schema used for annotating reports can be found in `simpleSchema.json`\n\n## Setup\n\nSetting up for this project involves installing dependencies.\n\n### Setting up environments and Installing dependencies\n\n```bash\nvirtualenv .venv\nsource .venv/bin/activate\n```\n\n### Installing dependencies\n\nTo install all the dependencies, please run the following:\n\n```bash\npip install -r requirements.txt\n```\n\n### Fine-tuning\n\nTo start fine-tuning language model, run:\n\n```bash\npython script/fit.py\n```\n\n### Testing\n\nFor getting test results on our test set, run:\n\n```bash\npython script/test.py\n```\n\n### Inference\n\nWe prepared [a jupyter notebook](notebooks/predict_reportql.ipynb) for Inference.\n\n## Fine-tuned Model\n\nOur fine-tuned ReportQL weights can be accessed on \ud83e\udd17 HuggingFace.\n\n* ReportQL: [base](https://huggingface.co/sarme/ReportQL-base)\n\n## License\n\nPlease see the [LICENSE](LICENSE) file for details.\n\n## Citation\n\nIf you find our work useful in your research, please consider citing us:\n\n```\n@article{moezzi2022application,\n  title={Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique},\n  author={Moezzi, Seyed Ali Reza and Ghaedi, Abdolrahman and Rahmanian, Mojdeh and Mousavi, Seyedeh Zahra and Sami, Ashkan},\n  journal={Journal of Digital Imaging},\n  pages={1--11},\n  year={2022},\n  publisher={Springer}\n}\n```", "size_bytes": "891645503", "downloads": 26}