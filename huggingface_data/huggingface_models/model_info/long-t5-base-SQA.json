{"pretrained_model_name": "Oscarshih/long-t5-base-SQA", "description": "```python=\nimport nlp2\nimport json\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom asrp.code2voice_model.hubert import hifigan_hubert_layer6_code100\nimport IPython.display as ipd\n\ntokenizer = AutoTokenizer.from_pretrained(\"Oscarshih/long-t5-base-SQA-15ep\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Oscarshih/long-t5-base-SQA-15ep\")\ndataset = load_dataset(\"voidful/NMSQA-CODE\")\ncs = hifigan_hubert_layer6_code100()\n\nqa_item = dataset['dev'][0]\nquestion_unit = json.loads(qa_item['hubert_100_question_unit'])[0][\"merged_code\"]\ncontext_unit = json.loads(qa_item['hubert_100_context_unit'])[0][\"merged_code\"]\nanswer_unit = json.loads(qa_item['hubert_100_answer_unit'])[0][\"merged_code\"]\n\n# groundtruth answer\nipd.Audio(data=cs(answer_unit), autoplay=False, rate=cs.sample_rate)\n\n# predict answer\ninputs = tokenizer(\"\".join([f\"v_tok_{i}\" for i in question_unit]) + \"\".join([f\"v_tok_{i}\" for i in context_unit]), return_tensors=\"pt\")\ncode = tokenizer.batch_decode(model.generate(**inputs,max_length=1024))[0]\ncode = [int(i) for i in code.replace(\"</s>\",\"\").replace(\"<s>\",\"\").split(\"v_tok_\")[1:]]\nipd.Audio(data=cs(code), autoplay=False, rate=cs.sample_rate)\n```", "size_bytes": "1046899817", "downloads": 5}