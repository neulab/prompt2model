{"pretrained_model_name": "cbdb/ClassicalChineseOfficeTitleTranslation", "description": "---\nlanguage:\n- zh\ntags:\n- Seq2SeqLM\n- \u53e4\u6587\n- \u6587\u8a00\u6587\n- \u4e2d\u56fd\u53e4\u4ee3\u5b98\u804c\u7ffb\u8bd1\n- ancient\n- classical\nlicense: cc-by-nc-sa-4.0\nmetrics:\n- sacrebleu\n---\n\n# <font color=\"IndianRed\"> TITO (Classical Chinese Office Title Translation)</font>\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1UoG3QebyBlK6diiYckiQv-5dRB9dA4iv?usp=sharing/)\n\nOur model <font color=\"cornflowerblue\">TITO (Classical Chinese Office Title Translation) </font> is a Sequence to Sequence Classical Chinese language model that is intended to  <font color=\"IndianRed\">translate a Classical Chinese office title into English</font>. This model is first inherited from the MarianMTModel, and finetuned using a 6,208 high-quality translation pairs collected CBDB group (China Biographical Database). \n\n### <font color=\"IndianRed\"> How to use </font>\n\nHere is how to use this model to get the features of a given text in PyTorch:\n\n<font color=\"cornflowerblue\"> 1. Import model and packages </font>\n```python\nfrom transformers import MarianMTModel, MarianTokenizer\n\ndevice = torch.device('cuda')\nmodel_name = 'cbdb/ClassicalChineseOfficeTitleTranslation'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name).to(device)\n```\n\n<font color=\"cornflowerblue\"> 2. Load Data </font>\n```python\n# Load your data here\ntobe_translated = ['\u8b1b\u7b75\u5b98','\u5224\u53f8\u7c3f\u5c09','\u6563\u9a0e\u5e38\u4f8d','\u6bbf\u4e2d\u7701\u5c1a\u8f26\u5949\u5fa1']\n```\n\n<font color=\"cornflowerblue\"> 3. Make a prediction </font>\n```python\ninputs = tokenizer(tobe_translated, return_tensors=\"pt\", padding=True).to(device)\ntranslated = model.generate(**inputs, max_length=128)\ntran = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\nfor c, t in zip(tobe_translated, tran):\n    print(f'{c}: {t}')\n```\n\u8b1b\u7b75\u5b98: Lecturer<br>\n\u5224\u53f8\u7c3f\u5c09: Supervisor of the Commandant of Records<br>\n\u6563\u9a0e\u5e38\u4f8d: Policy Advisor<br>\n\u6bbf\u4e2d\u7701\u5c1a\u8f26\u5949\u5fa1: Chief Steward of the Palace Administration<br>\n\n### <font color=\"IndianRed\">Authors </font>\nQueenie Luo (queenieluo[at]g.harvard.edu)\n<br>\nHongsu Wang\n<br>\nPeter Bol\n<br>\nCBDB Group\n\n### <font color=\"IndianRed\">License </font>\nCopyright (c) 2023 CBDB\n\nExcept where otherwise noted, content on this repository is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0).\nTo view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or\nsend a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.", "size_bytes": "310018949", "downloads": 11}