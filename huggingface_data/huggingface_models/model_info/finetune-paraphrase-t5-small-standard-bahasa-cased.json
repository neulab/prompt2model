{"pretrained_model_name": "mesolitica/finetune-paraphrase-t5-small-standard-bahasa-cased", "description": "---\nlanguage: \n  - ms\ntags:\n- paraphrase\nmetrics:\n- sacrebleu\n---\n\n# finetune-paraphrase-t5-small-standard-bahasa-cased\n\nFinetuned T5 small on MS paraphrase tasks.\n\n## Dataset\n\n1. translated PAWS, https://huggingface.co/datasets/mesolitica/translated-PAWS\n2. translated MRPC, https://huggingface.co/datasets/mesolitica/translated-MRPC\n3. translated ParaSCI, https://huggingface.co/datasets/mesolitica/translated-paraSCI\n\n## Finetune details\n\n1. Finetune using single RTX 3090 Ti.\n\nScripts at https://github.com/huseinzol05/malaya/tree/master/session/paraphrase/hf-t5\n\n## Supported prefix\n\n1. `parafrasa: {string}`, for MS paraphrase.\n\n## Evaluation\n\nEvaluated on MRPC validation set and ParaSCI Arxiv test set.\n\n```\n{'name': 'BLEU',\n 'score': 37.598729045833316,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '62.6/42.5/33.2/27.0 (BP = 0.957 ratio = 0.958 hyp_len = 96781 ref_len = 101064)',\n 'bp': 0.9567103919247614,\n 'counts': [60539, 38753, 28443, 21680],\n 'totals': [96781, 91237, 85693, 80149],\n 'sys_len': 96781,\n 'ref_len': 101064,\n 'precisions': [62.55256713611143,\n  42.47509234192268,\n  33.19174261608299,\n  27.049620082596164],\n 'prec_str': '62.6/42.5/33.2/27.0',\n 'ratio': 0.9576209134805668}\n```", "size_bytes": "242011067", "downloads": 2}