{"pretrained_model_name": "uaritm/ukrt5-base", "description": "---\nlanguage:\n- uk\n- en\n- multilingual\nlicense: mit\ntags:\n- ukrainian\n- english\n---\n\nThis is a variant of the [google/mt5-base](https://huggingface.co/google/mt5-base) model, in which Ukrainian and 9% English words remain.\nThis model has 252M parameters - 43% of the original size.\nSpecial thanks for the practical example and inspiration: [cointegrated ](https://huggingface.co/cointegrated)\n\n## Citing & Authors\n```\n@misc{Uaritm,\n      title={SetFit: Classification of medical texts}, \n      author={Vitaliy Ostashko},\n      year={2022},\n      url={https://esemi.org}\n}\n```\n", "size_bytes": "1008048205", "downloads": 3}