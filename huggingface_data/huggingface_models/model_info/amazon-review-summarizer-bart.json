{"pretrained_model_name": "mabrouk/amazon-review-summarizer-bart", "description": "# BART (large-sized model), fine-tuned on Amazon Reviews (English Language)\n\nThe BART model was pre-trained on the CNN-DailyMail dataset, but it was re-trained on the Amazon's Website Purchase that were provided in English Language. The purpose of doing this was to build a pipeline that is designed to summarize user reviews on Amazon.com.\n\n## Model description\n\nAccording to huggingface, BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text.\n\n## Datasets\nLink: [Amazon Reviews Corpus](https://huggingface.co/datasets/amazon_reviews_multi)\n\n## Intended uses & limitations\n\nThis model is intended to be used for summarizing user reviews on websites. \n\n### How to use\n\nHere is how to use this model with the [pipeline API](https://huggingface.co/transformers/main_classes/pipelines.html):\n\n```python\nfrom transformers import pipeline\nsummarizer = pipeline(\"summarization\", model=\"mabrouk/amazon-review-summarizer-bart\")\nreview = \"\"\" I really like this book. It takes a step-by-step approach to introduce the reader to the IBM Q Experience, to the basics underlying quantum computing, and to the reality of the noise involved in the current machines. This introduction is technical and shows the user how to use the IBM system either directly through the GUI on their website or by running Python code on one's own machine. The text provides examples of small exercises to try and stimulates ideas of new things to try. The IBM Q Exp Qiskit software modules are identified and introduced - Terra, Aer, Ignis, and Aqua, as well as the backends that one can choose to do the computing. The book ends with two great chapters on quantum algorithms.\n\"\"\"\nprint(summarizer(review, min_length = 60))\n>>> [{'summary': 'This book is a great resource, and a great read, to learn about quantum and start writing your first programs, or to brush up on your programming skills. I loved that there is a quiz at the end of every chapter so you can check and see how...'}]\n```\n\n### Reference\nPre-traind Model: [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct.)\nRe-trained Dataset: [Amazon Reviews Corpus](https://huggingface.co/datasets/amazon_reviews_multi)", "size_bytes": "1625533697", "downloads": 60}