{"pretrained_model_name": "shrishail/t5_paraphrase_msrp_paws", "description": "---\nlanguage: \"en\"\ntags:\n- paraphrase-generation\n- text-generation\n- Conditional Generation\ninference: false\n---\n\n# Simple model for Paraphrase Generation\n\u200b\n## Model description\n\u200b\nT5-based model for generating paraphrased sentences. It is trained on the labeled [MSRP](https://www.microsoft.com/en-us/download/details.aspx?id=52398) and [Google PAWS](https://github.com/google-research-datasets/paws) dataset.\n\u200b\n## How to use\n\u200b\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"shrishail/t5_paraphrase_msrp_paws\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"shrishail/t5_paraphrase_msrp_paws\")\n\u200b\nsentence = \"This is something which i cannot understand at all\"\ntext =  \"paraphrase: \" + sentence + \" </s>\"\nencoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\ninput_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\noutputs = model.generate(\n    input_ids=input_ids, attention_mask=attention_masks,\n    max_length=256,\n    do_sample=True,\n    top_k=120,\n    top_p=0.95,\n    early_stopping=True,\n    num_return_sequences=5\n)\nfor output in outputs:\n    line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    print(line)\n\u200b\n```\n\n", "size_bytes": "242085627", "downloads": 4}