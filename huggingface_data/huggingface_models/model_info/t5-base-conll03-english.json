{"pretrained_model_name": "dbmdz/t5-base-conll03-english", "description": "---\nlanguage: en\nlicense: mit\ndatasets:\n- conll2003\nwidget:\n- text: My name is Clara Clever and I live in Berkeley , California .\n---\n\n# T5 Base Model for Named Entity Recognition (NER, CoNLL-2003)\n\nIn this repository, we open source a T5 Base model, that was fine-tuned on the official CoNLL-2003 NER dataset.\n\nWe use the great [TANL library](https://github.com/amazon-research/tanl) from Amazon for fine-tuning the model.\n\nThe exact approach of fine-tuning is presented in the \"TANL: Structured Prediction as Translation between Augmented Natural Languages\"\npaper from Giovanni Paolini, Ben Athiwaratkun, Jason Krone, Jie Ma, Alessandro Achille, Rishita Anubhai, Cicero Nogueira dos Santos, Bing Xiang and Stefano Soatto.\n\n# Fine-Tuning\n\nWe use the same hyper-parameter settings as used in the official implementation with one minor change. Instead of using 8 V100 GPUs, we train the model\non one V100 GPU and used gradient accumulation. The slighly modified configuration file (`config.ini`) then looks like:\n\n```ini\n[conll03]\ndatasets = conll03\nmodel_name_or_path = t5-base\nnum_train_epochs = 10\nmax_seq_length = 256\nmax_seq_length_eval = 512\nper_device_train_batch_size = 4\nper_device_eval_batch_size = 4\ndo_train = True\ndo_eval = True\ndo_predict = True\ngradient_accumulation_steps = 8\n```\n\nIt took around 2 hours to fine-tune that model on the 14,041 training sentences of CoNLL-2003 dataset.\n\n# Evaluation\n\nOn the development set, the following evaluation results could be achieved:\n\n```json\n{\n\"entity_precision\": 0.9536446086664427,\n\"entity_recall\": 0.9555705149781218,\n\"entity_f1\": 0.9546065904505716,\n\"entity_precision_no_type\": 0.9773261672824992,\n\"entity_recall_no_type\": 0.9792998990238977,\n\"entity_f1_no_type\": 0.9783120376597176\n}\n```\n\nThe evaluation results on the test set looks like:\n\n```json\n{\n\"entity_precision\": 0.912182296231376,\n\"entity_recall\": 0.9213881019830028,\n\"entity_f1\": 0.9167620893155995,\n\"entity_precision_no_type\": 0.953900087642419,\n\"entity_recall_no_type\": 0.9635269121813032,\n\"entity_f1_no_type\": 0.9586893332158901\n}\n```\n\nTo summarize: On the development set, 95.46% F1-Score and 91.68% on test set were achieved with this model. The paper reported a F1-Score of 91.7%.\n\n# License\n\nThe models is licensed under [MIT](https://choosealicense.com/licenses/mit/).\n\n# Acknowledgments\n\nThanks to the generous support from the [Hugging Face](https://huggingface.co/) team,\nit is possible to download both cased and uncased models from their S3 storage \ud83e\udd17\n", "size_bytes": "891730879", "downloads": 314}