{"pretrained_model_name": "deep-learning-analytics/triviaqa-t5-base", "description": "---\nlanguage: \"eng\"\ntags:\n- triviaqa\n- t5-base\n- pytorch\n- lm-head\n- question-answering\n- closed-book\n- t5\n- pipeline:question-answering\ndatasets:\n- triviaqa \nwidget:\n- text: [\"Mount Everest is found in which mountain range?\",\"None\"]\nmetrics:\n- EM: 17\n- Subset match: 24.5\n---\n\n# Model name\nClosed Book Trivia-QA T5 base\n\n## Model description\n\nThis is a T5-base model trained on No Context Trivia QA data set. The input to the model is a Trivia type question. The model is tuned to search for the answer in its memory to return it. The pretrained model used here was trained on Common Crawl (C4) data set. The model was trained for 135 epochs using a batch size of 32 and learning rate of 1e-3. Max_input_lngth is set as 25 and max_output_length is 10. Model attained an EM score of 17 and a Subset Match score of 24.5\nWe have written a blog post that covers the training procedure. Please find it [here](https://medium.com/@priya.dwivedi/build-a-trivia-bot-using-t5-transformer-345ff83205b6). \n\nTest the model on Trivia Questions from the websites below:\nhttps://www.triviaquestionss.com/easy-trivia-questions/\nhttps://laffgaff.com/easy-trivia-questions-and-answers/\n\n## Usage\n\n```\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\n\ntokenizer = AutoTokenizer.from_pretrained(\"deep-learning-analytics/triviaqa-t5-base\")\nmodel = AutoModelWithLMHead.from_pretrained(\"deep-learning-analytics/triviaqa-t5-base\")\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ntext = \"Who directed the movie Jaws?\"\n\npreprocess_text = text.strip().replace(\"\\n\",\"\")\ntokenized_text = tokenizer.encode(preprocess_text, return_tensors=\"pt\").to(device)\n\nouts = model.model.generate(\n            tokenized_text,\n            max_length=10,\n            num_beams=2,\n            early_stopping=True\n           )\n\ndec = [tokenizer.decode(ids) for ids in outs]\nprint(\"Predicted Answer: \", dec)\n```\n", "size_bytes": "891695056", "downloads": 196}