{"pretrained_model_name": "jmeadows17/MathT5-large", "description": "---\nlicense: openrail\npipeline_tag: text-generation\n---\n\n**To use MathT5 easily:**\n\n1. Download  ```MathT5.py```.\n2. ```from MathT5 import load_model, inference```\n3. ```tokenizer, model = load_model(\"jmeadows17/MathT5-large\")```\n4. ```inference(prompt, tokenizer, model)```\n\n```MathT5.pretty_print(text, prompt=True)``` makes prompts and outputs (```prompt=False```) easier to read.\n\n**Overview**\n\nMathT5-large is a version of FLAN-T5-large fine-tuned for 25 epochs on 15K (LaTeX) synthetic mathematical derivations (containing 4 - 10 equations), that were generated using a symbolic solver (SymPy).\nIt outperforms the few-shot performance of GPT-4 and ChatGPT on a derivation generation task in ROUGE, BLEU, BLEURT, and GLEU scores, and shows some generalisation capabilities.\nIt was trained on 155 physics symbols, but struggles with out-of-vocabulary symbols. Paper available here: https://arxiv.org/abs/2307.09998.\n\n\n**Example prompt:**\n\n```prompt = \"Given \\\\cos{(q)} = \\\\theta{(q)},\nthen derive - \\\\sin{(q)} = \\\\frac{d}{d q} \\\\theta{(q)},\nthen obtain (- \\\\sin{(q)})^{q} (\\\\frac{d}{d q} \\\\cos{(q)})^{q} = (- \\\\sin{(q)})^{2 q}\"```\n\nOutput derivations are equations separated by \"and\".\n\nAdditional prompts can be found in \"training_prompts.json\" alongside the model files.\n\nUse ```\"jmeadows17/MathT5-base\"``` for the lightweight version.", "size_bytes": "2950746503", "downloads": 47}