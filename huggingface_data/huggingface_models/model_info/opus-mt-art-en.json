{"pretrained_model_name": "Helsinki-NLP/opus-mt-art-en", "description": "---\nlanguage: \n- eo\n- io\n- art\n- en\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### art-eng\n\n* source group: Artificial languages \n* target group: English \n*  OPUS readme: [art-eng](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/art-eng/README.md)\n\n*  model: transformer\n* source language(s): afh_Latn avk_Latn dws_Latn epo ido ido_Latn ile_Latn ina_Latn jbo jbo_Cyrl jbo_Latn ldn_Latn lfn_Cyrl lfn_Latn nov_Latn qya qya_Latn sjn_Latn tlh_Latn tzl tzl_Latn vol_Latn\n* target language(s): eng\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus2m-2020-07-31.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-07-31.zip)\n* test set translations: [opus2m-2020-07-31.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-07-31.test.txt)\n* test set scores: [opus2m-2020-07-31.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-07-31.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| Tatoeba-test.afh-eng.afh.eng \t| 1.2 \t| 0.099 |\n| Tatoeba-test.avk-eng.avk.eng \t| 0.4 \t| 0.105 |\n| Tatoeba-test.dws-eng.dws.eng \t| 1.6 \t| 0.076 |\n| Tatoeba-test.epo-eng.epo.eng \t| 34.6 \t| 0.530 |\n| Tatoeba-test.ido-eng.ido.eng \t| 12.7 \t| 0.310 |\n| Tatoeba-test.ile-eng.ile.eng \t| 4.6 \t| 0.218 |\n| Tatoeba-test.ina-eng.ina.eng \t| 5.8 \t| 0.254 |\n| Tatoeba-test.jbo-eng.jbo.eng \t| 0.2 \t| 0.115 |\n| Tatoeba-test.ldn-eng.ldn.eng \t| 0.7 \t| 0.083 |\n| Tatoeba-test.lfn-eng.lfn.eng \t| 1.8 \t| 0.172 |\n| Tatoeba-test.multi.eng \t| 11.6 \t| 0.287 |\n| Tatoeba-test.nov-eng.nov.eng \t| 5.1 \t| 0.215 |\n| Tatoeba-test.qya-eng.qya.eng \t| 0.7 \t| 0.113 |\n| Tatoeba-test.sjn-eng.sjn.eng \t| 0.9 \t| 0.090 |\n| Tatoeba-test.tlh-eng.tlh.eng \t| 0.2 \t| 0.124 |\n| Tatoeba-test.tzl-eng.tzl.eng \t| 1.4 \t| 0.109 |\n| Tatoeba-test.vol-eng.vol.eng \t| 0.5 \t| 0.115 |\n\n\n### System Info: \n- hf_name: art-eng\n\n- source_languages: art\n\n- target_languages: eng\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/art-eng/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['eo', 'io', 'art', 'en']\n\n- src_constituents: {'sjn_Latn', 'tzl', 'vol_Latn', 'qya', 'tlh_Latn', 'ile_Latn', 'ido_Latn', 'tzl_Latn', 'jbo_Cyrl', 'jbo', 'lfn_Latn', 'nov_Latn', 'dws_Latn', 'ldn_Latn', 'avk_Latn', 'lfn_Cyrl', 'ina_Latn', 'jbo_Latn', 'epo', 'afh_Latn', 'qya_Latn', 'ido'}\n\n- tgt_constituents: {'eng'}\n\n- src_multilingual: True\n\n- tgt_multilingual: False\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-07-31.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-07-31.test.txt\n\n- src_alpha3: art\n\n- tgt_alpha3: eng\n\n- short_pair: art-en\n\n- chrF2_score: 0.287\n\n- bleu: 11.6\n\n- brevity_penalty: 1.0\n\n- ref_len: 73037.0\n\n- src_name: Artificial languages\n\n- tgt_name: English\n\n- train_date: 2020-07-31\n\n- src_alpha2: art\n\n- tgt_alpha2: en\n\n- prefer_old: False\n\n- long_pair: art-eng\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "300041769", "downloads": 17}