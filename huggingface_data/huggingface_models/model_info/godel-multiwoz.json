{"pretrained_model_name": "gonced8/godel-multiwoz", "description": "---\nlicense: gpl-3.0\ndatasets:\n- multi_woz_v22\nlanguage:\n- en\nmetrics:\n- bleu\n- rouge\n---\n\nPretrained model: [GODEL-v1_1-base-seq2seq](https://huggingface.co/microsoft/GODEL-v1_1-base-seq2seq/)\n\nFine-tuning dataset: [MultiWOZ 2.2](https://github.com/budzianowski/multiwoz/tree/master/data/MultiWOZ_2.2)\n\n# How to use:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"gonced8/godel-multiwoz\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"gonced8/godel-multiwoz\")\n\n# Encoder input\ncontext = [\n    \"USER: I need train reservations from norwich to cambridge\",\n    \"SYSTEM: I have 133 trains matching your request. Is there a specific day and time you would like to travel?\",\n    \"USER: I'd like to leave on Monday and arrive by 18:00.\",\n]\n\ninput_text = \" EOS \".join(context[-5:]) + \" => \"\n\nmodel_inputs = tokenizer(\n    input_text, max_length=512, truncation=True, return_tensors=\"pt\"\n)[\"input_ids\"]\n\n# Decoder input\nanswer_start = \"SYSTEM: \"\n\ndecoder_input_ids = tokenizer(\n    \"<pad>\" + answer_start,\n    max_length=256,\n    truncation=True,\n    add_special_tokens=False,\n    return_tensors=\"pt\",\n)[\"input_ids\"]\n\n# Generate\noutput = model.generate(\n    model_inputs, decoder_input_ids=decoder_input_ids, max_length=256\n)\noutput = tokenizer.decode(\n    output[0], clean_up_tokenization_spaces=True, skip_special_tokens=True\n)\n\nprint(output)\n# SYSTEM: TR4634 arrives at 17:35. Would you like me to book that for you?\n```", "size_bytes": "891617279", "downloads": 28}