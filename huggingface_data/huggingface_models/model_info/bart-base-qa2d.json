{"pretrained_model_name": "MarkS/bart-base-qa2d", "description": "---\nlicense: afl-3.0\n---\n\n# Generating Declarative Statements from QA Pairs\n\nThere are already some rule-based models that can accomplish this task, but I haven't seen any transformer-based models that can do so. Therefore, I trained this model based on `Bart-base` to transform QA pairs into declarative statements.\n\nI compared the this model with other rule base models, including \n\n> [paper1](https://aclanthology.org/D19-5401.pdf) (2019), which proposes **2 Encoder Pointer-Gen model**\n\nand\n\n> [paper2](https://arxiv.org/pdf/2112.03849.pdf) (2021), which proposes **RBV2 model**\n\n**Here are results compared to 2 Encoder Pointer-Gen model (on testset released by paper1)**\n\nTest on testset\n\n| Model   | 2 Encoder Pointer-Gen(2019) | BART-base  |\n| ------- | --------------------------- | ---------- |\n| BLEU    | 74.05                       | **78.878** |\n| ROUGE-1 | 91.24                       | **91.937** |\n| ROUGE-2 | 81.91                       | **82.177** |\n| ROUGE-L | 86.25                       | **87.172** |\n\nTest on NewsQA testset\n\n| Model   | 2 Encoder Pointer-Gen | BART       |\n| ------- | --------------------- | ---------- |\n| BLEU    | 73.29                 | **74.966** |\n| ROUGE-1 | **95.38**             | 89.328     |\n| ROUGE-2 | **87.18**             | 78.538     |\n| ROUGE-L | **93.65**             | 87.583     |\n\nTest on free_base testset\n\n| Model   | 2 Encoder Pointer-Gen | BART       |\n| ------- | --------------------- | ---------- |\n| BLEU    | 75.41                 | **76.082** |\n| ROUGE-1 | **93.46**             | 92.693     |\n| ROUGE-2 | **82.29**             | 81.216     |\n| ROUGE-L | **87.5**              | 86.834     |\n\n\n\n**As paper2 doesn't release its own dataset, it's hard to make a fair comparison. But according to results in paper2, the Bleu and ROUGE score of their model is lower than that of MPG, which is exactly the 2 Encoder Pointer-Gen model.**\n\n| Model        | BLEU | ROUGE-1 | ROUGE-2 | ROUGE-L |\n| ------------ | ---- | ------- | ------- | ------- |\n| RBV2         | 74.8 | 95.3    | 83.1    | 90.3    |\n| RBV2+BERT    | 71.5 | 93.9    | 82.4    | 89.5    |\n| RBV2+RoBERTa | 72.1 | 94      | 83.1    | 89.8    |\n| RBV2+XLNET   | 71.2 | 93.6    | 82.3    | 89.4    |\n| MPG          | 75.8 | 94.4    | 87.4    | 91.6    |\n\nThere are reasons to believe that this model performs better than RBV2.\n\nTo sum up, this model performs nearly as well as the SOTA rule-based model evaluated with BLEU and ROUGE score. However the sentence pattern is lack of diversity.\n\n(It's worth mentioning that even though I tried my best to conduct objective tests, the testsets I could find were more or less different from what they introduced in the paper.)\n\n## How to use\n\n\n```python\nfrom transformers import BartTokenizer, BartForConditionalGeneration\ntokenizer = BartTokenizer.from_pretrained(\"MarkS/bart-base-qa2d\")\nmodel = BartForConditionalGeneration.from_pretrained(\"MarkS/bart-base-qa2d\")\n\ninput_text = \"question: what day is it today? answer: Tuesday\"\ninput = tokenizer(input_text, return_tensors='pt')\noutput = model.generate(input.input_ids)\nresult = tokenizer.batch_decode(output, skip_special_tokens=True)\n```\n\n", "size_bytes": "557979193", "downloads": 6}