{"pretrained_model_name": "inseq/wmt20-mlqe-ro-en", "description": "---\nlanguage:\n- en\n- ro\n- multilingual\nlicense: cc-by-sa-4.0\ntags:\n- translation\n- wmt20\ndatasets:\n- wmt/europarl\n- setimes\nwidget:\n- text: \"Limba rom\u00e2n\u0103 este o limb\u0103 indo-european\u0103 din grupul italic \u0219i din subgrupul oriental al limbilor romanice. Printre limbile romanice, rom\u00e2na este a cincea dup\u0103 num\u0103rul de vorbitori, \u00een urma spaniolei, portughezei, francezei \u0219i italienei.\"\n- text: \"Scalia s-a n\u0103scut \u00een Trenton, statul New Jersey. A studiat la liceul Xavier High School din Manhattan, \u0219i apoi la colegiul de arte liberale al Universit\u0103\u021bii Georgetown din Washington, D.C.\"\n- text: \"Totu\u0219i, este amenin\u021bat\u0103 de alter\u0103ri ale habitatului s\u0103u, iar \u00een Ucraina \u0219i partea european\u0103 din arealul s\u0103u a Rusiei este \u00een declin rapid\"\n---\n\n# Fairseq Ro-En NMT WMT20 MLQE\n\nThis repository contains the Romanian-English model trained with the [fairseq toolkit](https://github.com/pytorch/fairseq) that was used to produce translations used in the WMT20 shared task on quality estimation (QE) on the [MLQE dataset](https://github.com/facebookresearch/mlqe).\n\nThe checkpoint was converted from the original fairseq checkpoint available [here](https://github.com/facebookresearch/mlqe/tree/master/nmt_models) using the `convert_fsmt_original_pytorch_checkpoint_to_pytorch.py` script from the \ud83e\udd17 Transformers library (v4.26.0).\n\nPlease refer to the repositories linked above for additional information on usage, parameters and training data.", "size_bytes": "380022533", "downloads": 7}