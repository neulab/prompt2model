{"pretrained_model_name": "allenai/DREAM", "description": "---\nlanguage: \"en\"  # Example: en\nlicense: \"cc-by-4.0\"  # Example: apache-2.0 or any license from https://hf.co/docs/hub/repositories-licenses\nlibrary_name: \"transformers\"  # Optional. Example: keras or any library from https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Libraries.ts\n\n---\n\nThis is the T5-11B model described in our paper DREAM: Improving Situational QA by First Elaborating the Situation, NAACL 2022 (Arxiv link: https://arxiv.org/abs/2112.08656, ACL Anthology link: https://aclanthology.org/2022.naacl-main.82/)\n  \n  \n  \n# What is DREAM \ud83d\udcad?\nDREAM can be used to:\n\n* Build scene elaborations in a dataset-neutral way \ud83d\uddbc\ufe0f\n\n* \ud83d\udcc8 Improve QA performance across different end-tasks and on different models \ud83d\udcc8\n\nWhen people \ud83e\uddd1\u200d\ud83d\udcbb answer questions about a specific situation, cognitive science \ud83e\udde0 suggests that they form a mental picture \ud83d\uddbc\ufe0f of that situation. Will language models \ud83e\udd16 answer such questions more accurately if provided with additional details about the question situation \ud83d\uddbc\ufe0f ?\n\nWe train a new model, DREAM \ud83d\udcad , to answer questions that elaborate the scenes \ud83d\uddbc\ufe0f that situated questions are about, and then provide those elaborations as additional context \ud83d\udcc4 to a QA model \ud83e\udd16 . Our results show that DREAM \ud83d\udcad is able to create more \u2705 accurate, \u2705 useful, and \u2705 consistent scene elaborations than a representative\nSOTA \ud83c\udf1f, zero-shot model (Macaw \ud83e\udd9c ).\n\nRemarkably, using DREAM\u2019s \ud83d\udcad scene elaborations \ud83d\uddbc\ufe0f as additional context improves\ud83d\udcc8 the answer accuracy across different downstream QA systems \ud83e\udd16 and on different end-tasks \ud83d\udcdd (including beyond that obtainable by further fine-tuning the QA system on DREAM\u2019s training data \ud83d\udcda). Our approach is question-agnostic \ud83d\udcab, leaves end-task QA models unchanged \u2728, and thus easily portable to other QA models \ud83c\udf1f, suggesting exciting opportunities for further improving and exploiting scene elaborations to better solve new problems. \ud83d\udca1\n\nWe invite you to try out DREAM \ud83d\udcad for your own application!\n    \n    \n    \n# How to use DREAM \ud83d\udcad?\nWe provide a quick example of how you can try out DREAM with just a few lines of code:\n```\n>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n>>> model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/DREAM\")\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"t5-11b\")\n>>> input_string = \"$answer$ ; $question$ = [SITUATION] hitting someones car in the drive thru on purpose. [QUERY] rot\"\n>>> input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n>>> output = model.generate(input_ids, max_length=200)\n>>> tokenizer.batch_decode(output, skip_special_tokens=True)\n[\"$answer$ = It's wrong to damage other people's property.\"]\n```\n\nAs discussed in our paper, DREAM supports the following possible dimensions for each input situation S:\n```\n1. M : motivation of character(s) before S.\n2. E: emotion of character(s) after S.\n3. ROT : general Rule of Thumb (ROT) about whether action described in S is socially acceptable or not (also known as social norm).\n4. Con: likely consequence of action in S.\n```\nTo get DREAM's output for these dimensions, use the corresponding terms below after the \"[QUERY] \" tag in your input string:\n```\nmotivation\nemotion\nrot\nconsequence\n```\n    \n    \n    \n# More details about DREAM \ud83d\udcad ...\nFor more details about DREAM, please refer to our:\n* \ud83d\udcc4Paper: https://aclanthology.org/2022.naacl-main.82/\n* \ud83d\udcbbDataset & Model: https://github.com/allenai/dream/\n\nFor additional instructions about using the DREAM model and sample commands, please refer to https://github.com/allenai/dream/blob/main/model/README_DREAM_model.md.", "size_bytes": 45624074240, "downloads": 11}