{"pretrained_model_name": "vasudevgupta/mbart-bhasha-hin-eng", "description": "---\ndatasets: pib\nwidget:\n- text: \"\u0928\u092e\u0938\u094d\u0924\u0947! \u092e\u0948\u0902 \u0935\u093e\u0938\u0941\u0926\u0947\u0935 \u0917\u0941\u092a\u094d\u0924\u093e \u0939\u0942\u0902\"\n\n---\n\nmBART (a pre-trained model by Facebook) is pre-trained to de-noise multiple languages simultaneously with BART objective.\n\nCheckpoint available in this repository is obtained after fine-tuning `facebook/mbart-large-cc25` on all samples (~260K) from Bhasha (pib_v1.3) Hindi-English parallel corpus. This checkpoint gives decent results for Hindi-english translation.", "size_bytes": "2436180855", "downloads": 153}