{"pretrained_model_name": "abhi-pwr/news-summarizer", "description": "---\n{}\n---\n# news-summarizer\n\n# T5 Base Model Fine-Tuned for News Article Summarization\n\nThis repository contains a fine-tuned T5 base model for news article summarization. The model has been trained to generate concise summaries of news articles given their full text.\n\n## Model Details\n\n- Model: T5 Base\n- Fine-Tuning Task: News Article Summarization\n- Training Data: Dataset of news articles with corresponding summaries\n- Tokenizer: T5Tokenizer\n- Maximum Input Length: 512 tokens\n- Maximum Output Length: 150 tokens\n- Beam Search: Enabled (with 4 beams)\n- Early Stopping: Enabled\n\n## Usage\n\nTo use the fine-tuned T5 model for news article summarization, follow the instructions below:\n\n1. Install the required dependencies:\n   pip install transformers torch\n2. Load the fine-tuned model:\n```python\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel_name = 'abhi-pwr/news-summarizer'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n3.Generate summaries:\ninput_text = \"Enter the news article here.\"\ninputs = tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\nsummary_ids = model.generate(inputs, max_length=150, num_beams=4, early_stopping=True)\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n\n", "size_bytes": "891702929", "downloads": 111}