{"pretrained_model_name": "sander-wood/text-to-music", "description": "---\nlicense: mit\nlanguage: en\nwidget:\n- text: This is a traditional Irish dance music.\ninference:\n  parameters:\n    top_p: 0.9\n    max_length: 1024\n    do_sample: true\ntags:\n- music\n---\n# Exploring the Efficacy of Pre-trained Checkpoints in Text-to-Music Generation Task\n\n## Model description\n\nThis language-music model takes [BART-base](https://huggingface.co/facebook/bart-base) fine-tunes on 282,870 English text-music pairs, where all scores are represented in ABC notation. It was introduced in the paper [Exploring the Efficacy of Pre-trained Checkpoints in Text-to-Music Generation Task](https://arxiv.org/abs/2211.11216) by Wu et al. and released in [this repository](https://github.com/sander-wood/text-to-music). \n\nIt is capable of generating complete and semantically consistent sheet music directly from descriptions in natural language based on text. To the best of our knowledge, this is the first model that achieves text-conditional symbolic music generation which is trained on real text-music pairs, and the music is generated entirely by the model and without any hand-crafted rules.\n\nThis language-music model is available for online use and experience on [Textune: Generating Tune from Text](https://huggingface.co/spaces/sander-wood/text-to-music). With this online platform, you can easily input your desired text descriptions and receive a generated sheet music output from the model.\n\nDue to copyright reasons, we are unable to publicly release the training dataset of this model. Instead, we have made available the [WikiMusicText](https://huggingface.co/datasets/sander-wood/wikimusictext) (WikiMT) dataset, which includes 1010 pairs of text-music data and can be used to evaluate the performance of language-music models.\n\n## Intended uses & limitations\n\nYou can use this model for text-conditional music generation. All scores generated by this model can be written on one stave (for vocal solo or instrumental solo) in standard classical notation, and are in a variety of styles, e.g., blues, classical, folk, jazz, pop, and world music. We recommend using the script in [this repository](https://github.com/sander-wood/text-to-music) for inference. The generated tunes are in ABC notation, and can be converted to sheet music or audio using [this website](https://ldzhangyx.github.io/abc/), or [this software](https://sourceforge.net/projects/easyabc/).\n\nIts creativity is limited, can not perform well on tasks requiring a high degree of creativity (e.g., melody style transfer), and it is input-sensitive. For more information, please check [our paper](https://arxiv.org/abs/2211.11216).\n\n### How to use\n\nHere is how to use this model in PyTorch:\n\n```python\nimport torch\nfrom samplings import top_p_sampling, temperature_sampling\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained('sander-wood/text-to-music')\nmodel = AutoModelForSeq2SeqLM.from_pretrained('sander-wood/text-to-music')\nmodel = model\n\nmax_length = 1024\ntop_p = 0.9\ntemperature = 1.0\n\ntext = \"This is a traditional Irish dance music.\"\ninput_ids = tokenizer(text, \n                      return_tensors='pt', \n                      truncation=True, \n                      max_length=max_length)['input_ids']\n\ndecoder_start_token_id = model.config.decoder_start_token_id\neos_token_id = model.config.eos_token_id\n\ndecoder_input_ids = torch.tensor([[decoder_start_token_id]])\n\nfor t_idx in range(max_length):\n    outputs = model(input_ids=input_ids, \n    decoder_input_ids=decoder_input_ids)\n    probs = outputs.logits[0][-1]\n    probs = torch.nn.Softmax(dim=-1)(probs).detach().numpy()\n    sampled_id = temperature_sampling(probs=top_p_sampling(probs, \n                                                           top_p=top_p, \n                                                           return_probs=True),\n                                      temperature=temperature)\n    decoder_input_ids = torch.cat((decoder_input_ids, torch.tensor([[sampled_id]])), 1)\n    if sampled_id!=eos_token_id:\n        continue\n    else:\n        tune = \"X:1\\n\"\n        tune += tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True)\n        print(tune)\n        break\n```\n\n### Generation Examples\nHere are some examples generated by this model without cherry-picking.\n```\n######################## INPUT TEXT ########################\n\nThis is a traditional Irish dance music.\nNote Length-1/8\nMeter-6/8\nKey-D\n\n####################### OUTPUT TUNES #######################\n\nX:1\nL:1/8\nM:6/8\nK:D\n A | BEE BEE | Bdf edB | BAF FEF | DFA BAF | BEE BEE | Bdf edB | BAF DAF | FED E2 :: A |\n Bef gfe | faf edB | BAF FEF | DFA BAF | Bef gfe | faf edB | BAF DAF | FED E2 :|\n\nX:2\nL:1/8\nM:6/8\nK:D\n A |: DED F2 A | d2 f ecA | G2 B F2 A | E2 F GFE | DED F2 A | d2 f ecA | Bgf edc |1 d3 d2 A :|2\n d3 d2 a || a2 f d2 e | f2 g agf | g2 e c2 d | e2 f gfe | fed gfe | agf bag | fed cde | d3 d2 a |\n agf fed | Adf agf | gfe ecA | Ace gfe | fed gfe | agf bag | fed cde | d3 d2 ||\n\nX:3\nL:1/8\nM:6/8\nK:D\n BEE BEE | Bdf edB | BAF FEF | DFA dBA | BEE BEE | Bdf edB | BAF FEF |1 DED DFA :|2 DED D2 e |:\n faf edB | BAF DFA | BAF FEF | DFA dBA | faf edB | BAF DFA | BdB AFA |1 DED D2 e :|2 DED DFA ||\n```\n\n```\n######################## INPUT TEXT ########################\n\nThis is a jazz-swing lead sheet with chord and vocal.\n\n####################### OUTPUT TUNES #######################\n\nX:1\nL:1/8\nM:4/4\nK:F\n\"F\" CFG |\"F\" A6 z G |\"Fm7\" A3 G\"Bb7\" A3 G |\"F\" A6 z G |\"F7\" A4\"Eb7\" G4 |\"F\" F6 z F |\n\"Dm\" A3 G\"Dm/C\" A3 G |\"Bb\" A2\"Gm\" B2\"C7\" G3 G |\"F\" F8- |\"Dm7\"\"G7\" F6 z2 |\"C\" C4 C3 C |\n\"C7\" C2 B,2\"F\" C4 |\"F\" C4 C3 C |\"Dm\" D2 C2\"Dm/C\" D4 |\"Bb\" D4 D3 D |\"Bb\" D2 C2\"C7\" D4 |\"F\" C8- |\n\"F\" C4\"Gm\" z C\"C7\" FG |\"F\" A6 z G |\"Fm7\" A3 G\"Bb7\" A3 G |\"F\" A6 z G |\"F7\" A4\"Eb7\" G4 |\"F\" F6 z F |\n\"Dm\" A3 G\"Dm/C\" A3 G |\"Bb\" A2\"Gm\" B2\"C7\" G3 G |\"F\" F8- |\"F\" F6 z2 |]\n\nX:2\nL:1/4\nM:4/4\nK:F\n\"^A\"\"F\" A3 A |\"Am7\" A2\"D7\" A2 |\"Gm7\" G2\"C7\" G A |\"F\" F4 |\"F\" A3 A |\"Am7\" A2\"D7\" A2 |\"Gm7\" G2\"C7\" G A |\n\"F\" F4 |\"Gm\" B3 B |\"Am7\" B2\"D7\" B2 |\"Gm\" B2\"D7\" B A |\"Gm7\" G4 |\"F\" A3 A |\"Am7\" A2\"D7\" A2 |\n\"Gm7\" G2\"C7\" G A |\"F\" F4 |\"Bb7\" F3 G |\"F\" A2 A2 |\"Gm\" B2\"C7\" B2 |\"F\" c2\"D7\" c c |\"Gm7\" c2\"C7\" B2 |\n\"F\" A2\"F7\" A2 |\"Bb\" B2\"F\" B A |\"Bb\" B2\"F\" B A |\"Gm\" B2\"F\" B A |\"Gm7\" B2\"F\" B A |\"Gm7\" B2\"F\" B A |\n\"C7\" B2 c2 |\"F\"\"Bb7\" A4 |\"F\"\"Bb7\" z4 |]\n\nX:3\nL:1/4\nM:4/4\nK:Bb\n B, ||\"Gm\"\"^A1\" G,2 B, D |\"D7\" ^F A2 G/=F/ |\"Gm\" G2\"Cm7\" B c |\"F7\" A2 G =F |\"Bb\" D2 F A |\n\"Cm7\" c e2 d/c/ |\"Gm7\" B3/2 G/-\"C7\" G2- |\"F7\" G2 z B, |\"Gm\"\"^B\" G,2 B, D |\"D7\" ^F A2 G/=F/ |\n\"Gm\" G2\"Cm7\" B c |\"F7\" A2 G =F |\"Bb\" D2 F A |\"Cm7\" c e2 d/c/ |\"Gm7\" B3/2 G/-\"C7\" G2- |\"F7\" G2 z2 ||\n\"^C\"\"F7\"\"^A2\" F4- | F E D C |\"Bb\" D2 F B | d3 c/B/ |\"F\" A2\"Cm7\" G2 |\"D7\" ^F2 G2 |\"Gm\" B3\"C7\" A |\n\"F7\" G4 ||\"F7\"\"^A3\" F4- | F E D C |\"Bb\" D2 F B | d3 c/B/ |\"F\" A2\"Cm7\" G2 |\"D7\" ^F2 G2 |\"Gm\" B3 A |\n\"C7\" G4 ||\"^B\"\"Gm\"\"^C\" B2 c B |\"Cm\" c B c B |\"Gm7\" c2 B A |\"C7\" B3 A |\"Bb\" B2 c B |\"G7\" d c B A |\n\"Cm\" G2 A G |\"F7\" F2 z G ||\"^C\"\"F7\" F F3 |\"Bb\" D D3 |\"Cm\" E E3 |\"D7\" ^F F3 |\"Gm\" G2 A B |\"C7\" d3 d |\n\"Gm\" d3 d |\"D7\" d3 B, ||\"^D\"\"Gm\" G,2 B, D |\"D7\" ^F A2 G/=F/ |\"Gm\" G2\"Cm7\" B c |\"F7\" A2 G =F |\n\"Bb\" D2 F A |\"Cm7\" c e2 d/c/ |\"Gm7\" B3/2 G/-\"C7\" G2- |\"F7\" G2 z2 |]\n```\n\n```\n######################## INPUT TEXT ########################\n\nThis is a Chinese folk song from the Jiangnan region. It was created during the Qianlong era (1735-1796) of the Qing dynasty. Over time, many regional variations were created, and the song gained popularity both in China and abroad. One version of the song describes a custom of giving jasmine flowers, popular in the southern Yangtze delta region of China.\n\n####################### OUTPUT TUNES #######################\n\nX:1\nL:1/8\nQ:1/4=100\nM:2/4\nK:C\n\"^Slow\" DA A2 | GA c2- | c2 G2 | c2 GF | GA/G/ F2 | E2 DC | DA A2 | GA c2- | c2 GA | cd- d2 |\n cA c2- | c2 GA | cd- d2 | cA c2- | c2 GA | c2 A2 | c2 d2 | cA c2- | c2 c2 | A2 G2 | F2 AG | F2 ED |\n CA,/C/ D2- | D2 CD | F2 A2 | G2 ED | CG A2 | G2 FD | CA,/C/ D2- | D2 CD | F2 A2 | G2 ED |\n CG A2 | G2 FD | CA,/C/ D2- | D2 z2 :|\n\nX:2\nL:1/8\nQ:1/4=100\nM:2/4\nK:C\n\"^ MDolce\" Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- | E2 z2 | EG ed | c2 AG | cA cd |\n A2 AG | E2 ED | CD E2- | E2 z2 |\"^ howeveroda\" Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- |\n E2 z2 | A2 cA | GA E2- | E2 z2 | GA cd | e2 ed | cd e2- | e2 z2 | ge d2 | cd c2- | c2 z2 |\n Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- | E2 z2 | EG ed | c2 AG | cA cd | A2 AG | E2 ED |\n CD E2- | E2 z2 |\"^DDtisata\" Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- | E2 z2 | A2 cA |\n GA E2- | E2 z2 | GA cd | e2 ed | cd e2- | e2 z2 | ge d2 | cd c2- | c2 z2 | Ac de | d2 AG |\n cA cd | A2 AG | E2 ED | CD E2- | E2 z2 | Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- | E2 z2 |\n Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- | E2 z2 |\"^  Easy\" Ac de | d2 AG | cA cd |\n A2 AG | E2 ED | CD E2- | E2 z2 | Ac de | d2 AG | cA cd | A2 AG | E2 ED | CD E2- | E2 z2 |]\n\nX:3\nL:1/8\nQ:1/4=60\nM:4/4\nK:C\n\"^S books defe..\" AA A2 cdcc | AcAG A4- | A8 | A,4 CD C2 | A,4 cdcA | A2 GA- A4- | A2 GA A2 AA |\n AG E2 D2 C2 | D6 ED | C2 D4 C2 | D2 C2 D4 | C2 A,2 CD C2 | A,4 cdcA | A2 GA- A4- | A2 GA A2 AA |\n AG E2 D2 C2 | D6 z2 |]\n```\n\n### BibTeX entry and citation info\n\n```bibtex\n@inproceedings{\nwu2023exploring,\ntitle={Exploring the Efficacy of Pre-trained Checkpoints in Text-to-Music Generation Task}, \nauthor={Shangda Wu and Maosong Sun},\nbooktitle={The AAAI-23 Workshop on Creative AI Across Modalities},\nyear={2023},\nurl={https://openreview.net/forum?id=QmWXskBhesn}\n}\n```", "size_bytes": "557969145", "downloads": 2612}