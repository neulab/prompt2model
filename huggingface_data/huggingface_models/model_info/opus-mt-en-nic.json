{"pretrained_model_name": "Helsinki-NLP/opus-mt-en-nic", "description": "---\nlanguage: \n- en\n- sn\n- rw\n- wo\n- ig\n- sg\n- ee\n- zu\n- lg\n- ts\n- ln\n- ny\n- yo\n- rn\n- xh\n- nic\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### eng-nic\n\n* source group: English \n* target group: Niger-Kordofanian languages \n*  OPUS readme: [eng-nic](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-nic/README.md)\n\n*  model: transformer\n* source language(s): eng\n* target language(s): bam_Latn ewe fuc fuv ibo kin lin lug nya run sag sna swh toi_Latn tso umb wol xho yor zul\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)\n* download original weights: [opus-2020-07-27.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-nic/opus-2020-07-27.zip)\n* test set translations: [opus-2020-07-27.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-nic/opus-2020-07-27.test.txt)\n* test set scores: [opus-2020-07-27.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-nic/opus-2020-07-27.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| Tatoeba-test.eng-bam.eng.bam \t| 6.2 \t| 0.029 |\n| Tatoeba-test.eng-ewe.eng.ewe \t| 4.5 \t| 0.258 |\n| Tatoeba-test.eng-ful.eng.ful \t| 0.5 \t| 0.073 |\n| Tatoeba-test.eng-ibo.eng.ibo \t| 3.9 \t| 0.267 |\n| Tatoeba-test.eng-kin.eng.kin \t| 6.4 \t| 0.475 |\n| Tatoeba-test.eng-lin.eng.lin \t| 1.2 \t| 0.308 |\n| Tatoeba-test.eng-lug.eng.lug \t| 3.9 \t| 0.405 |\n| Tatoeba-test.eng.multi \t| 11.1 \t| 0.427 |\n| Tatoeba-test.eng-nya.eng.nya \t| 14.0 \t| 0.622 |\n| Tatoeba-test.eng-run.eng.run \t| 13.6 \t| 0.477 |\n| Tatoeba-test.eng-sag.eng.sag \t| 5.5 \t| 0.199 |\n| Tatoeba-test.eng-sna.eng.sna \t| 19.6 \t| 0.557 |\n| Tatoeba-test.eng-swa.eng.swa \t| 1.8 \t| 0.163 |\n| Tatoeba-test.eng-toi.eng.toi \t| 8.3 \t| 0.231 |\n| Tatoeba-test.eng-tso.eng.tso \t| 50.0 \t| 0.789 |\n| Tatoeba-test.eng-umb.eng.umb \t| 7.8 \t| 0.342 |\n| Tatoeba-test.eng-wol.eng.wol \t| 6.7 \t| 0.143 |\n| Tatoeba-test.eng-xho.eng.xho \t| 26.4 \t| 0.620 |\n| Tatoeba-test.eng-yor.eng.yor \t| 15.5 \t| 0.342 |\n| Tatoeba-test.eng-zul.eng.zul \t| 35.9 \t| 0.750 |\n\n\n### System Info: \n- hf_name: eng-nic\n\n- source_languages: eng\n\n- target_languages: nic\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-nic/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['en', 'sn', 'rw', 'wo', 'ig', 'sg', 'ee', 'zu', 'lg', 'ts', 'ln', 'ny', 'yo', 'rn', 'xh', 'nic']\n\n- src_constituents: {'eng'}\n\n- tgt_constituents: {'bam_Latn', 'sna', 'kin', 'wol', 'ibo', 'swh', 'sag', 'ewe', 'zul', 'fuc', 'lug', 'tso', 'lin', 'nya', 'yor', 'run', 'xho', 'fuv', 'toi_Latn', 'umb'}\n\n- src_multilingual: False\n\n- tgt_multilingual: True\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-nic/opus-2020-07-27.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-nic/opus-2020-07-27.test.txt\n\n- src_alpha3: eng\n\n- tgt_alpha3: nic\n\n- short_pair: en-nic\n\n- chrF2_score: 0.42700000000000005\n\n- bleu: 11.1\n\n- brevity_penalty: 1.0\n\n- ref_len: 10625.0\n\n- src_name: English\n\n- tgt_name: Niger-Kordofanian languages\n\n- train_date: 2020-07-27\n\n- src_alpha2: en\n\n- tgt_alpha2: nic\n\n- prefer_old: False\n\n- long_pair: eng-nic\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "305017869", "downloads": 25}