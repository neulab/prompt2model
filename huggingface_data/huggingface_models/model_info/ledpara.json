{"pretrained_model_name": "liamcripwell/ledpara", "description": "---\nlanguage:\n- en\n---\n\n# LED_para document simplification model\n\nThis is a pretrained version of the document simplification model presented in the Findings of ACL 2023 paper [\"Context-Aware Document Simplification\"](https://arxiv.org/abs/2305.06274). \n\nIt is an end-to-end system based on the [Longformer encoder-decoder](https://huggingface.co/allenai/led-base-16384) that operates at the paragraph-level.\n\nTarget reading levels (1-4) should be indicated via a control token prepended to each input sequence (\"\\<RL_1\\>\", \"\\<RL_2\\>\", \"\\<RL_3\\>\", \"\\<RL_4\\>\"). If using the terminal interface, this will be handled automatically.\n\n## How to use\nIt is recommended to use the [plan_simp](https://github.com/liamcripwell/plan_simp/tree/main) library to interface with the model.\n\nHere is how to use this model in PyTorch:\n\n```python\nfrom plan_simp.models.bart import load_simplifier\n\nsimplifier, tokenizer, hparams = load_simplifier(\"liamcripwell/ledpara\")\n\ntext = \"<RL_3> Turing has an extensive legacy with statues of him and many things named after him, including an annual award for computer science innovations. He appears on the current Bank of England \u00a350 note, which was released on 23 June 2021, to coincide with his birthday. A 2019 BBC series, as voted by the audience, named him the greatest person of the 20th century.\"\ninputs = tokenizer(text, return_tensors=\"pt\")\noutputs = model.generate(**inputs, num_beams=5)\n```\n\nGeneration and evaluation can also be run from the terminal.\n\n```bash\npython plan_simp/scripts/generate.py inference \n    --model_ckpt=liamcripwell/ledpara \n    --test_file=<test_data>\n    --reading_lvl=s_level \n    --out_file=<output_csv>\n\npython plan_simp/scripts/eval_simp.py\n    --input_data=newselaauto_docs_test.csv\n    --output_data=test_out_ledpara.csv\n    --x_col=complex_str\n    --r_col=simple_str\n    --y_col=pred\n    --doc_id_col=pair_id\n    --prepro=True\n    --sent_level=True\n```\n\n", "size_bytes": "647713559", "downloads": 2}