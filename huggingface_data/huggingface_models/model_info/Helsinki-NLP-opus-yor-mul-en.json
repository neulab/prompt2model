{"pretrained_model_name": "kingabzpro/Helsinki-NLP-opus-yor-mul-en", "description": "---\nlicense: apache-2.0\nlanguage:\n- yo\n- en\nmetrics:\n- rouge\npipeline_tag: translation\ntags:\n- text\n- machine-translation\n- language-translation\n- seq2seq\n- helsinki-nlp\n---\n## Predicting English Translation\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Loading tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"kingabzpro/Helsinki-NLP-opus-yor-mul-en\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"kingabzpro/Helsinki-NLP-opus-yor-mul-en\").to('cuda')\n\n# Prediction\na = model.generate(**tokenizer.prepare_seq2seq_batch('N\u00edn\u00fa \u00ecp\u00e8 kan l\u1eb9\u0301y\u00ecn \u00ecgb\u00e0 n\u00e1\u00e0, w\u1ecd\u0301n s\u1ecd f\u00fan a\u1e63oj\u00fa il\u00e9e\u1e63\u1eb9\u0301 BlaBlaCar p\u00e9 \u00e8t\u00f2 n\u00e1\u00e0 ti y\u00ed pad\u00e0, p\u00e9',return_tensors='pt').to('cuda'))\ntext = tokenizer.batch_decode(a)\n\n# Cleaning text\ntext = str(text)\ntext = re.sub(\"<pad> \",\"\",text)\ntext = re.sub(\"'\",\"\",text)\ntext = text.replace(\"[\", \"\")\ntext = text.replace(\"]\", \"\")\ntext\n```\n## Result\n```\n'In a statement after that hearing, the BualaCard\u2019s representative was told that the event had changed, that he had turned up.'\n```\n## ROGUE Score\n**0.3025**", "size_bytes": "308325725", "downloads": 23}