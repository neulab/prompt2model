{"pretrained_model_name": "Helsinki-NLP/opus-mt-ru-en", "description": "---\ntags:\n- translation\nlicense: cc-by-4.0\n---\n\n### opus-mt-ru-en\n\n## Table of Contents\n- [Model Details](#model-details)\n- [Uses](#uses)\n- [Risks, Limitations and Biases](#risks-limitations-and-biases)\n- [Training](#training)\n- [Evaluation](#evaluation)\n- [Citation Information](#citation-information)\n- [How to Get Started With the Model](#how-to-get-started-with-the-model)\n\n## Model Details\n**Model Description:**\n- **Developed by:** Language Technology Research Group at the University of Helsinki\n- **Model Type:** Transformer-align\n- **Language(s):**  \n  - Source Language: Russian\n  - Target Language: English\n- **License:** CC-BY-4.0\n- **Resources for more information:**\n  - [GitHub Repo](https://github.com/Helsinki-NLP/OPUS-MT-train)\n\n\n\n## Uses\n\n#### Direct Use\n\nThis model can be used for translation and text-to-text generation.\n\n\n## Risks, Limitations and Biases\n\n**CONTENT WARNING: Readers should be aware this section contains content that is disturbing, offensive, and can propagate historical and current stereotypes.**\n\nSignificant research has explored bias and fairness issues with language models (see, e.g., [Sheng et al. (2021)](https://aclanthology.org/2021.acl-long.330.pdf) and [Bender et al. (2021)](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)).\n\nFurther details about the dataset for this model can be found in the OPUS readme: [ru-en](https://github.com/Helsinki-NLP/OPUS-MT-train/blob/master/models/ru-en/README.md)\n\n## Training\n#### Training Data\n##### Preprocessing\n* Pre-processing: Normalization + SentencePiece\n* Dataset: [opus](https://github.com/Helsinki-NLP/Opus-MT)\n* Download original weights: [opus-2020-02-26.zip](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-26.zip)\n\n* Test set translations: [opus-2020-02-26.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-26.test.txt)\n\n\n## Evaluation\n\n#### Results\n\n* test set scores: [opus-2020-02-26.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/ru-en/opus-2020-02-26.eval.txt)\n\n#### Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| newstest2012.ru.en \t| 34.8 \t| 0.603 |\n| newstest2013.ru.en \t| 27.9 \t| 0.545 |\n| newstest2014-ruen.ru.en \t| 31.9 \t| 0.591 |\n| newstest2015-enru.ru.en \t| 30.4 \t| 0.568 |\n| newstest2016-enru.ru.en \t| 30.1 \t| 0.565 |\n| newstest2017-enru.ru.en \t| 33.4 \t| 0.593 |\n| newstest2018-enru.ru.en \t| 29.6 \t| 0.565 |\n| newstest2019-ruen.ru.en \t| 31.4 \t| 0.576 |\n| Tatoeba.ru.en \t| 61.1 \t| 0.736 |\n\n## Citation Information\n\n```bibtex\n@InProceedings{TiedemannThottingal:EAMT2020,\n  author = {J{\\\"o}rg Tiedemann and Santhosh Thottingal},\n  title = {{OPUS-MT} \u2014 {B}uilding open translation services for the {W}orld},\n  booktitle = {Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)},\n  year = {2020},\n  address = {Lisbon, Portugal}\n }\n```\n\n## How to Get Started With the Model\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n```\n", "size_bytes": "306991893", "downloads": 329637}