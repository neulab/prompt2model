{"pretrained_model_name": "NYTK/translation-bart-en-hu", "description": "---\n\nlanguage: \n  - en\n  - hu\ntags:\n- translation\nlicense: apache-2.0\nmetrics:\n- sacrebleu\n- chrf\nwidget:\n- text: \"This may not make much sense to you, sir, but I'd like to ask your permission to date your daughter.\"\n  example_title: \"Translation: English-Hungarian\"\n\n---\n\n# BART Translation model\n\nFor further models, scripts and details, see [our repository](https://github.com/nytud/machine-translation) or [our demo site](https://juniper.nytud.hu/demo/nlp).\n\n- Source language: English\n- Target language: Hungarian\n\n- Pretrained on English WikiText-103 and Hungarian Wikipedia\n- Finetuned on subcorpora from OPUS\n\t- Segments: 56.837.602\n\n## Limitations\n\n- tokenized input text (tokenizer: [HuSpaCy](https://huggingface.co/huspacy))\n\n## Results\n\n| Model | BLEU | chrF-3 |\n| ------------- | ------------- | ------------- |\n| Google en-hu  | 25.30  | 54.08 |\n| **BART-base-enhu** | **34.38**  | **58.88** |\n| Google hu-en| 34.48  | 59.59 |\n| **BART-base-huen** | **38.03** | **61,37** |\n\n## Citation\nIf you use this model, please cite the following paper:\n```\n@inproceedings {yang-bart,\n    title = {{BARTerezz\u00fcnk! Messze, messze, messze a vil\u00e1gt\u00f3l, - BART k\u00eds\u00e9rleti modellek magyar nyelvre}},\n\tbooktitle = {XVIII. Magyar Sz\u00e1m\u00edt\u00f3g\u00e9pes Nyelv\u00e9szeti Konferencia},\n\tyear = {2022},\n\tpublisher = {Szegedi Tudom\u00e1nyegyetem, Informatikai Int\u00e9zet},\n\taddress = {Szeged, Magyarorsz\u00e1g},\n\tauthor = {Yang, Zijian Gy\u0151z\u0151},\n\tpages = {15--29}\n}\n\n```\n", "size_bytes": "526410579", "downloads": 46}