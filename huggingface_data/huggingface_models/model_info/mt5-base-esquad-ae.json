{"pretrained_model_name": "lmqg/mt5-base-esquad-ae", "description": "\n---\nlicense: cc-by-4.0\nmetrics:\n- bleu4\n- meteor\n- rouge-l\n- bertscore\n- moverscore\nlanguage: es\ndatasets:\n- lmqg/qg_esquad\npipeline_tag: text2text-generation\ntags:\n- answer extraction\nwidget:\n- text: \"<hl> En la di\u00e1spora somal\u00ed, m\u00faltiples eventos isl\u00e1micos de recaudaci\u00f3n de fondos se llevan a cabo cada a\u00f1o en ciudades como Birmingham, Londres, Toronto y Minneapolis, donde los acad\u00e9micos y profesionales somal\u00edes dan conferencias y responden preguntas de la audiencia. <hl> El prop\u00f3sito de estos eventos es recaudar dinero para nuevas escuelas o universidades en Somalia, para ayudar a los somal\u00edes que han sufrido como consecuencia de inundaciones y / o sequ\u00edas, o para reunir fondos para la creaci\u00f3n de nuevas mezquitas como.\"\n  example_title: \"Answering Extraction Example 1\" \n- text: \"<hl> Los estudiosos y los histori a dores est\u00e1n divididos en cuanto a qu\u00e9 evento se\u00f1ala el final de la era helen\u00edstica. <hl> El per\u00edodo helen\u00edstico se puede ver que termina con la conquista final del coraz\u00f3n griego por Roma en 146 a. C. tras la guerra aquea, con la derrota final del reino ptolemaico en la batalla de Actium en 31 a. Helen\u00edstico se distingue de hel\u00e9nico en que el primero abarca toda la esfera de influencia griega antigua directa, mientras que el segundo se refiere a la propia Grecia.\"\n  example_title: \"Answering Extraction Example 2\" \nmodel-index:\n- name: lmqg/mt5-base-esquad-ae\n  results:\n  - task:\n      name: Text2text Generation\n      type: text2text-generation\n    dataset:\n      name: lmqg/qg_esquad\n      type: default\n      args: default\n    metrics:\n    - name: BLEU4 (Answer Extraction)\n      type: bleu4_answer_extraction\n      value: 32.14\n    - name: ROUGE-L (Answer Extraction)\n      type: rouge_l_answer_extraction\n      value: 49.6\n    - name: METEOR (Answer Extraction)\n      type: meteor_answer_extraction\n      value: 42.73\n    - name: BERTScore (Answer Extraction)\n      type: bertscore_answer_extraction\n      value: 90.66\n    - name: MoverScore (Answer Extraction)\n      type: moverscore_answer_extraction\n      value: 81.22\n    - name: AnswerF1Score (Answer Extraction)\n      type: answer_f1_score__answer_extraction\n      value: 74.84\n    - name: AnswerExactMatch (Answer Extraction)\n      type: answer_exact_match_answer_extraction\n      value: 57.81\n---\n\n# Model Card of `lmqg/mt5-base-esquad-ae`\nThis model is fine-tuned version of [google/mt5-base](https://huggingface.co/google/mt5-base) for answer extraction on the [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) (dataset_name: default) via [`lmqg`](https://github.com/asahi417/lm-question-generation).\n\n\n### Overview\n- **Language model:** [google/mt5-base](https://huggingface.co/google/mt5-base)   \n- **Language:** es  \n- **Training data:** [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) (default)\n- **Online Demo:** [https://autoqg.net/](https://autoqg.net/)\n- **Repository:** [https://github.com/asahi417/lm-question-generation](https://github.com/asahi417/lm-question-generation)\n- **Paper:** [https://arxiv.org/abs/2210.03992](https://arxiv.org/abs/2210.03992)\n\n### Usage\n- With [`lmqg`](https://github.com/asahi417/lm-question-generation#lmqg-language-model-for-question-generation-)\n```python\nfrom lmqg import TransformersQG\n\n# initialize model\nmodel = TransformersQG(language=\"es\", model=\"lmqg/mt5-base-esquad-ae\")\n\n# model prediction\nanswers = model.generate_a(\"a noviembre , que es tambi\u00e9n la estaci\u00f3n lluviosa.\")\n\n```\n\n- With `transformers`\n```python\nfrom transformers import pipeline\n\npipe = pipeline(\"text2text-generation\", \"lmqg/mt5-base-esquad-ae\")\noutput = pipe(\"<hl> En la di\u00e1spora somal\u00ed, m\u00faltiples eventos isl\u00e1micos de recaudaci\u00f3n de fondos se llevan a cabo cada a\u00f1o en ciudades como Birmingham, Londres, Toronto y Minneapolis, donde los acad\u00e9micos y profesionales somal\u00edes dan conferencias y responden preguntas de la audiencia. <hl> El prop\u00f3sito de estos eventos es recaudar dinero para nuevas escuelas o universidades en Somalia, para ayudar a los somal\u00edes que han sufrido como consecuencia de inundaciones y / o sequ\u00edas, o para reunir fondos para la creaci\u00f3n de nuevas mezquitas como.\")\n\n```\n\n## Evaluation\n\n\n- ***Metric (Answer Extraction)***: [raw metric file](https://huggingface.co/lmqg/mt5-base-esquad-ae/raw/main/eval/metric.first.answer.paragraph_sentence.answer.lmqg_qg_esquad.default.json) \n\n|                  |   Score | Type    | Dataset                                                          |\n|:-----------------|--------:|:--------|:-----------------------------------------------------------------|\n| AnswerExactMatch |   57.81 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| AnswerF1Score    |   74.84 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| BERTScore        |   90.66 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| Bleu_1           |   43.7  | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| Bleu_2           |   38.74 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| Bleu_3           |   35.16 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| Bleu_4           |   32.14 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| METEOR           |   42.73 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| MoverScore       |   81.22 | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n| ROUGE_L          |   49.6  | default | [lmqg/qg_esquad](https://huggingface.co/datasets/lmqg/qg_esquad) |\n\n\n\n## Training hyperparameters\n\nThe following hyperparameters were used during fine-tuning:\n - dataset_path: lmqg/qg_esquad\n - dataset_name: default\n - input_types: ['paragraph_sentence']\n - output_types: ['answer']\n - prefix_types: None\n - model: google/mt5-base\n - max_length: 512\n - max_length_output: 32\n - epoch: 17\n - batch: 8\n - lr: 0.0005\n - fp16: False\n - random_seed: 1\n - gradient_accumulation_steps: 8\n - label_smoothing: 0.15\n\nThe full configuration can be found at [fine-tuning config file](https://huggingface.co/lmqg/mt5-base-esquad-ae/raw/main/trainer_config.json).\n\n## Citation\n```\n@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}\n\n```\n", "size_bytes": "2329634869", "downloads": 5}