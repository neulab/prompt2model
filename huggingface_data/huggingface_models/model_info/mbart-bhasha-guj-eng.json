{"pretrained_model_name": "vasudevgupta/mbart-bhasha-guj-eng", "description": "---\ndatasets: pib\nwidget:\n- text: \"\u0ab9\u0ac7\u0aaf! \u0ab9\u0ac1\u0a82 \u0ab5\u0abe\u0ab8\u0ac1\u0aa6\u0ac7\u0ab5 \u0a97\u0ac1\u0aaa\u0acd\u0aa4\u0abe \u0a9b\u0ac1\u0a82\"\n\n---\n\nmBART (a pre-trained model by Facebook) is pre-trained to de-noise multiple languages simultaneously with BART objective.\n\nCheckpoint available in this repository is obtained after fine-tuning `facebook/mbart-large-cc25` on all samples (~60K) from Bhasha (pib_v1.3) Gujarati-English parallel corpus. This checkpoint gives decent results for Gujarati-english translation.", "size_bytes": "2436180719", "downloads": 31}