{"pretrained_model_name": "stephenleejm/T5_yoda_translator", "description": "# Introduction\n\nThis model translate between Yoda-ish to English and vice versa. It makes use of the [T5-base](https://huggingface.co/t5-base) model and finetuning.\nBasically it trains for 2 tasks using the same dataset. In Yoda-ish to English, trains\n\n# Dataset\nFor this first version of the model I used a small sample of 20 Yoda quotes for training. I am in the midst of collecting more samples for training.\n\n# Usage\n**Input**\n\nFor Yoda-ish to English, you can use the prefix \"y_to_e: text\" to pass in as the input.\n\nFor English to Yodaish you can use the prefix \"e_to_y: text\"\n\n**Output**\nThe translated sentence.\n\n E.g\n \n e_to_y: I am sick of you => Sick of you, I am \n\n# Spaces\nTo try this model you can access it [here](https://huggingface.co/spaces/stephenleejm/yoda_translator)", "size_bytes": "891700799", "downloads": 2}