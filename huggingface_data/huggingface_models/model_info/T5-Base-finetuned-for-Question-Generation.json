{"pretrained_model_name": "ZhangCheng/T5-Base-finetuned-for-Question-Generation", "description": "---\nlanguage: en\ndatasets:\n- squad\ntags:\n- Question Generation\nwidget:\n - text: \"<answer> T5 <context> Cheng fine-tuned T5 on SQuAD for question generation.\"\n   example_title: \"Example 1\"\n - text: \"<answer> SQuAD <context> Cheng fine-tuned T5 on SQuAD dataset for question generation.\"\n   example_title: \"Example 2\"\n - text: \"<answer> thousands <context> Transformers provides thousands of pre-trained models to perform tasks on different modalities such as text, vision, and audio.\"\n   example_title: \"Example 3\"\n---\n\n# T5-Base Fine-Tuned on SQuAD for Question Generation\n\n### Model in Action:\n\n```python\nimport torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntrained_model_path = 'ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation'\ntrained_tokenizer_path = 'ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation'\n\nclass QuestionGeneration:\n\n    def __init__(self, model_dir=None):\n        self.model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n        self.tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer_path)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model = self.model.to(self.device)\n        self.model.eval()\n\n    def generate(self, answer: str, context: str):\n        input_text = '<answer> %s <context> %s ' % (answer, context)\n        encoding = self.tokenizer.encode_plus(\n            input_text,\n            return_tensors='pt'\n        )\n        input_ids = encoding['input_ids']\n        attention_mask = encoding['attention_mask']\n        outputs = self.model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        question = self.tokenizer.decode(\n            outputs[0],\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=True\n        )\n        return {'question': question, 'answer': answer, 'context': context}\n\nif __name__ == \"__main__\":\n    context = 'ZhangCheng fine-tuned T5 on SQuAD dataset for question generation.'\n    answer = 'ZhangCheng'\n    QG = QuestionGeneration()\n    qa = QG.generate(answer, context)\n    print(qa['question'])\n    # Output: \n    # Who fine-tuned T5 on SQuAD dataset for question generation?\n```\n", "size_bytes": "891727295", "downloads": 1677}