{"pretrained_model_name": "paust/pko-chat-t5-large", "description": "---\nlicense: mit\nlanguage:\n- ko\nlibrary_name: transformers\npipeline_tag: text2text-generation\nwidget:\n  - text: |\n      \uc0ac\uc6a9\uc790\uac00 \ud55c \ub9d0\uc744 \uc77d\uace0 \uadf8\uc5d0 \uc9c8\ubb38\uc5d0 \ub2f5\ud558\uac70\ub098 \uba85\ub839\uc5d0 \uc751\ub2f5\ud558\ub294 \ube44\uc11c\uc785\ub2c8\ub2e4.\n      \n      \uc0ac\uc6a9\uc790:\n      \ud55c\uad6d\uc758 \uc218\ub3c4\ub294 \uc5b4\ub514\uc778\uac00\uc694?\n      \n      \ube44\uc11c:\n        \n---\n\n# Chat T5\n[SourceCode](https://github.com/paust-team/pko-t5/tree/main/pkot5/chat)\n\nChat T5 \ub294 [pko-flan-t5-large](https://huggingface.co/paust/pko-flan-t5-large) \ub97c \uae30\ubc18\uc73c\ub85c \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.\n\n[KoAlpaca](https://github.com/beomi/koalpaca) \uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \ub370\uc774\ud130\uc14b\uacfc [evolve-instruct](https://github.com/lcw99/evolve-instruct) \uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \ub370\uc774\ud130\uc14b\uc744 \ud559\uc2b5\ud588\uc2b5\ub2c8\ub2e4.\n\uc88b\uc740 \ub370\uc774\ud130\ub97c \uacf5\uac1c\ud574\uc8fc\uc154\uc11c \uac10\uc0ac\ud569\ub2c8\ub2e4.\n\n\n### Model\n- [Huggingface](https://huggingface.co/paust/pko-chat-t5-large)\n\n### Example\n```python\nfrom transformers import T5TokenizerFast, T5ForConditionalGeneration\ntokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\", device_map='cuda')\n\nprompt_tpl = \"\uc0ac\uc6a9\uc790\uac00 \ud55c \ub9d0\uc744 \uc77d\uace0 \uadf8\uc5d0 \uc9c8\ubb38\uc5d0 \ub2f5\ud558\uac70\ub098 \uba85\ub839\uc5d0 \uc751\ub2f5\ud558\ub294 \ube44\uc11c\uc785\ub2c8\ub2e4.\\n\\n\uc0ac\uc6a9\uc790:\\n{text}\\n\\n\ube44\uc11c:\\n\"\nprompt = prompt_tpl.format(text=\"\ud55c\uad6d\uc758 \uc218\ub3c4\ub294 \uc5b4\ub514\uc778\uac00\uc694?\")\ninput_ids = tokenizer(prompt, return_tensors='pt').input_ids\nlogits = model.generate(\n    input_ids,\n    max_new_tokens=1024,\n    temperature=0.5,\n    no_repeat_ngram_size=6,\n    do_sample=True,\n    num_return_sequences=1,\n)\ntext = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\nprint(text)  # \ud55c\uad6d\uc758 \uc218\ub3c4\ub294 \uc11c\uc6b8\uc785\ub2c8\ub2e4.\n```\n\n## License\n[PAUST](https://paust.io)\uc5d0\uc11c \ub9cc\ub4e0 pko-t5\ub294 [MIT license](https://github.com/paust-team/pko-t5/blob/main/LICENSE) \ud558\uc5d0 \uacf5\uac1c\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "size_bytes": "1641163589", "downloads": 35}