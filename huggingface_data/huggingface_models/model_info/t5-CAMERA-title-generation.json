{"pretrained_model_name": "Mizuiro-sakura/t5-CAMERA-title-generation", "description": "---\nlicense: mit\ntags:\n- t5\n- transformers\n- pytorch\n- text2text-generation\n- seq2seq\nlanguage: ja\ndatasets: shunk031/CAMERA\npipeline_tag: text2text-generation\n---\n\n# sonoisa/t5-base-japanese\u3092\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3057\u3066\u3001\u30bf\u30a4\u30c8\u30eb\u751f\u6210\u306b\u7528\u3044\u308c\u308b\u3088\u3046\u306b\u3057\u305f\u30e2\u30c7\u30eb\u3067\u3059\u3002\n\u6587\u7ae0\u3092\u5165\u529b\u3059\u308b\u3068\u3001\u751f\u6210\u578b\u8981\u7d04\u3092\u884c\u3044\u3001\u30bf\u30a4\u30c8\u30eb\u3092\u751f\u6210\u3057\u307e\u3059\u3002\n\n# This model is a title generation model which is based on sonoisa/t5-base-japanese.\nIf you input the text, this model ouput the title of the text.\n\n# sonoisa/t5-base-japanese\u3068\u306f\uff1f\u3000what is sonoisa/t5-base-japanese?\n>This is a T5 (Text-to-Text Transfer Transformer) model pretrained on Japanese corpus.\n\n>\u6b21\u306e\u65e5\u672c\u8a9e\u30b3\u30fc\u30d1\u30b9\uff08\u7d04100GB\uff09\u3092\u7528\u3044\u3066\u4e8b\u524d\u5b66\u7fd2\u3092\u884c\u3063\u305fT5 (Text-to-Text Transfer Transformer) \u30e2\u30c7\u30eb\u3067\u3059\u3002\n\n>Wikipedia\u306e\u65e5\u672c\u8a9e\u30c0\u30f3\u30d7\u30c7\u30fc\u30bf (2020\u5e747\u67086\u65e5\u6642\u70b9\u306e\u3082\u306e)\n>OSCAR\u306e\u65e5\u672c\u8a9e\u30b3\u30fc\u30d1\u30b9\n>CC-100\u306e\u65e5\u672c\u8a9e\u30b3\u30fc\u30d1\u30b9\n>\u3053\u306e\u30e2\u30c7\u30eb\u306f\u4e8b\u524d\u5b66\u7fd2\u306e\u307f\u3092\u884c\u306a\u3063\u305f\u3082\u306e\u3067\u3042\u308a\u3001\u7279\u5b9a\u306e\u30bf\u30b9\u30af\u306b\u5229\u7528\u3059\u308b\u306b\u306f\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n>\u672c\u30e2\u30c7\u30eb\u306b\u3082\u3001\u5927\u898f\u6a21\u30b3\u30fc\u30d1\u30b9\u3092\u7528\u3044\u305f\u8a00\u8a9e\u30e2\u30c7\u30eb\u306b\u3064\u304d\u307e\u3068\u3046\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u5185\u5bb9\u306e\u504f\u308a\u306b\u7531\u6765\u3059\u308b\u504f\u3063\u305f\uff08\u502b\u7406\u7684\u3067\u306f\u306a\u304b\u3063\u305f\u308a\u3001\u6709\u5bb3\u3060\u3063\u305f\u308a\u3001\u30d0\u30a4\u30a2\u30b9\u304c\u3042\u3063\u305f\u308a\u3059\u308b\uff09\u51fa\u529b\u7d50\u679c\u306b\u306a\u308b\u554f\u984c\u304c\u6f5c\u5728\u7684\u306b\u3042\u308a\u307e\u3059\u3002 \u3053\u306e\u554f\u984c\u304c\u767a\u751f\u3057\u3046\u308b\u3053\u3068\u3092\u60f3\u5b9a\u3057\u305f\u4e0a\u3067\u3001\u88ab\u5bb3\u304c\u767a\u751f\u3057\u306a\u3044\u7528\u9014\u306b\u306e\u307f\u5229\u7528\u3059\u308b\u3088\u3046\u6c17\u3092\u3064\u3051\u3066\u304f\u3060\u3055\u3044\u3002\n\n>SentencePiece\u30c8\u30fc\u30af\u30ca\u30a4\u30b6\u30fc\u306e\u5b66\u7fd2\u306b\u306f\u4e0a\u8a18Wikipedia\u306e\u5168\u30c7\u30fc\u30bf\u3092\u7528\u3044\u307e\u3057\u305f\u3002\n\nhttps://huggingface.co/sonoisa/t5-base-japanese/blob/main/README.md\n\u3088\u308a\u5f15\u7528\n\n# \u4f7f\u3044\u65b9\u3000how to use\ntransformers, datasets, sentencepiece\u3092install\u3057\u3066\u3001\u4e0b\u8a18\u306e\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002\nAfter install transformers, datasets and sentencepiece, please execute this code.\n\n```python\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\n\ntokenizer = T5Tokenizer.from_pretrained('sonoisa/t5-base-japanese')\nmodel = T5ForConditionalGeneration.from_pretrained('Mizuiro-sakura/t5-CAMERA-title-generation')\n\ntext = \"\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3068\u306f\u4eba\u9593\u306e\u8133\u306e\u795e\u7d4c\u56de\u8def\u306e\u69cb\u9020\u3092\u6570\u5b66\u7684\u306b\u8868\u73fe\u3059\u308b\u624b\u6cd5\u3067\u3059\u3002\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306fPython\u306b\u3088\u3063\u3066\u69cb\u6210\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u3002\"\nmax_seq_length=256\ntoken=tokenizer(text,\n        truncation=True,\n        max_length=max_seq_length,\n        padding=\"max_length\")\n\noutput=model.generate(input_ids = torch.tensor(token['input_ids']).unsqueeze(0), attention_mask = torch.tensor(token['attention_mask']).unsqueeze(0))\noutput_decode=tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(output_decode)\n```", "size_bytes": "891702929", "downloads": 4}