{"pretrained_model_name": "IDEA-CCNL/Randeng-T5-77M-MultiTask-Chinese", "description": "---\nlicense: apache-2.0\nlanguage: zh\ntags:\n- Text2Text Generation\n- T5\n- chinese\n- sentencepiece\ninference: true\nwidget:\n- text: \"\u60c5\u611f\u5206\u6790\u4efb\u52a1\uff1a\u3010\u623f\u95f4\u8fd8\u662f\u6bd4\u8f83\u8212\u9002\u7684,\u9152\u5e97\u670d\u52a1\u826f\u597d\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u60c5\u611f\u6001\u5ea6\u662f\u4ec0\u4e48\uff1f\u6b63\u9762/\u8d1f\u9762\"\n- type: \"text-generation\"\n---\n\n# Randeng-T5-77M-MultiTask-Chinese\n\n- Main Page:[Fengshenbang](https://fengshenbang-lm.com/)\n- Github: [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)\n\n## \u7b80\u4ecb Brief Introduction\n\n\u5728Randeng-T5-77M\u7684\u57fa\u7840\u4e0a\uff0c\u6536\u96c6\u4e86100\u4e2a\u5de6\u53f3\u7684\u4e2d\u6587\u6570\u636e\u96c6\uff0c\u8fdb\u884cText2Text\u7edf\u4e00\u8303\u5f0f\u7684\u6709\u76d1\u7763\u4efb\u52a1\u9884\u8bad\u7ec3\u3002\n\nOn the basis of Randeng-T5-77M, about 100 Chinese datasets were collected and pre-trained for the supervised task of Text2Text unified paradigm.\n\n## \u6a21\u578b\u5206\u7c7b Model Taxonomy\n\n|  \u9700\u6c42 Demand  | \u4efb\u52a1 Task       | \u7cfb\u5217 Series      | \u6a21\u578b Model    | \u53c2\u6570 Parameter | \u989d\u5916 Extra |\n|  :----:  | :----:  | :----:  | :----:  | :----:  | :----:  |\n| \u901a\u7528 General | \u81ea\u7136\u8bed\u8a00\u8f6c\u6362 NLT | \u71c3\u706f Randeng | MultiTask |      77M      |    \u591a\u4efb\u52a1-\u4e2d\u6587 MultiTask-Chinese    |\n\n\n## \u6a21\u578b\u4fe1\u606f Model Information\n\n\u53c2\u8003\u8bba\u6587\uff1a[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](http://jmlr.org/papers/v21/20-074.html)\n\n\u57fa\u4e8e[Randeng-T5-77M](https://huggingface.co/IDEA-CCNL/Randeng-T5-77M)\uff0c\u6211\u4eec\u5728\u6536\u96c6\u7684100+\u4e2a\u4e2d\u6587\u9886\u57df\u7684\u591a\u4efb\u52a1\u6570\u636e\u96c6\uff08\u4ece\u4e2d\u91c7\u6837\u4e8630w+\u4e2a\u6837\u672c\uff09\u4e0a\u5fae\u8c03\u4e86\u5b83\uff0c\u5f97\u5230\u4e86\u6b64\u591a\u4efb\u52a1\u7248\u672c\u3002\u8fd9\u4e9b\u591a\u4efb\u52a1\u5305\u62ec\uff1a\u60c5\u611f\u5206\u6790\uff0c\u65b0\u95fb\u5206\u7c7b\uff0c\u6587\u672c\u5206\u7c7b\uff0c\u610f\u56fe\u8bc6\u522b\uff0c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff0c\u591a\u9879\u9009\u62e9\uff0c\u6307\u4ee3\u6d88\u89e3\uff0c\u62bd\u53d6\u5f0f\u9605\u8bfb\u7406\u89e3\uff0c\u5b9e\u4f53\u8bc6\u522b\uff0c\u5173\u952e\u8bcd\u62bd\u53d6\uff0c\u751f\u6210\u5f0f\u6458\u8981\u3002\n\nBased on [Randeng-T5-77M](https://huggingface.co/IDEA-CCNL/Randeng-T5-77M), we fine-tuned it on a collection of 100+ multitasking datasets in Chinese domains (from which 30w+ samples were sampled) to obtain this multitasking version. These multitasks include: sentiment analysis, news classification, text classification, intention recognition, natural language inference, multiple choice, denotational disambiguation, extractive reading comprehension, entity recognition, keyword extraction, and generative summarization.\n\n\n## \u4f7f\u7528 Usage\n\n```python\nimport torch\nfrom transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n\n# load tokenizer and model \npretrained_model = \"IDEA-CCNL/Randeng-T5-77M-MultiTask-Chinese\"\n\nspecial_tokens = [\"<extra_id_{}>\".format(i) for i in range(100)]\ntokenizer = T5Tokenizer.from_pretrained(\n    pretrained_model,\n    do_lower_case=True,\n    max_length=512,\n    truncation=True,\n    additional_special_tokens=special_tokens,\n)\nconfig = T5Config.from_pretrained(pretrained_model)\nmodel = T5ForConditionalGeneration.from_pretrained(pretrained_model, config=config)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.eval()\n\n# tokenize\ntext = \"\u60c5\u611f\u5206\u6790\u4efb\u52a1\uff1a\u3010\u623f\u95f4\u8fd8\u662f\u6bd4\u8f83\u8212\u9002\u7684,\u9152\u5e97\u670d\u52a1\u826f\u597d\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u60c5\u611f\u6001\u5ea6\u662f\u4ec0\u4e48\uff1f\u6b63\u9762/\u8d1f\u9762\"\nencode_dict = tokenizer(text, max_length=512, padding='max_length',truncation=True)\n\ninputs = {\n  \"input_ids\": torch.tensor([encode_dict['input_ids']]).long(),\n  \"attention_mask\": torch.tensor([encode_dict['attention_mask']]).long(),\n  }\n\n# generate answer\nlogits = model.generate(\n  input_ids = inputs['input_ids'],\n  max_length=100, \n  early_stopping=True,\n  )\n\nlogits=logits[:,1:]\npredict_label = [tokenizer.decode(i,skip_special_tokens=True) for i in logits]\nprint(predict_label)\n\n# model output: \u6b63\u9762\n```\n\n\u9664\u4e86\u5206\u7c7b\u4efb\u52a1\uff0c\u5176\u4ed6\u4efb\u52a1\u7684\u6570\u636e\u6784\u9020\u4f8b\u5b50\u5982\u4e0b\uff1a\n\nIn addition to classification tasks, data construction examples of other tasks are as follows:\n\n```python\nexample_dict={\n    \"\u6587\u672c\u5206\u7c7b\":{\"text_a\":\"\u94a2\u7434\u57573\u522b\u8e29\u767d\u5757\u513f3\u94a2\u7434\u57573\u662f\u4e00\u6b3e\u7b80\u6d01\u7684\u94a2\u7434\u6a21\u62df\u8f6f\u4ef6,\u5728Android\u5e73\u53f0\u4e0a,\u7c7b\u4f3c\u7684\u8f6f\u4ef6\u8fd8\u662f\u6bd4\u8f83\u591a\u7684\u3002\",\"choices\":[\"\u76f8\u673a\",\"\u5f71\u89c6\u5a31\u4e50\",\"\u68cb\u724c\u4e2d\u5fc3\",\"\u65b0\u95fb\",\"\u8d22\u7ecf\",\"\u7b56\u7565\",\"\u4f11\u95f2\u76ca\u667a\",\"\u6559\u80b2\"]},\n    '\u65b0\u95fb\u5206\u7c7b':{\"text_a\":\"\u5fae\u8f6f\u62ab\u9732\u62d3\u6251\u91cf\u5b50\u8ba1\u7b97\u673a\u8ba1\u5212\uff01\",\"choices\":[\"\u6545\u4e8b\",\"\u6587\u5316\",\"\u5a31\u4e50\",\"\u4f53\u80b2\",\"\u8d22\u7ecf\",\"\u623f\u4ea7\",\"\u6c7d\u8f66\",\"\u6559\u80b2\",\"\u79d1\u6280\"]},\n    '\u60c5\u611f\u5206\u6790':{\"text_a\":\"\u521a\u4e70iphone13 pro \u8fd8\u4e0d\u5230\u4e00\u4e2a\u6708\uff0c\u5929\u5929\u6b7b\u673a\u6700\u5dee\u7684\u4e00\u6b21\u8d2d\u7269\u4f53\u9a8c\",\"choices\":[\"\u597d\u8bc4\",\"\u5dee\u8bc4\"]},\n    '\u610f\u56fe\u8bc6\u522b':{\"text_a\":\"\u6253\u7535\u8bdd\u7ed9\u5434\u5c0f\u519b\u3002\",\"choices\":[\"\u653e\u97f3\u4e50\",\"\u64ad\u653e\u4e0b\u4e00\u9996\",\"\u6253\u7535\u8bdd\",\"\u9000\u51fa\u5bfc\u822a\",\"\u5f00\u59cb\u5bfc\u822a\",\"\u5176\u4ed6\",\"\u6682\u505c\u97f3\u4e50\",\"\u5bfc\u822a\",\"\u5f00\u5bfc\u822a\"]},\n\n    '\u8bed\u4e49\u5339\u914d':{\"text_a\":\"\u4eca\u5929\u5fc3\u60c5\u4e0d\u597d\",\"text_b\":\"\u6211\u5f88\u4e0d\u5f00\u5fc3\",\"choices\":[\"\u76f8\u4f3c\",\"\u4e0d\u76f8\u4f3c\"]},\n    '\u81ea\u7136\u8bed\u8a00\u63a8\u7406':{\"text_a\":\"\u5c0f\u660e\u6b63\u5728\u4e0a\u9ad8\u4e2d\",\"text_b\":\"\u5c0f\u660e\u662f\u4e00\u4e2a\u521d\u4e2d\u751f\",\"choices\":[\"\u65e0\u5173\",\"\u77db\u76fe\",\"\u8574\u542b\"]},\n\n    '\u591a\u9879\u9009\u62e9':{\"text_a\":\"\u8fd9\u5927\u5bb6\u5343\u4e07\u4e0d\u80fd\u7740\u6025\uff0c\u6211\u4eec\u73b0\u5728\u53ea\u662f\u6682\u65f6\u8f93\u4e867\u5206\u3002\u8ddd\u79bb\u6bd4\u8d5b\u7ed3\u675f\u8fd8\u670920\u591a\u5206\u949f\u5462\uff0c\u6211\u4eec\u662f\u5b8c\u5168\u6709\u673a\u4f1a\u8f6c\u8d25\u4e3a\u8d62\u7684\uff0c\u5927\u5bb6\u52a0\u6cb9!\",\"question\":\"\u8bf4\u8bdd\u4eba\u5e0c\u671b\u5927\u5bb6\uff1a\",\"choices\":[\"\u522b\u5f97\u610f\",\"\u51b7\u9759\u4e00\u4e9b\",\"\u52a0\u5feb\u901f\u5ea6\",\"\u63d0\u524d\u9884\u4e60\"]},\n    '\u6307\u4ee3\u6d88\u89e3':{\"text_a\":\"\u674e\u9e23\u89c9\u5f97\u8463\u5ba2\u8fd9\u4eba\uff0c\u8e0f\u5b9e\u5f97\u53eb\u4eba\u96be\u53d7\u3002\u53ef\u56e0\u4e3a\u5b5f\u91ce\u548c\u68ee\u68ee\u592a\u75af\uff0c\u4ed6\u53ea\u597d\u53bb\u627e\u8463\u5ba2\u804a\u5929\uff0c\u4f46\u5728\u8463\u5ba2\u773c\u91cc\uff0c\u674e\u9e23\u4e5f\u662f\u4e0d\u6b63\u5e38\uff0c\u4ed6\u7adf\u7136\u653e\u7740\u73b0\u6210\u7684\u5927\u5b66\u4e0d\u613f\u4e0a\u3002\",\"question\":\"\u3010\u4ed6\u3011\u6307\u7684\u662f\u3010\u674e\u9e23\u3011\u5417\uff1f\",\"choices\":[\"\u662f\",\"\u4e0d\u662f\"]},\n\n    '\u5b9e\u4f53\u8bc6\u522b':{\"text_a\":\"\u5317\u4eac\u5927\u5b66\u662f\u6211\u56fd\u7684\u4e00\u5ea7\u5386\u53f2\u540d\u6821\uff0c\u5750\u843d\u5728\u6d77\u6dc0\u533a\uff0c\u8521\u5143\u57f9\u66fe\u7ecf\u62c5\u4efb\u6821\u957f\",\"question\":\"\u673a\u6784\"},\n    '\u62bd\u53d6\u5f0f\u9605\u8bfb\u7406\u89e3':{\"text_a\":\"\u300aH\u300b\u6b63\u5f0f\u5b9a\u68633\u67087\u65e5\u4e0b\u5348\u4e24\u70b9\u6574\u5728\u4eac\u4e1c\u5546\u57ce\u72ec\u5bb6\u5e73\u53f0\u5f00\u542f\u7b2c\u4e00\u62795000\u4efd\u9884\u552e,\u5b9a\u4ef7230\u5143\u4eba\u6c11\u5e01,\u56de\u9988\u6700\u5fe0\u5b9e\u7684\u706b\u661f\u6b4c\u8ff7,\u610f\u5728\u7528\u7cbe\u54c1\u56de\u9988\u4e09\u5e74\u6765\u8ddf\u968f\u534e\u6668\u5b87\u97f3\u4e50\u4e0d\u79bb\u4e0d\u5f03\u7684\u7c89\u4e1d\u4eec\u7684\u652f\u6301\u4e0e\u539a\u7231\",\"question\":\"\u534e\u6668\u5b87\u4e13\u8f91h\u9884\u552e\u4ef7\u683c\u662f\u591a\u5c11\uff1f\"},\n    '\u5173\u952e\u8bcd\u62bd\u53d6':{\"text_a\":\"\u4eca\u513f\u5728\u5927\u4f17\u70b9\u8bc4\uff0c\u627e\u5230\u4e86\u53e3\u7891\u4e0d\u9519\u7684\u8001\u8336\u6545\u4e8b\u79c1\u623f\u83dc\u3002\"},\n\n    \"\u751f\u6210\u5f0f\u6458\u8981\":{\"text_a\":\"\u9488\u5bf9\u4f20\u7edf\u7684\u6d41\u91cf\u5206\u7c7b\u7ba1\u7406\u7cfb\u7edf\u5b58\u5728\u4e0d\u7a33\u5b9a\u3001\u7ed3\u679c\u53cd\u9988\u4e0d\u53ca\u65f6\u3001\u5206\u7c7b\u7ed3\u679c\u663e\u793a\u4e0d\u76f4\u89c2\u7b49\u95ee\u9898,\u8bbe\u8ba1\u4e00\u4e2a\u57fa\u4e8eweb\u7684\u5728\u7ebf\u7684\u6d41\u91cf\u5206\u7c7b\u7ba1\u7406\u7cfb\u7edf.\u8be5\u7cfb\u7edf\u91c7\u7528\u6d41\u4e2d\u524d5\u4e2a\u5305(\u6392\u96643\u6b21\u63e1\u624b\u5305)\u6240\u542b\u4fe1\u606f\u4f5c\u4e3a\u7279\u5f81\u503c\u8ba1\u7b97\u8d44\u6e90,\u96c6\u6210\u4e00\u79cd\u6216\u591a\u79cd\u5206\u7c7b\u7b97\u6cd5\u7528\u4e8e\u5728\u7ebf\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b,\u5e94\u7528\u6570\u636e\u53ef\u89c6\u5316\u6280\u672f\u5904\u7406\u5206\u7c7b\u7ed3\u679c.\u5b9e\u9a8c\u8868\u660e:\u5728\u91c7\u7528\u9002\u5e94\u5728\u7ebf\u5206\u7c7b\u7684\u7279\u5f81\u96c6\u548cc4.5\u51b3\u7b56\u6811\u7b97\u6cd5\u505a\u5206\u7c7b\u65f6,\u7cfb\u7edf\u80fd\u5feb\u901f\u505a\u51fa\u5206\u7c7b,\u4e14\u7cbe\u5ea6\u8fbe\u523094\uff05\u4ee5\u4e0a;\u6570\u636e\u53ef\u89c6\u5316\u6709\u52a9\u4e8e\u4eba\u673a\u4ea4\u4e92,\u6539\u5584\u5206\u7c7b\u6307\u5bfc.\"}\n}\n\n\n# \u6784\u9020prompt\u7684\u8fc7\u7a0b\u4e2d\uff0cverbalizer\u8fd9\u4e2a\u5360\u4f4dkey\u7684\u5185\u5bb9\uff0c\u662f\u901a\u8fc7 \"/\".join(choices) \u62fc\u63a5\u8d77\u6765\ndataset2instruction = {\n    \"\u60c5\u611f\u5206\u6790\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u60c5\u611f\u6001\u5ea6\u662f\u4ec0\u4e48\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n    \"\u6587\u672c\u5206\u7c7b\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u7c7b\u522b\u662f\u4ec0\u4e48\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n    \"\u65b0\u95fb\u5206\u7c7b\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u7c7b\u522b\u662f\u4ec0\u4e48\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n    \"\u610f\u56fe\u8bc6\u522b\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u8fd9\u53e5\u8bdd\u7684\u610f\u56fe\u662f\u4ec0\u4e48\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n# --------------------\n    \"\u81ea\u7136\u8bed\u8a00\u63a8\u7406\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u548c\u3010{}\u3011\uff0c\u4ee5\u4e0a\u4e24\u53e5\u8bdd\u7684\u903b\u8f91\u5173\u7cfb\u662f\u4ec0\u4e48\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"text_b\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n    \"\u8bed\u4e49\u5339\u914d\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u548c\u3010{}\u3011\uff0c\u4ee5\u4e0a\u4e24\u53e5\u8bdd\u7684\u5185\u5bb9\u662f\u5426\u76f8\u4f3c\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"text_b\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n# -----------------------\n    \"\u6307\u4ee3\u6d88\u89e3\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u6587\u7ae0\u3010{}\u3011\u4e2d{}{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"question\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n    \"\u591a\u9879\u9009\u62e9\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u9605\u8bfb\u6587\u7ae0\u3010{}\u3011\u95ee\u9898\u3010{}\u3011\uff1f{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"question\", \"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n# ------------------------\n    \"\u62bd\u53d6\u5f0f\u9605\u8bfb\u7406\u89e3\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u9605\u8bfb\u6587\u7ae0\u3010{}\u3011\u95ee\u9898\u3010{}\u3011\u7684\u7b54\u6848\u662f\u4ec0\u4e48\uff1f\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"question\"],\n        \"data_type\": \"mrc\",\n    },\n    \"\u5b9e\u4f53\u8bc6\u522b\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u627e\u51fa\u3010{}\u3011\u8fd9\u7bc7\u6587\u7ae0\u4e2d\u6240\u6709\u3010{}\u3011\u7c7b\u578b\u7684\u5b9e\u4f53\uff1f\",\n        \"keys_order\": [\"subtask_type\",\"text_a\", \"question\"],\n        \"data_type\": \"ner\",\n    },\n# ------------------------\n    \"\u5173\u952e\u8bcd\u62bd\u53d6\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u5173\u952e\u8bcd\u662f\u4ec0\u4e48\uff1f\",\n        \"keys_order\": [\"subtask_type\",\"text_a\"],\n        \"data_type\": \"keys\",\n    },\n    \"\u5173\u952e\u8bcd\u8bc6\u522b\":{\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u9605\u8bfb\u6587\u7ae0\u3010{}\u3011\u95ee\u9898\u3010{}\u3011{}\",\n        \"keys_order\": [\"subtask_type\",\"text_a\",\"question\",\"verbalizer\"],\n        \"data_type\": \"classification\",\n    },\n    \"\u751f\u6210\u5f0f\u6458\u8981\": {\n        \"prompt\": \"{}\u4efb\u52a1\uff1a\u3010{}\u3011\u8fd9\u7bc7\u6587\u7ae0\u7684\u6458\u8981\u662f\u4ec0\u4e48\uff1f\",\n        \"keys_order\": [\"subtask_type\",\"text_a\"],\n        \"data_type\": \"summ\",\n    }, \n}\n\ndef get_instruction(sample):\n\n    template = dataset2instruction[sample[\"subtask_type\"]]\n    # print(template)\n    # print(sample)\n    sample[\"instruction\"] = template[\"prompt\"].format(*[\n                sample[k] for k in template[\"keys_order\"]\n            ])\n\n    print(sample[\"instruction\"])\n    \n    return sample[\"instruction\"]\n```\n\n## \u9884\u8bad\u7ec3\u6216\u5fae\u8c03 prtrain or finetune\n\u5982\u679c\u60a8\u5bf9\u4e8e\u600e\u4e48\u9884\u8bad\u7ec3Randeng-T5\u6a21\u578b\u6216\u8005\u60f3\u5728\u81ea\u5df1\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5fae\u8c03Randeng\u6a21\u578b\uff0c\u6b22\u8fce\u4f7f\u7528[Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM/)\u9879\u76ee\uff0c\u8fd9\u91cc\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u793a\u4f8b\uff1a\n- [\u9884\u8bad\u7ec3](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/pretrain_t5)\n- [\u5fae\u8c03](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/mt5_summary)\n\nIf you want to pre train the Randeng T5 model or fine tune the Randeng model in your downstream tasks, welcome to use [Fengshenbang LM]\uff08 https://github.com/IDEA-CCNL/Fengshenbang-LM/ \uff09A complete example of the project is provided here:\n\n- [Pre training](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/pretrain_t5)\n- [Fine tune](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/mt5_summary)\n\n\n## \u5f15\u7528 Citation\n\n\u5982\u679c\u60a8\u5728\u60a8\u7684\u5de5\u4f5c\u4e2d\u4f7f\u7528\u4e86\u6211\u4eec\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5f15\u7528\u6211\u4eec\u7684[\u8bba\u6587](https://arxiv.org/abs/2209.02970)\uff1a\n\nIf you are using the resource for your work, please cite the our [paper](https://arxiv.org/abs/2209.02970):\n\n```text\n@article{fengshenbang,\n  author    = {Jiaxing Zhang and Ruyi Gan and Junjie Wang and Yuxiang Zhang and Lin Zhang and Ping Yang and Xinyu Gao and Ziwei Wu and Xiaoqun Dong and Junqing He and Jianheng Zhuo and Qi Yang and Yongfeng Huang and Xiayu Li and Yanghan Wu and Junyu Lu and Xinyu Zhu and Weifeng Chen and Ting Han and Kunhao Pan and Rui Wang and Hao Wang and Xiaojun Wu and Zhongshen Zeng and Chongpei Chen},\n  title     = {Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence},\n  journal   = {CoRR},\n  volume    = {abs/2209.02970},\n  year      = {2022}\n}\n```\n\n\u4e5f\u53ef\u4ee5\u5f15\u7528\u6211\u4eec\u7684[\u7f51\u7ad9](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n\nYou can also cite our [website](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n\n```text\n@misc{Fengshenbang-LM,\n  title={Fengshenbang-LM},\n  author={IDEA-CCNL},\n  year={2021},\n  howpublished={\\url{https://github.com/IDEA-CCNL/Fengshenbang-LM}},\n}\n```", "size_bytes": "309825349", "downloads": 294}