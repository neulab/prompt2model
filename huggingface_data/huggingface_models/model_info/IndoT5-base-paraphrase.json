{"pretrained_model_name": "Wikidepia/IndoT5-base-paraphrase", "description": "---\nlanguage:\n- id\n---\n# Paraphrase Generation with IndoT5 Base\n\nIndoT5-base trained on translated PAWS.\n\n## Model in action\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"Wikidepia/IndoT5-base-paraphrase\")  \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Wikidepia/IndoT5-base-paraphrase\")\n\nsentence = \"Anak anak melakukan piket kelas agar kebersihan kelas terjaga\"\ntext =  \"paraphrase: \" + sentence + \" </s>\"\n\nencoding = tokenizer(text, padding='longest', return_tensors=\"pt\")\noutputs = model.generate(\n    input_ids=encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"],\n    max_length=512,\n    do_sample=True,\n    top_k=200,\n    top_p=0.95,\n    early_stopping=True,\n    num_return_sequences=5\n)\n```\n\n## Limitations\n\nSometimes paraphrase contain date which doesnt exists in the original text :/\n\n## Acknowledgement\n\nThanks to Tensorflow Research Cloud for providing TPU v3-8s.", "size_bytes": "990438115", "downloads": 701}