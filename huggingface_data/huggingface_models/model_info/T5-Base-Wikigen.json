{"pretrained_model_name": "Suchinthana/T5-Base-Wikigen", "description": "---\nlicense: mit\nwidget:\n- text: 'writeWiki: Jupiter'\n- text: 'writeWiki: Sri Lanka'\n- text: 'writeWiki: Language Model'\nlanguage:\n- en\ndatasets:\n- wikipedia\n---\n\n### Fine tuned T5 base model with Simple English Wikipedia Dataset\n\nThis model is fine tuned with articles from Simple English Wikipedia for article generation. Used around 25,000 articles for training.\n\n### How to use\n\nWe have to use **\"writeWiki: \"** part at the begining of each prompt.\n\nYou can use this model directly with a pipeline for text generation. This example generates a different sequence each time it's run:\n\n```py\n>>> from transformers import pipeline\n>>> generator = pipeline('text2text-generation', model='Suchinthana/T5-Base-Wikigen')\n>>> generator(\"writeWiki: Microcontroller\", do_sample=True, max_length=250)\n```", "size_bytes": "891733009", "downloads": 7}