{"pretrained_model_name": "Den4ikAI/FRED-T5-XL_instructor_chitchat", "description": "---\nlicense: mit\nlanguage:\n- ru\npipeline_tag: text2text-generation\nwidget:\n- text: '<SC6>\u0427\u0435\u043b\u043e\u0432\u0435\u043a: \u041e\u0442\u0432\u0435\u0442\u044c \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441. \u041f\u043e\u0447\u0435\u043c\u0443 \u0442\u0440\u0430\u0432\u0430 \u0437\u0435\u043b\u0435\u043d\u0430\u044f?\\n\u0411\u043e\u0442: <extra_id_0>'\n- text: '<SC1>\u0422\u0435\u0431\u044f \u0437\u043e\u0432\u0443\u0442 \u0410\u043d\u0444\u0438\u0441\u0430. \u0422\u0435\u0431\u0435 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435.\\n\u0421\u043e\u0431\u0435\u0441\u0435\u0434\u043d\u0438\u043a \u0441\u043a\u0430\u0437\u0430\u043b: \u041f\u0440\u0438\u0432\u0435\u0442\\n\u0422\u044b \u043e\u0442\u0432\u0435\u0442\u0438\u043b: <extra_id_0>'\n- text: '<SC6>\u0422\u0435\u0431\u044f \u0437\u043e\u0432\u0443\u0442 \u0410\u043d\u0444\u0438\u0441\u0430. \u0422\u0435\u0431\u0435 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435.\\n\u0421\u043e\u0431\u0435\u0441\u0435\u0434\u043d\u0438\u043a \u0441\u043a\u0430\u0437\u0430\u043b: \u0427\u0442\u043e \u0434\u0435\u043b\u0430\u0442\u044c, \u0435\u0441\u043b\u0438 \u0448\u0430\u043b\u044f\u0442 \u043d\u0435\u0440\u0432\u0438\u0448\u043a\u0438?\\n\u0422\u044b \u043e\u0442\u0432\u0435\u0442\u0438\u043b: <extra_id_0>'\n---\n# Den4ikAI/FRED-T5-XL_instructor_chitchat\n\u0418\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 FRED-T5-XL. \u041e\u0431\u0440\u0430\u0442\u0438\u0442\u0435 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u043d\u0430 \u043f\u0440\u043e\u043c\u043f\u0442\u044b \u0432 \u043f\u0440\u0438\u043c\u0435\u0440\u0435 \u0447\u0438\u0442-\u0447\u0430\u0442\u0430.\n# \u041f\u0440\u0438\u043c\u0435\u0440 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f [Instruct]\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\nimport torch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\ntokenizer = AutoTokenizer.from_pretrained(\"Den4ikAI/FRED-T5-XL_instructor_chitchat\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Den4ikAI/FRED-T5-XL_instructor_chitchat\", torch_dtype=torch.float16).to(device)\nmodel.eval()\ngeneration_config = GenerationConfig.from_pretrained(\"Den4ikAI/FRED-T5-XL_instructor_chitchat\")\ndef generate(prompt):\n  data = tokenizer(f\"<SC6>\u0427\u0435\u043b\u043e\u0432\u0435\u043a: {prompt}\\n\u0411\u043e\u0442: <extra_id_0>\", return_tensors=\"pt\").to(model.device)\n  output_ids = model.generate(\n      **data,\n      generation_config=generation_config\n  )[0]\n  print(tokenizer.decode(data[\"input_ids\"][0].tolist()))\n  out = tokenizer.decode(output_ids.tolist())\n  return out\nwhile 1:\n  generate(input(\":> \"))\n\n```\n# \u041f\u0440\u0438\u043c\u0435\u0440 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f [Chitchat]\n```python\nimport torch\nimport transformers\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nt5_tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"Den4ikAI/FRED-T5-XL_instructor_chitchat\")\nt5_model = transformers.T5ForConditionalGeneration.from_pretrained(\"Den4ikAI/FRED-T5-XL_instructor_chitchat\")\ngeneration_config = transformers.GenerationConfig.from_pretrained(\"Den4ikAI/FRED-T5-XL_instructor_chitchat\")\n\nwhile True:\n    print('-'*80)\n    dialog = []\n    while True:\n        msg = input('H:> ').strip()\n        if len(msg) == 0:\n            break\n        msg = msg[0].upper() + msg[1:]\n        dialog.append('\u0421\u043e\u0431\u0435\u0441\u0435\u0434\u043d\u0438\u043a \u0441\u043a\u0430\u0437\u0430\u043b: ' + msg)\n        # \u0414\u0430\u043d\u043d\u044b\u0439 \u043f\u0440\u0438\u043c\u0435\u0440 \u043f\u0440\u043e\u043c\u043f\u0442\u0430 \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0432\u0435\u0441\u0442\u0438 \u0434\u0438\u0430\u043b\u043e\u0433 \u0438 \u043f\u0438\u0441\u0430\u0442\u044c \u0438\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0438.\n        # prompt = '<SC6>\u0422\u0435\u0431\u044f \u0437\u043e\u0432\u0443\u0442 \u0410\u043d\u0444\u0438\u0441\u0430. \u0422\u0435\u0431\u0435 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435.' + '\\n'.join(dialog) + '\\n\u0422\u044b \u043e\u0442\u0432\u0435\u0442\u0438\u043b: <extra_id_0>'\n        # \u0412\u0442\u043e\u0440\u043e\u0439 \u043f\u0440\u0438\u043c\u0435\u0440 - \u043f\u0440\u043e\u043c\u043f\u0442 \u043f\u0440\u043e\u0441\u0442\u043e \u0434\u043b\u044f \u0434\u0438\u0430\u043b\u043e\u0433\u043e\u0432. \u0412 \u0442\u0430\u043a\u043e\u043c \u0440\u0435\u0436\u0438\u043c\u0435 \u043d\u0435 \u0431\u0443\u0434\u0435\u0442 \u0433\u043b\u044e\u043a\u043e\u0432, \u043a\u043e\u0433\u0434\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u043a\u0438\u0434\u0430\u0435\u0442 \u043a\u0443\u0441\u043e\u043a \u043f\u0440\u043e\u043c\u043f\u0442\u0430 \u0432 \u043e\u0442\u0432\u0435\u0442.\n        prompt = '<SC1>\u0422\u0435\u0431\u044f \u0437\u043e\u0432\u0443\u0442 \u0410\u043d\u0444\u0438\u0441\u0430. \u0422\u0435\u0431\u0435 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435.' + '\\n'.join(dialog) + '\\n\u0422\u044b \u043e\u0442\u0432\u0435\u0442\u0438\u043b: <extra_id_0>'\n\n        input_ids = t5_tokenizer(prompt, return_tensors='pt').input_ids\n        out_ids = t5_model.generate(input_ids=input_ids.to(device), generation_config=generation_config)\n        t5_output = t5_tokenizer.decode(out_ids[0][1:])\n        if '</s>' in t5_output:\n            t5_output = t5_output[:t5_output.find('</s>')].strip()\n\n        t5_output = t5_output.replace('<extra_id_0>', '').strip()\n        t5_output = t5_output.split('\u0421\u043e\u0431\u0435\u0441\u0435\u0434\u043d\u0438\u043a')[0].strip()\n        print('B:> {}'.format(t5_output))\n        dialog.append('\u0422\u044b \u043e\u0442\u0432\u0435\u0442\u0438\u043b: ' + t5_output)\n```\n# Citation\n```\n@MISC{Den4ikAI/FRED-T5-XL_instructor_chitchat,\n    author  = {Denis Petrov},\n    title   = {Russian Instruct and Chitchat model},\n    url     = {https://huggingface.co/Den4ikAI/FRED-T5-XL_instructor_chitchat/},\n    year    = 2023\n}\n```", "size_bytes": "3480907589", "downloads": 244}