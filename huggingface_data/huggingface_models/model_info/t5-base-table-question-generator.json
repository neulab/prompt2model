{"pretrained_model_name": "PrimeQA/t5-base-table-question-generator", "description": "---\nlicense: apache-2.0\n---\n\n# Model description\n\nThis is an [t5-base](https://huggingface.co/t5-base) model, finetuned to generate questions given a table using [WikiSQL](https://huggingface.co/datasets/wikisql) dataset. It was trained to take the SQL, answer and column header of a table as input to generate questions. For more information check our T3QA [paper](https://aclanthology.org/2021.emnlp-main.342/) from EMNLP 2021.\n\n# Overview\n\n*Language model*: t5-base \\\n*Language*: English \\\n*Task*: Table Question Generation \\\n*Data*: WikiSQL\n\n# Intented use and limitations\nOne can use this model to generate questions given a table. Biases associated with pre-training of T5 and WikiSQL dataset may be present.\n\n## Usage\nOne can use this model directly in the [PrimeQA](https://github.com/primeqa/primeqa) framework as in this example [notebook](https://github.com/primeqa/primeqa/blob/tableqg/notebooks/qg/tableqg_inference.ipynb).\n\n## Citation\n```bibtex\n@inproceedings{chemmengath2021topic,\n  title={Topic Transferable Table Question Answering},\n  author={Chemmengath, Saneem and Kumar, Vishwajeet and\n          Bharadwaj, Samarth and Sen, Jaydeep and\n          Canim, Mustafa and Chakrabarti, Soumen and\n          Gliozzo, Alfio and Sankaranarayanan, Karthik},\n  booktitle={Proceedings of the 2021 Conference on \n      Empirical Methods in Natural Language Processing},\n  pages={4159--4172},\n  year={2021}\n}\n```\n\n", "size_bytes": "891660223", "downloads": 71}