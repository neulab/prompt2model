{"pretrained_model_name": "nestoralvaro/mt5-small-test-amazon", "description": "---\nlicense: apache-2.0\ntags:\n- summarization\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: mt5-small-test-amazon\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# mt5-small-test-amazon\n\nThis model is a fine-tuned version of [google/mt5-small](https://huggingface.co/google/mt5-small) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 1.9515\n- Rouge1: 30.3066\n- Rouge2: 3.3019\n- Rougel: 30.1887\n- Rougelsum: 30.0314\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 5.6e-05\n- train_batch_size: 8\n- eval_batch_size: 8\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 8\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Rouge1  | Rouge2 | Rougel  | Rougelsum |\n|:-------------:|:-----:|:----:|:---------------:|:-------:|:------:|:-------:|:---------:|\n| 10.0147       | 1.0   | 1004 | 2.9904          | 7.3703  | 0.2358 | 7.3703  | 7.4292    |\n| 3.4892        | 2.0   | 2008 | 2.4061          | 23.4178 | 2.4764 | 23.2901 | 23.3097   |\n| 2.724         | 3.0   | 3012 | 2.1630          | 26.6706 | 2.8302 | 26.6509 | 26.5723   |\n| 2.4395        | 4.0   | 4016 | 2.0815          | 26.7296 | 2.9481 | 26.6313 | 26.533    |\n| 2.2881        | 5.0   | 5020 | 2.0048          | 30.1887 | 3.3019 | 30.0708 | 29.9135   |\n| 2.1946        | 6.0   | 6024 | 1.9712          | 29.4811 | 2.9481 | 29.4025 | 29.3042   |\n| 2.1458        | 7.0   | 7028 | 1.9545          | 29.8153 | 3.3019 | 29.717  | 29.5204   |\n| 2.1069        | 8.0   | 8032 | 1.9515          | 30.3066 | 3.3019 | 30.1887 | 30.0314   |\n\n\n### Framework versions\n\n- Transformers 4.20.0\n- Pytorch 1.11.0+cu113\n- Datasets 2.3.2\n- Tokenizers 0.12.1\n", "size_bytes": "1200770757", "downloads": 4}