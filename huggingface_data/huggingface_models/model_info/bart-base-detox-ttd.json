{"pretrained_model_name": "s-nlp/bart-base-detox-ttd", "description": "---\nlanguage:\n- en\ntags:\n- detoxification\nlicenses:\n- cc-by-nc-sa\npipeline_tag: text2text-generation\n---\n\n**Model Overview**\n\nIt is a TT-compressed model of original BART-based detoxification model\n[s-nlp/bart-base-detox][1].\n\n**How to use**\n\n```python\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nmodel = AutoModelForSeq2SeqLM \\\n    .from_pretrained('s-nlp/bart-base-detox-ttd', trust_remote_code=True)\ntokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n\ntoxics = ['that sick fuck is going to be out in 54 years.']\ntokens = tokenizer(toxics)\ntokens = model.generate(**tokens, num_return_sequences=1, do_sample=False,\n                        temperature=1.0, repetition_penalty=10.0,\n                        max_length=128, num_beams=5)\nneutrals = tokenizer.decode(tokens[0, ...], skip_special_tokens=True)\nprint(neutrals) # stdout: She is going to be out in 54 years.\n```\n\n[1]: //s-nlp/bart-base-detox\n", "size_bytes": "536167389", "downloads": 2}