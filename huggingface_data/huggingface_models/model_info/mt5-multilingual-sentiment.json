{"pretrained_model_name": "Chirayu/mt5-multilingual-sentiment", "description": "# This model predicts the sentiment('Negative'/'Positive') for the input sentence. It is fine-tuned mt5-small\n\nThe present model supports 6 languages -\n1) English\n2) Hindi\n3) German\n4) Korean\n5) Japanese\n6) Portuguese\n\nHere is how to use this model\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Chirayu/mt5-multilingual-sentiment\")\ntokenizer = AutoTokenizer.from_pretrained(\"Chirayu/mt5-multilingual-sentiment\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ndef get_sentiment(text, num_beams=2,max_length=512, repetition_penalty=2.5, length_penalty=1, early_stopping=True,top_p=.95, top_k=50, num_return_sequences=1):\n  \n  input_ids = tokenizer.encode(\n    text, return_tensors=\"pt\", add_special_tokens=True\n  )\n  \n  input_ids = input_ids.to(device)\n  generated_ids = model.generate(\n      input_ids=input_ids,\n     \n      num_beams=num_beams,\n      max_length=max_length,\n      repetition_penalty=repetition_penalty,\n      length_penalty=length_penalty,\n      early_stopping=early_stopping,\n      top_p=top_p,\n      top_k=top_k,\n      num_return_sequences=num_return_sequences,\n  )\n  sentiment = [tokenizer.decode(generated_id,skip_special_tokens=True,clean_up_tokenization_spaces=True,) for generated_id in generated_ids]\n  return sentiment\n```", "size_bytes": "1200770885", "downloads": 12}