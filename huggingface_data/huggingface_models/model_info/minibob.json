{"pretrained_model_name": "artemsnegirev/minibob", "description": "---\nlicense: apache-2.0\ndatasets:\n- artemsnegirev/ru-word-games\nlanguage:\n- ru\nmetrics:\n- exact_match\npipeline_tag: text2text-generation\n---\n\nModel was trained on companion [dataset](artemsnegirev/ru-word-games). Minibob guess word from a description modeling well known Alias word game.\n\n```python\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\nprefix = \"guess word:\"\n\ndef predict_word(prompt, model, tokenizer):\n    prompt = prompt.replace(\"...\", \"<extra_id_0>\")\n    prompt = f\"{prefix} {prompt}\"\n\n    input_ids = tokenizer([prompt], return_tensors=\"pt\").input_ids\n\n    outputs = model.generate(\n        input_ids.to(model.device), \n        num_beams=5, \n        max_new_tokens=8,\n        do_sample=False,\n        num_return_sequences=5\n    )\n\n    candidates = set()\n        \n    for tokens in outputs:\n        candidate = tokenizer.decode(tokens, skip_special_tokens=True)\n        candidate = candidate.strip().lower()\n\n        candidates.add(candidate)\n\n    return candidates\n\nmodel_name = \"artemsnegirev/minibob\"\n\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\nprompt = \"\u044d\u0442\u043e \u0436\u0438\u0432\u043e\u0442\u043d\u043e\u0435 \u0441 \u043a\u043e\u043f\u044b\u0442\u0430\u043c\u0438 \u043d\u0430 \u043d\u0435\u043c \u0435\u0437\u0434\u044f\u0442\"\n\nprint(predict_word(prompt, model, tokenizer))\n# {'\u0432\u0435\u0440\u0431\u043b\u044e\u0434', '\u043a\u043e\u043d\u044c', '\u043a\u043e\u043d\u044f', '\u043b\u043e\u0448\u0430\u0434\u044c', '\u043f\u043e\u043d\u0438'}\n```\n\nDetailed github-based [tutorial](https://github.com/artemsnegirev/minibob) with pipeline and source code for building Minibob", "size_bytes": "891702929", "downloads": 3}