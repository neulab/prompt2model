{"pretrained_model_name": "Salesforce/discord_qg", "description": "---\nlicense: apache-2.0\nlanguage:\n- en\ntags:\n- question_generation\n- qg\n- qgen\nwidget:\n- text: \"The International Monetary Fund warned on Tuesday that colliding pressures from inflation, war-driven energy and food crises and sharply higher interest rates were pushing the world to the brink of recession and threatening financial market stability.\"\n  example_title: \"Example 1\"\n\n---\n\nModel card for the Question Generation component of the Discord Questions paper (EMNLP 2022 - Findings). The model is a finetuned BART-large, and can be used with the following command:\n```py\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ndqg_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/discord_qg\")\ndiscord_qg = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/discord_qg\")\n\nparagraph = \"The International Monetary Fund warned on Tuesday that colliding pressures from inflation, war-driven energy and food crises and sharply higher interest rates were pushing the world to the brink of recession and threatening financial market stability.\"\n\nencoder_ids = dqg_tokenizer.batch_encode_plus([paragraph], add_special_tokens=True, return_tensors=\"pt\")\nmodel_output = discord_qg.generate(**encoder_ids)\n\ngenerated_texts = dqg_tokenizer.batch_decode(model_output, skip_special_tokens=True)\nprint(generated_texts) #  ['When was the last time the IMF warned of a global recession?']\n```\n\nThe model has a tendency to generate \"When \" questions. If you would rather generate other questions you can do the following:\n\n```py\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nqg_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/discord_qg\")\nqg_model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/discord_qg\")\n\nparagraph = \"The International Monetary Fund warned on Tuesday that colliding pressures from inflation, war-driven energy and food crises and sharply higher interest rates were pushing the world to the brink of recession and threatening financial market stability.\"\n\nfor start_word in [\"How\", \"Why\"]:\n    encoder_ids = qg_tokenizer.batch_encode_plus([paragraph], add_special_tokens=True, padding=True, truncation=True, return_tensors=\"pt\")\n    decoder_input_ids = qg_tokenizer.batch_encode_plus([start_word], add_special_tokens=True, return_tensors=\"pt\")[\"input_ids\"][:, :-1]\n    model_output = qg_model.generate(**encoder_ids, decoder_input_ids=decoder_input_ids, max_length=20)\n    generated_questions = qg_tokenizer.batch_decode(model_output, skip_special_tokens=True)\n\n    print(generated_questions)\n ```\n Prints:\n ```\n['How will the global economy be affected?']\n['Why was the IMF warning?']\n ```", "size_bytes": "1625549871", "downloads": 51}