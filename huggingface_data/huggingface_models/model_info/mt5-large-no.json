{"pretrained_model_name": "erlingh/mt5-large-no", "description": "---\nlicense: apache-2.0\nlanguage:\n- 'no'\n- en\nwidget:\n  - text: >-\n      <extra_id_0> hver uke samles Regjeringens medlemmer til Statsr\u00e5d p\u00e5\n      <extra_id_1>. Dette organet er \u00f8verste <extra_id_2> i Norge. For at m\u00f8tet\n      skal v\u00e6re <extra_id_3>, m\u00e5 over halvparten av regjeringens <extra_id_4>\n      v\u00e6re til stede.\n  - text: >-\n      At <extra_id_0> there are countless paintings and <extra_id_1>, some are even <extra_id_2>\n      the romans.\n---\n\nThis is a pruned version of the ```google/mt5-large``` model. Here, the input and output embeddings are pruned to support a greatly reduced vocabulary.\nThe chosen vocabulary has 30K norwegian, english and special tokens, ~12% of the old size. This reduces the model size by roughly 37%.\nThe model is still OK on similar languages, like German and Danish, but very different languages like arabic are no longer understood.\nThis model is intended as starting point for finetuning mt5 for norwegian applications.", "size_bytes": "3115353157", "downloads": 65}