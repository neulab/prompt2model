{"pretrained_model_name": "voidful/asr_hubert_cluster_bart_base", "description": "---\nlanguage: en\ndatasets:\n- librispeech\ntags:\n- audio\n- automatic-speech-recognition\n- speech\n- asr\n- hubert\nlicense: apache-2.0\nmetrics:\n- wer\n- cer\n---\n\n# voidful/asr_hubert_cluster_bart_base\n\n\n## Usage\ndownload file\n```shell\nwget https://raw.githubusercontent.com/voidful/hubert-cluster-code/main/km_feat_100_layer_20\nwget https://cdn-media.huggingface.co/speech_samples/sample1.flac\n```\n\nHubert kmeans code\n```python\nimport joblib\nimport torch\nfrom transformers import Wav2Vec2FeatureExtractor, HubertModel\nimport soundfile as sf\n\n\nclass HubertCode(object):\n    def __init__(self, hubert_model, km_path, km_layer):\n        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(hubert_model)\n        self.model = HubertModel.from_pretrained(hubert_model)\n        self.km_model = joblib.load(km_path)\n        self.km_layer = km_layer\n        self.C_np = self.km_model.cluster_centers_.transpose()\n        self.Cnorm_np = (self.C_np ** 2).sum(0, keepdims=True)\n\n        self.C = torch.from_numpy(self.C_np)\n        self.Cnorm = torch.from_numpy(self.Cnorm_np)\n        if torch.cuda.is_available():\n            self.C = self.C.cuda()\n            self.Cnorm = self.Cnorm.cuda()\n            self.model = self.model.cuda()\n\n    def __call__(self, filepath, sampling_rate=None):\n        speech, sr = sf.read(filepath)\n        input_values = self.processor(speech, return_tensors=\"pt\", sampling_rate=sr).input_values\n        if torch.cuda.is_available():\n            input_values = input_values.cuda()\n        hidden_states = self.model(input_values, output_hidden_states=True).hidden_states\n        x = hidden_states[self.km_layer].squeeze()\n        dist = (\n                x.pow(2).sum(1, keepdim=True)\n                - 2 * torch.matmul(x, self.C)\n                + self.Cnorm\n        )\n        return dist.argmin(dim=1).cpu().numpy()\n```\ninput\n```python\nhc = HubertCode(\"facebook/hubert-large-ll60k\", './km_feat_100_layer_20', 20)\nvoice_ids = hc('./sample1.flac')\n```\nbart model\n````python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ntokenizer = AutoTokenizer.from_pretrained(\"voidful/asr_hubert_cluster_bart_base\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"voidful/asr_hubert_cluster_bart_base\")\n````\ngenerate output\n```python\ngen_output = model.generate(input_ids=tokenizer(\"\".join([f\":vtok{i}:\" for i in voice_ids]),return_tensors='pt').input_ids,max_length=1024)\nprint(tokenizer.decode(gen_output[0], skip_special_tokens=True))\n```\n\n## Result\n`going along slushy country roads and speaking to damp audience in drifty school rooms day after day for a fortnight he'll have to put in an appearance at some place of worship on sunday morning and he can come to ask immediately afterwards`\n", "size_bytes": "715471875", "downloads": 8}