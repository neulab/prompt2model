{"pretrained_model_name": "ThomasNLG/t5-qg_squad1-en", "description": "---\nlanguage: en\ntags:\n- qg\n- question\n- generation\n- SQuAD\n- metric\n- nlg\n- t5-small\nlicense: mit\ndatasets:\n- squad\nmodel-index:\n- name: t5-qg_squad1-en\n  results:\n  - task: \n      name: Question Generation\n      type: Text2Text-Generation\nwidget:\n   - text: \"sv1 </s> Louis 14 </s> Louis 14 was a French King.\"\n---\n# t5-qg_squad1-en\n\n## Model description\nThis model is a *Question Generation* model based on T5-small.\nIt is actually a component of [QuestEval](https://github.com/ThomasScialom/QuestEval) metric but can be used independently as it is, for QG only.\n\n\n## How to use\n```python\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"ThomasNLG/t5-qg_squad1-en\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"ThomasNLG/t5-qg_squad1-en\")\n```\n\nYou can play with the model using the inference API, the text input format should follow this template (accordingly to the training stage of the model):\n\n`text_input = \"sv1 </s> {ANSWER} </s> {CONTEXT}\"`\n\n## Training data\nThe model was trained on SQuAD.\n\n\n### Citation info\n\n```bibtex\n@article{scialom2020QuestEval,\n  title={QuestEval: Summarization Asks for Fact-based Evaluation},\n  author={Scialom, Thomas and Dray, Paul-Alexis and Gallinari, Patrick and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo and Wang, Alex},\n  journal={arXiv preprint arXiv:2103.12693},\n  year={2021}\n}\n```", "size_bytes": "891647800", "downloads": 3022}