{"pretrained_model_name": "hou/translation-model", "description": "---\nlicense: cc-by-nc-4.0\ntags:\n- generated_from_trainer\nmetrics:\n- bleu\nmodel-index:\n- name: NLLB-alt-cv-bleu-40\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# NLLB-alt-cv-bleu-40\n\nThis model is a fine-tuned version of [facebook/nllb-200-distilled-600M](https://huggingface.co/facebook/nllb-200-distilled-600M) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 1.7734\n- Bleu: 30.3568\n- Gen Len: 50.699\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 0.0001\n- train_batch_size: 8\n- eval_batch_size: 8\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 40\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Bleu    | Gen Len |\n|:-------------:|:-----:|:-----:|:---------------:|:-------:|:-------:|\n| 2.1031        | 1.0   | 1380  | 1.6725          | 6.1774  | 56.292  |\n| 1.4925        | 2.0   | 2760  | 1.3799          | 8.9414  | 54.966  |\n| 1.1976        | 3.0   | 4140  | 1.2417          | 10.7993 | 55.32   |\n| 0.9973        | 4.0   | 5520  | 1.1744          | 13.7633 | 51.225  |\n| 0.8305        | 5.0   | 6900  | 1.1461          | 14.8273 | 51.723  |\n| 0.6918        | 6.0   | 8280  | 1.1261          | 16.02   | 50.83   |\n| 0.5823        | 7.0   | 9660  | 1.1556          | 17.8129 | 49.93   |\n| 0.4934        | 8.0   | 11040 | 1.1567          | 19.3213 | 50.647  |\n| 0.4049        | 9.0   | 12420 | 1.1794          | 21.712  | 50.722  |\n| 0.3342        | 10.0  | 13800 | 1.2320          | 22.2956 | 50.552  |\n| 0.2747        | 11.0  | 15180 | 1.2749          | 24.3631 | 50.443  |\n| 0.2281        | 12.0  | 16560 | 1.2996          | 25.4046 | 52.437  |\n| 0.1849        | 13.0  | 17940 | 1.3378          | 26.5399 | 50.361  |\n| 0.153         | 14.0  | 19320 | 1.3709          | 27.0563 | 51.077  |\n| 0.1256        | 15.0  | 20700 | 1.4128          | 27.8781 | 51.129  |\n| 0.1103        | 16.0  | 22080 | 1.4354          | 28.6894 | 51.974  |\n| 0.0893        | 17.0  | 23460 | 1.4859          | 28.0852 | 52.005  |\n| 0.0778        | 18.0  | 24840 | 1.4973          | 28.9053 | 50.803  |\n| 0.0683        | 19.0  | 26220 | 1.5294          | 29.2219 | 50.845  |\n| 0.0592        | 20.0  | 27600 | 1.5576          | 29.1227 | 51.051  |\n| 0.0505        | 21.0  | 28980 | 1.5885          | 29.4121 | 50.376  |\n| 0.0441        | 22.0  | 30360 | 1.6028          | 29.5531 | 51.946  |\n| 0.0397        | 23.0  | 31740 | 1.6254          | 29.3607 | 50.811  |\n| 0.0361        | 24.0  | 33120 | 1.6374          | 29.5197 | 51.166  |\n| 0.0323        | 25.0  | 34500 | 1.6423          | 29.7589 | 51.335  |\n| 0.0288        | 26.0  | 35880 | 1.6630          | 29.6029 | 51.036  |\n| 0.0257        | 27.0  | 37260 | 1.6800          | 29.4437 | 50.623  |\n| 0.0235        | 28.0  | 38640 | 1.6887          | 29.9344 | 50.797  |\n| 0.0201        | 29.0  | 40020 | 1.7096          | 30.1522 | 50.694  |\n| 0.018         | 30.0  | 41400 | 1.7223          | 30.1291 | 50.425  |\n| 0.0163        | 31.0  | 42780 | 1.7282          | 29.8131 | 51.114  |\n| 0.0148        | 32.0  | 44160 | 1.7299          | 29.9721 | 50.851  |\n| 0.0133        | 33.0  | 45540 | 1.7463          | 30.0369 | 50.477  |\n| 0.0122        | 34.0  | 46920 | 1.7514          | 30.0663 | 51.133  |\n| 0.0112        | 35.0  | 48300 | 1.7508          | 30.0451 | 50.736  |\n| 0.0099        | 36.0  | 49680 | 1.7631          | 30.0576 | 50.62   |\n| 0.0087        | 37.0  | 51060 | 1.7683          | 30.1648 | 50.874  |\n| 0.0083        | 38.0  | 52440 | 1.7750          | 30.2558 | 50.667  |\n| 0.0076        | 39.0  | 53820 | 1.7757          | 30.3551 | 50.886  |\n| 0.0076        | 40.0  | 55200 | 1.7734          | 30.3568 | 50.699  |\n\n\n### Framework versions\n\n- Transformers 4.21.0\n- Pytorch 1.10.0+cu113\n- Datasets 2.4.0\n- Tokenizers 0.12.1\n", "size_bytes": "2460465095", "downloads": 2}