{"pretrained_model_name": "kinshuk-h/flan-t5-kelm-tekgen-kg-w-context-small", "description": "\n---\nlicense: mit\nlanguage:\n- en\npipeline_tag: text2text-generation\ntags:\n- legal\n---\n# flan-t5-kelm-tekgen-kg-w-context-small\n\nGoogle's Flan T5 model ([flan-t5-small](https://huggingface.co/google/flan-t5-small)) trained over KG triples from the [KELM TEKGEN Corpus](https://github.com/google-research-datasets/KELM-corpus#part-1-tekgen-training-corpus) using the training method used for [KGT-5](https://huggingface.co/spaces/apoorvumang/kgt5) along with additional context supplied alongside the prompts.\n\n", "size_bytes": "307907461", "downloads": 2}