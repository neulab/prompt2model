{"pretrained_model_name": "VietAI/envit5-base", "description": "---\nlanguage: vi\ndatasets:\n- cc100\ntags:\n- summarization\n- translation\n- question-answering\n\nlicense: mit\n---\n\n# EnViT5-base\n\nState-of-the-art pretrained Transformer-based encoder-decoder model for Vietnamese and English used in [MTet's paper](https://arxiv.org/abs/2210.05610).\n\n## How to use\nFor more details, do check out [our Github repo](https://github.com/vietai/mtet). \n\n[Finetunning examples can be found here](https://github.com/vietai/ViT5/tree/main/finetunning_huggingface).\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\u200b\ntokenizer = AutoTokenizer.from_pretrained(\"VietAI/envit5-base\")  \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/envit5-base\")\nmodel.cuda()\n\n\n# need prefix for en: and vi: sentences\ninputs = [\n    \"vi: VietAI l\u00e0 t\u1ed5 ch\u1ee9c phi l\u1ee3i nhu\u1eadn v\u1edbi s\u1ee9 m\u1ec7nh \u01b0\u01a1m m\u1ea7m t\u00e0i n\u0103ng v\u1ec1 tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o v\u00e0 x\u00e2y d\u1ef1ng m\u1ed9t c\u1ed9ng \u0111\u1ed3ng c\u00e1c chuy\u00ean gia trong l\u0129nh v\u1ef1c tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o \u0111\u1eb3ng c\u1ea5p qu\u1ed1c t\u1ebf t\u1ea1i Vi\u1ec7t Nam.\",\n    \"vi: Theo b\u00e1o c\u00e1o m\u1edbi nh\u1ea5t c\u1ee7a Linkedin v\u1ec1 danh s\u00e1ch vi\u1ec7c l\u00e0m tri\u1ec3n v\u1ecdng v\u1edbi m\u1ee9c l\u01b0\u01a1ng h\u1ea5p d\u1eabn n\u0103m 2020, c\u00e1c ch\u1ee9c danh c\u00f4ng vi\u1ec7c li\u00ean quan \u0111\u1ebfn AI nh\u01b0 Chuy\u00ean gia AI (Artificial Intelligence Specialist), K\u1ef9 s\u01b0 ML (Machine Learning Engineer) \u0111\u1ec1u x\u1ebfp th\u1ee9 h\u1ea1ng cao.\",\n    \"en: Our teams aspire to make discoveries that impact everyone, and core to our approach is sharing our research and tools to fuel progress in the field.\",\n    \"en: We're on a journey to advance and democratize artificial intelligence through open source and open science.\"\n    ]\n\noutputs = model.generate(tokenizer(inputs, return_tensors=\"pt\", padding=True).input_ids.to('cuda'), max_length=512)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n\n```\n\n## Citation\n```\n@misc{mtet,\n  doi = {10.48550/ARXIV.2210.05610},\n  url = {https://arxiv.org/abs/2210.05610},\n  author = {Ngo, Chinh and Trinh, Trieu H. and Phan, Long and Tran, Hieu and Dang, Tai and Nguyen, Hieu and Nguyen, Minh and Luong, Minh-Thang},\n  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {MTet: Multi-domain Translation for English and Vietnamese},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution 4.0 International}\n}\n\n```", "size_bytes": "1100503117", "downloads": 594}