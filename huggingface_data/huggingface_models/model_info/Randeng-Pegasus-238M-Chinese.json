{"pretrained_model_name": "IDEA-CCNL/Randeng-Pegasus-238M-Chinese", "description": "---\nlanguage: zh\ntags:\n- summarization\n- chinese\ninference: False\n---\n\n# Randeng-Pegasus-238M-Chinese\n\n- Main Page:[Fengshenbang](https://fengshenbang-lm.com/)\n- Github: [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)\n\n## \u7b80\u4ecb Brief Introduction\n\n\u5584\u4e8e\u5904\u7406\u6458\u8981\u4efb\u52a1\u7684\uff0c\u4e2d\u6587\u7248\u7684PAGASUS-base\u3002\n\nGood at solving text summarization tasks, Chinese PAGASUS-base.\n\n## \u6a21\u578b\u5206\u7c7b Model Taxonomy\n\n|  \u9700\u6c42 Demand  | \u4efb\u52a1 Task       | \u7cfb\u5217 Series      | \u6a21\u578b Model    | \u53c2\u6570 Parameter | \u989d\u5916 Extra |\n|  :----:  | :----:  | :----:  | :----:  | :----:  | :----:  |\n| \u901a\u7528 General | \u81ea\u7136\u8bed\u8a00\u8f6c\u6362 NLT | \u71c3\u706f Randeng | PEFASUS |      238M      |     \u4e2d\u6587-Chinese    |\n\n## \u6a21\u578b\u4fe1\u606f Model Information\n\n\u53c2\u8003\u8bba\u6587\uff1a[PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization](https://arxiv.org/pdf/1912.08777.pdf)\n\n\u4e3a\u4e86\u89e3\u51b3\u4e2d\u6587\u7684\u81ea\u52a8\u6458\u8981\u4efb\u52a1\uff0c\u6211\u4eec\u9075\u5faaPEGASUS\u7684\u8bbe\u8ba1\u6765\u8bad\u7ec3\u4e2d\u6587\u7684\u7248\u672c\u3002\u6211\u4eec\u4f7f\u7528\u4e86\u609f\u9053\u8bed\u6599\u5e93(180G\u7248\u672c)\u4f5c\u4e3a\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u8003\u8651\u5230\u4e2d\u6587sentence piece\u4e0d\u7a33\u5b9a\uff0c\u6211\u4eec\u5728Randeng-PEGASUS\u4e2d\u540c\u65f6\u4f7f\u7528\u4e86\u7ed3\u5df4\u5206\u8bcd\u548cBERT\u5206\u8bcd\u5668\u3002\u6211\u4eec\u4e5f\u63d0\u4f9blarge\u7684\u7248\u672c\uff1a[IDEA-CCNL/Randeng-Pegasus-523M-Chinese](https://huggingface.co/IDEA-CCNL/Randeng-Pegasus-523M-Chinese)\u3002\u4ee5\u53ca\uff0c\u6211\u4eec\u4e5f\u63d0\u4f9b\u4e86\u5728\u4e2d\u6587\u6458\u8981\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u7248\u672c\uff1a[Randeng-Pegasus-238M-Summary-Chinese](https://huggingface.co/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese)\u3002\n\nTo solve Chinese abstractive summarization tasks, we follow the PEGASUS guidelines. We employ a version of WuDao Corpora (180 GB version) as a pre-training dataset. In addition, considering that the Chinese sentence chunk is unstable, we utilize jiebaand BERT tokenizer in our Randeng-PEGASUS. We also provide a large size version, available with [IDEA-CCNL/Randeng-Pegasus-523M-Chinese](https://huggingface.co/IDEA-CCNL/Randeng-Pegasus-523M-Chinese). And, we also provide a version after fine-tuning on Chinese text summarization datasets: [Randeng-Pegasus-238M-Summary-Chinese](https://huggingface.co/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese).\n\n## \u4f7f\u7528 Usage\n\n```python\nfrom transformers import PegasusForConditionalGeneration\n# Need to download tokenizers_pegasus.py and other Python script from Fengshenbang-LM github repo in advance,\n# or you can download tokenizers_pegasus.py and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_238M/tree/main\n# Stronly recomend you git clone the Fengshenbang-LM repo:\n# 1. git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\n# and then you will see the tokenizers_pegasus.py and data_utils.py which are needed by pegasus model\nfrom tokenizers_pegasus import PegasusTokenizer\n\nmodel = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-238M-Chinese\")\ntokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-238M-Chinese\")\n\ntext = \"\u636e\u5fae\u4fe1\u516c\u4f17\u53f7\u201c\u754c\u9762\u201d\u62a5\u9053\uff0c4\u65e5\u4e0a\u534810\u70b9\u5de6\u53f3\uff0c\u4e2d\u56fd\u53d1\u6539\u59d4\u53cd\u5784\u65ad\u8c03\u67e5\u5c0f\u7ec4\u7a81\u51fb\u67e5\u8bbf\u5954\u9a70\u4e0a\u6d77\u529e\u4e8b\u5904\uff0c\u8c03\u53d6\u6570\u636e\u6750\u6599\uff0c\u5e76\u5bf9\u591a\u540d\u5954\u9a70\u9ad8\u7ba1\u8fdb\u884c\u4e86\u7ea6\u8c08\u3002\u622a\u6b62\u6628\u65e5\u665a9\u70b9\uff0c\u5305\u62ec\u5317\u4eac\u6885\u8d5b\u5fb7\u65af-\u5954\u9a70\u9500\u552e\u670d\u52a1\u6709\u9650\u516c\u53f8\u4e1c\u533a\u603b\u7ecf\u7406\u5728\u5185\u7684\u591a\u540d\u7ba1\u7406\u4eba\u5458\u4ecd\u7559\u5728\u4e0a\u6d77\u529e\u516c\u5ba4\u5185\"\ninputs = tokenizer(text, max_length=512, return_tensors=\"pt\")\n\n# Generate Summary\nsummary_ids = model.generate(inputs[\"input_ids\"])\ntokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n# model output: \u622a\u6b62\u6628\u65e5\u665a9\u70b9\uff0c\u5305\u62ec\u5317\u4eac\u6885\u8d5b\u5fb7\u65af-\u5954\u9a70\u9500\u552e\u670d\u52a1\u6709\u9650\u516c\u53f8\u4e1c\u533a\u603b\u7ecf\u7406\u5728\u5185\u7684\u591a\u540d\u7ba1\u7406\u4eba\u5458\u4ecd\u7559\u5728\u4e0a\u6d77\u529e\u516c\u5ba4\u5185\n```\n\n## \u5f15\u7528 Citation\n\n\u5982\u679c\u60a8\u5728\u60a8\u7684\u5de5\u4f5c\u4e2d\u4f7f\u7528\u4e86\u6211\u4eec\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5f15\u7528\u6211\u4eec\u7684[\u8bba\u6587](https://arxiv.org/abs/2209.02970)\uff1a\n\nIf you are using the resource for your work, please cite the our [paper](https://arxiv.org/abs/2209.02970):\n\n```text\n@article{fengshenbang,\n  author    = {Jiaxing Zhang and Ruyi Gan and Junjie Wang and Yuxiang Zhang and Lin Zhang and Ping Yang and Xinyu Gao and Ziwei Wu and Xiaoqun Dong and Junqing He and Jianheng Zhuo and Qi Yang and Yongfeng Huang and Xiayu Li and Yanghan Wu and Junyu Lu and Xinyu Zhu and Weifeng Chen and Ting Han and Kunhao Pan and Rui Wang and Hao Wang and Xiaojun Wu and Zhongshen Zeng and Chongpei Chen},\n  title     = {Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence},\n  journal   = {CoRR},\n  volume    = {abs/2209.02970},\n  year      = {2022}\n}\n```\n\n\u4e5f\u53ef\u4ee5\u5f15\u7528\u6211\u4eec\u7684[\u7f51\u7ad9](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n\nYou can also cite our [website](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n\n```text\n@misc{Fengshenbang-LM,\n  title={Fengshenbang-LM},\n  author={IDEA-CCNL},\n  year={2021},\n  howpublished={\\url{https://github.com/IDEA-CCNL/Fengshenbang-LM}},\n}\n```\n", "size_bytes": "477094431", "downloads": 114}