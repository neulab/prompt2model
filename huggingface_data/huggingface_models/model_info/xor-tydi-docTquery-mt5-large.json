{"pretrained_model_name": "ielabgroup/xor-tydi-docTquery-mt5-large", "description": "---\nlicense: apache-2.0\nlibrary_name: transformers\npipeline_tag: text2text-generation\n\ninference:\n  parameters:\n    do_sample: true\n    max_length: 64\n    top_k: 10\n    temperature: 1\n    num_return_sequences: 10\nwidget:\n  - text: >-\n      Generate a Japanese question for this passage: Transformer (machine learning model) A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input (which includes the recursive output) data.\n    \n  - text: >-\n      Generate a Arabic question for this passage: Transformer (machine learning model) A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input (which includes the recursive output) data.\n---\n\n## Model description\n\nmT5-large query generation model that is trained with XOR QA data.\n\nUsed in paper [Bridging the Gap Between Indexing and Retrieval for\nDifferentiable Search Index with Query Generation](https://arxiv.org/pdf/2206.10128.pdf)\n\nand [Augmenting Passage Representations with Query Generation\nfor Enhanced Cross-Lingual Dense Retrieval](https://arxiv.org/pdf/2305.03950.pdf)\n\n### How to use\n```python\nfrom transformers import pipeline\n\nlang2mT5 = dict(\n    ar='Arabic',\n    bn='Bengali',\n    fi='Finnish',\n    ja='Japanese',\n    ko='Korean',\n    ru='Russian',\n    te='Telugu'\n)\nPROMPT = 'Generate a {lang} question for this passage: {title} {passage}'\n\ntitle = 'Transformer (machine learning model)'\npassage = 'A transformer is a deep learning model that adopts the mechanism of self-attention, differentially ' \\\n          'weighting the significance of each part of the input (which includes the recursive output) data.'\n\n\nmodel_name_or_path = 'ielabgroup/xor-tydi-docTquery-mt5-large'\ninput_text = PROMPT.format_map({'lang': lang2mT5['ja'],\n                                'title': title,\n                                'passage': passage})\n\ngenerator = pipeline(model=model_name_or_path,\n                     task='text2text-generation',\n                     device=\"cuda:0\",\n                     )\n\nresults = generator(input_text,\n                    do_sample=True,\n                    max_length=64,\n                    num_return_sequences=10,\n                    )\n\nfor i, result in enumerate(results):\n    print(f'{i + 1}. {result[\"generated_text\"]}')\n```\n\n### BibTeX entry and citation info\n\n```bibtex\n@article{zhuang2022bridging,\n  title={Bridging the gap between indexing and retrieval for differentiable search index with query generation},\n  author={Zhuang, Shengyao and Ren, Houxing and Shou, Linjun and Pei, Jian and Gong, Ming and Zuccon, Guido and Jiang, Daxin},\n  journal={arXiv preprint arXiv:2206.10128},\n  year={2022}\n}\n\n@inproceedings{zhuang2023augmenting,\n\ttitle={Augmenting Passage Representations with Query Generation for Enhanced Cross-Lingual Dense Retrieval},\n\tauthor={Zhuang, Shengyao and Shou, Linjun and Zuccon, Guido},\n\tbooktitle={Proceedings of the 46th international ACM SIGIR conference on research and development in information retrieval},\n\tyear={2023}\n}\n```", "size_bytes": "4918511257", "downloads": 27}