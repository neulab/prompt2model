{"pretrained_model_name": "aiautomationlab/german-news-title-gen-mt5", "description": "---\nlanguage: \n  - de\ntags:\n  - summarization\n  - arxiv:2005.00661\n  - arxiv:2111.09525\n  - arxiv:2112.08542\n  - arxiv:2104.04302\n  - arxiv:2109.09209\nlicense: mit\nmetrics:\n  - rouge\nwidget:\n- text: \"Als Reaktion auf die Brandserie wurde am Mittwoch bei der Kriminalpolizei W\u00fcrzburg eine Ermittlungskommission eingerichtet. Ich habe den Eindruck, der Brandstifter wird dreister, kommentiert Rosalinde Schraud, die B\u00fcrgermeisterin von Estenfeld, die Brandserie. Gerade die letzten beiden Brandstiftungen seien ungew\u00f6hnlich gewesen, da sie mitten am Tag und an frequentierten Stra\u00dfen stattgefunden haben.Kommt der Brandstifter aus Estenfeld?Norbert Walz ist das letzte Opfer des Brandstifters von Estenfeld. Ein Unbekannter hat am Dienstagnachmittag sein Gartenhaus angez\u00fcndet.Was da in seinem Kopf herumgeht, was da passiert \u2013 das ist ja unglaublich! Das kann schon jemand aus dem Ort sein, weil sich derjenige auskennt.Norbert Walz aus Estenfeld.Dass es sich beim Brandstifter wohl um einen B\u00fcrger ihrer Gemeinde handele, will die erste B\u00fcrgermeisterin von Estenfeld, Rosalinde Schraud, nicht best\u00e4tigen: In der Bev\u00f6lkerung gibt es nat\u00fcrlich Spekulationen, an denen ich mich aber nicht beteiligen will. Laut Schraud reagiert die B\u00fcrgerschaft mit vermehrter Aufmerksamkeit auf die Br\u00e4nde: Man guckt mehr in die Nachbarschaft. Aufh\u00f6ren wird die Brandserie wohl nicht, solange der T\u00e4ter nicht gefasst wird.Es w\u00e4re nicht ungew\u00f6hnlich, dass der T\u00e4ter aus der Umgebung von Estenfeld stammt. Wir bitten deshalb Zeugen, die sachdienliche Hinweise sowohl zu den Br\u00e4nden geben k\u00f6nnen, sich mit unserer Kriminalpolizei in Verbindung zu setzen.Philipp H\u00fcmmer, Sprecher des Polizeipr\u00e4sidiums UnterfrankenF\u00fcr Hinweise, die zur Ergreifung des T\u00e4ters f\u00fchren, hat das Bayerische Landeskriminalamt eine Belohnung von 2.000 Euro ausgesetzt.\"\n  example_title: \"Example article\"\ninference:\n  parameters:\n    num_beams: 5\n---\n\n# German news title gen\n\nThis is a model for the task of news headline generation in German. \n\nWhile this task is very similar to summarization, there remain differences like length, structure, and language style, which cause state-of-the-art summarization models not to be suited best for headline generation and demand further fine tuning on this task.\n\nFor this model, [mT5-base](https://huggingface.co/google/mt5-base) by Google is used as a foundation model. \n\n**The model is still work in progress**\n\n## Dataset & preprocessing\nThe model was finetuned on a corpus of news articles from [BR24](https://www.br.de/) published between  2015 and 2021. The texts are in german language and cover a range of different news topics like politics, sports, and culture, with a focus on topics that are relevant to the people living in Bavaria (Germany).\n\nIn a preprocessing step, article-headline pairs matching any of the following criteria were filtered out:\n- very short articles (number of words in text lower than 3x the number of words in the headline).\n- articles with headlines containing only words that are not contained in the text (lemmatized and excluding stopwords).\n- articles with headlines that are just the name of a known text format (e.g. \"Das war der Tag\" a format summarizing the most important topics of the day)\n\nFurther the prefix `summarize: ` was added to all articles to make use of the pretrained summarization capabilities of mT5.\n\nAfter filtering the corpus contained 89098 article-headline pairs, of which 87306 were used for training, 902 for validation, and 890 for testing.\n\n## Training \nAfter multiple test runs of finetuning the present model was further trained using the following parameters:\n- foundation-model: mT5-base\n- input_prefix: \"summarize: \"\n- num_train_epochs: 10\n- learning_rate: 5e-5\n- warmup_ratio: 0.3\n- lr_scheduler_type: constant_with_warmup\n- per_device_train_batch_size: 3\n- gradient_accumulation_steps: 2\n- fp16: False\n\nEvery 5000 steps a checkpoint is stored and evaluated on the validation set. After the training, the checkpoint with the best cross-entropy loss on the validation set is saved as the final model.\n\n## Usage\n\nBecause the model was fine tuned on mT5, the usage is analogous to the T5 model ([see docs](https://huggingface.co/docs/transformers/model_doc/t5)). Another option for using the model for inference is the huggingface [summarization pipeline](https://huggingface.co/docs/transformers/v4.23.1/en/main_classes/pipelines#transformers.SummarizationPipeline).\n\nIn both cases the prefix `summarize: ` has to be added to the input texts. \n\nFor obtaining higher quality headlines it is recommended to increase the beam size for genereation. In the evaluations conducted for this model a beam size of 5 was used.\n\n### Example: Direct model evaluation\n\n```python\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_id = \"\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n\ntext = \"Als Reaktion auf die Brandserie wurde am Mittwoch bei der Kriminalpolizei W\u00fcrzburg eine Ermittlungskommission eingerichtet. Ich habe den Eindruck, der Brandstifter wird dreister, kommentiert Rosalinde Schraud, die B\u00fcrgermeisterin von Estenfeld, die Brandserie. Gerade die letzten beiden Brandstiftungen seien ungew\u00f6hnlich gewesen, da sie mitten am Tag und an frequentierten Stra\u00dfen stattgefunden haben.Kommt der Brandstifter aus Estenfeld?Norbert Walz ist das letzte Opfer des Brandstifters von Estenfeld. Ein Unbekannter hat am Dienstagnachmittag sein Gartenhaus angez\u00fcndet.Was da in seinem Kopf herumgeht, was da passiert \u2013 das ist ja unglaublich! Das kann schon jemand aus dem Ort sein, weil sich derjenige auskennt.Norbert Walz aus Estenfeld.Dass es sich beim Brandstifter wohl um einen B\u00fcrger ihrer Gemeinde handele, will die erste B\u00fcrgermeisterin von Estenfeld, Rosalinde Schraud, nicht best\u00e4tigen: In der Bev\u00f6lkerung gibt es nat\u00fcrlich Spekulationen, an denen ich mich aber nicht beteiligen will. Laut Schraud reagiert die B\u00fcrgerschaft mit vermehrter Aufmerksamkeit auf die Br\u00e4nde: Man guckt mehr in die Nachbarschaft. Aufh\u00f6ren wird die Brandserie wohl nicht, solange der T\u00e4ter nicht gefasst wird.Es w\u00e4re nicht ungew\u00f6hnlich, dass der T\u00e4ter aus der Umgebung von Estenfeld stammt. Wir bitten deshalb Zeugen, die sachdienliche Hinweise sowohl zu den Br\u00e4nden geben k\u00f6nnen, sich mit unserer Kriminalpolizei in Verbindung zu setzen.Philipp H\u00fcmmer, Sprecher des Polizeipr\u00e4sidiums UnterfrankenF\u00fcr Hinweise, die zur Ergreifung des T\u00e4ters f\u00fchren, hat das Bayerische Landeskriminalamt eine Belohnung von 2.000 Euro ausgesetzt.\"\n\ninput_text = \"summarize: \" + text\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n\noutputs = model.generate(input_ids, num_beams=5)\ngenerated_headline = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(generated_headline)\n```\n\n### Example: Model evaluation using huggingface pipeline\n```python\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n\nmodel_id = \"\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id)\nheadline_generator = pipeline(\n    \"summarization\",\n    model=model,\n    tokenizer=tokenizer,\n    num_beams=5\n)\n\ntext = \"Als Reaktion auf die Brandserie wurde am Mittwoch bei der Kriminalpolizei W\u00fcrzburg eine Ermittlungskommission eingerichtet. Ich habe den Eindruck, der Brandstifter wird dreister, kommentiert Rosalinde Schraud, die B\u00fcrgermeisterin von Estenfeld, die Brandserie. Gerade die letzten beiden Brandstiftungen seien ungew\u00f6hnlich gewesen, da sie mitten am Tag und an frequentierten Stra\u00dfen stattgefunden haben.Kommt der Brandstifter aus Estenfeld?Norbert Walz ist das letzte Opfer des Brandstifters von Estenfeld. Ein Unbekannter hat am Dienstagnachmittag sein Gartenhaus angez\u00fcndet.Was da in seinem Kopf herumgeht, was da passiert \u2013 das ist ja unglaublich! Das kann schon jemand aus dem Ort sein, weil sich derjenige auskennt.Norbert Walz aus Estenfeld.Dass es sich beim Brandstifter wohl um einen B\u00fcrger ihrer Gemeinde handele, will die erste B\u00fcrgermeisterin von Estenfeld, Rosalinde Schraud, nicht best\u00e4tigen: In der Bev\u00f6lkerung gibt es nat\u00fcrlich Spekulationen, an denen ich mich aber nicht beteiligen will. Laut Schraud reagiert die B\u00fcrgerschaft mit vermehrter Aufmerksamkeit auf die Br\u00e4nde: Man guckt mehr in die Nachbarschaft. Aufh\u00f6ren wird die Brandserie wohl nicht, solange der T\u00e4ter nicht gefasst wird.Es w\u00e4re nicht ungew\u00f6hnlich, dass der T\u00e4ter aus der Umgebung von Estenfeld stammt. Wir bitten deshalb Zeugen, die sachdienliche Hinweise sowohl zu den Br\u00e4nden geben k\u00f6nnen, sich mit unserer Kriminalpolizei in Verbindung zu setzen.Philipp H\u00fcmmer, Sprecher des Polizeipr\u00e4sidiums UnterfrankenF\u00fcr Hinweise, die zur Ergreifung des T\u00e4ters f\u00fchren, hat das Bayerische Landeskriminalamt eine Belohnung von 2.000 Euro ausgesetzt.\"\ninput_text = \"summarize: \" + text\n\ngenerated_headline = headline_generator(input_text)[0][\"summary_text\"]\nprint(generated_headline)\n\n```\n\n\n## Limitations\nLike most state-of-the-art summarization models this model has issues with the factuality of the generated texts [^factuality]. **It is therefore strongly advised having a human fact-check the generated headlines.**\n\nAn analysis of possible biases reproduced by the present model, regardless of whether they originate from our finetuning or the underlying mT5 model, is beyond the scope of this work. We assume that biases exist within the model and an analysis will be a task for future work\n\nAs the model was trained on news articles from the time range 2015-2021, further biases and factual errors could emerge due to topic shifts in news articles and changes in the (e.g. political) situation.\n\n##  Evaluation\n\nThe model was evaluated on a held-out test set consisting of 890 article-headline pairs.\n\nFor each model the headlines were generated using beam search with a beam width of 5.\n\n### Quantitative\n\n| model | Rouge1 | Rouge2 | RougeL | RougeLsum |\n|-|-|-|-|-|\n| [T-Systems-onsite/mt5-small-sum-de-en-v2](https://huggingface.co/T-Systems-onsite/mt5-small-sum-de-en-v2)| 0.107 | 0.0297 | 0.098 | 0.098 |\n| aiautomationlab/german-news-title-gen-mt5 | 0.3131 | 0.0873 | 0.1997 | 0.1997 |\n\nFor evaluating the factuality of the generated headlines concerning the input text, we use 3 state-of-the-art metrics for summary evaluation (the parameters were chosen according to the recommendations from the respective papers or GitHub repositories). Because these metrics are only available for the English language the texts and generated headlines were translated from German to English using the [DeepL API](https://www.deepl.com/en/docs-api/) in an additional preprocessing step for this factuality evaluation.\n\n- **SummaC-CZ** [^summac]  \n  Yields a score between -1 and 1, representing the difference between entailment probability and contradiction probability (-1: the headline is not entailed in text and is completely contradicted by it, 1: the headline is fully entailed in text and not contradicted by it).\n\n  Parameters:\n  - `model_name`: [vitc](https://huggingface.co/tals/albert-xlarge-vitaminc-mnli)\n- **QAFactEval** [^qafacteval]  \n  Using Lerc Quip score, which is reported to perform best in the corresponding paper. The score yields a value between 0 and 5 representing the overlap between answers based on the headline and text to questions generated from the headline (0: no overlap, 5: perfect overlap).\n\n  Parameters:\n  - `use_lerc_quip`: True\n\n- **DAE (dependency arc entailment)** [^dae]  \n  Yields a binary value of either 0 or 1, representing whether all dependency arcs in the headline are entailed in the text (0: at least one dependency arc is not entailed, 1: all dependency arcs are entailed).\n\n  Parameters:\n  - model checkpoint: DAE_xsum_human_best_ckpt\n  - `model_type`: model_type\n  - `max_seq_length`: 512\n\n\nEach metric is calculated for all article-headline pairs in the test set and the respective mean score over the test set is reported.\n\n| model | SummacCZ | QAFactEval | DAE | \n|-|-|-|-|\n| [T-Systems-onsite/mt5-small-sum-de-en-v2](https://huggingface.co/T-Systems-onsite/mt5-small-sum-de-en-v2) | 0.6969 | 3.3023 | 0.8292 |\n| aiautomationlab/german-news-title-gen-mt5 | 0.4419 | 1.9265 | 0.7438 |\n\nIt can be observed that our model scores consistently lower than the T-Systems one. Following human evaluation, it seems that to match the structure and style specific to headlines the headline generation model has to be more abstractive than a model for summarization which leads to a higher frequency of hallucinations in the generated output.\n\n### Qualitative\nA qualitative evaluation conducted by members of the BR AI + Automation Lab showed that the model succeeds in producing headlines that match the language and style of news headlines, but also confirms that there are issues with the factual consistency common to state-of-the-art summarization models.\n\n## Future work\n\nFuture work on this model will focus on generating headlines with higher factual consistency regarding the text. Ideas to achieve this goal include:\n- Use of coreference resolution as additional preprocessing step for making the relations within the text more explicit to the model.\n- Use of contrastive learning [^contrastive_learning]\n- Use of different models for different news topics, as different topics seem to be prone to different types of errors, more specialized models may be able to improve performance.\n- Use of factuality metric models for reranking beam search candidates in the generation step.\n- Perform analysis of biases included in the model\n\n\n\n[^factuality]: Maynez, Joshua, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. \u201cOn Faithfulness and Factuality in Abstractive Summarization.\u201d In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 1906\u201319. Online: Association for Computational Linguistics, 2020. https://doi.org/10.18653/v1/2020.acl-main.173.\n\n[^summac]: Laban, Philippe, Tobias Schnabel, Paul N. Bennett, and Marti A. Hearst. \u201cSummaC: Re-Visiting NLI-Based Models for Inconsistency Detection in Summarization.\u201d Transactions of the Association for Computational Linguistics 10 (February 9, 2022): 163\u201377. https://doi.org/10.1162/tacl_a_00453.  \nCode: https://github.com/tingofurro/summac\n\n[^qafacteval]: Fabbri, Alexander R., Chien-Sheng Wu, Wenhao Liu, and Caiming Xiong. \u201cQAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization.\u201d arXiv, April 29, 2022. https://doi.org/10.48550/arXiv.2112.08542.  \nCode: https://github.com/salesforce/QAFactEval\n\n[^dae]: Goyal, Tanya, and Greg Durrett. \u201cAnnotating and Modeling Fine-Grained Factuality in Summarization.\u201d arXiv, April 9, 2021. http://arxiv.org/abs/2104.04302.  \nCode: https://github.com/tagoyal/factuality-datasets\n\n[^contrastive_learning]: Cao, Shuyang, and Lu Wang. \u201cCLIFF: Contrastive Learning for Improving Faithfulness and Factuality in Abstractive Summarization.\u201d In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 6633\u201349. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics, 2021. https://doi.org/10.18653/v1/2021.emnlp-main.532.\n\n\n", "size_bytes": "2329732045", "downloads": 1753}