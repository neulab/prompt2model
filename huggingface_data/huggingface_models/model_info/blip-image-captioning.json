{"pretrained_model_name": "prasanna2003/blip-image-captioning", "description": "---\npipeline_tag: image-to-text\ndatasets:\n- MMInstruction/M3IT\n---\n\n## Usage:\n```\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nimport torch\nfrom PIL import Image\n\nprocessor = BlipProcessor.from_pretrained(\"prasanna2003/blip-image-captioning\")\nif processor.tokenizer.eos_token is None:\n    processor.tokenizer.eos_token = '<|eos|>'\nmodel = BlipForConditionalGeneration.from_pretrained(\"prasanna2003/blip-image-captioning\")\n\nimage = Image.open('file_name.jpg').convert('RGB')\n\nprompt = \"\"\"Instruction: Generate a single line caption of the Image.\noutput: \"\"\"\n\ninputs = processor(image, prompt, return_tensors=\"pt\")\n\noutput = model.generate(**inputs, max_length=100)\nprint(processor.tokenizer.decode(output[0]))\n\n```", "size_bytes": "989827505", "downloads": 549}