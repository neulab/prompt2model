{"pretrained_model_name": "AndrewZeng/S2KG-base", "description": "# Semi-Supervised Knowledge-Grounded Pre-training for Task-Oriented Dialog Systems\n\nWe present our models for Track 2 of the SereTOD 2022 challenge, which is the first challenge of building semi-supervised and reinforced TOD systems on a large-scale real-world Chinese TOD dataset MobileCS. We build a knowledge-grounded dialog model, S2KG to formulate dialog history and local KB as input and predict the system response.\n\n[This paper](https://arxiv.org/abs/2210.08873) has been accepted at the SereTOD 2022 Workshop, EMNLP 2022\n\n## System Performance\n\nOur system achieves the first place both in the automatic evaluation and human interaction, especially with higher BLEU (+7.64) and Success (+13.6%) than the second place. The evaluation results for both Track 1 and Track 2, which can be accessed via this [this link](https://docs.google.com/spreadsheets/d/1w28AKkG6Wjmuo15QlRlRyrnv859MT1ry0CHV8tFxY9o/edit#gid=0).\n\n\n## S2KG for Generation\n\nWe release our S2KG-base model here. You can use this model for knowledge-grounded dialogue generation follow instructions [S2KG](https://github.com/Zeng-WH/S2KG).\n\n\n\n", "size_bytes": "1162314353", "downloads": 9}