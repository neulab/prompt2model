{"pretrained_model_name": "srir4m/t5-response-gen", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: t5-response-gen\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# t5-response-gen\n\nThis model is a fine-tuned version of [t5-base](https://huggingface.co/t5-base) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 1.9994\n- Rouge1: 19.7051\n- Rouge2: 6.4371\n- Rougel: 16.1965\n- Rougelsum: 18.3535\n- Gen Len: 18.94\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 4e-05\n- train_batch_size: 8\n- eval_batch_size: 8\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 5\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Rouge1  | Rouge2 | Rougel  | Rougelsum | Gen Len |\n|:-------------:|:-----:|:----:|:---------------:|:-------:|:------:|:-------:|:---------:|:-------:|\n| 2.6936        | 0.2   | 250  | 2.3362          | 17.8551 | 5.8099 | 15.0919 | 16.3812   | 19.0    |\n| 2.498         | 0.4   | 500  | 2.2190          | 18.3273 | 6.523  | 15.493  | 16.8039   | 19.0    |\n| 2.4146        | 0.6   | 750  | 2.1489          | 17.6972 | 5.8853 | 14.9319 | 16.2418   | 19.0    |\n| 2.3687        | 0.8   | 1000 | 2.1025          | 18.2632 | 6.5316 | 15.387  | 16.8129   | 19.0    |\n| 2.3183        | 1.0   | 1250 | 2.0706          | 19.3629 | 7.0224 | 16.3958 | 17.7654   | 19.0    |\n| 2.2796        | 1.2   | 1500 | 2.0421          | 18.9182 | 6.3816 | 15.2466 | 17.0433   | 19.0    |\n| 2.2434        | 1.4   | 1750 | 2.0169          | 19.0978 | 6.859  | 16.1165 | 17.5023   | 18.84   |\n| 2.2207        | 1.6   | 2000 | 1.9941          | 19.7175 | 6.6763 | 15.9078 | 17.922    | 18.84   |\n| 2.2123        | 1.8   | 2250 | 1.9794          | 18.6988 | 6.4585 | 15.7348 | 17.2209   | 18.84   |\n| 2.1911        | 2.0   | 2500 | 1.9637          | 18.2629 | 6.2245 | 15.3337 | 16.7855   | 19.0    |\n| 2.1429        | 2.2   | 2750 | 1.9496          | 19.7263 | 7.1514 | 16.3016 | 17.9426   | 19.0    |\n| 2.144         | 2.4   | 3000 | 1.9356          | 19.2725 | 6.5964 | 16.0789 | 17.499    | 19.0    |\n| 2.1473        | 2.6   | 3250 | 1.9261          | 19.7699 | 6.8235 | 16.1405 | 17.9833   | 19.0    |\n| 2.1053        | 2.8   | 3500 | 1.9156          | 19.1541 | 6.6579 | 15.8724 | 17.4114   | 19.0    |\n| 2.0992        | 3.0   | 3750 | 1.9060          | 19.2953 | 6.7249 | 16.1245 | 17.5537   | 19.0    |\n| 2.0767        | 3.2   | 4000 | 1.8990          | 20.23   | 7.3383 | 16.9756 | 18.6396   | 19.0    |\n| 2.0874        | 3.4   | 4250 | 1.8910          | 19.595  | 7.1441 | 16.4483 | 18.1055   | 19.0    |\n| 2.107         | 3.6   | 4500 | 1.8826          | 19.0376 | 6.2637 | 15.7023 | 17.0623   | 19.0    |\n| 2.1078        | 3.8   | 4750 | 1.8779          | 19.7408 | 6.8087 | 16.332  | 17.9344   | 19.0    |\n| 2.1134        | 4.0   | 5000 | 1.8927          | 19.8948 | 7.3009 | 16.7798 | 18.368    | 19.0    |\n| 2.1336        | 4.2   | 5250 | 1.9100          | 20.1098 | 6.7404 | 16.9506 | 18.7358   | 18.93   |\n| 2.1441        | 4.4   | 5500 | 1.9266          | 19.7587 | 6.2587 | 16.3207 | 18.4483   | 18.93   |\n| 2.1626        | 4.6   | 5750 | 1.9609          | 19.8193 | 6.2365 | 16.3354 | 18.4035   | 18.93   |\n| 2.1664        | 4.8   | 6000 | 1.9878          | 19.5972 | 6.2904 | 16.1372 | 18.3641   | 18.94   |\n| 2.2302        | 5.0   | 6250 | 1.9994          | 19.7051 | 6.4371 | 16.1965 | 18.3535   | 18.94   |\n\n\n### Framework versions\n\n- Transformers 4.25.1\n- Pytorch 1.13.0+cu116\n- Datasets 2.8.0\n- Tokenizers 0.13.2\n", "size_bytes": "891702929", "downloads": 5}