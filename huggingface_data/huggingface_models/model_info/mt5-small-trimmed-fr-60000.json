{"pretrained_model_name": "vocabtrimmer/mt5-small-trimmed-fr-60000", "description": "# Vocabulary Trimmed [google/mt5-small](https://huggingface.co/google/mt5-small): `vocabtrimmer/mt5-small-trimmed-fr-60000` \nThis model is a trimmed version of [google/mt5-small](https://huggingface.co/google/mt5-small) by [`vocabtrimmer`](https://github.com/asahi417/lm-vocab-trimmer), a tool for trimming vocabulary of language models to compress the model size.\nFollowing table shows a summary of the trimming process.\n\n|                            | google/mt5-small   | vocabtrimmer/mt5-small-trimmed-fr-60000   |\n|:---------------------------|:-------------------|:------------------------------------------|\n| parameter_size_full        | 300,176,768        | 105,503,104                               |\n| parameter_size_embedding   | 256,114,688        | 61,441,024                                |\n| vocab_size                 | 250,112            | 60,001                                    |\n| compression_rate_full      | 100.0              | 35.15                                     |\n| compression_rate_embedding | 100.0              | 23.99                                     |\n\n\nFollowing table shows the parameter used to trim vocabulary.\n\n | language   | dataset                     | dataset_column   | dataset_name   | dataset_split   |   target_vocab_size |   min_frequency |\n|:-----------|:----------------------------|:-----------------|:---------------|:----------------|--------------------:|----------------:|\n| fr         | vocabtrimmer/mc4_validation | text             | fr             | validation      |               60000 |               2 |", "size_bytes": "422073413", "downloads": 2}