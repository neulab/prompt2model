{"pretrained_model_name": "seonghyeonye/direct_3B", "description": "---\ndatasets:\n- bigscience/P3\nlanguage: en\nlicense: apache-2.0\nwidget:\n- text: \"A is the son's of B's uncle. What is the family relationship between A and B?\"\n- text: \"Reorder the words in this sentence: justin and name bieber years is my am I 27 old.\"\n- text: \"Task: copy but say the opposite.\\n\nPSG won its match against Barca.\"\n- text: \"Is this review positive or negative? Review: Best cast iron skillet you will every buy.\"\n  example_title: \"Sentiment analysis\"\n- text: \"Question A: How is air traffic controlled?\n\\nQuestion B: How do you become an air traffic controller?\\nPick one: these questions are duplicates or not duplicates.\"\n- text: \"Barack Obama nominated Hilary Clinton as his secretary of state on Monday. He chose her because she had foreign affairs experience as a former First Lady.\n\\nIn the previous sentence, decide who 'her' is referring to.\"\n  example_title: \"Coreference resolution\"\n- text: \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\\n\nSelect the category for the above sentence from: mobile, website, billing, account access.\"\n- text: \"Sentence 1: Gyorgy Heizler, head of the local disaster unit, said the coach was carrying 38 passengers.\\n\nSentence 2: The head of the local disaster unit, Gyorgy Heizler, said the bus was full except for 38 empty seats.\\n\\n\nDo sentences 1 and 2 have the same meaning?\"\n  example_title: \"Paraphrase identification\"\n- text: \"Here's the beginning of an article, choose a tag that best describes the topic of the article: business, cinema, politics, health, travel, sports.\\n\\n\nThe best and worst fo 007 as 'No time to die' marks Daniel Craig's exit.\\n\n(CNN) Some 007 math: 60 years, 25 movies (with a small asterisk) and six James Bonds. For a Cold War creation, Ian Fleming's suave spy has certainly gotten around, but despite different guises in the tuxedo and occasional scuba gear, when it comes to Bond ratings, there really shouldn't be much argument about who wore it best.\"\n- text: \"Max: Know any good websites to buy clothes from?\\n\nPayton: Sure :) LINK 1, LINK 2, LINK 3\\n\nMax: That's a lot of them!\\n\nPayton: Yeah, but they have different things so I usually buy things from 2 or 3 of them.\\n\nMax: I'll check them out. Thanks.\\n\\n\nWho or what are Payton and Max referring to when they say 'them'?\"\n- text: \"Is the word 'table' used in the same meaning in the two following sentences?\\n\\n\nSentence A: you can leave the books on the table over there.\\n\nSentence B: the tables in this book are very hard to read.\"\n- text: \"On a shelf, there are five books: a gray book, a red book, a purple book, a blue book, and a black book.\\n\nThe red book is to the right of the gray book. The black book is to the left of the blue book. The blue book is to the left of the gray book. The purple book is the second from the right.\\n\\n\nWhich book is the leftmost book?\"\n  example_title: \"Logic puzzles\"\n- text: \"The two men running to become New York City's next mayor will face off in their first debate Wednesday night.\\n\\n\nDemocrat Eric Adams, the Brooklyn Borough president and a former New York City police captain, is widely expected to win the Nov. 2 election against Republican Curtis Sliwa, the founder of the 1970s-era Guardian Angels anti-crime patril.\\n\\n\nWho are the men running for mayor?\"\n  example_title: \"Reading comprehension\"\n- text: \"The word 'binne' means any animal that is furry and has four legs, and the word 'bam' means a simple sort of dwelling.\\n\\n\nWhich of the following best characterizes binne bams?\\n\n- Sentence 1: Binne bams are for pets.\\n\n- Sentence 2: Binne bams are typically furnished with sofas and televisions.\\n\n- Sentence 3: Binne bams are luxurious apartments.\\n\n- Sentence 4: Binne bams are places where people live.\"\n---\n\n**Official repository**: [seonghyeonye/Flipped-Learning](https://github.com/seonghyeonye/Flipped-Learning)\n# Model Description\nDIRECT is a strong baseline of FLIPPED, based on the training objective on [T0-3B](https://huggingface.co/bigscience/T0_3B). \nWith only 5% token updates and half of training datasets compared to T0-3B, DIRECT outperforms T0-3B. (+6.38% mean accuracy on 14 NLP tasks, +1.19% mean accuracy on 14 BIG-bench tasks)\n\n# How to use\nOur overall explanation models along with ablations can be found in our [paper](https://arxiv.org/abs/2210.02969). We recommend using the [FLIPPED-11B](seonghyeonye/flipped_11B) checkpoint as it leads (on average) to the best performances on a variety of NLP tasks.\n|Model|Number of parameters|\n|-|-|\n|[Flipped_11B](https://huggingface.co/seonghyeonye/flipped_11B)|11 billion|\n|[Flipped_3B](https://huggingface.co/seonghyeonye/flipped_3B)|3 billion|\nHere is how to download the model in PyTorch:\n\n```python\nimport torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"seonghyeonye/direct_3B\")\ntokenizer = T5Tokenizer.from_pretrained(\"seonghyeonye/direct_3B\")\n```\nIf you want to use another checkpoint, please replace the path in `T5Tokenizer` and `T5ForConditionalGeneration`.\nWe also provide a quick [Jupyter Notebook](https://github.com/seonghyeonye/Flipped-Learning/blob/master/flipped_inference.ipynb) where you can inference with our method.\n**Note: the model was trained with fp32 activations. As such, we highly discourage running inference with fp16.**\n\n# Training procedure\nDIRECT model is based on [T5+LM](https://huggingface.co/google/t5-xl-lm-adapt), a Transformer-based encoder-decoder language model pre-trained with a masked language modeling-style objective additionally pretrained on language modeling objective on [C4](https://huggingface.co/datasets/c4).\nTraining details:\n- Fine-tuning steps: 5'000\n- Input sequence length: 512\n- Target sequence length: 128\n- Batch size: 240\n- Optimizer: Adafactor\n- Learning rate: 1e-4\n- Dropout: 0.1\n- Sampling strategy: proportional to the number of examples in each dataset (we randomly sampled any dataset if it has over 500'000 examples so that it has at most 500'000 examples. Also, we randomly choose which instruction to generate for each training steps, so ideally each instruction appears *num_examples/num_templates* while training.)\n\n# Training data\nWe trained different variants T0 with different mixtures of datasets.\n|Model|Training datasets|\n|--|--|\n|FLIPPED_11B|- Multiple-Choice QA: CommonsenseQA, DREAM, QUAIL, QuaRTz, Social IQA, WiQA, Cosmos, QASC, Quarel, SciQ<br>-  Sentiment: Amazon, App Reviews, IMDB, Rotten Tomatoes, Yelp<br>- Topic Classification: AG News, DBPedia<br>- Paraphrase Identification: MRPC, PAWS, QQP|\n|FLIPPED_3B|Same as FLIPPED-11B|\n|DIRECT_3B|Same as FLIPPED-11B|\nWe only choose prompts examples that has output lables, which can be found on the dataset page.\n\n# Evaluation data\n\nWe evaluate our models on following datasets:\n|Task category|Datasets|\n|-|-|\n|Natural language inference|ANLI(R1, R2, R3), CB, RTE|\n|Coreference resolution|WSC, Winogrande|\n|Word sense disambiguation|WiC|\n|Sentence completion|COPA, HellaSwag, Story Cloze|\n|QA|PIQA, ARC-Challenge, OpenbookQA|\nWe also evaluate FLIPPED on a subset of [BIG-bench benchmark](https://github.com/google/BIG-bench):\n- Code description task\n- Conceptual combinations\n- Hindu knowledge json\n- Known unknowns\n- Language identification\n- Logic grid puzzle task\n- Logical deduction\n- Common misconceptions\n- Movie dialog same or different\n- Novel concepts\n- Strategyqa\n- Formal fallacies syllogisms negation\n- VitaminC\n- Winowhy multiple choice\n\n# Label generalization\nWe evaluate the robustness of models on following datasets with changing the output label of the datasets. The substitute words can be found in our [paper](https://arxiv.org/abs/2210.02969).\n|Task category|(Datasets, Template name)| \n|-|-|\n|Unseen tasks|(WSC, does the pronoun refer to), (CB, can we infer), (RTE, MNLI crowdsource)|\n|Seen tasks|(IMDB, Reviewer Enjoyment Yes No), (PAWS, Meaning) |\n The template name we used can be found in the [promptsource template library](https://github.com/bigscience-workshop/promptsource/tree/main/promptsource/templates). \n# BibTeX entry and citation info\n```bibtex\n@article{ye2022guess,\n  title={Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners},\n  author={Ye, Seonghyeon and Kim, Doyoung and Jang, Joel and Shin, Joongbo and Seo, Minjoon},\n  journal={arXiv preprint arXiv:2210.02969},\n  year={2022}\n}\n```", "size_bytes": 11925413888, "downloads": 3}