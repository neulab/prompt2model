{"pretrained_model_name": "Danish-summarisation/DanSumT5-large", "description": "---\npipeline_tag: summarization\nlicense: apache-2.0\nlanguage:\n- da\n---\n\n# mT5-large fine-tuned for News article Summarisation \u270f\ufe0f\ud83e\uddfe\n\n[Google's mT5](https://aclanthology.org/2021.naacl-main.41/) for **summarisation** downstream task.\n\n# Model summary\nThis repository contains a model for Danish abstractive summarisation of news articles. The summariser is based on a language-specific mT5-large.\n\nThe model is fine-tuned using an abstractive subset of the DaNewsroom dataset (Varab & Schluter, 2020), according to the binned density categories employed in Newsroom (Grusky et al., 2019).\n\n# References\nGrusky, M., Naaman, M., & Artzi, Y. (2018). Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies. ArXiv:1804.11283 [Cs]. http://arxiv.org/abs/1804.11283\n\nVarab, D., & Schluter, N. (2020). DaNewsroom: A Large-scale Danish Summarisation Dataset. Proceedings of the 12th Language Resources and Evaluation Conference, 6731\u20136739. https://aclanthology.org/2020.lrec-1.831\n", "size_bytes": "4918507577", "downloads": 47}