{"pretrained_model_name": "akhooli/mbart-large-cc25-en-ar", "description": "---\ntags:\n- translation\n\nlanguage:\n- en\n- ar\n\nlicense: mit\n---\n### mbart-large-en-ar\nThis is mbart-large-cc25, finetuned on a subset of the UN corpus for en_ar.  \nUsage: see [example notebook](https://colab.research.google.com/drive/1I6RFOWMaTpPBX7saJYjnSTddW0TD6H1t?usp=sharing) \nNote: model has limited training set, not fully trained (do not use for production). \n", "size_bytes": "2444523612", "downloads": 59}