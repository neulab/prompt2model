{"pretrained_model_name": "bowphs/PhilTa", "description": "---\nlanguage: \n- multilingual\n- grc\n- en\n- la\nlicense: apache-2.0\ninference: false\n---\n# PhilTa\n\nThe paper [Exploring Language Models for Classical Philology](https://todo.com) is the first effort to systematically provide state-of-the-art language models for Classical Philology. PhilTa is a T5-base sized, multilingual, encoder-decoder variant.  \n\nThis model was trained using data from the [Open Greek & Latin Project](https://opengreekandlatin.org/), the CLARIN corpus [Greek Medieval Texts](https://inventory.clarin.gr/corpus/890), the [Patrologia Graeca](https://patristica.net/graeca/), the [Corpus Corporum](https://mlat.uzh.ch/), and [Project Gutenberg](https://www.gutenberg.org/).\n\nFurther information can be found in our paper or in our [GitHub repository](https://github.com/Heidelberg-NLP/ancient-language-models).\n\n## Usage\n```python\nfrom transformers import AutoTokenizer, AutoModelForConditionalGeneration\n\ntokenizer = AutoTokenizer.from_pretrained('bowphs/PhilTa')\nmodel = AutoModelForConditionalGeneration.from_pretrained('bowphs/PhilTa')\n```\nPlease check out the awesome Hugging Face tutorials on how to fine-tune our models.\n\n## Evaluation Results\nWhen fine-tuned on lemmatization data from [EvaLatin 2022](https://universaldependencies.org/), PhilTa achieves the following results:\n\n| Task | Classical | Cross-genre  | Cross-time |\n|:--:|:--:|:--:|:--:|\n|      |97.33|93.40|91.91|\n\nPhilTa is especially strong when more than one of the three languages should be processed. \n\n## Contact\nIf you have any questions or problems, feel free to [reach out](mailto:riemenschneider@cl.uni-heidelberg.de).\n\n## Citation\n```bibtex\n@incollection{riemenschneiderfrank:2023,\n    address = \"Toronto, Canada\",\n    author = \"Riemenschneider, Frederick and Frank, Anette\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL\u201923)\",\n    note = \"to appear\",\n    pubType = \"incollection\",\n    publisher = \"Association for Computational Linguistics\",\n    title = \"Exploring Large Language Models for Classical Philology\",\n    url = \"https://arxiv.org/abs/2305.13698\",\n    year = \"2023\",\n    key = \"riemenschneiderfrank:2023\"\n}\n```\n", "size_bytes": "1186857037", "downloads": 6}