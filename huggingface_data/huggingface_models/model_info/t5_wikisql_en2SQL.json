{"pretrained_model_name": "dbernsohn/t5_wikisql_en2SQL", "description": "# t5_wikisql_en2SQL\n---\nlanguage: en\ndatasets:\n- wikisql\n---\n\nThis is a [t5-small](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) fine-tuned version on the [wikisql dataset](https://huggingface.co/datasets/wikisql) for **English** to **SQL** **translation** text2text mission.\n\nTo load the model:\n(necessary packages: !pip install transformers sentencepiece)\n```python\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\ntokenizer = AutoTokenizer.from_pretrained(\"dbernsohn/t5_wikisql_en2SQL\")\nmodel = AutoModelWithLMHead.from_pretrained(\"dbernsohn/t5_wikisql_en2SQL\")\n```\n\nYou can then use this model to translate SQL queries into plain english.\n\n```python\nquery = \"what are the names of all the people in the USA?\"\ninput_text = f\"translate English to Sql: {query} </s>\"\nfeatures = tokenizer([input_text], return_tensors='pt')\n\noutput = model.generate(input_ids=features['input_ids'].cuda(), \n                        attention_mask=features['attention_mask'].cuda())\n\ntokenizer.decode(output[0])\n# Output: \"SELECT Name FROM table WHERE Country = USA\"\n```\n\nThe whole training process and hyperparameters are in my [GitHub repo](https://github.com/DorBernsohn/CodeLM/tree/main/SQLM)\n\n> Created by [Dor Bernsohn](https://www.linkedin.com/in/dor-bernsohn-70b2b1146/)", "size_bytes": "242088060", "downloads": 196}