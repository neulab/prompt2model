{"pretrained_model_name": "henryu-lin/t5-3b-samsum-deepspeed", "description": "---\nlanguage: en\ntags:\n- azureml\n- t5\n- summarization\n- deepspeed\nlicense: apache-2.0\ndatasets:\n- samsum\nmodel-index:\n- name: t5-3b-samsum-deepspeed\n  results:\n  - task: \n      name: Abstractive Text Summarization\n      type: abstractive-text-summarization\n    dataset:\n      name: \"SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization\" \n      type: samsum\nwidget:\n- text: | \n    Henry: Hey, is Nate coming over to watch the movie tonight?\n    Kevin: Yea, he said he'll be arriving a bit later at around 7 since he gets off of work at 6. Have you taken out the garbage yet? It's starting to make the kitchen really smell.\n    Henry: Oh I forgot. I'll do that once I'm finished with my assignment for my math class.\n    Kevin: Yea, you should take it out as soon as possible. And also, Nate is bringing his girlfriend too.\n    Henry: Nice, I'm really looking forward to seeing them again.\n---\n\n## `t5-3b-samsum-deepspeed`\nThis model was trained using Microsoft's `AzureML` and `DeepSpeed`'s ZeRO 2 optimization. It was fine-tuned on the `SAMSum` corpus from `t5-3b` checkpoint.\n\nMore information on the fine-tuning process (includes samples and benchmarks):  \n*(currently still WIP, updates coming soon: 7/6/21~7/9/21)*\n\n## Resource Usage\nThese results are retrieved from AzureML Studio's resource monitoring module. All experiments were ran on AzureML's low priority clusters.\n\n| key | value |\n| --- | ----- |\n| AzureML SKU | ND40rs_v2 (8 X V100 32GB) |\n| Region | US West 2 |\n| Run Duration | 43m 51.05s |\n| Compute Cost (LowPriority/Dedicated) | $3.22/$16.10 (USD) |\n| Average CPU Utilization | 46.0% |\n| Average GPU Utilization | 56.9% |\n| GPU Memory Usage (Avg/Peak) | 26.77/30.49 (GB) |\n| Total GPU Energy Usage | 2448.69 (kJ) |\n\n*Compute cost is calculated from run duration and SKU's price per hour. Updated SKU pricing could be found here: https://azure.microsoft.com/en-us/pricing/details/machine-learning/  \n*Peak memory usage is calculated from average peak across all utilized GPUs.  \n\n### Carbon Emissions\nThese results are obtained using `codecarbon`. The carbon emission is estimated from training runtime only (excluding setup and evaluation runtime).  \nCodeCarbon: https://github.com/mlco2/codecarbon  \n\n| key | value |\n| --- | ----- |\n| timestamp | 2021-07-06T21:57:39 |\n| duration | 1841.4621863365173 |\n| emissions | 0.17802492531467784 |\n| energy_consumed | 0.5982020339874927 |\n| country_name | USA |\n| region | Washington |\n| cloud_provider | azure |\n| cloud_region | westus2 |\n\n## Hyperparameters\n```yaml\nfp16: True\nper device batch size: 2\neffective batch size: 16\nepoch: 3.0\nlearning rate: 3e-5\nweight decay: 0.0\nseed: 1\n```\n*Same `per device batch size` for evaluations\n\n### DeepSpeed\nOptimizer = `AdamW`, Scheduler = `WarmupDecayLR`, Offload = `none`\n```json\n  \"zero_optimization\": {\n    \"stage\": 2,\n    \"allgather_partitions\": true,\n    \"allgather_bucket_size\": 1000000000,\n    \"overlap_comm\": true,\n    \"reduce_scatter\": true,\n    \"reduce_bucket_size\": 1000000000,\n    \"contiguous_gradients\": true\n  }\n```\n\n## Usage\n```python\nfrom transformers import pipeline\nsummarizer = pipeline(\"summarization\", model=\"henryu-lin/t5-3b-samsum-deepspeed\")\n\nconversation = '''Henry: Hey, is Nate coming over to watch the movie tonight?\n    Kevin: Yea, he said he'll be arriving a bit later at around 7 since he gets off of work at 6. Have you taken out the garbage yet? It's starting to make the kitchen really smell.\n    Henry: Oh I forgot. I'll do that once I'm finished with my assignment for my math class.\n    Kevin: Yea, you should take it out as soon as possible. And also, Nate is bringing his girlfriend too.\n    Henry: Nice, I'm really looking forward to seeing them again.\n'''\nsummarizer(conversation)\n```\n\n## Results\n| ROUGE | Score |\n| ----- | ----- |\n| eval_rouge1 | 54.7875 |\n| eval_rouge2 | 30.565 |\n| eval_rougeL | 45.7625 |\n| eval_rougeLsum | 50.3915 |\n| predict_rouge1 | 53.6628 |\n| predict_rouge2 | 29.0196 |\n| predict_rougeL | 45.1257 |\n| predict_rougeLsum | 49.171 |\n\n| Metric | Value |\n| ------ | ----- |\n| eval_gen_len | 25.3399 |\n| predict_gen_len | 24.9133 |\n| train_loss | 1.1206104169494209 |\n| eval_loss | 1.0732421875 |\n| predict_loss | 1.087890625 |\n| train_runtime | 1841.3751 |\n| train_samples | 14732 |\n| train_samples_per_second | 24.002 |\n| train_steps_per_second | 1.501 |\n| eval_runtime | 163.8357 |\n| eval_samples | 818 |\n| eval_samples_per_second | 4.993 |\n| eval_steps_per_second | 0.317 |\n| predict_runtime | 168.8245 |\n| predict_samples | 819 |\n| predict_samples_per_second | 4.851 |\n| predict_steps_per_second | 0.308 |\n| total_steps | 2763 |\n| total_flos | 1.84452086400811e+17 |\n", "size_bytes": "11406519952", "downloads": 4}