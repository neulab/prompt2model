{"pretrained_model_name": "noahkim/KoBART_with_LED", "description": "---\nlanguage: ko\ntags:\n- summarization\n- bart\n- longformer\n---\n- This model is a [kobart-news](https://huggingface.co/ainize/kobart-news) finetuned on the [\ubb38\uc11c\uc694\uc57d \ud14d\uc2a4\ud2b8/\uc2e0\ubb38\uae30\uc0ac](https://aihub.or.kr/aidata/8054)\n\n<<20220904  Commit>>\n\n\uac1c\uc778 \uc2a4\ud130\ub514\uc6a9\uc73c\ub85c \uae34 \ubb38\uc7a5\uc758 \uc694\uc57d \ubaa8\ub378 \ud2b9\ud654\ub41c \ubaa8\ub378\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574 KoBART \ubaa8\ub378\uc744 Longformer Encoder Decoder\ub85c \ubcc0\ud658\ud55c \ubaa8\ub378\uc785\ub2c8\ub2e4.\n\uae30\uc874\uc758 transformers\ub97c \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c \ubd88\ub7ec\uc640\uc11c \ubaa8\ub378\uc744 \uc2e4\ud589\ud558\ub294 \ubc29\ubc95\uc740 \uc0ac\uc6a9\ud560 \uc218\ub294 \uc5c6\uc2b5\ub2c8\ub2e4.\ud83d\ude02\n\uac19\uc774 \uc62c\ub824\ub193\uc740 load_model.py\ub97c \ub77c\uc774\ube0c\ub7ec\ub9ac\ud654\ud558\uc5ec \ubaa8\ub378\uc744 \ub85c\ub4dc\ud558\uc2dc\uba74 \uc0ac\uc6a9 \uac00\ub2a5\ud569\ub2c8\ub2e4.\n \n\ucd94\ud6c4 \uc9c0\uc18d\uc801\uc778 \uc5c5\ub370\uc774\ud2b8\ub85c \ubcc4\ub3c4\uc758 \ubd88\ud3b8\ud568 \uc5c6\uc774 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ubc14\uafb8\uaca0\uc2b5\ub2c8\ub2e4.\n\n<pre><code>\n# Python Code\nfrom transformers import PreTrainedTokenizerFas\nfrom load_model import LongformerBartForConditionalGeneration\n\ntokenizer = PreTrainedTokenizerFast.from_pretrained(\"hohovisual/KoBART_with_LED\")\nmodel = LongformerBartForConditionalGeneration.from_pretrained(\"hohovisual/KoBART_with_LED model file path\")\n</pre></code>", "size_bytes": "547646513", "downloads": 13}