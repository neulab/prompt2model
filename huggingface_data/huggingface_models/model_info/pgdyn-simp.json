{"pretrained_model_name": "liamcripwell/pgdyn-simp", "description": "---\nlanguage:\n- en\n---\n\n# pgdyn-plan\n\nThis is a pretrained model for the simplification component of the PG_Dyn system, described in the EACL 2023 paper \"Document-Level Planning for Text Simplification\". \nIt is the be used in conjunction with [the planning component](https://huggingface.co/liamcripwell/pgdyn-plan) to form the full pipeline. \nThe code [in this repo](https://github.com/liamcripwell/plan_simp) should be used.\n\n## How to use\n\nHere is how to load this model in PyTorch:\n\n```python\nfrom plan_simp.models.classifier import load_planner\nfrom plan_simp.models.bart import load_simplifier\n\n# contextual simplification planner\nplanner, p_tokenizer, p_hparams = load_planner(\"liamcripwell/pgdyn-plan\")\n\n# simplification model\nsimplifier, tokenizer, hparams = load_simplifier(\"liamcripwell/pgdyn-simp\")\n```\n\nTo perform end-to-end planning+simplification with dynamic document context, use the commands below. This assumed data is in a `.csv` format and context representations have been generated for each input document.\n\n```bash\n# using planner\npython plan_simp/scripts/generate.py dynamic \n  --clf_model_ckpt=<planner_model> # e.g. liamcripwell/pgdyn-plan\n  --model_ckpt=<simplification_model> # e.g. liamcripwell/pgdyn-simp\n  --test_file=<test_sentences>\n  --doc_id_col=pair_id # document identifier for each sentence\n  --context_doc_id=c_id\n  --context_dir=<context_dir>\n  --reading_lvl=s_level \n  --out_file=<output_csv>\n\n# manual specification of operations (no planner)\npython plan_simp/scripts/generate.py inference \n  --model_ckpt=<simplification_model> # e.g. liamcripwell/pgdyn-simp\n  --test_file=<test_sentences> \n  --op_col=label\n  --reading_lvl=s_level \n  --out_file=<output_csv> \n```\n", "size_bytes": "557996857", "downloads": 16}