{"pretrained_model_name": "RUCAIBox/mtl-question-answering", "description": "---\nlicense: apache-2.0\nlanguage:\n- en\ntags:\n- text-generation\n- text2text-generation\npipeline_tag: text2text-generation\nwidget:\n- text: \"Answer the following question: From which country did Angola achieve independence in 1975?\"\n  example_title: \"Example1\"\n- text: \"Answer the following question: what is ce certified [X_SEP] The CE marking is the manufacturer's declaration that the product meets the requirements of the applicable EC directives. Officially, CE is an abbreviation of Conformite Conformit\u00e9, europeenne Europ\u00e9enne Meaning. european conformity\"\n  example_title: \"Example2\"\n---\n\n# MTL-question-answering\nThe MTL-question-answering model was proposed in [**MVP: Multi-task Supervised Pre-training for Natural Language Generation**](https://arxiv.org/abs/2206.12131) by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.\n\nThe detailed information and instructions can be found [https://github.com/RUCAIBox/MVP](https://github.com/RUCAIBox/MVP).\n\n## Model Description\nMTL-question-answering is supervised pre-trained using a mixture of labeled question answering datasets. It is a variant (Single) of our main [MVP](https://huggingface.co/RUCAIBox/mvp) model. It follows a standard Transformer encoder-decoder architecture.\n\nMTL-question-answering is specially designed for question answering tasks, such as reading comprehension (SQuAD), conversational question answering (CoQA) and closed-book question-answering (Natural Questions).\n\n## Example\n```python\n>>> from transformers import MvpTokenizer, MvpForConditionalGeneration\n\n>>> tokenizer = MvpTokenizer.from_pretrained(\"RUCAIBox/mvp\")\n>>> model = MvpForConditionalGeneration.from_pretrained(\"RUCAIBox/mtl-question-answering\")\n\n>>> inputs = tokenizer(\n...     \"Answer the following question: From which country did Angola achieve independence in 1975?\",\n...     return_tensors=\"pt\",\n... )\n>>> generated_ids = model.generate(**inputs)\n>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n['Portugal']\n```\n\n## Related Models\n**MVP**: [https://huggingface.co/RUCAIBox/mvp](https://huggingface.co/RUCAIBox/mvp).\n\n**Prompt-based models**:\n\n- MVP-multi-task: [https://huggingface.co/RUCAIBox/mvp-multi-task](https://huggingface.co/RUCAIBox/mvp-multi-task).\n- MVP-summarization: [https://huggingface.co/RUCAIBox/mvp-summarization](https://huggingface.co/RUCAIBox/mvp-summarization).\n- MVP-open-dialog: [https://huggingface.co/RUCAIBox/mvp-open-dialog](https://huggingface.co/RUCAIBox/mvp-open-dialog).\n- MVP-data-to-text: [https://huggingface.co/RUCAIBox/mvp-data-to-text](https://huggingface.co/RUCAIBox/mvp-data-to-text).\n- MVP-story: [https://huggingface.co/RUCAIBox/mvp-story](https://huggingface.co/RUCAIBox/mvp-story).\n- MVP-question-answering: [https://huggingface.co/RUCAIBox/mvp-question-answering](https://huggingface.co/RUCAIBox/mvp-question-answering).\n- MVP-question-generation: [https://huggingface.co/RUCAIBox/mvp-question-generation](https://huggingface.co/RUCAIBox/mvp-question-generation).\n- MVP-task-dialog: [https://huggingface.co/RUCAIBox/mvp-task-dialog](https://huggingface.co/RUCAIBox/mvp-task-dialog).\n\n**Multi-task models**:\n- MTL-summarization: [https://huggingface.co/RUCAIBox/mtl-summarization](https://huggingface.co/RUCAIBox/mtl-summarization).\n- MTL-open-dialog: [https://huggingface.co/RUCAIBox/mtl-open-dialog](https://huggingface.co/RUCAIBox/mtl-open-dialog).\n- MTL-data-to-text: [https://huggingface.co/RUCAIBox/mtl-data-to-text](https://huggingface.co/RUCAIBox/mtl-data-to-text).\n- MTL-story: [https://huggingface.co/RUCAIBox/mtl-story](https://huggingface.co/RUCAIBox/mtl-story).\n- MTL-question-answering: [https://huggingface.co/RUCAIBox/mtl-question-answering](https://huggingface.co/RUCAIBox/mtl-question-answering).\n- MTL-question-generation: [https://huggingface.co/RUCAIBox/mtl-question-generation](https://huggingface.co/RUCAIBox/mtl-question-generation).\n- MTL-task-dialog: [https://huggingface.co/RUCAIBox/mtl-task-dialog](https://huggingface.co/RUCAIBox/mtl-task-dialog).\n\n## Citation\n```bibtex\n@article{tang2022mvp,\n  title={MVP: Multi-task Supervised Pre-training for Natural Language Generation},\n  author={Tang, Tianyi and Li, Junyi and Zhao, Wayne Xin and Wen, Ji-Rong},\n  journal={arXiv preprint arXiv:2206.12131},\n  year={2022},\n  url={https://arxiv.org/abs/2206.12131},\n}\n```\n", "size_bytes": "1625538817", "downloads": 19}