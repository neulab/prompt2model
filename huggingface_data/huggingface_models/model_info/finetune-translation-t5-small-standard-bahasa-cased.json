{"pretrained_model_name": "mesolitica/finetune-translation-t5-small-standard-bahasa-cased", "description": "---\nlanguage: \n  - ms\ntags:\n- translation\nmetrics:\n- sacrebleu\n---\n\n# finetune-translation-t5-small-standard-bahasa-cased\n\nFinetuned T5 small on EN-MS and MS-EN translation tasks.\n\n## Dataset\n\n1. EN-MS dataset, https://huggingface.co/datasets/mesolitica/en-ms\n2. MS-EN dataset, https://huggingface.co/datasets/mesolitica/ms-en\n3. NLLB eng_Latn-zsm_Latn, https://github.com/huseinzol05/malay-dataset/tree/master/translation/laser\n\n## Finetune details\n\n1. Finetune using single RTX 3090 Ti.\n\nScripts at https://github.com/huseinzol05/malaya/tree/master/session/translation/hf-t5\n\n## Supported prefix\n\n1. `terjemah Inggeris ke Melayu: {string}`, for EN-MS translation.\n2. `terjemah Melayu ke Inggeris: {string}`, for MS-EN translation.\n\n## Evaluation\n\neng_Latn-zsm_Latn,\n```\n{'name': 'BLEU',\n 'score': 43.93729753370648,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '74.9/52.2/37.9/27.7 (BP = 0.976 ratio = 0.977 hyp_len = 21510 ref_len = 22027)',\n 'bp': 0.9762512158466284,\n 'counts': [16101, 10712, 7389, 5134],\n 'totals': [21510, 20513, 19516, 18519],\n 'sys_len': 21510,\n 'ref_len': 22027,\n 'precisions': [74.85355648535565,\n  52.220543070248134,\n  37.86124205779873,\n  27.722879205140668],\n 'prec_str': '74.9/52.2/37.9/27.7',\n 'ratio': 0.9765288055568166}\nchrF2++ = 67.43\n```\n\nzsm_Latn-eng_Latn,\n```\n{'name': 'BLEU',\n 'score': 42.01021763049599,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '71.7/49.0/35.6/26.1 (BP = 0.989 ratio = 0.989 hyp_len = 23302 ref_len = 23570)',\n 'bp': 0.988564726798463,\n 'counts': [16700, 10937, 7587, 5294],\n 'totals': [23302, 22305, 21308, 20311],\n 'sys_len': 23302,\n 'ref_len': 23570,\n 'precisions': [71.6676680113295,\n  49.03384891279982,\n  35.60634503472874,\n  26.06469400817291],\n 'prec_str': '71.7/49.0/35.6/26.1',\n 'ratio': 0.9886296139159949}\nchrF2++ = 64.67\n```", "size_bytes": "242011067", "downloads": 10}