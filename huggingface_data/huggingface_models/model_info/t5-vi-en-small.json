{"pretrained_model_name": "NlpHUST/t5-vi-en-small", "description": "---\nlanguage:\n- vi\n\ntags:\n- t5\n- seq2seq\n\n# Machine translation for vietnamese\n## Model Description\nT5-vi-en-small is a transformer model for vietnamese machine translation designed using T5 architecture.\n## Training data\nT5-vi-en-small was trained on 4M sentence pairs (english,vietnamese)\n### How to use\n\n```py\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"NlpHUST/t5-vi-en-small\")\ntokenizer = T5Tokenizer.from_pretrained(\"NlpHUST/t5-vi-en-small\")\nmodel.to(device)\n\nsrc = \"Indonesia ph\u1ecfng \u0111o\u00e1n nguy\u00ean nh\u00e2n t\u00e0u ng\u1ea7m ch\u1edf 53 ng\u01b0\u1eddi m\u1ea5t t\u00edch b\u00ed \u1ea9n\"\ntokenized_text = tokenizer.encode(src, return_tensors=\"pt\").to(device)\nmodel.eval()\nsummary_ids = model.generate(\n                    tokenized_text,\n                    max_length=256, \n                    num_beams=5,\n                    repetition_penalty=2.5, \n                    length_penalty=1.0, \n                    early_stopping=True\n                )\noutput = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\nprint(output)\n\nIndonesia anticipates the cause of the submarine transporting 53 mysterious missing persons\n\n```", "size_bytes": "1200794207", "downloads": 5}