{"pretrained_model_name": "Helsinki-NLP/opus-mt-afa-afa", "description": "---\nlanguage: \n- so\n- ti\n- am\n- he\n- mt\n- ar\n- afa\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### afa-afa\n\n* source group: Afro-Asiatic languages \n* target group: Afro-Asiatic languages \n*  OPUS readme: [afa-afa](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/afa-afa/README.md)\n\n*  model: transformer\n* source language(s): apc ara arq arz heb kab mlt shy_Latn thv\n* target language(s): apc ara arq arz heb kab mlt shy_Latn thv\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)\n* download original weights: [opus-2020-07-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/afa-afa/opus-2020-07-26.zip)\n* test set translations: [opus-2020-07-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/afa-afa/opus-2020-07-26.test.txt)\n* test set scores: [opus-2020-07-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/afa-afa/opus-2020-07-26.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| Tatoeba-test.ara-ara.ara.ara \t| 4.3 \t| 0.148 |\n| Tatoeba-test.ara-heb.ara.heb \t| 31.9 \t| 0.525 |\n| Tatoeba-test.ara-kab.ara.kab \t| 0.3 \t| 0.120 |\n| Tatoeba-test.ara-mlt.ara.mlt \t| 14.0 \t| 0.428 |\n| Tatoeba-test.ara-shy.ara.shy \t| 1.3 \t| 0.050 |\n| Tatoeba-test.heb-ara.heb.ara \t| 17.0 \t| 0.464 |\n| Tatoeba-test.heb-kab.heb.kab \t| 1.9 \t| 0.104 |\n| Tatoeba-test.kab-ara.kab.ara \t| 0.3 \t| 0.044 |\n| Tatoeba-test.kab-heb.kab.heb \t| 5.1 \t| 0.099 |\n| Tatoeba-test.kab-shy.kab.shy \t| 2.2 \t| 0.009 |\n| Tatoeba-test.kab-tmh.kab.tmh \t| 10.7 \t| 0.007 |\n| Tatoeba-test.mlt-ara.mlt.ara \t| 29.1 \t| 0.498 |\n| Tatoeba-test.multi.multi \t| 20.8 \t| 0.434 |\n| Tatoeba-test.shy-ara.shy.ara \t| 1.2 \t| 0.053 |\n| Tatoeba-test.shy-kab.shy.kab \t| 2.0 \t| 0.134 |\n| Tatoeba-test.tmh-kab.tmh.kab \t| 0.0 \t| 0.047 |\n\n\n### System Info: \n- hf_name: afa-afa\n\n- source_languages: afa\n\n- target_languages: afa\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/afa-afa/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['so', 'ti', 'am', 'he', 'mt', 'ar', 'afa']\n\n- src_constituents: {'som', 'rif_Latn', 'tir', 'kab', 'arq', 'afb', 'amh', 'arz', 'heb', 'shy_Latn', 'apc', 'mlt', 'thv', 'ara', 'hau_Latn', 'acm', 'ary'}\n\n- tgt_constituents: {'som', 'rif_Latn', 'tir', 'kab', 'arq', 'afb', 'amh', 'arz', 'heb', 'shy_Latn', 'apc', 'mlt', 'thv', 'ara', 'hau_Latn', 'acm', 'ary'}\n\n- src_multilingual: True\n\n- tgt_multilingual: True\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/afa-afa/opus-2020-07-26.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/afa-afa/opus-2020-07-26.test.txt\n\n- src_alpha3: afa\n\n- tgt_alpha3: afa\n\n- short_pair: afa-afa\n\n- chrF2_score: 0.434\n\n- bleu: 20.8\n\n- brevity_penalty: 1.0\n\n- ref_len: 15215.0\n\n- src_name: Afro-Asiatic languages\n\n- tgt_name: Afro-Asiatic languages\n\n- train_date: 2020-07-26\n\n- src_alpha2: afa\n\n- tgt_alpha2: afa\n\n- prefer_old: False\n\n- long_pair: afa-afa\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "247886085", "downloads": 28}