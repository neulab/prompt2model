{"pretrained_model_name": "sappho192/ffxiv-ja-ko-translator", "description": "---\nlicense: mit\ndatasets:\n- Helsinki-NLP/tatoeba_mt\nlanguage:\n- ja\n- ko\npipeline_tag: translation\ntags:\n- python\n- transformer\n- pytorch\n---\n# Japanese to Korean translator for FFXIV\n\n**FINAL FANTASY is a registered trademark of Square Enix Holdings Co., Ltd.**\n\nThis project is detailed on the [Github repo](https://github.com/sappho192/ffxiv-ja-ko-translator).\n\n# Demo\n[![demo.gif](demo.gif)](https://huggingface.co/spaces/sappho192/ffxiv-ja-ko-translator-demo)\n[Click to try demo](https://huggingface.co/spaces/sappho192/ffxiv-ja-ko-translator-demo)\n\n# Usage\n\nCheck the [test_eval.ipynb](https://huggingface.co/sappho192/ffxiv-ja-ko-translator/blob/main/test_eval.ipynb) or below section.\n\n## Inference\n\n```Python\nfrom transformers import(\n    EncoderDecoderModel,\n    PreTrainedTokenizerFast,\n    BertJapaneseTokenizer,\n)\n\nimport torch\n\nencoder_model_name = \"cl-tohoku/bert-base-japanese-v2\"\ndecoder_model_name = \"skt/kogpt2-base-v2\"\n\nsrc_tokenizer = BertJapaneseTokenizer.from_pretrained(encoder_model_name)\ntrg_tokenizer = PreTrainedTokenizerFast.from_pretrained(decoder_model_name)\n\n# You should change following `./best_model` to the path of model **directory**\nmodel = EncoderDecoderModel.from_pretrained(\"./best_model\")\n\ntext = \"\u30ae\u30eb\u30ac\u30e1\u30c3\u30b7\u30e5\u8a0e\u4f10\u6226\"\n# text = \"\u30ae\u30eb\u30ac\u30e1\u30c3\u30b7\u30e5\u8a0e\u4f10\u6226\u306b\u884c\u3063\u3066\u304d\u307e\u3059\u3002\u4e00\u7dd2\u306b\u884c\u304d\u307e\u3057\u3087\u3046\u304b\uff1f\"\n\ndef translate(text_src):\n    embeddings = src_tokenizer(text_src, return_attention_mask=False, return_token_type_ids=False, return_tensors='pt')\n    embeddings = {k: v for k, v in embeddings.items()}\n    output = model.generate(**embeddings)[0, 1:-1]\n    text_trg = trg_tokenizer.decode(output.cpu())\n    return text_trg\n\nprint(translate(text))\n```", "size_bytes": "1084290109", "downloads": 94}