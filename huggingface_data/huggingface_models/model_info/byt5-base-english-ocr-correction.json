{"pretrained_model_name": "yelpfeast/byt5-base-english-ocr-correction", "description": "---\nlanguage: en\ndatasets:\n- wikitext\n---\n\n# ByT5 base English fine tuned for OCR Correction\n\nThis model is a fine-tuned version of the [byt5-base](https://huggingface.co/google/byt5-base) for OCR Correction. ByT5 was\nintroduced in [this paper](https://arxiv.org/abs/2105.13626) and the idea and code for fine-tuning the model for OCR Correction was taken from [here](https://blog.ml6.eu/ocr-correction-with-byt5-5994d1217c07).\n\n## Model description\n\nbyt5-base-english-ocr-correction is a model that has taken the byt5-base model and fine-tuned it an OCR Correction dataset. The model has been fine-tuned to take an input sentence that has incorrectly transcribed from an OCR model and output a sentence that corrects the errors.\n\nThe model was trained by taking the [wikitext dataset](https://huggingface.co/datasets/wikitext) and adding synthetic OCR errors using [nlpaug](https://github.com/makcedward/nlpaug).\n\n## Intended uses & limitations\n\nYou can use the model for Text-to-Text Generation to remove errors caused by an OCR model.\n\n### How to use\n\n\n```python\nfrom transformers import T5ForConditionalGeneration\nimport torch\nimport nlpaug.augmenter.char as nac\n\naug = nac.OcrAug(aug_char_p =0.4, aug_word_p = 0.6)\ncorrected_text = \"Life is like a box of chocolates\"\naugmented_text = aug.augment(corrected_text)\n\nmodel = T5ForConditionalGeneration.from_pretrained('yelpfeast/byt5-base-english-ocr-correction')\n\ninput_ids = torch.tensor([list(\"Life is like a box of chocolates.\".encode(\"utf-8\"))]) + 3  # add 3 for special tokens\nlabels = torch.tensor([list(\"La vie est comme une bo\u00eete de chocolat.\".encode(\"utf-8\"))]) + 3  # add 3 for special tokens\n\nloss = model(input_ids, labels=labels).loss # forward pass\n```\n\n```python\n\nfrom transformers import T5ForConditionalGeneration, AutoTokenizer\nimport nlpaug.augmenter.char as nac\n\naug = nac.OcrAug(aug_char_p =0.4, aug_word_p = 0.6)\ncorrected_text = \"Life is like a box of chocolates\"\naugmented_text = aug.augment(corrected_text)\nprint(augmented_text)\n\nmodel = T5ForConditionalGeneration.from_pretrained('yelpfeast/byt5-base-english-ocr-correction')\ntokenizer = AutoTokenizer.from_pretrained(\"yelpfeast/byt5-base-english-ocr-correction\")\n\ninputs = tokenizer(augmented_text, return_tensors=\"pt\", padding=True)\n\noutput_sequences = model.generate(\n\n    input_ids=inputs[\"input_ids\"],\n\n    attention_mask=inputs[\"attention_mask\"],\n\n    do_sample=False,  # disable sampling to test if batching affects output\n\n)\n\nprint(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))\n```\n### Limitations\n\nThe model has been trained on text that has been artificially corrupted to look like OCR errors. These errors may not be similar for all OCR models and hence the model may not do a good job at producing fully correct text. ", "size_bytes": "1198608045", "downloads": 213}