{"pretrained_model_name": "erickfm/neutrally", "description": "---\nlanguage: \n  - en\nlicense: apache-2.0\ndatasets:\n- WNC\nmetrics:\n- accuracy\n---\n\nThis model is a fine-tuned checkpoint of [T5-base](https://huggingface.co/t5-base). Fine-tuned on the [Wiki Neutrality Corpus (WNC)](https://github.com/rpryzant/neutralizing-bias), a labeled dataset composed of 180,000 biased and neutralized sentence pairs that are generated from Wikipedia edits tagged for \u201cneutral point of view\u201d. This model achieves state of the art (SOTA) performance with a **BLEU score of 94.08** and an **accuracy of 48.37** on a test split of the WNC, narrowly beating out previous SOTA work from [Pryzant et al](https://nlp.stanford.edu/pubs/pryzant2020bias.pdf).\n\nFor more details about BLEU, see this [wiki](https://en.wikipedia.org/wiki/BLEU). <br>\nFor more details about this project visit our [web app](https://apps-summer22.ischool.berkeley.edu/neutrally/).\n\n", "size_bytes": "891700799", "downloads": 3}