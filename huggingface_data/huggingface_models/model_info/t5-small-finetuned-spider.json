{"pretrained_model_name": "tomhavy/t5-small-finetuned-spider", "description": "---\ntags:\n- generated_from_trainer\nmodel-index:\n- name: t5-small-finetuned-spider\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# t5-small-finetuned-spider\n\nThis model was trained from scratch on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.1914\n- Rouge2 Precision: 0.6349\n- Rouge2 Recall: 0.3964\n- Rouge2 Fmeasure: 0.4619\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 5e-05\n- train_batch_size: 5\n- eval_batch_size: 16\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 15\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Rouge2 Precision | Rouge2 Recall | Rouge2 Fmeasure |\n|:-------------:|:-----:|:-----:|:---------------:|:----------------:|:-------------:|:---------------:|\n| 0.2912        | 1.0   | 1120  | 0.2631          | 0.5653           | 0.3537        | 0.4118          |\n| 0.2967        | 2.0   | 2240  | 0.2465          | 0.5758           | 0.363         | 0.4209          |\n| 0.3106        | 3.0   | 3360  | 0.2372          | 0.5858           | 0.367         | 0.427           |\n| 0.2993        | 4.0   | 4480  | 0.2340          | 0.5995           | 0.3791        | 0.4403          |\n| 0.2702        | 5.0   | 5600  | 0.2204          | 0.6035           | 0.3786        | 0.4401          |\n| 0.2624        | 6.0   | 6720  | 0.2159          | 0.6094           | 0.3807        | 0.4435          |\n| 0.2463        | 7.0   | 7840  | 0.2121          | 0.6207           | 0.3911        | 0.4544          |\n| 0.2427        | 8.0   | 8960  | 0.2053          | 0.6198           | 0.3886        | 0.452           |\n| 0.2336        | 9.0   | 10080 | 0.2014          | 0.6217           | 0.3871        | 0.4518          |\n| 0.2256        | 10.0  | 11200 | 0.1980          | 0.6298           | 0.394         | 0.4589          |\n| 0.2212        | 11.0  | 12320 | 0.1960          | 0.6304           | 0.3936        | 0.4589          |\n| 0.2141        | 12.0  | 13440 | 0.1962          | 0.63             | 0.3939        | 0.4586          |\n| 0.2069        | 13.0  | 14560 | 0.1921          | 0.6328           | 0.3942        | 0.4594          |\n| 0.2096        | 14.0  | 15680 | 0.1915          | 0.632            | 0.3953        | 0.46            |\n| 0.2115        | 15.0  | 16800 | 0.1914          | 0.6349           | 0.3964        | 0.4619          |\n\n\n### Framework versions\n\n- Transformers 4.19.0\n- Pytorch 1.11.0+cu113\n- Datasets 2.2.1\n- Tokenizers 0.12.1\n", "size_bytes": "242070267", "downloads": 11}