{"pretrained_model_name": "sankhajay/mt5-base-sinaha-qa", "description": "\\n\n---\n\nlanguage: si\n\ntags:\n- question-answering\n- Sinhala\n\nwidget:\n- context: \"\u0dc1\u0dca\u200d\u0dbb\u0dd3 \u0dbd\u0d82\u0d9a\u0dcf\u0dc0 \u0dba\u0db1\u0dd4 \u0d89\u0db1\u0dca\u0daf\u0dd2\u0dba\u0dcf\u0db1\u0dd4 \u0dc3\u0dcf\u0d9c\u0dbb\u0dba\u0dda \u0db4\u0dd2\u0dc4\u0dd2\u0da7\u0dd2 \u0db8\u0db1\u0dbb\u0db8\u0dca \u0daf\u0dd4\u0db4\u0dad\u0d9a\u0dd2.\"\n  text: \"\u0dc1\u0dca\u200d\u0dbb\u0dd3 \u0dbd\u0d82\u0d9a\u0dcf\u0dc0 \u0db4\u0dd2\u0dc4\u0dd2\u0da7\u0dcf \u0d87\u0dad\u0dca\u0dad\u0dda \u0d9a\u0ddc\u0dc4\u0dd9\u0daf ?\"\n  \n\n\n---\n\n# mt5-base-sinhala-qa\n\nThis is an mt5-based Question Answering model for the Sinhalese language. Training is done on translated SQuAD dataset of 8k questions. The translation was done by google translate API. \n\nThe training was done on Google Colab TPU environment with parallel training techniques. The training was done on around 9k data points which consists of context, question, answer trios for the Sinhala language. Evaluation is done using standard SQuAD evaluation script on around 1k data points which gave following results on the best parameter setting. Evaluation matrices used are EM matric and F1 score matric.\n\nEvaluation - {'EM': 39.413680781758956, 'f1': 66.16331104953571}", "size_bytes": "2225227329", "downloads": 9}