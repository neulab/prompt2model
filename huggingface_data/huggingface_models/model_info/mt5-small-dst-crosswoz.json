{"pretrained_model_name": "ConvLab/mt5-small-dst-crosswoz", "description": "---\nlanguage:\n- zh\nlicense: apache-2.0\ntags:\n- mt5-small\n- text2text-generation\n- dialog state tracking\n- conversational system\n- task-oriented dialog\ndatasets:\n- ConvLab/crosswoz\nmetrics:\n- Joint Goal Accuracy\n- Slot F1\n\nmodel-index:\n- name: mt5-small-dst-crosswoz\n  results:\n  - task:\n      type: text2text-generation\n      name: dialog state tracking\n    dataset:\n      type: ConvLab/crosswoz\n      name: CrossWOZ\n      split: test\n      revision: 4a3e56082543ed9eecb9c76ef5eadc1aa0cc5ca0\n    metrics:\n      - type: Joint Goal Accuracy\n        value: 62.5\n        name: JGA\n      - type: Slot F1\n        value: 90.4\n        name: Slot F1\n\nwidget:\n- text: \"user: \u4f60\u597d\uff0c\u7ed9\u6211\u63a8\u8350\u4e00\u4e2a\u8bc4\u5206\u662f5\u5206\uff0c\u4ef7\u683c\u5728100-200\u5143\u7684\u9152\u5e97\u3002\\nsystem: \u63a8\u8350\u60a8\u53bb\u5317\u4eac\u5e03\u63d0\u514b\u7cbe\u54c1\u9152\u5e97\u3002\\nuser: \u5317\u4eac\u5e03\u63d0\u514b\u7cbe\u54c1\u9152\u5e97\u9152\u5e97\u662f\u4ec0\u4e48\u7c7b\u578b\uff0c\u6709\u5065\u8eab\u623f\u5417\uff1f\\nsystem: \u5317\u4eac\u5e03\u63d0\u514b\u7cbe\u54c1\u9152\u5e97\u8bc4\u5206\u662f4.8\u5206\uff0c\u662f\u9ad8\u6863\u578b\u9152\u5e97\uff0c\u6ca1\u6709\u5065\u8eab\u623f\u3002\\nuser: \u7ed9\u6211\u63a8\u8350\u4e00\u4e2a\u8bc4\u5206\u57284.5\u5206\u4ee5\u4e0a\uff0c\u6e38\u73a9\u65f6\u95f4\u57282\u5c0f\u65f6 - 3\u5c0f\u65f6\u7684\u514d\u8d39\u666f\u70b9\u3002\"\n- text: \"user: \u60a8\u597d\uff0c\u8bf7\u5e2e\u6211\u63a8\u8350\u4e2a4.5\u5206\u4ee5\u4e0a\u7684\u666f\u70b9\u6e38\u73a9\u5457\uff0c\u6700\u597d\u628a\u5468\u8fb9\u6709\u4ec0\u4e48\u9152\u5e97\u544a\u8bc9\u6211\u4e00\u4e0b\u3002\\nsystem: \u90a3\u6211\u63a8\u8350\u60a8\u6545\u5bab\uff0c\u5468\u8fb9\u7684\u9152\u5e97\u6709\u5317\u4eac\u5929\u4f26\u738b\u671d\u9152\u5e97, \u5317\u4eac\u9996\u90fd\u5bbe\u9986, \u5317\u4eac\u8d35\u90fd\u5927\u9152\u5e97\u3002\\nuser: \u90a3\u8bf7\u5728\u6545\u5bab\u5468\u8fb9\u7684\u9152\u5e97\u91cc\uff0c\u5e2e\u6211\u627e\u4e2a\u8bc4\u5206\u57284.5\u5206\u4ee5\u4e0a\u7684\u5e97\u3002\\nsystem: \u5317\u4eac\u8d35\u90fd\u5927\u9152\u5e97\u7b26\u5408\u60a8\u7684\u8981\u6c42\u3002\\nuser: \u8bf7\u5e2e\u6211\u547c\u53eb\u4e00\u8f86\u4ece\u6545\u5bab\u5230\u5317\u4eac\u8d35\u90fd\u5927\u9152\u5e97\u7684\u51fa\u79df\u8f66\uff0c\u544a\u8bc9\u6211\u8f66\u578b\u548c\u8f66\u724c\u53f7\u3002\"\n\ninference:\n  parameters:\n    max_length: 100\n\n---\n\n# mt5-small-dst-crosswoz\n\nThis model is a fine-tuned version of [mt5-small](https://huggingface.co/mt5-small) on [CrossWOZ](https://huggingface.co/datasets/ConvLab/crosswoz).\n\nRefer to [ConvLab-3](https://github.com/ConvLab/ConvLab-3) for model description and usage.\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 0.001\n- train_batch_size: 16\n- eval_batch_size: 16\n- seed: 42\n- gradient_accumulation_steps: 4\n- total_train_batch_size: 64\n- optimizer: Adafactor\n- lr_scheduler_type: linear\n- num_epochs: 10.0\n\n### Framework versions\n\n- Transformers 4.20.1\n- Pytorch 1.11.0+cu113\n- Datasets 2.3.2\n- Tokenizers 0.12.1", "size_bytes": "1200721605", "downloads": 15}