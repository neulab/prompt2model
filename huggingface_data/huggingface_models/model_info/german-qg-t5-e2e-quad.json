{"pretrained_model_name": "dehio/german-qg-t5-e2e-quad", "description": "---\nlicense: mit\nwidget:\n- text: \"Naturschutzwarte haben auf der ostfriesischen Insel Wangerooge zwei seltene Kurzschn\u00e4uzige Seepferdchen entdeckt. Die Tiere seien vergangene Woche bei einer sogenannten Sp\u00fclsaumkontrolle entdeckt worden, bei der die Str\u00e4nde eigentlich nach M\u00fcll und toten V\u00f6geln abgesucht w\u00fcrden, sagte der Gesch\u00e4ftsf\u00fchrer der zust\u00e4ndigen Naturschutz- und Forschungsgemeinschaft Mellumrat, Mathias Heckroth. Dabei seien den Natursch\u00fctzern am Nordstrand kurz hintereinander die beiden leblosen, nur wenige Zentimeter gro\u00dfen Tiere aufgefallen. Experten der Nationalparkverwaltung bestimmten beide Tiere als Kurzschn\u00e4uzige Seepferdchen (Hippocampus hippocampus).\"\ninference:\n  parameters:\n    max_length: 128\nlanguage:\n- de\ntags:\n- question generation\ndatasets:\n- deepset/germanquad\nmodel-index:\n- name: german-qg-t5-e2e-quad\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# german-qg-t5-e2e-quad (Work in progress)\n\nThis model is a end-to-end question generation model in German. Given a text, it generates several questions about it. This model is a fine-tuned version of [valhalla/t5-base-e2e-qg](https://huggingface.co/valhalla/t5-base-e2e-qg) on the [GermanQuAD dataset from deepset](https://huggingface.co/datasets/deepset/germanquad).\n\n## Model description \n\nMore information needed\n\n## Training and evaluation data\n\nBleu_1: 0.196051  \nBleu_2: 0.122380  \nBleu_3: 0.079980  \nBleu_4: 0.053672  \n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 0.0001\n- train_batch_size: 4\n- eval_batch_size: 4\n- seed: 42\n- gradient_accumulation_steps: 8\n- total_train_batch_size: 32\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 10.0\n\n### Training results\n\n\n\n### Framework versions\n\n- Transformers 4.16.0.dev0\n- Pytorch 1.10.0+cu111\n- Datasets 1.16.1\n- Tokenizers 0.10.3\n", "size_bytes": "891651007", "downloads": 1084}