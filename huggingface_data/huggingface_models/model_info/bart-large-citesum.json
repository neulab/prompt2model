{"pretrained_model_name": "yuningm/bart-large-citesum", "description": "---\nlicense: cc-by-nc-4.0\nlanguage: en\ntags:\n- summarization\ndatasets:\n- yuningm/citesum\nwidget:\n- text: \"Abstract-This paper presents a control strategy that allows a group of mobile robots to position themselves to optimize the measurement of sensory information in the environment. The robots use sensed information to estimate a function indicating the relative importance of different areas in the environment. Their estimate is then used to drive the network to a desirable placement configuration using a computationally simple decentralized control law. We formulate the problem, provide a practical control solution, and present the results of numerical simulations. We then discuss experiments carried out on a swarm of mobile robots.\"\n  example_title: \"Networked Robots\"\n- text: \"Abstract. In this paper, a Bayesian method for face recognition is proposed based on Markov Random Fields (MRF) modeling. Constraints on image features as well as contextual relationships between them are explored and encoded into a cost function derived based on a statistical model of MRF. Gabor wavelet coefficients are used as the base features, and relationships between Gabor features at different pixel locations are used to provide higher order contextual constraints. The posterior probability of matching configuration is derived based on MRF modeling. Local search and discriminate analysis are used to evaluate local matches, and a contextual constraint is applied to evaluate mutual matches between local matches. The proposed MRF method provides a new perspective for modeling the face recognition problem. Experiments demonstrate promising results.\"\n  example_title: \"Bayesian Face Recognition\"\n- text: \"Abstract One of the most relevant applications of digital image forensics is to accurately identify the device used for taking a given set of images, a problem called source identification. This paper studies recent developments in the field and proposes the mixture of two techniques (Sensor Imperfections and Wavelet Transforms) to get better source identification of images generated with mobile devices. Our results show that Sensor Imperfections and Wavelet Transforms can jointly serve as good forensic features to help trace the source camera of images produced by mobile phones. Furthermore, the model proposed here can also determine with high precision both the brand and model of the device.\"\n  example_title: \"Source identification for mobile devices\"\n---\n\n\n# Bart-Large CiteSum (Sentences)\n\nThis is facebook/bart-large fine-tuned on CiteSum.  \nThe \"src\" column is the input and the \"tgt\" column is the target summarization.\n\n## Authors\n### Yuning Mao, Ming Zhong, Jiawei Han\n#### University of Illinois Urbana-Champaign  \n{yuningm2, mingz5, hanj}@illinois.edu\n\n## Results\n\n```\n{\n    \"epoch\": 5.28,\n    \"eval_gen_len\": 37.0464,\n    \"eval_loss\": 2.058537483215332,\n    \"eval_rouge1\": 41.3415,\n    \"eval_rouge2\": 19.2246,\n    \"eval_rougeL\": 33.3258,\n    \"eval_rougeLsum\": 33.5075,\n    \"eval_runtime\": 697.7289,\n    \"eval_samples\": 4721,\n    \"eval_samples_per_second\": 6.766,\n    \"eval_steps_per_second\": 0.847,\n    \"predict_gen_len\": 37.0159,\n    \"predict_loss\": 2.0521159172058105,\n    \"predict_rouge1\": 41.9288,\n    \"predict_rouge2\": 19.5963,\n    \"predict_rougeL\": 33.7098,\n    \"predict_rougeLsum\": 33.9124,\n    \"predict_runtime\": 718.1231,\n    \"predict_samples\": 4921,\n    \"predict_samples_per_second\": 6.853,\n    \"predict_steps_per_second\": 0.858,\n    \"train_loss\": 1.7884394331498579,\n    \"train_runtime\": 23049.0303,\n    \"train_samples\": 83304,\n    \"train_samples_per_second\": 69.417,\n    \"train_steps_per_second\": 8.677\n}\n```\n\n## Dataset Description\nCiteSum: Citation Text-guided Scientific Extreme Summarization and Low-resource Domain Adaptation.  \nCiteSum contains TLDR summaries for scientific papers from their citation texts without human annotation, making it around 30 times larger than the previous human-curated dataset SciTLDR.\n## Homepage\nhttps://github.com/morningmoni/CiteSum\n## Paper\nhttps://arxiv.org/abs/2205.06207\n\n## Dataset on Hub\nhttps://huggingface.co/datasets/nbroad/citesum\n\n## How to use model\n\n```python\nfrom transformers import pipeline\nsummarizer = pipeline(\"summarization\", model=\"yuningm/bart-large-citesum\")\n\narticle = ''' We describe a convolutional neural network that learns\\\n feature representations for short textual posts using hashtags as a\\\n  supervised signal. The proposed approach is trained on up to 5.5 \\\n  billion words predicting 100,000 possible hashtags. As well as strong\\\n   performance on the hashtag prediction task itself, we show that its \\\n   learned representation of text (ignoring the hashtag labels) is useful\\\n    for other tasks as well. To that end, we present results on a document\\\n     recommendation task, where it also outperforms a number of baselines.\n'''\nsummarizer(article)\n# [{'summary_text': 'REF proposed a convolutional neural network \n# that learns feature representations for short textual posts \n# using hashtags as a supervised signal.'}]\n```\n", "size_bytes": "1625557313", "downloads": 12}