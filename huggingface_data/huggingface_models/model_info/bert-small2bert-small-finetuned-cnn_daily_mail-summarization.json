{"pretrained_model_name": "mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization", "description": "---\nlanguage: en\nlicense: apache-2.0\ndatasets:\n- cnn_dailymail\ntags:\n- summarization\n---\n\n# Bert-small2Bert-small Summarization with \ud83e\udd17EncoderDecoder Framework\n\nThis model is a warm-started *BERT2BERT* ([small](https://huggingface.co/google/bert_uncased_L-4_H-512_A-8)) model fine-tuned on the *CNN/Dailymail* summarization dataset.\n\nThe model achieves a **17.37** ROUGE-2 score on *CNN/Dailymail*'s test dataset.\n\nFor more details on how the model was fine-tuned, please refer to \n[this](https://colab.research.google.com/drive/1Ekd5pUeCX7VOrMx94_czTkwNtLN32Uyu?usp=sharing) notebook.\n\n## Results on test set \ud83d\udcdd\n\n| Metric | # Value   |\n| ------ | --------- |\n| **ROUGE-2** | **17.37** |\n\n\n\n## Model in Action \ud83d\ude80\n\n```python\nfrom transformers import BertTokenizerFast, EncoderDecoderModel\nimport torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntokenizer = BertTokenizerFast.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization')\nmodel = EncoderDecoderModel.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization').to(device)\n\ndef generate_summary(text):\n    # cut off at BERT max length 512\n    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n    input_ids = inputs.input_ids.to(device)\n    attention_mask = inputs.attention_mask.to(device)\n\n    output = model.generate(input_ids, attention_mask=attention_mask)\n\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n  \ntext = \"your text to be summarized here...\"\ngenerate_summary(text)\n```\n\n> Created by [Manuel Romero/@mrm8488](https://twitter.com/mrm8488) | [LinkedIn](https://www.linkedin.com/in/manuel-romero-cs/)\n\n> Made with <span style=\"color: #e25555;\">&hearts;</span> in Spain\n", "size_bytes": "247150043", "downloads": 547}