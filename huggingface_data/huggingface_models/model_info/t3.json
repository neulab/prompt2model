{"pretrained_model_name": "ayushutkarsh/t3", "description": "---\nlicense: apache-2.0\ndatasets:\n- McGill-NLP/FaithDial\nlanguage:\n- en\nmetrics:\n- bleu\n- bertscore\n- accuracy\npipeline_tag: conversational\n---\nT3 stands for Terribly Tiny Transformers that are an efficient way of creating tiny distilled (student) models for hallucination-free LLM models in parameter-constrained environment (edge devices).\nThe base model is a T3 adaptation of T5 model. The paradigm of T3 models can be extended to all types of models ( encoder only, decoder only & seq2seq)", "size_bytes": "296956283", "downloads": 55}