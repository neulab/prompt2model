{"pretrained_model_name": "pain/text2svg_summarization-2-epochs-28-step-367000", "description": "```py\ntext =  \"Context: \u0633\u0639\u064a; Char: \u0633; Pos: 0\"\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"pain/text2svg_summarization-2-epochs-28-step-367000\")\ninputs = tokenizer(text, return_tensors=\"pt\").input_ids\n\nfrom transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"pain/text2svg_summarization-2-epochs-28-step-367000\")\noutputs = model.generate(inputs, max_new_tokens=1024, do_sample=False)\n\ntok_out = tokenizer.decode(outputs[0],skip_special_tokens=True)\ntok_out\n```", "size_bytes": "4918519193", "downloads": 5}