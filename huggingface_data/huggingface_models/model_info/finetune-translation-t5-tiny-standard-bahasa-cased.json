{"pretrained_model_name": "mesolitica/finetune-translation-t5-tiny-standard-bahasa-cased", "description": "---\nlanguage: \n  - ms\ntags:\n- translation\nmetrics:\n- sacrebleu\n---\n\n# finetune-translation-t5-tiny-standard-bahasa-cased\n\nFinetuned T5 tiny on EN-MS and MS-EN translation tasks.\n\n## Dataset\n\n1. EN-MS dataset, https://huggingface.co/datasets/mesolitica/en-ms\n2. MS-EN dataset, https://huggingface.co/datasets/mesolitica/ms-en\n3. NLLB eng_Latn-zsm_Latn, https://github.com/huseinzol05/malay-dataset/tree/master/translation/laser\n\n## Finetune details\n\n1. Finetune using single RTX 3090 Ti.\n\nScripts at https://github.com/huseinzol05/malaya/tree/master/session/translation/hf-t5\n\n## Supported prefix\n\n1. `terjemah Inggeris ke Melayu: {string}`, for EN-MS translation.\n2. `terjemah Melayu ke Inggeris: {string}`, for MS-EN translation.\n\n## Evaluation\n\neng_Latn-zsm_Latn,\n```\n{'name': 'BLEU',\n 'score': 41.625536185056305,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '73.4/50.1/35.7/25.7 (BP = 0.971 ratio = 0.972 hyp_len = 21400 ref_len = 22027)',\n 'bp': 0.9711259908305946,\n 'counts': [15718, 10223, 6926, 4731],\n 'totals': [21400, 20403, 19406, 18409],\n 'sys_len': 21400,\n 'ref_len': 22027,\n 'precisions': [73.44859813084112,\n  50.10537666029506,\n  35.68999278573637,\n  25.699386169808246],\n 'prec_str': '73.4/50.1/35.7/25.7',\n 'ratio': 0.9715349343986925}\nchrF2++ = 65.70\n```\n\nzsm_Latn-eng_Latn,\n```\n{'name': 'BLEU',\n 'score': 37.26048464066508,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '68.3/44.1/30.5/21.4 (BP = 0.995 ratio = 0.995 hyp_len = 23457 ref_len = 23570)',\n 'bp': 0.9951942593830536,\n 'counts': [16020, 9908, 6547, 4376],\n 'totals': [23457, 22460, 21463, 20466],\n 'sys_len': 23457,\n 'ref_len': 23570,\n 'precisions': [68.29517841156158,\n  44.1139804096171,\n  30.503657457019056,\n  21.381803967555946],\n 'prec_str': '68.3/44.1/30.5/21.4',\n 'ratio': 0.9952057700466695}\nchrF2++ = 61.29\n```", "size_bytes": "139023962", "downloads": 284}