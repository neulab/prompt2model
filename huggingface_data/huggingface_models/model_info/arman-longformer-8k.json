{"pretrained_model_name": "zedfum/arman-longformer-8k", "description": "---\nlanguage:\n- fa\npipeline_tag: summarization\n---\n# Model Card for Model arman-longformer-8k\n\n<!-- Provide a quick summary of what the model is/does. -->\nThis project use Longformer's attention mechanism to [alireza7/ARMAN-MSR-persian-base](https://huggingface.co/alireza7/ARMAN-MSR-persian-base) in order to perform abstractive summarization on long documents. so new model can accept 8K tokens (rather than 512 tokens).it should be fine-tuned for summarization tasks.\n\nconverting code is available in [github repository](https://github.com/ZEDFUM/arman-to-longformer)\n\n\n", "size_bytes": "1196740045", "downloads": 30}