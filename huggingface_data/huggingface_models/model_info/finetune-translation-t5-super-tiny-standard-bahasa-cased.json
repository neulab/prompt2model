{"pretrained_model_name": "mesolitica/finetune-translation-t5-super-tiny-standard-bahasa-cased", "description": "---\nlanguage: \n  - ms\ntags:\n- translation\nmetrics:\n- sacrebleu\n---\n\n# finetune-translation-t5-super-tiny-standard-bahasa-cased\n\nFinetuned T5 super tiny on EN-MS and MS-EN translation tasks.\n\n## Dataset\n\n1. EN-MS dataset, https://huggingface.co/datasets/mesolitica/en-ms\n2. MS-EN dataset, https://huggingface.co/datasets/mesolitica/ms-en\n3. NLLB eng_Latn-zsm_Latn, https://github.com/huseinzol05/malay-dataset/tree/master/translation/laser\n\n## Finetune details\n\n1. Finetune using single RTX 3090 Ti.\n\nScripts at https://github.com/huseinzol05/malaya/tree/master/session/translation/hf-t5\n\n## Supported prefix\n\n1. `terjemah Inggeris ke Melayu: {string}`, for EN-MS translation.\n2. `terjemah Melayu ke Inggeris: {string}`, for MS-EN translation.\n\n## Evaluation\n\neng_Latn-zsm_Latn,\n```\n{'name': 'BLEU',\n 'score': 39.18834189893951,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '72.6/48.3/33.5/23.6 (BP = 0.960 ratio = 0.961 hyp_len = 21172 ref_len = 22027)',\n 'bp': 0.9604210226409274,\n 'counts': [15376, 9741, 6434, 4284],\n 'totals': [21172, 20175, 19178, 18181],\n 'sys_len': 21172,\n 'ref_len': 22027,\n 'precisions': [72.62422066880787,\n  48.28252788104089,\n  33.54885806653457,\n  23.563060337715196],\n 'prec_str': '72.6/48.3/33.5/23.6',\n 'ratio': 0.9611840014527625}\nchrF2++ = 64.03\n```\n\nzsm_Latn-eng_Latn,\n```\n{'name': 'BLEU',\n 'score': 34.10561487832948,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '67.3/41.6/27.8/18.7 (BP = 0.982 ratio = 0.982 hyp_len = 23139 ref_len = 23570)',\n 'bp': 0.9815458410942027,\n 'counts': [15569, 9216, 5871, 3777],\n 'totals': [23139, 22142, 21145, 20148],\n 'sys_len': 23139,\n 'ref_len': 23570,\n 'precisions': [67.28467090194044,\n  41.62225634540692,\n  27.765429179475053,\n  18.746277546158428],\n 'prec_str': '67.3/41.6/27.8/18.7',\n 'ratio': 0.9817140432753501}\nchrF2++ = 59.18\n```", "size_bytes": "50724632", "downloads": 229}