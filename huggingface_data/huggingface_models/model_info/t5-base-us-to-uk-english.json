{"pretrained_model_name": "EnglishVoice/t5-base-us-to-uk-english", "description": "---\nlanguage:\n- en\ntags:\n- text2text-generation\n- paraphrase-generation\nlicense: apache-2.0\nwidget:\n - text: \"US  to UK: My favorite color is yellow.\"\n---\n\n### About the model\n\nThe model has been trained on a dataset containing [249525  sentences with US English spelling](https://www.englishvoice.ai/p/us-to-uk/ \"249525  sentences with US English spelling\"), along with their UK English equivalent.\n\nThe purpose of the model is to rewrite sentences from US English to UK English. It is capable not only of changing the spelling of words (such as \"color\" to \"colour\") but also changes the vocabulary appropriately (for example, \"subway\" to \"underground\", \"lawyer\" to \"solicitor\" and so on).\n\n### Generation examples\n\n| Input | Output |\n| :------------ | :------------ |\n| My favorite color is yellow. | My favourite colour is yellow. |\n| I saw a guy in yellow sneakers at the subway station. | I saw a bloke in yellow trainers at the underground station. |\n| You could have gotten hurt! | You could have got hurt! |\n\n### The dataset\n\nThe dataset was developed by English Voice AI Labs. You can download it from our website:\n[https://www.EnglishVoice.ai/](https://www.EnglishVoice.ai/ \"https://www.EnglishVoice.ai/\")\n\n### Sample code\n\nSample Python code:\n\n```python\nimport torch\nfrom transformers import T5ForConditionalGeneration,T5Tokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"EnglishVoice/t5-base-us-to-uk-english\")\ntokenizer = T5Tokenizer.from_pretrained(\"EnglishVoice/t5-base-us-to-uk-english\")\nmodel = model.to(device)\n\ninput = \"My favorite color is yellow.\"\n\ntext =  \"US to UK: \" + input\nencoding = tokenizer.encode_plus(text, return_tensors = \"pt\")\ninput_ids = encoding[\"input_ids\"].to(device)\nattention_masks = encoding[\"attention_mask\"].to(device)\nbeam_outputs = model.generate(\n    input_ids = input_ids,\n    attention_mask = attention_masks,\n    early_stopping = True,\n)\n\nresult = tokenizer.decode(beam_outputs[0], skip_special_tokens=True)\nprint(result)\n\n```\n\nOutput:\n\n```My favourite colour is yellow.```\n", "size_bytes": "891730879", "downloads": 233}