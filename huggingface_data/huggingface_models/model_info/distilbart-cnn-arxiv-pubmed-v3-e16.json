{"pretrained_model_name": "theojolliffe/distilbart-cnn-arxiv-pubmed-v3-e16", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: distilbart-cnn-arxiv-pubmed-v3-e16\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# distilbart-cnn-arxiv-pubmed-v3-e16\n\nThis model is a fine-tuned version of [theojolliffe/distilbart-cnn-arxiv-pubmed](https://huggingface.co/theojolliffe/distilbart-cnn-arxiv-pubmed) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.8502\n- Rouge1: 57.1726\n- Rouge2: 42.87\n- Rougel: 44.7485\n- Rougelsum: 55.6955\n- Gen Len: 141.5926\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 2e-05\n- train_batch_size: 1\n- eval_batch_size: 1\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 16\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Rouge1  | Rouge2  | Rougel  | Rougelsum | Gen Len  |\n|:-------------:|:-----:|:-----:|:---------------:|:-------:|:-------:|:-------:|:---------:|:--------:|\n| 1.4961        | 1.0   | 795   | 1.0907          | 53.2509 | 33.4232 | 34.4499 | 50.987    | 142.0    |\n| 0.8874        | 2.0   | 1590  | 0.9408          | 52.9708 | 34.499  | 36.537  | 50.3924   | 140.4074 |\n| 0.6994        | 3.0   | 2385  | 0.8731          | 53.4488 | 34.2476 | 37.4579 | 51.1979   | 142.0    |\n| 0.4883        | 4.0   | 3180  | 0.8521          | 53.5463 | 34.7519 | 37.8143 | 51.106    | 142.0    |\n| 0.3923        | 5.0   | 3975  | 0.8227          | 53.3556 | 35.0361 | 37.1719 | 50.9195   | 141.2222 |\n| 0.2727        | 6.0   | 4770  | 0.8323          | 54.8422 | 37.333  | 39.6388 | 52.2975   | 141.8148 |\n| 0.2158        | 7.0   | 5565  | 0.8252          | 54.0343 | 36.0109 | 38.34   | 51.6282   | 142.0    |\n| 0.1734        | 8.0   | 6360  | 0.7985          | 54.9597 | 38.283  | 41.0033 | 52.9537   | 142.0    |\n| 0.1366        | 9.0   | 7155  | 0.8112          | 56.315  | 40.3948 | 42.2944 | 54.3719   | 142.0    |\n| 0.1275        | 10.0  | 7950  | 0.8238          | 55.8688 | 39.4747 | 43.0286 | 53.9269   | 142.0    |\n| 0.0978        | 11.0  | 8745  | 0.8345          | 54.9934 | 40.0148 | 42.2721 | 53.324    | 142.0    |\n| 0.0738        | 12.0  | 9540  | 0.8322          | 56.3862 | 41.4322 | 44.1406 | 54.4768   | 142.0    |\n| 0.0688        | 13.0  | 10335 | 0.8384          | 55.9261 | 40.7102 | 43.5825 | 54.2394   | 142.0    |\n| 0.0587        | 14.0  | 11130 | 0.8435          | 56.8475 | 41.7188 | 44.0671 | 54.9813   | 142.0    |\n| 0.0529        | 15.0  | 11925 | 0.8476          | 57.4678 | 42.3804 | 45.4776 | 55.746    | 142.0    |\n| 0.0469        | 16.0  | 12720 | 0.8502          | 57.1726 | 42.87   | 44.7485 | 55.6955   | 141.5926 |\n\n\n### Framework versions\n\n- Transformers 4.18.0\n- Pytorch 1.11.0+cu113\n- Datasets 2.1.0\n- Tokenizers 0.12.1\n", "size_bytes": "1222361081", "downloads": 2}