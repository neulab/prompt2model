{"pretrained_model_name": "minhtoan/t5-small-vietnamese-news", "description": "---\nlanguage: vi\ndatasets:\n- Wikilingua \n- Vietnews\ntags:\n- summarization\nlicense: mit\n\nwidget:\n- text: 'VKS c\u00e1o bu\u1ed9c \u00f4ng Nguy\u1ec5n Th\u1ebf Hi\u1ec7p c\u00f3 sai ph\u1ea1m trong v\u1ee5 ch\u00e1y g\u1ea7n B\u1ec7nh vi\u1ec7n Nhi trung \u01b0\u01a1ng khi\u1ebfn 2 ng\u01b0\u1eddi ch\u1ebft, thi\u1ec7t h\u1ea1i 1,9 t\u1ef7 \u0111\u1ed3ng song b\u1ecb c\u00e1o kh\u1eb3ng \u0111\u1ecbnh v\u00f4 t\u1ed9i. M\u1ee9c \u00e1n \u0111\u1ec1 ngh\u1ecb 9-10 n\u0103m t\u00f9 v\u1edbi b\u1ecb c\u00e1o 73 tu\u1ed5i \u0111\u01b0\u1ee3c \u0111\u1ea1i di\u1ec7n VKSND qu\u1eadn Ba \u0110\u00ecnh \u0111\u01b0a ra chi\u1ec1u 28/11, quy bu\u1ed9c ph\u1ea1m t\u1ed9i Vi ph\u1ea1m quy \u0111\u1ecbnh v\u1ec1 ph\u00f2ng ch\u00e1y ch\u1eefa ch\u00e1y, theo \u0110i\u1ec1u 313 B\u1ed9 lu\u1eadt H\u00ecnh s\u1ef1. VKS nh\u1eadn \u0111\u1ecbnh \u00f4ng Hi\u1ec7p c\u00f3 l\u1ed7i trong vi\u1ec7c v\u1eadn h\u00e0nh nh\u00e0 tr\u1ecd kh\u00f4ng ph\u00e9p, kh\u00f4ng \u0111\u1ee7 \u0111i\u1ec1u ki\u1ec7n an to\u00e0n ph\u00f2ng ch\u00e1y ch\u1eefa ch\u00e1y, g\u00e2y thi\u1ec7t h\u1ea1i v\u1ec1 t\u00e0i s\u1ea3n v\u00e0 khi\u1ebfn hai ng\u01b0\u1eddi ch\u1ebft. Tuy nhi\u00ean, b\u1ecb c\u00e1o ch\u01b0a b\u1ed3i th\u01b0\u1eddng. B\u1ea3n lu\u1eadn t\u1ed9i n\u00eau, t\u1ea1i phi\u00ean t\u00f2a h\u00f4m nay \u00f4ng Hi\u1ec7p \"ch\u01b0a t\u1ecf th\u00e1i \u0111\u1ed9 \u0103n n\u0103n h\u1ed1i h\u1eadn, c\u00f3 nh\u00e2n th\u00e2n \u0111\u1eb7c bi\u1ec7t x\u1ea5u\". T\u1eeb h\u00e0ng ch\u1ee5c n\u0103m tr\u01b0\u1edbc, \u00f4ng t\u1eebng 11 l\u1ea7n b\u1ecb l\u1eadp danh ch\u1ec9 b\u1ea3n v\u1ec1 h\u00e0nh vi tr\u1ed9m c\u1eafp, n\u0103m 1985 l\u1ea1i nh\u1eadn 18 n\u0103m t\u00f9 v\u1ec1 c\u00e1c t\u1ed9i c\u01b0\u1edbp t\u00e0i s\u1ea3n, hi\u1ebfp d\u00e2m, \u0111\u01b0a h\u1ed1i l\u1ed9...'\n\ninference:\n  parameters:\n    max_length: 150\n---\n# Text summarization for Vietnamese Language\n\nState-of-the-art lightweights pretrained Transformer-based encoder-decoder model for Vietnamese.\n\nModel trained on dataset Vietnamese News with input length = 512, output length = 150\n## How to use\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n# Example test data on VNExpress: https://vnexpress.net/ong-hiep-khung-khong-nhan-toi-trong-vu-chay-gan-benh-vien-nhi-4541483.html\ntokenizer = AutoTokenizer.from_pretrained(\"minhtoan/t5-small-vietnamese-news\")  \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"minhtoan/t5-small-vietnamese-news\")\nmodel.cuda()\nsrc = 'VKS c\u00e1o bu\u1ed9c \u00f4ng Nguy\u1ec5n Th\u1ebf Hi\u1ec7p c\u00f3 sai ph\u1ea1m trong v\u1ee5 ch\u00e1y g\u1ea7n B\u1ec7nh vi\u1ec7n Nhi trung \u01b0\u01a1ng khi\u1ebfn 2 ng\u01b0\u1eddi ch\u1ebft, thi\u1ec7t h\u1ea1i 1,9 t\u1ef7 \u0111\u1ed3ng song b\u1ecb c\u00e1o kh\u1eb3ng \u0111\u1ecbnh v\u00f4 t\u1ed9i. M\u1ee9c \u00e1n \u0111\u1ec1 ngh\u1ecb 9-10 n\u0103m t\u00f9 v\u1edbi b\u1ecb c\u00e1o 73 tu\u1ed5i \u0111\u01b0\u1ee3c \u0111\u1ea1i di\u1ec7n VKSND qu\u1eadn Ba \u0110\u00ecnh \u0111\u01b0a ra chi\u1ec1u 28/11, quy bu\u1ed9c ph\u1ea1m t\u1ed9i Vi ph\u1ea1m quy \u0111\u1ecbnh v\u1ec1 ph\u00f2ng ch\u00e1y ch\u1eefa ch\u00e1y, theo \u0110i\u1ec1u 313 B\u1ed9 lu\u1eadt H\u00ecnh s\u1ef1. VKS nh\u1eadn \u0111\u1ecbnh \u00f4ng Hi\u1ec7p c\u00f3 l\u1ed7i trong vi\u1ec7c v\u1eadn h\u00e0nh nh\u00e0 tr\u1ecd kh\u00f4ng ph\u00e9p, kh\u00f4ng \u0111\u1ee7 \u0111i\u1ec1u ki\u1ec7n an to\u00e0n ph\u00f2ng ch\u00e1y ch\u1eefa ch\u00e1y, g\u00e2y thi\u1ec7t h\u1ea1i v\u1ec1 t\u00e0i s\u1ea3n v\u00e0 khi\u1ebfn hai ng\u01b0\u1eddi ch\u1ebft. Tuy nhi\u00ean, b\u1ecb c\u00e1o ch\u01b0a b\u1ed3i th\u01b0\u1eddng. B\u1ea3n lu\u1eadn t\u1ed9i n\u00eau, t\u1ea1i phi\u00ean t\u00f2a h\u00f4m nay \u00f4ng Hi\u1ec7p \"ch\u01b0a t\u1ecf th\u00e1i \u0111\u1ed9 \u0103n n\u0103n h\u1ed1i h\u1eadn, c\u00f3 nh\u00e2n th\u00e2n \u0111\u1eb7c bi\u1ec7t x\u1ea5u\". T\u1eeb h\u00e0ng ch\u1ee5c n\u0103m tr\u01b0\u1edbc, \u00f4ng t\u1eebng 11 l\u1ea7n b\u1ecb l\u1eadp danh ch\u1ec9 b\u1ea3n v\u1ec1 h\u00e0nh vi tr\u1ed9m c\u1eafp, n\u0103m 1985 l\u1ea1i nh\u1eadn 18 n\u0103m t\u00f9 v\u1ec1 c\u00e1c t\u1ed9i c\u01b0\u1edbp t\u00e0i s\u1ea3n, hi\u1ebfp d\u00e2m, \u0111\u01b0a h\u1ed1i l\u1ed9...'\ntokenized_text = tokenizer.encode(src, return_tensors=\"pt\").cuda()\nmodel.eval()\nsummary_ids = model.generate(tokenized_text, max_length=150)\noutput = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\noutput\n```\n\n## Author\n`\nPhan Minh Toan \n`", "size_bytes": "1200770885", "downloads": 47}