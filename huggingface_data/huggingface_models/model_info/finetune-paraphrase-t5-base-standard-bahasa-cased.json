{"pretrained_model_name": "mesolitica/finetune-paraphrase-t5-base-standard-bahasa-cased", "description": "---\nlanguage: \n  - ms\ntags:\n- paraphrase\nmetrics:\n- sacrebleu\n---\n\n# finetune-paraphrase-t5-base-standard-bahasa-cased\n\nFinetuned T5 base on MS paraphrase tasks.\n\n## Dataset\n\n1. translated PAWS, https://huggingface.co/datasets/mesolitica/translated-PAWS\n2. translated MRPC, https://huggingface.co/datasets/mesolitica/translated-MRPC\n3. translated ParaSCI, https://huggingface.co/datasets/mesolitica/translated-paraSCI\n\n## Finetune details\n\n1. Finetune using single RTX 3090 Ti.\n\nScripts at https://github.com/huseinzol05/malaya/tree/master/session/paraphrase/hf-t5\n\n## Supported prefix\n\n1. `parafrasa: {string}`, for MS paraphrase.\n\n## Evaluation\n\nEvaluated on MRPC validation set and ParaSCI Arxiv test set.\n\n```\n{'name': 'BLEU',\n 'score': 35.95965899952292,\n '_mean': -1.0,\n '_ci': -1.0,\n '_verbose': '61.7/41.3/32.0/25.8 (BP = 0.944 ratio = 0.946 hyp_len = 95593 ref_len = 101064)',\n 'bp': 0.9443747373110852,\n 'counts': [59014, 37157, 27016, 20383],\n 'totals': [95593, 90049, 84505, 78961],\n 'sys_len': 95593,\n 'ref_len': 101064,\n 'precisions': [61.73464584226878,\n  41.263090095392506,\n  31.969705934560086,\n  25.81400944770203],\n 'prec_str': '61.7/41.3/32.0/25.8',\n 'ratio': 0.9458659859099184}\n```", "size_bytes": "891611135", "downloads": 2}