{"pretrained_model_name": "joefox/mbart-large-ru-zh-ru-many-to-many-mmt", "description": "---\nlanguage:\n- ru\n- zh\ntags:\n- translation\nlicense: mit\ndatasets:\n- ccmatrix\n- joefox/newstest-2017-2019-ru_zh\nmetrics:\n- sacrebleu\n---\n\n# mBART-large Russian to Chinese and  Chinese to Russian multilingual machine translation\n\nThis model is a fine-tuned checkpoint of [mBART-large-50-many-to-many-mmt](https://huggingface.co/facebook/mbart-large-50-many-to-many-mmt). `joefox/mbart-large-ru-zh-ru-many-to-many-mmt` is fine-tuned for ru-zh and zh-ru machine translation. \n\n\n\n\nThe model can translate directly between any pair of Russian and Chinese languages. To translate into a target language, the target language id is forced as the first generated token. To force the target language id as the first generated token, pass the `forced_bos_token_id` parameter to the `generate` method..\n\nThis [post in Russian](https://habr.com/ru/post/721330/) gives more details.\n\n\n\nExample translate Russian to Chinese\n\n```python\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\nmodel = MBartForConditionalGeneration.from_pretrained(\"joefox/mbart-large-ru-zh-ru-many-to-many-mmt\")\ntokenizer = MBart50TokenizerFast.from_pretrained(\"joefox/mbart-large-ru-zh-ru-many-to-many-mmt\")\n\nsrc_text = \"\u0421\u044a\u0435\u0448\u044c \u0435\u0449\u0451 \u044d\u0442\u0438\u0445 \u043c\u044f\u0433\u043a\u0438\u0445 \u0444\u0440\u0430\u043d\u0446\u0443\u0437\u0441\u043a\u0438\u0445 \u0431\u0443\u043b\u043e\u043a.\"\n\n# translate Russian to Chinese\ntokenizer.src_lang = \"ru_RU\"\nencoded_ru = tokenizer(src_text, return_tensors=\"pt\")\ngenerated_tokens = model.generate(\n    **encoded_ru,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"zh_CN\"]\n)\nresult = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\nprint(result)\n#\u518d\u5403\u4e00\u4e9b\u6cd5\u56fd\u9762\u5305\u3002\n```\n\nand Example translate Chinese to Russian\n\n\n\n```python\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\nmodel = MBartForConditionalGeneration.from_pretrained(\"joefox/mbart-large-ru-zh-ru-many-to-many-mmt\")\ntokenizer = MBart50TokenizerFast.from_pretrained(\"joefox/mbart-large-ru-zh-ru-many-to-many-mmt\")\n\nsrc_text = \"\u5403\u4e00\u4e9b\u8f6f\u7684\u6cd5\u56fd\u9762\u5305\u3002\"\n# translate Chinese to Russian\ntokenizer.src_lang = \"zh_CN\"\nencoded_zh = tokenizer(src_text, return_tensors=\"pt\")\ngenerated_tokens = model.generate(\n    **encoded_zh,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"ru_RU\"]\n)\nresult = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\nprint(result)\n#\u0415\u0448\u044c\u0442\u0435 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0444\u0440\u0430\u043d\u0446\u0443\u0437\u0441\u043a\u043e\u0433\u043e \u0445\u043b\u0435\u0431\u0430.\n```\n\n## Languages covered\n\nRussian (ru_RU), Chinese (zh_CN)\n\n", "size_bytes": "1604960669", "downloads": 111}