{"pretrained_model_name": "flax-community/t5-recipe-generation", "description": "---\nlanguage: en\ntags:\n- seq2seq\n- t5\n- text-generation\n- recipe-generation\npipeline_tag: text2text-generation\nwidget:\n  - text: \"provolone cheese, bacon, bread, ginger\"\n  - text: \"sugar, crunchy jif peanut butter, cornflakes\"\n  - text: \"sweet butter, confectioners sugar, flaked coconut, condensed milk, nuts, vanilla, dipping chocolate\"\n  - text: \"macaroni, butter, salt, bacon, milk, flour, pepper, cream corn\"\n  - text: \"hamburger, sausage, onion, regular, american cheese, colby cheese\"\n  - text: \"chicken breasts, onion, garlic, great northern beans, black beans, green chilies, broccoli, garlic oil, butter, cajun seasoning, salt, oregano, thyme, black pepper, basil, worcestershire sauce, chicken broth, sour cream, chardonnay wine\"\n  - text: \"serrano peppers, garlic, celery, oregano, canola oil, vinegar, water, kosher salt, salt, black pepper\"\n---\n\n![avatar](chef-transformer.png)\n\n# Chef Transformer (T5) \n> This is part of the\n[Flax/Jax Community Week](https://discuss.huggingface.co/t/recipe-generation-model/7475), organized by [HuggingFace](https://huggingface.co/) and TPU usage sponsored by Google.\n\nWant to give it a try? Then what's the wait, head over to Hugging Face Spaces [here](https://huggingface.co/spaces/flax-community/chef-transformer).\n\n\n## Team Members\n- Mehrdad Farahani ([m3hrdadfi](https://huggingface.co/m3hrdadfi))\n- Kartik Godawat ([dk-crazydiv](https://huggingface.co/dk-crazydiv))\n- Haswanth Aekula ([hassiahk](https://huggingface.co/hassiahk))\n- Deepak Pandian ([rays2pix](https://huggingface.co/rays2pix))\n- Nicholas Broad ([nbroad](https://huggingface.co/nbroad))\n\n## Dataset\n\n[RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation](https://recipenlg.cs.put.poznan.pl/). This dataset contains **2,231,142** cooking recipes (>2 millions) with size of **2.14 GB**. It's processed in more careful way.\n\n### Example\n\n```json\n{\n  \"NER\": [\n    \"oyster crackers\",\n    \"salad dressing\",\n    \"lemon pepper\",\n    \"dill weed\",\n    \"garlic powder\",\n    \"salad oil\"\n  ],\n  \"directions\": [\n    \"Combine salad dressing mix and oil.\",\n    \"Add dill weed, garlic powder and lemon pepper.\",\n    \"Pour over crackers; stir to coat.\",\n    \"Place in warm oven.\",\n    \"Use very low temperature for 15 to 20 minutes.\"\n  ],\n  \"ingredients\": [\n    \"12 to 16 oz. plain oyster crackers\",\n    \"1 pkg. Hidden Valley Ranch salad dressing mix\",\n    \"1/4 tsp. lemon pepper\",\n    \"1/2 to 1 tsp. dill weed\",\n    \"1/4 tsp. garlic powder\",\n    \"3/4 to 1 c. salad oil\"\n  ],\n  \"link\": \"www.cookbooks.com/Recipe-Details.aspx?id=648947\",\n  \"source\": \"Gathered\",\n  \"title\": \"Hidden Valley Ranch Oyster Crackers\"\n}\n```\n\n## How To Use\n\n```bash\n# Installing requirements\npip install transformers\n```\n\n```python\nfrom transformers import FlaxAutoModelForSeq2SeqLM\nfrom transformers import AutoTokenizer\n\nMODEL_NAME_OR_PATH = \"flax-community/t5-recipe-generation\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH, use_fast=True)\nmodel = FlaxAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME_OR_PATH)\n\nprefix = \"items: \"\n# generation_kwargs = {\n#     \"max_length\": 512,\n#     \"min_length\": 64,\n#     \"no_repeat_ngram_size\": 3,\n#     \"early_stopping\": True,\n#     \"num_beams\": 5,\n#     \"length_penalty\": 1.5,\n# }\ngeneration_kwargs = {\n    \"max_length\": 512,\n    \"min_length\": 64,\n    \"no_repeat_ngram_size\": 3,\n    \"do_sample\": True,\n    \"top_k\": 60,\n    \"top_p\": 0.95\n}\n\n\nspecial_tokens = tokenizer.all_special_tokens\ntokens_map = {\n    \"<sep>\": \"--\",\n    \"<section>\": \"\\n\"\n}\ndef skip_special_tokens(text, special_tokens):\n    for token in special_tokens:\n        text = text.replace(token, \"\")\n\n    return text\n\ndef target_postprocessing(texts, special_tokens):\n    if not isinstance(texts, list):\n        texts = [texts]\n    \n    new_texts = []\n    for text in texts:\n        text = skip_special_tokens(text, special_tokens)\n\n        for k, v in tokens_map.items():\n            text = text.replace(k, v)\n\n        new_texts.append(text)\n\n    return new_texts\n\ndef generation_function(texts):\n    _inputs = texts if isinstance(texts, list) else [texts]\n    inputs = [prefix + inp for inp in _inputs]\n    inputs = tokenizer(\n        inputs, \n        max_length=256, \n        padding=\"max_length\", \n        truncation=True, \n        return_tensors=\"jax\"\n    )\n\n    input_ids = inputs.input_ids\n    attention_mask = inputs.attention_mask\n\n    output_ids = model.generate(\n        input_ids=input_ids, \n        attention_mask=attention_mask,\n        **generation_kwargs\n    )\n    generated = output_ids.sequences\n    generated_recipe = target_postprocessing(\n        tokenizer.batch_decode(generated, skip_special_tokens=False),\n        special_tokens\n    )\n    return generated_recipe\n```\n\n```python\nitems = [\n    \"macaroni, butter, salt, bacon, milk, flour, pepper, cream corn\",\n    \"provolone cheese, bacon, bread, ginger\"\n]\ngenerated = generation_function(items)\nfor text in generated:\n    sections = text.split(\"\\n\")\n    for section in sections:\n        section = section.strip()\n        if section.startswith(\"title:\"):\n            section = section.replace(\"title:\", \"\")\n            headline = \"TITLE\"\n        elif section.startswith(\"ingredients:\"):\n            section = section.replace(\"ingredients:\", \"\")\n            headline = \"INGREDIENTS\"\n        elif section.startswith(\"directions:\"):\n            section = section.replace(\"directions:\", \"\")\n            headline = \"DIRECTIONS\"\n        \n        if headline == \"TITLE\":\n            print(f\"[{headline}]: {section.strip().capitalize()}\")\n        else:\n            section_info = [f\"  - {i+1}: {info.strip().capitalize()}\" for i, info in enumerate(section.split(\"--\"))]\n            print(f\"[{headline}]:\")\n            print(\"\\n\".join(section_info))\n\n    print(\"-\" * 130)\n```\n\nOutput:\n```text\n[TITLE]: Macaroni and corn\n[INGREDIENTS]:\n  - 1: 2 c. macaroni\n  - 2: 2 tbsp. butter\n  - 3: 1 tsp. salt\n  - 4: 4 slices bacon\n  - 5: 2 c. milk\n  - 6: 2 tbsp. flour\n  - 7: 1/4 tsp. pepper\n  - 8: 1 can cream corn\n[DIRECTIONS]:\n  - 1: Cook macaroni in boiling salted water until tender.\n  - 2: Drain.\n  - 3: Melt butter in saucepan.\n  - 4: Blend in flour, salt and pepper.\n  - 5: Add milk all at once.\n  - 6: Cook and stir until thickened and bubbly.\n  - 7: Stir in corn and bacon.\n  - 8: Pour over macaroni and mix well.\n----------------------------------------------------------------------------------------------------------------------------------\n[TITLE]: Grilled provolone and bacon sandwich\n[INGREDIENTS]:\n  - 1: 2 slices provolone cheese\n  - 2: 2 slices bacon\n  - 3: 2 slices sourdough bread\n  - 4: 2 slices pickled ginger\n[DIRECTIONS]:\n  - 1: Place a slice of provolone cheese on one slice of bread.\n  - 2: Top with a slice of bacon.\n  - 3: Top with a slice of pickled ginger.\n  - 4: Top with the other slice of bread.\n  - 5: Heat a skillet over medium heat.\n  - 6: Place the sandwich in the skillet and cook until the cheese is melted and the bread is golden brown.\n----------------------------------------------------------------------------------------------------------------------------------\n```\n\n## Evaluation\nSince the test set is not available, we will evaluate the model based on a shared test set. This test set consists of 5% of the whole test (*= 5,000 records*), \nand we will generate five recipes for each input(*= 25,000 records*). \nThe following table summarizes the scores obtained by the **Chef Transformer** and **RecipeNLG** as our baseline.\n\n|                                   Model                                  |    COSIM   |     WER    |   ROUGE-2  |    BLEU    |    GLEU    |   METEOR   |\n|:------------------------------------------------------------------------:|:----------:|:----------:|:----------:|:----------:|:----------:|:----------:|\n|            [RecipeNLG](https://huggingface.co/mbien/recipenlg)           |   0.5723   |   1.2125   |   0.1354   |   0.1164   |   0.1503   |   0.2309   |\n| [Chef Transformer](huggingface.co/flax-community/t5-recipe-generation) * | **0.7282** | **0.7613** | **0.2470** | **0.3245** | **0.2624** | **0.4150** |\n\n*From the 5 generated recipes corresponding to each NER (food items), only the highest score was taken into account in the WER, COSIM, and ROUGE metrics. At the same time, BLEU, GLEU, Meteor were designed to have many possible references.*\n\n\n## Copyright\n\nSpecial thanks to those who provided these fantastic materials.\n- [Anatomy](https://www.flaticon.com/free-icon)\n- [Chef Hat](https://www.vecteezy.com/members/jellyfishwater)\n- [Moira Nazzari](https://pixabay.com/photos/food-dessert-cake-eggs-butter-3048440/)\n- [Instagram Post](https://www.freepik.com/free-psd/recipes-ad-social-media-post-template_11520617.htm)", "size_bytes": "891727295", "downloads": 1358}