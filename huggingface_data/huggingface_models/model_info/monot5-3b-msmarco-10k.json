{"pretrained_model_name": "castorini/monot5-3b-msmarco-10k", "description": "This model is a T5-3B reranker fine-tuned on the MS MARCO passage dataset for 10k steps (or 1 epoch).\n\nFor more details on how to use it, check [pygaggle.ai](pygaggle.ai)\n\nPaper describing the model: [Document Ranking with a Pretrained Sequence-to-Sequence Model](https://www.aclweb.org/anthology/2020.findings-emnlp.63/)\n\nThis model is also the state of the art on the BEIR Benchmark.\n- Paper: [No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval](https://arxiv.org/abs/2206.02873)\n- [Repository](https://github.com/guilhermemr04/scaling-zero-shot-retrieval)\n", "size_bytes": "11406622919", "downloads": 3819}