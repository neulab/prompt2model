{"pretrained_model_name": "Helsinki-NLP/opus-mt-zh-he", "description": "---\nlanguage: \n- zh\n- he\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### zho-heb\n\n* source group: Chinese \n* target group: Hebrew \n*  OPUS readme: [zho-heb](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/zho-heb/README.md)\n\n*  model: transformer-align\n* source language(s): cmn cmn_Bopo cmn_Hang cmn_Hani cmn_Hira cmn_Kana cmn_Latn cmn_Yiii lzh lzh_Bopo lzh_Hang lzh_Hani lzh_Hira lzh_Kana lzh_Yiii\n* target language(s): heb\n* model: transformer-align\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus-2020-06-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/zho-heb/opus-2020-06-17.zip)\n* test set translations: [opus-2020-06-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/zho-heb/opus-2020-06-17.test.txt)\n* test set scores: [opus-2020-06-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/zho-heb/opus-2020-06-17.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| Tatoeba-test.zho.heb \t| 28.5 \t| 0.469 |\n\n\n### System Info: \n- hf_name: zho-heb\n\n- source_languages: zho\n\n- target_languages: heb\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/zho-heb/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['zh', 'he']\n\n- src_constituents: {'cmn_Hans', 'nan', 'nan_Hani', 'gan', 'yue', 'cmn_Kana', 'yue_Hani', 'wuu_Bopo', 'cmn_Latn', 'yue_Hira', 'cmn_Hani', 'cjy_Hans', 'cmn', 'lzh_Hang', 'lzh_Hira', 'cmn_Hant', 'lzh_Bopo', 'zho', 'zho_Hans', 'zho_Hant', 'lzh_Hani', 'yue_Hang', 'wuu', 'yue_Kana', 'wuu_Latn', 'yue_Bopo', 'cjy_Hant', 'yue_Hans', 'lzh', 'cmn_Hira', 'lzh_Yiii', 'lzh_Hans', 'cmn_Bopo', 'cmn_Hang', 'hak_Hani', 'cmn_Yiii', 'yue_Hant', 'lzh_Kana', 'wuu_Hani'}\n\n- tgt_constituents: {'heb'}\n\n- src_multilingual: False\n\n- tgt_multilingual: False\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/zho-heb/opus-2020-06-17.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/zho-heb/opus-2020-06-17.test.txt\n\n- src_alpha3: zho\n\n- tgt_alpha3: heb\n\n- short_pair: zh-he\n\n- chrF2_score: 0.469\n\n- bleu: 28.5\n\n- brevity_penalty: 0.986\n\n- ref_len: 3654.0\n\n- src_name: Chinese\n\n- tgt_name: Hebrew\n\n- train_date: 2020-06-17\n\n- src_alpha2: zh\n\n- tgt_alpha2: he\n\n- prefer_old: False\n\n- long_pair: zho-heb\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "312087009", "downloads": 13}