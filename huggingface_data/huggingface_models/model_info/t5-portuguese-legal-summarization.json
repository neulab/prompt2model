{"pretrained_model_name": "stjiris/t5-portuguese-legal-summarization", "description": "---\nlanguage:\n- pt\nthumbnail: Portuguese T5 for the Legal Domain\ntags:\n- transformers\nlicense: mit\npipeline_tag: summarization\n---\n\n\n[![INESC-ID](https://www.inesc-id.pt/wp-content/uploads/2019/06/INESC-ID-logo_01.png)](https://www.inesc-id.pt/projects/PR07005/)\n\n[![A Semantic Search System for Supremo Tribunal de Justi\u00e7a](https://rufimelo99.github.io/SemanticSearchSystemForSTJ/_static/logo.png)](https://rufimelo99.github.io/SemanticSearchSystemForSTJ/)\n\nWork developed as part of [Project IRIS](https://www.inesc-id.pt/projects/PR07005/).\n\nThesis: [A Semantic Search System for Supremo Tribunal de Justi\u00e7a](https://rufimelo99.github.io/SemanticSearchSystemForSTJ/)\n\n# stjiris/t5-portuguese-legal-summarization\n\nT5 Model fine-tuned over \u201cunicamp-dl/ptt5-base-portuguese-vocab\u201d t5 model.\n\nWe utilized various jurisprudence and its summary to train this model.\n\n\n## Usage (HuggingFace transformers)\n```python\n# name of folder principal\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel_checkpoint = \"stjiris/t5-portuguese-legal-summarization\"\nt5_model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)\nt5_tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n\npreprocess_text = \"These are some big words and text and words and text, again, that we want to summarize\"\nt5_prepared_Text = \"summarize: \"+preprocess_text\n#print (\"original text preprocessed: \\n\", preprocess_text)\n\ntokenized_text = t5_tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n\n\n# summmarize \nsummary_ids = t5_model.generate(tokenized_text,\n                                    num_beams=4,\n                                    no_repeat_ngram_size=2,\n                                    min_length=512,\n                                    max_length=1024,\n                                    early_stopping=True)\n\noutput = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\nprint (\"\\n\\nSummarized text: \\n\",output)\n\n```\n\n## Citing & Authors\n\n### Contributions\n[@rufimelo99](https://github.com/rufimelo99)\n\nIf you use this work, please cite:\n\n```bibtex\n@inproceedings{MeloSemantic,\n\tauthor = {Melo, Rui and Santos, Professor Pedro Alexandre and Dias, Professor Jo{\\~ a}o},\n\ttitle = {A {Semantic} {Search} {System} for {Supremo} {Tribunal} de {Justi}{\\c c}a},\n}\n\n@article{ptt5_2020,\n  title={PTT5: Pretraining and validating the T5 model on Brazilian Portuguese data},\n  author={Carmo, Diedre and Piau, Marcos and Campiotti, Israel and Nogueira, Rodrigo and Lotufo, Roberto},\n  journal={arXiv preprint arXiv:2008.09144},\n  year={2020}\n}\n\n```", "size_bytes": "891697151", "downloads": 191}