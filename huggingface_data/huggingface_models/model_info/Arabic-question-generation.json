{"pretrained_model_name": "MIIB-NLP/Arabic-question-generation", "description": "---\nlanguage: \n- ar\ntags:\n- answer-aware-question-generation \n- question-generation\n- QG\nwidget:\n- text: \"context: \u0627\u0644\u062b\u0648\u0631\u0629 \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u064a\u0629 \u0623\u0648 \u062b\u0648\u0631\u0629 \u0627\u0644\u0645\u0644\u064a\u0648\u0646 \u0634\u0647\u064a\u062f\u060c \u0627\u0646\u062f\u0644\u0639\u062a \u0641\u064a 1 \u0646\u0648\u0641\u0645\u0628\u0631 1954 \u0636\u062f \u0627\u0644\u0645\u0633\u062a\u0639\u0645\u0631 \u0627\u0644\u0641\u0631\u0646\u0633\u064a \u0648\u062f\u0627\u0645\u062a 7 \u0633\u0646\u0648\u0627\u062a \u0648\u0646\u0635\u0641. \u0627\u0633\u062a\u0634\u0647\u062f \u0641\u064a\u0647\u0627 \u0623\u0643\u062b\u0631 \u0645\u0646 \u0645\u0644\u064a\u0648\u0646 \u0648\u0646\u0635\u0641 \u0645\u0644\u064a\u0648\u0646 \u062c\u0632\u0627\u0626\u0631\u064a answer:  7 \u0633\u0646\u0648\u0627\u062a \u0648\u0646\u0635\u0641 </s>\n\"\n- text: \"context: \u0627\u0633\u0643\u062a\u0644\u0646\u062f\u0627 \u062f\u0648\u0644\u0629 \u0641\u064a \u0634\u0645\u0627\u0644 \u063a\u0631\u0628 \u0623\u0648\u0631\u0648\u0628\u0627\u060c \u062a\u0639\u062a\u0628\u0631 \u062c\u0632\u0621 \u0645\u0646 \u0627\u0644\u062f\u0648\u0644 \u0627\u0644\u0623\u0631\u0628\u0639 \u0627\u0644\u0645\u0643\u0648\u0646\u0629 \u0627\u0644\u0645\u0645\u0644\u0643\u0629 \u0627\u0644\u0645\u062a\u062d\u062f\u0629. \u062a\u062d\u062a\u0644 \u0627\u0644\u062b\u0644\u062b \u0627\u0644\u0634\u0645\u0627\u0644\u064a \u0645\u0646 \u062c\u0632\u064a\u0631\u0629 \u0628\u0631\u064a\u0637\u0627\u0646\u064a\u0627 \u0627\u0644\u0639\u0638\u0645\u0649 \u0648\u062a\u062d\u062f\u0647\u0627 \u062c\u0646\u0648\u0628\u0627 \u0625\u0646\u062c\u0644\u062a\u0631\u0627 \u0648\u064a\u062d\u062f\u0647\u0627 \u0634\u0631\u0642\u0627 \u0628\u062d\u0631 \u0627\u0644\u0634\u0645\u0627\u0644 \u0648\u063a\u0631\u0628\u0627 \u0627\u0644\u0645\u062d\u064a\u0637 \u0627\u0644\u0623\u0637\u0644\u0633\u064a. \u0639\u0627\u0635\u0645\u062a\u0647\u0627 \u0623\u062f\u0646\u0628\u0631\u0629\u060c \u0648\u0623\u0647\u0645 \u0645\u062f\u0646\u0647\u0627 \u0648\u0623\u0643\u0628\u0631\u0647\u0627 \u0645\u062f\u064a\u0646\u0629 \u063a\u0644\u0627\u0633\u0643\u0648. \u0643\u0627\u0646\u062a \u0627\u0633\u0643\u062a\u0644\u0646\u062f\u0627 \u0645\u0645\u0644\u0643\u0629 \u0645\u0633\u062a\u0642\u0644\u0629 \u062d\u062a\u0649 1 \u0645\u0627\u064a\u0648 1707  answer:  \u0623\u062f\u0646\u0628\u0631\u0629  </s>\"\n\n- text: \"context: \u062a\u0645 \u062a\u0641\u0643\u064a\u0643 \u0627\u0644\u0625\u0645\u0628\u0631\u0627\u0637\u0648\u0631\u064a\u0629 \u0627\u0644\u0646\u0645\u0633\u0627\u0648\u064a\u0629 \u0627\u0644\u0645\u062c\u0631\u064a\u0629 \u0641\u064a \u0639\u0627\u0645 1918 \u0628\u0639\u062f \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u062d\u0631\u0628 \u0627\u0644\u0639\u0627\u0644\u0645\u064a\u0629 \u0627\u0644\u0623\u0648\u0644\u0649. \u0648\u0643\u0627\u0646 \u0627\u0628\u0627\u0637\u0631\u062a\u0647\u0627: \u0627\u0644\u0625\u0645\u0628\u0631\u0627\u0637\u0648\u0631 \u0641\u0631\u0627\u0646\u0633 \u062c\u0648\u0632\u064a\u0641 \u0627\u0644\u0623\u0648\u0644 \u0647\u0627\u0628\u0633\u0628\u0648\u0631\u063a \u0644\u0648\u0631\u064a\u0646 (\u0641\u064a \u0627\u0644\u0641\u062a\u0631\u0629 \u0645\u0646 1867 \u0625\u0644\u0649 1916) \u0648\u0627\u0644\u0625\u0645\u0628\u0631\u0627\u0637\u0648\u0631\u0629 \u0625\u0644\u064a\u0632\u0627\u0628\u064a\u062b (\u0645\u0646 1867 \u0625\u0644\u0649 1898)\u060c \u062a\u0628\u0639\u0647\u0627 \u0627\u0644\u0625\u0645\u0628\u0631\u0627\u0637\u0648\u0631 \u062a\u0634\u0627\u0631\u0644\u0632 \u0627\u0644\u0623\u0648\u0644 \u0625\u0645\u0628\u0631\u0627\u0637\u0648\u0631 \u0627\u0644\u0646\u0645\u0633\u0627 (\u0645\u0646 1916 \u0625\u0644\u0649 1918). answer: 1918 </s>\n\"\nmetrics:\n- bleu\nmodel-index:\n- name: Arabic-Question-Generation\n  results:\n  - task:\n      name: Question-Generation\n      type: automatic-question-generation\n    metrics:\n    - name: Bleu1\n      type: bleu\n      value: 37.62\n    - name: Bleu2\n      type: bleu\n      value: 27.80\n    - name: Bleu3\n      type: bleu\n      value: 20.89\n    - name: Bleu4\n      type: bleu\n      value: 15.87\n    - name: meteor\n      type: meteor\n      value: 33.19\n    - name: rougel\n      type: rouge\n      value: 43.37\n      \n\n---\n# Arabic Question Generation Model\n\nThis model is ready to use for **Question Generation** task, simply input the text and answer, the model will generate a question, This model is a fine-tuned version of [AraT5-Base](https://huggingface.co/UBC-NLP/AraT5-base) Model \n\n## Live Demo \nGet the Question from given Context and a Answer : [Arabic QG Model](https://huggingface.co/spaces/MIIB-NLP/Arabic-Question-Generation)\n\n## Model in Action \ud83d\ude80\n```python\n#Requirements: !pip install transformers\nfrom transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"MIIB-NLP/Arabic-question-generation\")\ntokenizer = AutoTokenizer.from_pretrained(\"MIIB-NLP/Arabic-question-generation\")\n\ndef get_question(context,answer):\n  text=\"context: \" +context + \" \" + \"answer: \" + answer + \" </s>\"\n  text_encoding = tokenizer.encode_plus(\n      text,return_tensors=\"pt\"\n  )\n  model.eval()\n  generated_ids =  model.generate(\n    input_ids=text_encoding['input_ids'],\n    attention_mask=text_encoding['attention_mask'],\n    max_length=64,\n    num_beams=5,\n    num_return_sequences=1\n  )\n  return tokenizer.decode(generated_ids[0],skip_special_tokens=True,clean_up_tokenization_spaces=True).replace('question: ',' ')\n\ncontext=\"\u0627\u0644\u062b\u0648\u0631\u0629 \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u064a\u0629 \u0623\u0648 \u062b\u0648\u0631\u0629 \u0627\u0644\u0645\u0644\u064a\u0648\u0646 \u0634\u0647\u064a\u062f\u060c \u0627\u0646\u062f\u0644\u0639\u062a \u0641\u064a 1 \u0646\u0648\u0641\u0645\u0628\u0631 1954 \u0636\u062f \u0627\u0644\u0645\u0633\u062a\u0639\u0645\u0631 \u0627\u0644\u0641\u0631\u0646\u0633\u064a \u0648\u062f\u0627\u0645\u062a 7 \u0633\u0646\u0648\u0627\u062a \u0648\u0646\u0635\u0641. \u0627\u0633\u062a\u0634\u0647\u062f \u0641\u064a\u0647\u0627 \u0623\u0643\u062b\u0631 \u0645\u0646 \u0645\u0644\u064a\u0648\u0646 \u0648\u0646\u0635\u0641 \u0645\u0644\u064a\u0648\u0646 \u062c\u0632\u0627\u0626\u0631\u064a\"\nanswer =\" 7 \u0633\u0646\u0648\u0627\u062a \u0648\u0646\u0635\u0641\"\n\nget_question(context,answer)\n\n#output : question=\"\u0643\u0645 \u0627\u0633\u062a\u0645\u0631\u062a \u0627\u0644\u062b\u0648\u0631\u0629 \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u064a\u0629\u061f \" \n\n```\n\n## Details of Ara-T5\n\nThe **Ara-T5** model was presented in [AraT5: Text-to-Text Transformers for Arabic Language Generation](https://arxiv.org/abs/2109.12068) by *El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed* \n\n\n## Contacts\n\n**Mihoubi Akram Fawzi**: [Linkedin](https://www.linkedin.com/in/mihoubi-akram/) | [Github](https://github.com/mihoubi-akram) | <mihhakram@gmail.com>\n\n**Ibrir Adel**: [Linkedin](https://www.linkedin.com/in/adel-ibrir/) | [Github]() | <adelibrir2015@gmail.com>\n\n", "size_bytes": "1131173775", "downloads": 86}