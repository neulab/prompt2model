{"pretrained_model_name": "fadhilarkan/qa-indo-math-k-v2", "description": "---\n\nmodel-index:\n- name: qa-indo-math-k-v2\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# qa-indo-math-k-v2\n\nThis model was trained from scratch on an unkown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 1.9328\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 2e-05\n- train_batch_size: 16\n- eval_batch_size: 16\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 100\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss |\n|:-------------:|:-----:|:----:|:---------------:|\n| No log        | 1.0   | 80   | 0.7969          |\n| No log        | 2.0   | 160  | 0.7612          |\n| No log        | 3.0   | 240  | 0.7624          |\n| No log        | 4.0   | 320  | 0.7424          |\n| No log        | 5.0   | 400  | 0.7634          |\n| No log        | 6.0   | 480  | 0.7415          |\n| 0.9241        | 7.0   | 560  | 0.7219          |\n| 0.9241        | 8.0   | 640  | 0.7792          |\n| 0.9241        | 9.0   | 720  | 0.7803          |\n| 0.9241        | 10.0  | 800  | 0.7666          |\n| 0.9241        | 11.0  | 880  | 0.7614          |\n| 0.9241        | 12.0  | 960  | 0.7616          |\n| 0.6373        | 13.0  | 1040 | 0.7673          |\n| 0.6373        | 14.0  | 1120 | 0.7818          |\n| 0.6373        | 15.0  | 1200 | 0.8030          |\n| 0.6373        | 16.0  | 1280 | 0.8021          |\n| 0.6373        | 17.0  | 1360 | 0.8025          |\n| 0.6373        | 18.0  | 1440 | 0.8628          |\n| 0.5614        | 19.0  | 1520 | 0.8616          |\n| 0.5614        | 20.0  | 1600 | 0.8739          |\n| 0.5614        | 21.0  | 1680 | 0.8647          |\n| 0.5614        | 22.0  | 1760 | 0.9006          |\n| 0.5614        | 23.0  | 1840 | 0.9560          |\n| 0.5614        | 24.0  | 1920 | 0.9395          |\n| 0.486         | 25.0  | 2000 | 0.9453          |\n| 0.486         | 26.0  | 2080 | 0.9569          |\n| 0.486         | 27.0  | 2160 | 1.0208          |\n| 0.486         | 28.0  | 2240 | 0.9860          |\n| 0.486         | 29.0  | 2320 | 0.9806          |\n| 0.486         | 30.0  | 2400 | 1.0681          |\n| 0.486         | 31.0  | 2480 | 1.1085          |\n| 0.4126        | 32.0  | 2560 | 1.1028          |\n| 0.4126        | 33.0  | 2640 | 1.1110          |\n| 0.4126        | 34.0  | 2720 | 1.1573          |\n| 0.4126        | 35.0  | 2800 | 1.1387          |\n| 0.4126        | 36.0  | 2880 | 1.2067          |\n| 0.4126        | 37.0  | 2960 | 1.2079          |\n| 0.3559        | 38.0  | 3040 | 1.2152          |\n| 0.3559        | 39.0  | 3120 | 1.2418          |\n| 0.3559        | 40.0  | 3200 | 1.2023          |\n| 0.3559        | 41.0  | 3280 | 1.2679          |\n| 0.3559        | 42.0  | 3360 | 1.3178          |\n| 0.3559        | 43.0  | 3440 | 1.3419          |\n| 0.3084        | 44.0  | 3520 | 1.4702          |\n| 0.3084        | 45.0  | 3600 | 1.3824          |\n| 0.3084        | 46.0  | 3680 | 1.4227          |\n| 0.3084        | 47.0  | 3760 | 1.3925          |\n| 0.3084        | 48.0  | 3840 | 1.4940          |\n| 0.3084        | 49.0  | 3920 | 1.4110          |\n| 0.2686        | 50.0  | 4000 | 1.4534          |\n| 0.2686        | 51.0  | 4080 | 1.4749          |\n| 0.2686        | 52.0  | 4160 | 1.5351          |\n| 0.2686        | 53.0  | 4240 | 1.5479          |\n| 0.2686        | 54.0  | 4320 | 1.4755          |\n| 0.2686        | 55.0  | 4400 | 1.5207          |\n| 0.2686        | 56.0  | 4480 | 1.5075          |\n| 0.2388        | 57.0  | 4560 | 1.5470          |\n| 0.2388        | 58.0  | 4640 | 1.5361          |\n| 0.2388        | 59.0  | 4720 | 1.5914          |\n| 0.2388        | 60.0  | 4800 | 1.6430          |\n| 0.2388        | 61.0  | 4880 | 1.6249          |\n| 0.2388        | 62.0  | 4960 | 1.5503          |\n| 0.2046        | 63.0  | 5040 | 1.6441          |\n| 0.2046        | 64.0  | 5120 | 1.6789          |\n| 0.2046        | 65.0  | 5200 | 1.6174          |\n| 0.2046        | 66.0  | 5280 | 1.6175          |\n| 0.2046        | 67.0  | 5360 | 1.6947          |\n| 0.2046        | 68.0  | 5440 | 1.6299          |\n| 0.1891        | 69.0  | 5520 | 1.7419          |\n| 0.1891        | 70.0  | 5600 | 1.8442          |\n| 0.1891        | 71.0  | 5680 | 1.8802          |\n| 0.1891        | 72.0  | 5760 | 1.8233          |\n| 0.1891        | 73.0  | 5840 | 1.8172          |\n| 0.1891        | 74.0  | 5920 | 1.8181          |\n| 0.1664        | 75.0  | 6000 | 1.8399          |\n| 0.1664        | 76.0  | 6080 | 1.8128          |\n| 0.1664        | 77.0  | 6160 | 1.8423          |\n| 0.1664        | 78.0  | 6240 | 1.8380          |\n| 0.1664        | 79.0  | 6320 | 1.8941          |\n| 0.1664        | 80.0  | 6400 | 1.8636          |\n| 0.1664        | 81.0  | 6480 | 1.7949          |\n| 0.1614        | 82.0  | 6560 | 1.8342          |\n| 0.1614        | 83.0  | 6640 | 1.8123          |\n| 0.1614        | 84.0  | 6720 | 1.8639          |\n| 0.1614        | 85.0  | 6800 | 1.8580          |\n| 0.1614        | 86.0  | 6880 | 1.8816          |\n| 0.1614        | 87.0  | 6960 | 1.8579          |\n| 0.1487        | 88.0  | 7040 | 1.8783          |\n| 0.1487        | 89.0  | 7120 | 1.9175          |\n| 0.1487        | 90.0  | 7200 | 1.9025          |\n| 0.1487        | 91.0  | 7280 | 1.9207          |\n| 0.1487        | 92.0  | 7360 | 1.9195          |\n| 0.1487        | 93.0  | 7440 | 1.9142          |\n| 0.1355        | 94.0  | 7520 | 1.9333          |\n| 0.1355        | 95.0  | 7600 | 1.9238          |\n| 0.1355        | 96.0  | 7680 | 1.9256          |\n| 0.1355        | 97.0  | 7760 | 1.9305          |\n| 0.1355        | 98.0  | 7840 | 1.9294          |\n| 0.1355        | 99.0  | 7920 | 1.9301          |\n| 0.1297        | 100.0 | 8000 | 1.9328          |\n\n\n### Framework versions\n\n- Transformers 4.6.1\n- Pytorch 1.7.0\n- Datasets 1.11.0\n- Tokenizers 0.10.3\n", "size_bytes": "242089354", "downloads": 4}