{"pretrained_model_name": "lighteternal/SSE-TUC-mt-en-el-cased", "description": "---\nlanguage:\n- en\n- el\ntags:\n- translation\nwidget:\n- text: \"'Katerina', is the best name for a girl.\"\nlicense: apache-2.0\nmetrics:\n- bleu\n---\n\n## English to Greek NMT\n## By the Hellenic Army Academy (SSE) and the Technical University of Crete (TUC)\n\n* source languages: en\n* target languages: el\n* licence: apache-2.0\n* dataset: Opus, CCmatrix\n* model: transformer(fairseq)\n* pre-processing: tokenization + BPE segmentation\n* metrics: bleu, chrf\n\n### Model description\n\nTrained using the Fairseq framework, transformer_iwslt_de_en architecture.\\\\\nBPE segmentation (20k codes).\\\\\nMixed-case model. \n\n### How to use\n\n```\nfrom transformers import FSMTTokenizer, FSMTForConditionalGeneration\n\nmname = \"lighteternal/SSE-TUC-mt-en-el-cased\"\n\ntokenizer = FSMTTokenizer.from_pretrained(mname)\nmodel = FSMTForConditionalGeneration.from_pretrained(mname)\n\ntext = \" 'Katerina', is the best name for a girl.\"\n\nencoded = tokenizer.encode(text, return_tensors='pt')\n\noutputs = model.generate(encoded, num_beams=5, num_return_sequences=5, early_stopping=True)\nfor i, output in enumerate(outputs):\n    i += 1\n    print(f\"{i}: {output.tolist()}\")\n    \n    decoded = tokenizer.decode(output, skip_special_tokens=True)\n    print(f\"{i}: {decoded}\")\n```\n\n\n## Training data\n\nConsolidated corpus from Opus and CC-Matrix (~6.6GB in total)\n\n\n## Eval results\n\n\nResults on Tatoeba testset (EN-EL): \n\n| BLEU | chrF  |\n| ------ | ------ |\n| 76.9 |  0.733 |\n\n\nResults on XNLI parallel (EN-EL): \n\n| BLEU | chrF  |\n| ------ | ------ |\n| 65.4 |  0.624 |\n\n### BibTeX entry and citation info\n\nDimitris Papadopoulos, et al. \"PENELOPIE: Enabling Open Information Extraction for the Greek Language through Machine Translation.\" (2021). Accepted at EACL 2021 SRW\n \n\n### Acknowledgement\n\nThe research work was supported by the Hellenic Foundation for Research and Innovation (HFRI) under the HFRI PhD Fellowship grant (Fellowship Number:50, 2nd call)\n", "size_bytes": "205089118", "downloads": 8}