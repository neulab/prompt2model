{"pretrained_model_name": "vaishali/multitabqa-base-sql", "description": "---\nlanguage: en\ntags:\n- multitabqa\n- multi-table-question-answering\nlicense: mit\npipeline_tag: table-question-answering\n---\n\n# MultiTabQA (base-sized model) \n\nMultiTabQA was proposed in [MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering](https://arxiv.org/abs/2305.12820) by Vaishali Pal, Andrew Yates, Evangelos Kanoulas, Maarten de Rijke. The original repo can be found [here](https://github.com/kolk/MultiTabQA).\n\n## Model description\n\nMultiTabQA is a tableQA model which generates the answer table from multiple-input tables. It can handle multi-table operators such as UNION, INTERSECT, EXCEPT, JOINS, etc.\n\nMultiTabQA is based on the TAPEX(BART) architecture, which is a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder.\n\n## Intended Uses\n\nThis pre-trained model can be used on SQL queries over multiple input tables. \n\n### How to Use\n\nHere is how to use this model in transformers:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport pandas as pd\n\ntokenizer = AutoTokenizer.from_pretrained(\"vaishali/multitabqa-base-sql\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"vaishali/multitabqa-base-sql\")\n\nquery = \"select count(*) from department where department_id not in (select department_id from management)\"\ntable_names = ['department', 'management']\ntables=[{\"columns\":[\"Department_ID\",\"Name\",\"Creation\",\"Ranking\",\"Budget_in_Billions\",\"Num_Employees\"],\n                  \"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],\n                  \"data\":[\n                          [1,\"State\",\"1789\",1,9.96,30266.0],\n                          [2,\"Treasury\",\"1789\",2,11.1,115897.0],\n                          [3,\"Defense\",\"1947\",3,439.3,3000000.0],\n                          [4,\"Justice\",\"1870\",4,23.4,112557.0],\n                          [5,\"Interior\",\"1849\",5,10.7,71436.0],\n                          [6,\"Agriculture\",\"1889\",6,77.6,109832.0],\n                          [7,\"Commerce\",\"1903\",7,6.2,36000.0],\n                          [8,\"Labor\",\"1913\",8,59.7,17347.0],\n                          [9,\"Health and Human Services\",\"1953\",9,543.2,67000.0],\n                          [10,\"Housing and Urban Development\",\"1965\",10,46.2,10600.0],\n                          [11,\"Transportation\",\"1966\",11,58.0,58622.0],\n                          [12,\"Energy\",\"1977\",12,21.5,116100.0],\n                          [13,\"Education\",\"1979\",13,62.8,4487.0],\n                          [14,\"Veterans Affairs\",\"1989\",14,73.2,235000.0],\n                          [15,\"Homeland Security\",\"2002\",15,44.6,208000.0]\n                        ]\n                  },\n                  {\"columns\":[\"department_ID\",\"head_ID\",\"temporary_acting\"],\n                    \"index\":[0,1,2,3,4],\n                    \"data\":[\n                            [2,5,\"Yes\"],\n                            [15,4,\"Yes\"],\n                            [2,6,\"Yes\"],\n                            [7,3,\"No\"],\n                            [11,10,\"No\"]\n                          ]\n                  }]\n\ninput_tables = [pd.read_json(table, orient=\"split\") for table in tables]\n\n# flatten the model inputs in the format: query + \" \" + <table_name> : table_name1 + flattened_table1 + <table_name> : table_name2 + flattened_table2 + ...  \n#flattened_input = query + \" \" + [f\"<table_name> : {table_name} linearize_table(table) for table_name, table in zip(table_names, tables)]\nmodel_input_string = \"\"\"select count(*) from department where department_id not in (select department_id from management) <table_name> : department col : Department_ID | Name | Creation | Ranking | Budget_in_Billions | Num_Employees row 1 : 1 | State | 1789 | 1 | 9.96 | 30266 row 2 : 2 | Treasury | 1789 | 2 | 11.1 | 115897 row 3 : 3 | Defense | 1947 | 3 | 439.3 | 3000000 row 4 : 4 | Justice | 1870 | 4 | 23.4 | 112557 row 5 : 5 | Interior | 1849 | 5 | 10.7 | 71436 row 6 : 6 | Agriculture | 1889 | 6 | 77.6 | 109832 row 7 : 7 | Commerce | 1903 | 7 | 6.2 | 36000 row 8 : 8 | Labor | 1913 | 8 | 59.7 | 17347 row 9 : 9 | Health and Human Services | 1953 | 9 | 543.2 | 67000 row 10 : 10 | Housing and Urban Development | 1965 | 10 | 46.2 | 10600 row 11 : 11 | Transportation | 1966 | 11 | 58.0 | 58622 row 12 : 12 | Energy | 1977 | 12 | 21.5 | 116100 row 13 : 13 | Education | 1979 | 13 | 62.8 | 4487 row 14 : 14 | Veterans Affairs | 1989 | 14 | 73.2 | 235000 row 15 : 15 | Homeland Security | 2002 | 15 | 44.6 | 208000 <table_name> : management col : department_ID | head_ID | temporary_acting row 1 : 2 | 5 | Yes row 2 : 15 | 4 | Yes row 3 : 2 | 6 | Yes row 4 : 7 | 3 | No row 5 : 11 | 10 | No\"\"\"\ninputs = tokenizer(model_input_string, return_tensors=\"pt\")\n\noutputs = model.generate(**inputs)\n\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n# 'col : count(*) row 1 : 11'\n```\n\n### How to Fine-tune\n\nPlease find the fine-tuning script [here](https://github.com/kolk/MultiTabQA).\n\n### BibTeX entry and citation info\n\n```bibtex\n@misc{pal2023multitabqa,\n    title={MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering},\n    author={Vaishali Pal and Andrew Yates and Evangelos Kanoulas and Maarten de Rijke},\n    year={2023},\n    eprint={2305.12820},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n```", "size_bytes": "557969145", "downloads": 65}