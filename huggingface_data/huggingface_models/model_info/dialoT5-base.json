{"pretrained_model_name": "artemnech/dialoT5-base", "description": "How to use:\n\n```\nfrom collections import deque\nfrom  bs4 import BeautifulSoup\nimport requests\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer\nimport torch\n\nmodel_name = 'artemnech/dialoT5-base'\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef generate(text, **kwargs):\n    model.eval()\n    inputs = tokenizer(text, return_tensors='pt').to(model.device)\n    with torch.no_grad():\n        hypotheses = model.generate(**inputs,  **kwargs)\n    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)\n\ndef dialog(context):\n  \n    keyword = generate('keyword: ' + ' '.join(context), num_beams=2,)\n    knowlege = ''\n    if keyword != 'no_keywords':\n        resp = requests.get(f\"https://en.wikipedia.org/wiki/{keyword}\")\n        root = BeautifulSoup(resp.content, \"html.parser\")\n        knowlege =\"knowlege: \" + \" \".join([_.text.strip() for _ in root.find(\"div\", class_=\"mw-body-content mw-content-ltr\").find_all(\"p\", limit=2)])\n\n    answ = generate(f'dialog: ' + knowlege + ' '.join(context), num_beams=3,\n                    do_sample=True, temperature=1.1, encoder_no_repeat_ngram_size=5, \n                    no_repeat_ngram_size=5, \n                    max_new_tokens  = 30)\n    return answ\n\ncontext =deque([], maxlen=4)\nwhile True:\n    text = input()\n    text = 'user1>>: ' + text\n    context.append(text)\n    answ = dialog(context)\n    context.append('user2>>: ' + answ)\n\n    print('bot: ', answ)\n    \n```", "size_bytes": "891697151", "downloads": 2}