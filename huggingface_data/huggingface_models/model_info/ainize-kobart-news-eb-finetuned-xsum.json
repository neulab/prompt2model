{"pretrained_model_name": "eunbeee/ainize-kobart-news-eb-finetuned-xsum", "description": "---\nlicense: mit\ntags:\n- generated_from_trainer\nmetrics:\n- rouge\nmodel-index:\n- name: ainize-kobart-news-eb-finetuned-xsum\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# ainize-kobart-news-eb-finetuned-xsum\n\nThis model is a fine-tuned version of [ainize/kobart-news](https://huggingface.co/ainize/kobart-news) on the None dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.2147\n- Rouge1: 60.732\n- Rouge2: 39.1933\n- Rougel: 60.6507\n- Rougelsum: 60.6712\n- Gen Len: 19.3417\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 2e-05\n- train_batch_size: 4\n- eval_batch_size: 4\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 5\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Rouge1  | Rouge2  | Rougel  | Rougelsum | Gen Len |\n|:-------------:|:-----:|:----:|:---------------:|:-------:|:-------:|:-------:|:---------:|:-------:|\n| 1.0649        | 1.0   | 749  | 0.5502          | 56.6571 | 36.5992 | 56.6185 | 56.6364   | 19.2929 |\n| 0.7103        | 2.0   | 1498 | 0.3904          | 59.1212 | 38.3611 | 59.093  | 59.1191   | 19.31   |\n| 0.4723        | 3.0   | 2247 | 0.2922          | 60.1133 | 38.7819 | 60.0439 | 60.0572   | 19.2659 |\n| 0.3841        | 4.0   | 2996 | 0.2367          | 60.4405 | 39.0176 | 60.366  | 60.4057   | 19.3397 |\n| 0.3091        | 5.0   | 3745 | 0.2147          | 60.732  | 39.1933 | 60.6507 | 60.6712   | 19.3417 |\n\n\n### Framework versions\n\n- Transformers 4.19.2\n- Pytorch 1.11.0+cu113\n- Datasets 2.2.2\n- Tokenizers 0.12.1\n", "size_bytes": "495646265", "downloads": 13}