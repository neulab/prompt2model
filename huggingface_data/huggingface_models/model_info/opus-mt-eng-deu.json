{"pretrained_model_name": "teelinsan/opus-mt-eng-deu", "description": "---\nlanguage:\n- en\n- de\ntags:\n- translation\n- opus-mt\nlicense: cc-by-4.0\nmodel-index:\n- name: opus-mt-eng-deu\n  results:\n  - task:\n      name: Translation eng-deu\n      type: translation\n      args: eng-deu\n    dataset:\n      name: Tatoeba-test.eng-deu\n      type: tatoeba_mt\n      args: eng-deu\n    metrics:\n    - name: BLEU\n      type: bleu\n      value: 45.8\n---\n\n# Opus Tatoeba English-German\n\n*This model was obtained by running the script [convert_marian_to_pytorch.py](https://github.com/huggingface/transformers/blob/master/src/transformers/models/marian/convert_marian_to_pytorch.py) - [Instruction available here](https://github.com/huggingface/transformers/tree/main/scripts/tatoeba). The original models were trained by [J\u00f6rg Tiedemann](https://blogs.helsinki.fi/tiedeman/) using the [MarianNMT](https://marian-nmt.github.io/) library. See all available `MarianMTModel` models on the profile of the [Helsinki NLP](https://huggingface.co/Helsinki-NLP) group.\n\nThis is the conversion of checkpoint [opus-2021-02-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus-2021-02-22.zip/eng-deu/opus-2021-02-22.zip)\n*\n\n\n---\n\n### eng-deu\n\n* source language name: English\n* target language name: German\n* OPUS readme: [README.md](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/README.md)\n\n* model: transformer\n* source language code: en\n* target language code: de\n* dataset: opus \n* release date: 2021-02-22\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus-2021-02-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus-2021-02-22.zip/eng-deu/opus-2021-02-22.zip)\n* Training data: \n  * deu-eng: Tatoeba-train (86845165)\n* Validation data: \n  * deu-eng: Tatoeba-dev, 284809\n  * total-size-shuffled: 284809\n  * devset-selected: top 5000  lines of Tatoeba-dev.src.shuffled!\n* Test data: \n  * newssyscomb2009.eng-deu: 502/11271\n  * news-test2008.eng-deu: 2051/47427\n  * newstest2009.eng-deu: 2525/62816\n  * newstest2010.eng-deu: 2489/61511\n  * newstest2011.eng-deu: 3003/72981\n  * newstest2012.eng-deu: 3003/72886\n  * newstest2013.eng-deu: 3000/63737\n  * newstest2014-deen.eng-deu: 3003/62964\n  * newstest2015-ende.eng-deu: 2169/44260\n  * newstest2016-ende.eng-deu: 2999/62670\n  * newstest2017-ende.eng-deu: 3004/61291\n  * newstest2018-ende.eng-deu: 2998/64276\n  * newstest2019-ende.eng-deu: 1997/48969\n  * Tatoeba-test.eng-deu: 10000/83347\n* test set translations file: [test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus-2021-02-22.zip/eng-deu/opus-2021-02-22.test.txt)\n* test set scores file: [eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-deu/opus-2021-02-22.zip/eng-deu/opus-2021-02-22.eval.txt)\n* BLEU-scores\n|Test set|score|\n|---|---|\n|newstest2018-ende.eng-deu|46.4|\n|Tatoeba-test.eng-deu|45.8|\n|newstest2019-ende.eng-deu|42.4|\n|newstest2016-ende.eng-deu|37.9|\n|newstest2015-ende.eng-deu|32.0|\n|newstest2017-ende.eng-deu|30.6|\n|newstest2014-deen.eng-deu|29.6|\n|newstest2013.eng-deu|27.6|\n|newstest2010.eng-deu|25.9|\n|news-test2008.eng-deu|23.9|\n|newstest2012.eng-deu|23.8|\n|newssyscomb2009.eng-deu|23.3|\n|newstest2011.eng-deu|22.9|\n|newstest2009.eng-deu|22.7|\n* chr-F-scores\n|Test set|score|\n|---|---|\n|newstest2018-ende.eng-deu|0.697|\n|newstest2019-ende.eng-deu|0.664|\n|Tatoeba-test.eng-deu|0.655|\n|newstest2016-ende.eng-deu|0.644|\n|newstest2015-ende.eng-deu|0.601|\n|newstest2014-deen.eng-deu|0.595|\n|newstest2017-ende.eng-deu|0.593|\n|newstest2013.eng-deu|0.558|\n|newstest2010.eng-deu|0.55|\n|newssyscomb2009.eng-deu|0.539|\n|news-test2008.eng-deu|0.533|\n|newstest2009.eng-deu|0.533|\n|newstest2012.eng-deu|0.53|\n|newstest2011.eng-deu|0.528|", "size_bytes": "221610115", "downloads": 33}