{"pretrained_model_name": "evolveon/flan-alpaca-gpt4-base-3k", "description": "---\nlicense: apache-2.0\ndatasets:\n- tatsu-lab/alpaca\nlanguage:\n- en\n---\n# Model Card for Flan-Alpaca-GPT4-base-3k\n\nThis model was obtained by fine-tuning the `google/flan-t5-base` model on the tatsu-lab/alpaca dataset with the max_source_length option set to 3048. The instructions at the following repository were used for fine-tuning: https://github.com/declare-lab/flan-alpaca\nThe goal of this model was a learning exercise to determine if setting a higher max_source_length resulted in the model interpreting larger prompts during inference. \n\n### Model Description\n\n- **Language(s) (NLP)**: English\n- **Finetuned from model:** google/flan-t5-base\n\n## How to use\n\n```python\nfrom transformers import pipeline\n\nprompt = \"Write an email about an alpaca that likes flan\"\nmodel = pipeline(model=\"evolveon/flan-alpaca-gpt4-base-3k\")\nmodel(prompt, max_length=3048, do_sample=True)\n\n# Dear AlpacaFriend,\n# My name is Alpaca and I'm 10 years old.\n# I'm excited to announce that I'm a big fan of flan!\n# We like to eat it as a snack and I believe that it can help with our overall growth.\n# I'd love to hear your feedback on this idea. \n# Have a great day! \n# Best, AL Paca\n```", "size_bytes": "990404917", "downloads": 631}