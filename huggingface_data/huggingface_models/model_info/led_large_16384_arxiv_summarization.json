{"pretrained_model_name": "ArtifactAI/led_large_16384_arxiv_summarization", "description": "---\nlanguage: en\nlicense: apache-2.0\ntags:\n- summarization\ndatasets: arxiv-summarization\n---\n\n## Introduction\n\nA led-large-16384 model to summarize ArXiv papers. Inputs are the abstracts of papers and full documents, and outputs are the summaries of the papers.\n\n[Allenai's Longformer Encoder-Decoder (LED)](https://github.com/allenai/longformer#longformer).\n\nAs described in [Longformer: The Long-Document Transformer](https://arxiv.org/pdf/2004.05150.pdf) by Iz Beltagy, Matthew E. Peters, Arman Cohan, \n*led-base-16384* was initialized from [*bart-base*](https://huggingface.co/facebook/bart-base) since both models share the exact same architecture. To \nbe able to process 16K tokens, *bart-base*'s position embedding matrix was simply copied 16 times.\n", "size_bytes": "1839604721", "downloads": 156}