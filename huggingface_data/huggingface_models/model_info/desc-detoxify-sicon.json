{"pretrained_model_name": "infiniterik/desc-detoxify-sicon", "description": "---\nlicense: apache-2.0\nlanguage:\n- en\n---\n\n# `infiniterik/desc-detoxify-sicon`\n\n<!-- Provide a quick summary of what the model is/does. -->\n\nFine-tuned instance of [T5-Large](https://huggingface.co/t5-large) for detoxifying discourse surrounding abortion debate.\nImplementation and ethical considerations are listed in the paper [Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text](https://github.com/infiniterik/detoxify/blob/main/pdfs/detoxify-paper.pdf).\n\nGithub repository can be found [here](https://www.github.com/infiniterik/detoxify).\n\n## Citation\n\n<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->\n\n**BibTeX:**\n\n```\n@inproceedings{bose-etal-2023-detoxifying,\n    title = \"Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text\",\n    author = \"Bose, Ritwik  and Perera, Ian  and Dorr, Bonnie\",\n    booktitle = \"Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.sicon-1.2\",\n    pages = \"9--14\"\n}\n```\n", "size_bytes": "2950901185", "downloads": 24}