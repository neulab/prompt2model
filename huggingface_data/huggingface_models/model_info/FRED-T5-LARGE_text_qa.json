{"pretrained_model_name": "Den4ikAI/FRED-T5-LARGE_text_qa", "description": "---\nlicense: mit\ndatasets:\n- Den4ikAI/ru_sberquad_long_answers\nlanguage:\n- ru\nwidget:\n- text: '<SC6>\u0422\u0435\u043a\u0441\u0442: \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u043c\u0438 \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0442\u0430\u043c\u0438 \u0420\u041d \u041f\u0440\u043e\u0442\u043e\u043d-\u041c \u043f\u043e \u0446\u0435\u043d\u0435 \u0438 \u043f\u043e \u0432\u044b\u0432\u043e\u0434\u0438\u043c\u043e\u0439 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439 \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0435 \u044f\u0432\u043b\u044f\u044e\u0442\u0441\u044f \u0430\u043c\u0435\u0440\u0438\u043a\u0430\u043d\u0441\u043a\u0430\u044f \u0420\u041d Falcon 9, \u0435\u0432\u0440\u043e\u043f\u0435\u0439\u0441\u043a\u0430\u044f \u0440\u0430\u043a\u0435\u0442\u0430 \u0442\u044f\u0436\u0451\u043b\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430 \u0410\u0440\u0438\u0430\u043d-5 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0410\u0440\u0438\u0430\u043d\u044d\u0441\u043f\u0430\u0441 \u0438 \u043c\u0435\u0436\u0434\u0443\u043d\u0430\u0440\u043e\u0434\u043d\u044b\u0439 \u043f\u0440\u043e\u0435\u043a\u0442 \u041c\u043e\u0440\u0441\u043a\u043e\u0439 \u0441\u0442\u0430\u0440\u0442 \u0441 \u0420\u041d \u0441\u0440\u0435\u0434\u043d\u0435-\u0442\u044f\u0436\u0451\u043b\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430 \u0417\u0435\u043d\u0438\u0442. \u041a\u0440\u043e\u043c\u0435 \u0442\u043e\u0433\u043e, \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0442\u0430\u043c\u0438 \u043f\u043e \u043c\u0430\u0441\u0441\u0435 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439 \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438, \u0432\u044b\u0432\u043e\u0434\u0438\u043c\u043e\u0439 \u043d\u0430 \u043e\u0440\u0431\u0438\u0442\u0443, \u043c\u043e\u0433\u0443\u0442 \u0441\u0447\u0438\u0442\u0430\u0442\u044c\u0441\u044f \u0430\u043c\u0435\u0440\u0438\u043a\u0430\u043d\u0441\u043a\u0438\u0435 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u0438 \u0410\u0442\u043b\u0430\u0441-5 \u0438 \u0414\u0435\u043b\u044c\u0442\u0430-4, \u0430 \u0442\u0430\u043a\u0436\u0435 \u044f\u043f\u043e\u043d\u0441\u043a\u0438\u0439 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c H-IIB. \u0422\u0435\u043c \u043d\u0435 \u043c\u0435\u043d\u0435\u0435 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 \u0442\u0440\u0451\u0445 \u0443\u043f\u043e\u043c\u044f\u043d\u0443\u0442\u044b\u0445 \u0420\u041d \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u0435\u0432\u044b\u0448\u0430\u0435\u0442 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0420\u041d \u041f\u0440\u043e\u0442\u043e\u043d-\u041c, \u0438 \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043e\u043d\u0438 \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u043d\u0435 \u043a\u043e\u043d\u043a\u0443\u0440\u0438\u0440\u0443\u044e\u0442 \u0441 \u041f\u0440\u043e\u0442\u043e\u043d\u043e\u043c \u043d\u0430 \u0440\u044b\u043d\u043a\u0435 \u043a\u043e\u043c\u043c\u0435\u0440\u0447\u0435\u0441\u043a\u0438\u0445 \u0437\u0430\u043f\u0443\u0441\u043a\u043e\u0432[145].\\n\u0412\u043e\u043f\u0440\u043e\u0441: \u041a\u0430\u043a \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u042f\u043f\u043e\u043d\u0441\u043a\u0438\u0439 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c?\\n\u041e\u0442\u0432\u0435\u0442: <extra_id_0>'\npipeline_tag: text2text-generation\n---\n# Den4ikAI/FRED-T5-LARGE_text_qa\n\n\u041c\u043e\u0434\u0435\u043b\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0430 \u043e\u0442\u0432\u0435\u0447\u0430\u0442\u044c \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0442\u0435\u043a\u0441\u0442\u0430.\n\nWandb: [link](https://wandb.ai/den4ikai/huggingface/runs/qkzvhuxb)\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\nfrom transformers import GenerationConfig\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\ngeneration_config = GenerationConfig.from_pretrained(\"Den4ikAI/FRED-T5-LARGE_text_qa\")\ntokenizer = AutoTokenizer.from_pretrained(\"Den4ikAI/FRED-T5-LARGE_text_qa\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Den4ikAI/FRED-T5-LARGE_text_qa\").to(device)\nmodel.eval()\n\ndef generate(prompt):\n  data = tokenizer(f\"{prompt}\", return_tensors=\"pt\").to(model.device)\n  output_ids = model.generate(\n      **data,\n      generation_config=generation_config\n  )[0]\n  print(tokenizer.decode(data[\"input_ids\"][0].tolist()))\n  out = tokenizer.decode(output_ids.tolist())\n  return out\n\nwhile 1:\n  prompt = '''<SC6>\u0422\u0435\u043a\u0441\u0442: {}\\n\u0412\u043e\u043f\u0440\u043e\u0441: {}\\n\u041e\u0442\u0432\u0435\u0442: <extra_id_0>\n  '''.format(input('\u0422\u0435\u043a\u0441\u0442: '), input('\u0412\u043e\u043f\u0440\u043e\u0441: '))\n  print(generate(prompt))\n```", "size_bytes": "1641188165", "downloads": 219}