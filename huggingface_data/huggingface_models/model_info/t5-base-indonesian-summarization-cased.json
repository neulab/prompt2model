{"pretrained_model_name": "cahya/t5-base-indonesian-summarization-cased", "description": "---\nlanguage: id\ntags:\n- pipeline:summarization\n- summarization\n- t5\ndatasets:\n- id_liputan6\n---\n\n# Indonesian T5 Summarization Base Model\n\nFinetuned T5 base summarization model for Indonesian. \n\n## Finetuning Corpus\n\n`t5-base-indonesian-summarization-cased` model is based on `t5-base-bahasa-summarization-cased` by [huseinzol05](https://huggingface.co/huseinzol05), finetuned using [id_liputan6](https://huggingface.co/datasets/id_liputan6) dataset.\n\n## Load Finetuned Model\n\n```python\nfrom transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"cahya/t5-base-indonesian-summarization-cased\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"cahya/t5-base-indonesian-summarization-cased\")\n```\n\n## Code Sample\n\n```python\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"cahya/t5-base-indonesian-summarization-cased\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"cahya/t5-base-indonesian-summarization-cased\")\n\n# \nARTICLE_TO_SUMMARIZE = \"\"\n\n# generate summary\ninput_ids = tokenizer.encode(ARTICLE_TO_SUMMARIZE, return_tensors='pt')\nsummary_ids = model.generate(input_ids,\n            min_length=20,\n            max_length=80,\n            num_beams=10,\n            repetition_penalty=2.5,\n            length_penalty=1.0,\n            early_stopping=True,\n            no_repeat_ngram_size=2,\n            use_cache=True,\n            do_sample = True,\n            temperature = 0.8,\n            top_k = 50,\n            top_p = 0.95)\n\nsummary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\nprint(summary_text)\n```\n\nOutput:\n\n```\n\n```\n\n", "size_bytes": "891737400", "downloads": 163}