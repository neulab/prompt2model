{"pretrained_model_name": "Helsinki-NLP/opus-mt-inc-en", "description": "---\nlanguage: \n- bn\n- or\n- gu\n- mr\n- ur\n- hi\n- as\n- si\n- inc\n- en\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### inc-eng\n\n* source group: Indic languages \n* target group: English \n*  OPUS readme: [inc-eng](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/inc-eng/README.md)\n\n*  model: transformer\n* source language(s): asm awa ben bho gom guj hif_Latn hin mai mar npi ori pan_Guru pnb rom san_Deva sin snd_Arab urd\n* target language(s): eng\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus2m-2020-08-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/inc-eng/opus2m-2020-08-01.zip)\n* test set translations: [opus2m-2020-08-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/inc-eng/opus2m-2020-08-01.test.txt)\n* test set scores: [opus2m-2020-08-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/inc-eng/opus2m-2020-08-01.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| newsdev2014-hineng.hin.eng \t| 8.9 \t| 0.341 |\n| newsdev2019-engu-gujeng.guj.eng \t| 8.7 \t| 0.321 |\n| newstest2014-hien-hineng.hin.eng \t| 13.1 \t| 0.396 |\n| newstest2019-guen-gujeng.guj.eng \t| 6.5 \t| 0.290 |\n| Tatoeba-test.asm-eng.asm.eng \t| 18.1 \t| 0.363 |\n| Tatoeba-test.awa-eng.awa.eng \t| 6.2 \t| 0.222 |\n| Tatoeba-test.ben-eng.ben.eng \t| 44.7 \t| 0.595 |\n| Tatoeba-test.bho-eng.bho.eng \t| 29.4 \t| 0.458 |\n| Tatoeba-test.guj-eng.guj.eng \t| 19.3 \t| 0.383 |\n| Tatoeba-test.hif-eng.hif.eng \t| 3.7 \t| 0.220 |\n| Tatoeba-test.hin-eng.hin.eng \t| 38.6 \t| 0.564 |\n| Tatoeba-test.kok-eng.kok.eng \t| 6.6 \t| 0.287 |\n| Tatoeba-test.lah-eng.lah.eng \t| 16.0 \t| 0.272 |\n| Tatoeba-test.mai-eng.mai.eng \t| 75.6 \t| 0.796 |\n| Tatoeba-test.mar-eng.mar.eng \t| 25.9 \t| 0.497 |\n| Tatoeba-test.multi.eng \t| 29.0 \t| 0.502 |\n| Tatoeba-test.nep-eng.nep.eng \t| 4.5 \t| 0.198 |\n| Tatoeba-test.ori-eng.ori.eng \t| 5.0 \t| 0.226 |\n| Tatoeba-test.pan-eng.pan.eng \t| 17.4 \t| 0.375 |\n| Tatoeba-test.rom-eng.rom.eng \t| 1.7 \t| 0.174 |\n| Tatoeba-test.san-eng.san.eng \t| 5.0 \t| 0.173 |\n| Tatoeba-test.sin-eng.sin.eng \t| 31.2 \t| 0.511 |\n| Tatoeba-test.snd-eng.snd.eng \t| 45.7 \t| 0.670 |\n| Tatoeba-test.urd-eng.urd.eng \t| 25.6 \t| 0.456 |\n\n\n### System Info: \n- hf_name: inc-eng\n\n- source_languages: inc\n\n- target_languages: eng\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/inc-eng/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['bn', 'or', 'gu', 'mr', 'ur', 'hi', 'as', 'si', 'inc', 'en']\n\n- src_constituents: {'pnb', 'gom', 'ben', 'hif_Latn', 'ori', 'guj', 'pan_Guru', 'snd_Arab', 'npi', 'mar', 'urd', 'bho', 'hin', 'san_Deva', 'asm', 'rom', 'mai', 'awa', 'sin'}\n\n- tgt_constituents: {'eng'}\n\n- src_multilingual: True\n\n- tgt_multilingual: False\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/inc-eng/opus2m-2020-08-01.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/inc-eng/opus2m-2020-08-01.test.txt\n\n- src_alpha3: inc\n\n- tgt_alpha3: eng\n\n- short_pair: inc-en\n\n- chrF2_score: 0.502\n\n- bleu: 29.0\n\n- brevity_penalty: 1.0\n\n- ref_len: 64706.0\n\n- src_name: Indic languages\n\n- tgt_name: English\n\n- train_date: 2020-08-01\n\n- src_alpha2: inc\n\n- tgt_alpha2: en\n\n- prefer_old: False\n\n- long_pair: inc-eng\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "305537025", "downloads": 18}