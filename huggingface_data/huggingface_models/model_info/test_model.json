{"pretrained_model_name": "dongxq/test_model", "description": "---\nlanguage: zh\ntags:\n- summarization\ninference: True\n---\n\nTask: Summarization\n\n## Usage\n```python\n\nfrom transformers import PegasusForConditionalGeneration,BertTokenizer\nclass PegasusTokenizer(BertTokenizer):\n    model_input_names = [\"input_ids\", \"attention_mask\"]\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        # super().__init__(**kwargs)\n        self.add_special_tokens({'additional_special_tokens':[\"<mask_1>\"]})\n\n    def build_inputs_with_special_tokens(\n            self,\n            token_ids_0: List[int],\n            token_ids_1: Optional[List[int]] = None) -> List[int]:\n\n        if token_ids_1 is None:\n            return token_ids_0 + [self.eos_token_id]\n        return token_ids_0 + token_ids_1 + [self.eos_token_id]\n\n    def _special_token_mask(self, seq):\n        all_special_ids = set(\n            self.all_special_ids)  # call it once instead of inside list comp\n        # all_special_ids.remove(self.unk_token_id)  # <unk> is only sometimes special\n        return [1 if x in all_special_ids else 0 for x in seq]\n\n    def get_special_tokens_mask(\n            self,\n            token_ids_0: List[int],\n            token_ids_1: Optional[List[int]] = None,\n            already_has_special_tokens: bool = False) -> List[int]:\n        if already_has_special_tokens:\n            return self._special_token_mask(token_ids_0)\n        elif token_ids_1 is None:\n            return self._special_token_mask(token_ids_0) + [self.eos_token_id]\n        else:\n            return self._special_token_mask(token_ids_0 +\n                                            token_ids_1) + [self.eos_token_id]                              \nmodel = PegasusForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese')\ntokenizer = PegasusTokenizer.from_pretrained('IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese')\n\ntext = \"\u5728\u5317\u4eac\u51ac\u5965\u4f1a\u81ea\u7531\u5f0f\u6ed1\u96ea\u5973\u5b50\u5761\u9762\u969c\u788d\u6280\u5de7\u51b3\u8d5b\u4e2d\uff0c\u4e2d\u56fd\u9009\u624b\u8c37\u7231\u51cc\u593a\u5f97\u94f6\u724c\u3002\u795d\u8d3a\u8c37\u7231\u51cc\uff01\u4eca\u5929\u4e0a\u5348\uff0c\u81ea\u7531\u5f0f\u6ed1\u96ea\u5973\u5b50\u5761\u9762\u969c\u788d\u6280\u5de7\u51b3\u8d5b\u4e3e\u884c\u3002\u51b3\u8d5b\u5206\u4e09\u8f6e\u8fdb\u884c\uff0c\u53d6\u9009\u624b\u6700\u4f73\u6210\u7ee9\u6392\u540d\u51b3\u51fa\u5956\u724c\u3002\u7b2c\u4e00\u8df3\uff0c\u4e2d\u56fd\u9009\u624b\u8c37\u7231\u51cc\u83b7\u5f9769.90\u5206\u3002\u572812\u4f4d\u9009\u624b\u4e2d\u6392\u540d\u7b2c\u4e09\u3002\u5b8c\u6210\u52a8\u4f5c\u540e\uff0c\u8c37\u7231\u51cc\u53c8\u626e\u4e86\u4e2a\u9b3c\u8138\uff0c\u751a\u662f\u53ef\u7231\u3002\u7b2c\u4e8c\u8f6e\u4e2d\uff0c\u8c37\u7231\u51cc\u5728\u9053\u5177\u533a\u7b2c\u4e09\u4e2a\u969c\u788d\u5904\u5931\u8bef\uff0c\u843d\u5730\u65f6\u6454\u5012\u3002\u83b7\u5f9716.98\u5206\u3002\u7f51\u53cb\uff1a\u6454\u5012\u4e86\u4e5f\u6ca1\u5173\u7cfb\uff0c\u7ee7\u7eed\u52a0\u6cb9\uff01\u5728\u7b2c\u4e8c\u8df3\u5931\u8bef\u6454\u5012\u7684\u60c5\u51b5\u4e0b\uff0c\u8c37\u7231\u51cc\u9876\u4f4f\u538b\u529b\uff0c\u7b2c\u4e09\u8df3\u7a33\u7a33\u53d1\u6325\uff0c\u6d41\u7545\u843d\u5730\uff01\u83b7\u5f9786.23\u5206\uff01\u6b64\u8f6e\u6bd4\u8d5b\uff0c\u517112\u4f4d\u9009\u624b\u53c2\u8d5b\uff0c\u8c37\u7231\u51cc\u7b2c10\u4f4d\u51fa\u573a\u3002\u7f51\u53cb\uff1a\u770b\u6bd4\u8d5b\u65f6\u6211\u6bd4\u8c37\u7231\u51cc\u7d27\u5f20\uff0c\u52a0\u6cb9\uff01\"\ninputs = tokenizer(text, max_length=512, return_tensors=\"pt\")\n\n# Generate Summary\nsummary_ids = model.generate(inputs[\"input_ids\"])\ntokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n```\n\n## Citation\nIf you find the resource is useful, please cite the following website in your paper.\n```\n@misc{Fengshenbang-LM,\n  title={Fengshenbang-LM},\n  author={IDEA-CCNL},\n  year={2022},\n  howpublished={\\url{https://github.com/IDEA-CCNL/Fengshenbang-LM}},\n}\n```", "size_bytes": "1047395999", "downloads": 14}