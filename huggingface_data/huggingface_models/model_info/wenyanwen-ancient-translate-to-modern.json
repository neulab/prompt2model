{"pretrained_model_name": "raynardj/wenyanwen-ancient-translate-to-modern", "description": "---\nlanguage:\n- zh\n- zh\ntags:\n- translation\n- \u53e4\u6587\n- \u6587\u8a00\u6587\n- ancient\n- classical\nwidget:\n- text: \"\u6b64\u8bda\u5371\u6025\u5b58\u4ea1\u4e4b\u79cb\u4e5f\"\n\n---\n\n# From Classical(ancient) Chinese to Modern Chinese\n> This model translate Classical(ancient) Chinese to Modern Chinese, so I guess who's interested in the problemset can speak at least modern Chinese, hence... let me continue the documentation in Chinese\n\n# \u6587\u8a00\u6587\uff08\u53e4\u6587\uff09\u5230\u73b0\u4ee3\u6587\u7684\u7ffb\u8bd1\u5668\n> \u8fd9\u4e2a\u6a21\u578b\u5df2\u6709\u505a\u6210\u5e94\u7528\uff0c [\u3010\u968f\u65e0\u6daf\u3011](https://huggingface.co/spaces/raynardj/duguwen-classical-chinese-to-morden-translate)\u662f\u4e00\u4e2ahuggingface spaces + streamlit \u7684\u53e4\u6587\u9605\u8bfb\u5e94\u7528\uff08\u542b\u6d77\u91cf\u4e66\u7c4d\uff09\uff0c \u53ef\u4ee5\u5728\u9605\u8bfb\u65f6\u7ffb\u8bd1\n> \u8f93\u5165\u6587\u8a00\u6587\uff0c \u53ef\u4ee5\u662f\u65ad\u53e5 \u6216\u8005 \u672a\u65ad\u53e5\u7684\u6587\u8a00\u6587\uff0c \u6a21\u578b\u4f1a\u9884\u6d4b\u73b0\u4ee3\u6587\u7684\u8868\u8ff0\u3002 \u5176\u4ed6\u6a21\u578b\uff1a\n* \u4ece[\u73b0\u4ee3\u6587\u7ffb\u8bd1\u5230\u6587\u8a00\u6587](https://huggingface.co/raynardj/wenyanwen-chinese-translate-to-ancient)\n\n> \u4ece\u6587\u8a00\u6587\u5230\u73b0\u4ee3\u6587\u7684\u7ffb\u8bd1\u5668, \u6b22\u8fce\u524d\u5f80[\u6211\u7684github\u6587\u8a00\u8bd7\u8bcd\u9879\u76ee\u9875\u9762\u63a2\u8ba8\u3001\u52a0\u2b50\ufe0f ](https://github.com/raynardj/yuan)\n\n> \u8bad\u7ec3\u8bed\u6599\u662f\u5c31\u662f\u4e5d\u5341\u591a\u4e07\u53e5\u53e5\u5bf9\uff0c [\u6570\u636e\u96c6\u94fe\u63a5\ud83d\udcda](https://github.com/BangBOOM/Classical-Chinese)\u3002 \u8bad\u7ec3\u65f6source\u5e8f\u5217\uff08\u53e4\u6587\u5e8f\u5217\uff09\uff0c \u6309\u716750%\u7684\u6982\u7387\u6574\u53e5\u53bb\u9664\u6240\u6709\u6807\u70b9\u7b26\u53f7\u3002\n\n## \u63a8\u8350\u7684inference \u901a\u9053\n**\u6ce8\u610f**\n* \u4f60\u5fc5\u987b\u5c06```generate```\u51fd\u6570\u7684```eos_token_id```\u8bbe\u7f6e\u4e3a102\u5c31\u53ef\u4ee5\u7ffb\u8bd1\u51fa\u5b8c\u6574\u7684\u8bed\u53e5\uff0c \u4e0d\u7136\u7ffb\u8bd1\u5b8c\u4e86\u4f1a\u6709\u6b8b\u7559\u7684\u8bed\u53e5(\u56e0\u4e3a\u505a\u71b5\u7684\u65f6\u5019\u7528pad\u6807\u7b7e=-100\u5bfc\u81f4)\u3002\n\u76ee\u524dhuggingface \u9875\u9762\u4e0acompute\u6309\u94ae\u4f1a\u6709\u8fd9\u4e2a\u95ee\u9898\uff0c \u63a8\u8350\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u6765\u5f97\u5230\u7ffb\u8bd1\u7ed3\u679c\n* \u8bf7\u8bbe\u7f6e```generate```\u7684\u53c2\u6570```num_beams>=3```, \u4ee5\u8fbe\u5230\u8f83\u597d\u7684\u7ffb\u8bd1\u6548\u679c\n* \u8bf7\u8bbe\u7f6e```generate```\u7684\u53c2\u6570```max_length```256\uff0c \u4e0d\u7136\u7ed3\u679c\u4f1a\u5403\u6389\u53e5\u5b50\n```python\nfrom transformers import (\n  EncoderDecoderModel,\n  AutoTokenizer\n)\nPRETRAINED = \"raynardj/wenyanwen-ancient-translate-to-modern\"\ntokenizer = AutoTokenizer.from_pretrained(PRETRAINED)\nmodel = EncoderDecoderModel.from_pretrained(PRETRAINED)\ndef inference(text):\n    tk_kwargs = dict(\n      truncation=True,\n      max_length=128,\n      padding=\"max_length\",\n      return_tensors='pt')\n   \n    inputs = tokenizer([text,],**tk_kwargs)\n    with torch.no_grad():\n        return tokenizer.batch_decode(\n            model.generate(\n            inputs.input_ids,\n            attention_mask=inputs.attention_mask,\n            num_beams=3,\n            max_length=256,\n            bos_token_id=101,\n            eos_token_id=tokenizer.sep_token_id,\n            pad_token_id=tokenizer.pad_token_id,\n        ), skip_special_tokens=True)\n```\n\n## \u76ee\u524d\u7248\u672c\u7684\u6848\u4f8b\n> \u5f53\u7136\uff0c \u62ff\u6bd4\u8f83\u719f\u77e5\u7684\u8bed\u53e5\u8fc7\u6765\uff0c \u901a\u5e38\u4f1a\u6709\u4e9b\u8d3b\u7b11\u5927\u65b9\u7684\u5931\u8bef\uff0c \u5927\u5bb6\u5982\u679c\u6709\u597d\u73a9\u7684\u8c03\u620f\u6848\u4f8b\uff0c \u4e5f\u6b22\u8fce\u53cd\u9988\n```python\n>>> inference('\u975e\u6211\u65cf\u7c7b\u5176\u5fc3\u5fc5\u5f02')\n['\u4e0d \u662f \u6211 \u4eec \u7684 \u65cf \u7c7b \uff0c \u4ed6 \u4eec \u7684 \u5fc3 \u601d \u5fc5 \u7136 \u4e0d \u540c \u3002']\n>>> inference('\u8089\u98df\u8005\u9119\u672a\u80fd\u8fdc\u8c0b')\n['\u5403 \u8089 \u7684 \u4eba \u9119 \u964b \uff0c \u4e0d \u80fd \u957f \u8fdc \u8c0b \u5212 \u3002']\n# \u8fd9\u91cc\u6211\u597d\u51e0\u6279\u6a21\u578b\u90fd\u7ffb\u4e0d\u51fa\u8fd9\u4e2a**\u8f93**\u5b57\uff08\u751a\u81f3\u6709\u4e00\u4e2a\u7248\u672c\u7ffb\u6210\u4e86\u79e6\u59cb\u7687\u548c\u6c49\u6b66\u5e1d\uff09\uff0c \u53ef\u80fd\u5e76\u4e0d\u662f\u5f88\u53e4\u6734\u7684\u7528\u6cd5\uff0c \n>>> inference('\u6c5f\u5c71\u5982\u6b64\u591a\u5a07\u5f15\u65e0\u6570\u82f1\u96c4\u7ade\u6298\u8170\u60dc\u79e6\u7687\u6c49\u6b66\u7565\u8f93\u6587\u91c7\u5510\u5b97\u5b8b\u7956\u7a0d\u900a\u98ce\u9a9a')\n['\u6c5f \u5c71 \u5982 \u6b64 \u591a \uff0c \u62db \u5f15 \u65e0 \u6570 \u7684 \u82f1 \u96c4 \uff0c \u7ade \u76f8 \u6298 \u8170 \uff0c \u53ef \u60dc \u79e6 \u7687 \u3001 \u6c49 \u6b66 \uff0c \u7565 \u5fae \u6709 \u6587 \u91c7 \uff0c \u5510 \u5b97 \u3001 \u5b8b \u7956 \u7a0d \u7a0d \u900a \u51fa \u98ce \u96c5 \u3002']\n>>> inference(\"\u6e05\u98ce\u5f90\u6765\u6c34\u6ce2\u4e0d\u5174\")\n['\u6e05 \u98ce \u6162 \u6162 \u5439 \u6765 \uff0c \u6c34 \u6ce2 \u4e0d \u5174 \u3002']\n>>> inference(\"\u65e0\u4ed6\u552f\u624b\u719f\u5c14\")\n['\u6ca1 \u6709 \u522b \u7684 \u4e8b \uff0c \u53ea \u662f \u624b \u719f \u7f62 \u4e86 \u3002']\n>>> inference(\"\u6b64\u8bda\u5371\u6025\u5b58\u4ea1\u4e4b\u79cb\u4e5f\")\n['\u8fd9 \u5b9e \u5728 \u662f \u5371 \u6025 \u5b58 \u4ea1 \u7684 \u65f6 \u5019 \u3002']\n```\n\n## \u5176\u4ed6\u6587\u8a00\u8bd7\u8bcd\u7684\u8d44\u6e90\n* [\u9879\u76ee\u6e90\u4ee3\u7801 \ud83c\udf1f, \u6b22\u8fce+star\u63d0pr](https://github.com/raynardj/yuan)\n* [\u8de8\u8bed\u79cd\u641c\u7d22 \ud83d\udd0e](https://huggingface.co/raynardj/xlsearch-cross-lang-search-zh-vs-classicical-cn)\n* [\u73b0\u4ee3\u6587\u7ffb\u8bd1\u53e4\u6c49\u8bed\u7684\u6a21\u578b \u26f0](https://huggingface.co/raynardj/wenyanwen-chinese-translate-to-ancient)\n* [\u53e4\u6c49\u8bed\u5230\u73b0\u4ee3\u6587\u7684\u7ffb\u8bd1\u6a21\u578b, \u8f93\u5165\u53ef\u4ee5\u662f\u672a\u65ad\u53e5\u7684\u53e5\u5b50 \ud83d\ude80](https://huggingface.co/raynardj/wenyanwen-ancient-translate-to-modern)\n* [\u65ad\u53e5\u6a21\u578b \ud83d\udde1](https://huggingface.co/raynardj/classical-chinese-punctuation-guwen-biaodian)\n* [\u610f\u5883\u5173\u952e\u8bcd \u548c \u85cf\u5934\u5199\u8bd7\ud83e\udd16](https://huggingface.co/raynardj/keywords-cangtou-chinese-poetry)", "size_bytes": "960569915", "downloads": 68}