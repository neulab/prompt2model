{"pretrained_model_name": "artemnech/enrut5-base", "description": "---\nlanguage: [\"ru\", \"en\"]\ntags:\n- russian\nlicense: mit\nwidget:\n- text: \"translate en-ru: I'm afraid that I won't finish the report on time.\"\n---\nThis is mt5-base model [google/mt5-base](https://huggingface.co/google/mt5-base) in which only Russian and English tokens are left\n\nThe model has been fine-tuned for several tasks:\n* translation (opus100 dataset)\n* dialog (daily dialog dataset)\n\n\nHow to use:\n```\n# !pip install transformers sentencepiece\n\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer\nimport torch\n\nmodel_name = 'artemnech/enrut5-base'\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef generate(text, **kwargs):\n    model.eval()\n    inputs = tokenizer(text, return_tensors='pt').to(model.device)\n    with torch.no_grad():\n        hypotheses = model.generate(**inputs,  **kwargs)\n    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)\n\nprint(generate('translate ru-en: \u042f \u0431\u043e\u044e\u0441\u044c, \u0447\u0442\u043e \u044f \u043d\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0443 \u0434\u043e\u043a\u043b\u0430\u0434 \u0432 \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0435\u0435 \u0432\u0440\u0435\u043c\u044f.', num_beams=4,))\n# I fear I'm not going to complete the report in the near future.\n\nprint(generate(\"translate en-ru: I'm afraid that I won't finish the report on time.\", num_beams=4, max_length = 30))\n# \u042f \u0431\u043e\u044e\u0441\u044c, \u0447\u0442\u043e \u044f \u043d\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0443 \u0434\u043e\u043a\u043b\u0430\u0434 \u0432 \u0431\u043b\u0438\u0436\u0430\u0439\u0448\u0435\u0435 \u0432\u0440\u0435\u043c\u044f.\n\nprint(generate('dialog: user1>>: Hello', num_beams=2))\n# Hi\n\nprint(generate('dialog: user1>>: Hello user2>>: Hi user1>>: Would you like to drink something?', num_beams=2))\n# I would like to drink a glass of wine.\n\nfrom collections import deque\n\ncontext =deque([], maxlen=6)\nwhile True:\n    text = input()\n    text = 'user1>>: ' + text\n    context.append(text)\n    answ = generate('dialog: ' + ' '.join(context), num_beams=3, do_sample = True, temperature=1.5)\n    context.append('user2>>: ' + answ)\n\n    print('bot: ', answ)\n```\n", "size_bytes": "1045526605", "downloads": 15}