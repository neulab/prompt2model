{"pretrained_model_name": "CLAck/vi-en", "description": "---\nlanguage:\n- en\n- vi\ntags:\n- translation\nlicense: apache-2.0\ndatasets:\n- ALT\nmetrics:\n- sacrebleu\n---\n\nThis is a finetuning of a MarianMT pretrained on Chinese-English. The target language pair is Vietnamese-English.\n\n### Example\n```\n%%capture\n!pip install transformers transformers[sentencepiece]\n\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n# Download the pretrained model for English-Vietnamese available on the hub\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"CLAck/vi-en\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"CLAck/vi-en\")\n\nsentence = your_vietnamese_sentence\n# This token is needed to identify the source language\ninput_sentence = \"<2vi> \" + sentence \ntranslated = model.generate(**tokenizer(input_sentence, return_tensors=\"pt\", padding=True))\noutput_sentence = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n```\n\n### Training results\n\n| Epoch | Bleu    |\n|:-----:|:-------:|\n| 1.0   | 21.3180 |\n| 2.0   | 26.8012 |\n| 3.0   | 29.3578 |\n| 4.0   | 31.5178 |\n| 5.0   | 32.8740 |\n", "size_bytes": "328970373", "downloads": 17}