{"pretrained_model_name": "memyprokotow/rut5-REBEL-base", "description": "---\nlanguage:\n- ru\ntags:\n- seq2seq\n- relation-extraction\n- t5\nlicense: apache-2.0\ndatasets:\n- memyprokotow/rebel-dataset-rus\nwidget:\n- text: \"\u0417\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 9 \u043c\u0435\u0441\u044f\u0446\u0435\u0432 \u0438\u043d\u0432\u0435\u0441\u0442\u043e\u0440\u044b \u0432 \u0430\u0437\u0438\u0430\u0442\u0441\u043a\u0438\u0435 \u0434\u043e\u043b\u043b\u0430\u0440\u043e\u0432\u044b\u0435 \u0434\u043e\u043b\u0433\u043e\u0432\u044b\u0435 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432\u0430 \u043f\u043e\u0442\u0435\u0440\u044f\u043b\u0438 155 \u043c\u0438\u043b\u043b\u0438\u0430\u0440\u0434\u043e\u0432 \u0434\u043e\u043b\u043b\u0430\u0440\u043e\u0432, \u043f\u043e\u0441\u0442\u0440\u0430\u0434\u0430\u0432 \u043e\u0442 \u0441\u043b\u0430\u0431\u043e\u0441\u0442\u0438 \u041a\u0438\u0442\u0430\u044f \u0432 \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043a \u0433\u043b\u043e\u0431\u0430\u043b\u044c\u043d\u043e\u0439 \u0440\u0430\u0441\u043f\u0440\u043e\u0434\u0430\u0436\u0435 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0434\u043e\u0445\u043e\u0434\u0430, \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u043c\u043e\u0439 \u0432\u043e \u0432\u0441\u0435\u043c \u043c\u0438\u0440\u0435 \u043f\u043e \u043c\u0435\u0440\u0435 \u0440\u043e\u0441\u0442\u0430 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u043d\u044b\u0445 \u0441\u0442\u0430\u0432\u043e\u043a.\"\n\n---\n\n# REBEL-ru\nBased on russian part of wikipedia (scrapped with CROCODILE). \nModel trained for 3 epochs on russian ruT5-base\n\n\n# How to use\nSame code as REBEL-large (https://huggingface.co/Babelscape/rebel-large)\n```\n\ntext = '''\u0417\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 9 \u043c\u0435\u0441\u044f\u0446\u0435\u0432 \u0438\u043d\u0432\u0435\u0441\u0442\u043e\u0440\u044b \u0432 \u0430\u0437\u0438\u0430\u0442\u0441\u043a\u0438\u0435 \u0434\u043e\u043b\u043b\u0430\u0440\u043e\u0432\u044b\u0435 \u0434\u043e\u043b\u0433\u043e\u0432\u044b\u0435 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432\u0430 \u043f\u043e\u0442\u0435\u0440\u044f\u043b\u0438 155 \u043c\u0438\u043b\u043b\u0438\u0430\u0440\u0434\u043e\u0432 \u0434\u043e\u043b\u043b\u0430\u0440\u043e\u0432, \u043f\u043e\u0441\u0442\u0440\u0430\u0434\u0430\u0432 \u043e\u0442 \u0441\u043b\u0430\u0431\u043e\u0441\u0442\u0438 \u041a\u0438\u0442\u0430\u044f \u0432 \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043a \u0433\u043b\u043e\u0431\u0430\u043b\u044c\u043d\u043e\u0439 \u0440\u0430\u0441\u043f\u0440\u043e\u0434\u0430\u0436\u0435 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0434\u043e\u0445\u043e\u0434\u0430, \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u043c\u043e\u0439 \u0432\u043e \u0432\u0441\u0435\u043c \u043c\u0438\u0440\u0435 \u043f\u043e \u043c\u0435\u0440\u0435 \u0440\u043e\u0441\u0442\u0430 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u043d\u044b\u0445 \u0441\u0442\u0430\u0432\u043e\u043a. '''\n\n\nmodel_path = r\"memyprokotow/rut5-REBEL-base\"\ntriplet_extractor = pipeline('text2text-generation', model=model_path, \n                             tokenizer=model_path,\n                             #device=0\n                             )\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(text, return_tensors=True, return_text=False, max_length=500)[0][\"generated_token_ids\"]])\n\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets(text):\n    triplets = []\n    relation, subject, relation, object_ = '', '', '', ''\n    text = text.strip()\n    current = 'x'\n    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n        if token == \"<triplet>\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n                relation = ''\n            subject = ''\n        elif token == \"<subj>\":\n            current = 's'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n            object_ = ''\n        elif token == \"<obj>\":\n            current = 'o'\n            relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '':\n        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n    return triplets\nextracted_triplets = extract_triplets(extracted_text[0])\nprint(extracted_triplets)\n```\n", "size_bytes": "891316799", "downloads": 11}