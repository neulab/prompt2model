{"pretrained_model_name": "aiko/maeve-12-6-samsum", "description": "---\nlanguage: \n  - en\ntags:\n- text2text-generation\n- pytorch\nlicense: \"gpl-3.0\"\ndatasets:\n- samsum\nwidget:\n- text: \"Ruben has forgotten what the homework was. Alex tells him to ask the teacher.\"\n  example_title: \"I forgot my homework\"\n- text: \"Mac is lost at the zoo. Frank says he is at the gorilla exhibit. Charlie is going to see the minks.\"\n  example_title: \"Very sunny\"\n- text: \"Mac has started to date Dennis's mother. Dennis is going to beat him up.\"\n  example_title: \"Not very sunny\"\n---\n\n# Maeve - SAMSum\n\nMaeve is a language model that is similar to BART in structure but trained specially using a CAT (Conditionally Adversarial Transformer).\n\nThis allows the model to learn to create long-form text from short entries with high degrees of control and coherence that are impossible to achieve with traditional transformers.\n\nThis specific model has been trained on the SAMSum dataset, and can invert summaries into full-length news articles. Feel free to try examples on the right!\n", "size_bytes": "1222361081", "downloads": 6}