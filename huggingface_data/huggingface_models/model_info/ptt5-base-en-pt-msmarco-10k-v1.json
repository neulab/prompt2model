{"pretrained_model_name": "unicamp-dl/ptt5-base-en-pt-msmarco-10k-v1", "description": "---\nlanguage: pt\nlicense: mit\ntags:\n- msmarco\n- t5\n- pytorch\n- tensorflow\n- pt\n- pt-br\ndatasets:\n- msmarco\nwidget:\n- text: \"Texto de exemplo em portugu\u00eas\"\ninference: false\n---\n# PTT5-base Reranker finetuned on both English and Portuguese MS MARCO\n## Introduction\nptt5-base-msmarco-en-pt-10k-v1 is a T5-based model pretrained in the BrWac corpus, fine-tuned on both English and Portuguese translated version of MS MARCO passage dataset. In the version v1, the Portuguese dataset was translated using [Helsinki](https://huggingface.co/Helsinki-NLP) NMT model. This model was finetuned for 10k steps. \nFurther information about the dataset or the translation method can be found on our [**mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset**](https://arxiv.org/abs/2108.13897) and [mMARCO](https://github.com/unicamp-dl/mMARCO) repository.\n## Usage\n```python\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel_name = 'unicamp-dl/ptt5-base-msmarco-en-pt-10k-v1'\ntokenizer  = T5Tokenizer.from_pretrained(model_name)\nmodel      = T5ForConditionalGeneration.from_pretrained(model_name)\n\n```\n# Citation\nIf you use ptt5-base-msmarco-en-pt-10k-v1, please cite:\n\n    @misc{bonifacio2021mmarco,\n      title={mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset}, \n      author={Luiz Henrique Bonifacio and Vitor Jeronymo and Hugo Queiroz Abonizio and Israel Campiotti and Marzieh Fadaee and  and Roberto Lotufo and Rodrigo Nogueira},\n      year={2021},\n      eprint={2108.13897},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n", "size_bytes": "891727295", "downloads": 2}