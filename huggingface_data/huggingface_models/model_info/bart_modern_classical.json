{"pretrained_model_name": "xmj2002/bart_modern_classical", "description": "---\nlicense: apache-2.0\ndatasets:\n- xmj2002/Chinese_modern_classical\nlanguage:\n- zh\npipeline_tag: translation\n\n---\n\n\u4f7f\u7528\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u4e3a[fnlp/bart-base-chinese \u00b7 Hugging Face](https://huggingface.co/fnlp/bart-base-chinese)\n\n\u5b9e\u73b0\u7684\u529f\u80fd\u4e3a\u73b0\u4ee3\u6c49\u8bed\u5230\u6587\u8a00\u6587\uff08\u6309\u7167\u7ffb\u8bd1\u4efb\u52a1\u90a3\u6837\u8bad\u7ec3\uff09\n\n## \u8d85\u53c2\u6570\n\n- batch size: 32\n- epoch: 5\n- lr: 5e-5\n\n\u7531\u4e8e\u4f7f\u7528\u7684\u6570\u636e\u96c6\u6837\u672c\u6570\u5927\uff0c\u6240\u4ee5\u4ec5\u4f7f\u7528\u4e8610\u4e07\u6761\u6570\u636e\uff08\u6574\u4e2a\u6570\u636e\u96c6\u5171\u670997\u4e07\u6761\u6570\u636e\uff09\u8fdb\u884c\u8bad\u7ec3\u3002\n\n## Usage\n```python\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import AutoTokenizer\n\nprefix = \"\u666e\u901a\u8bdd\u5230\u6587\u8a00\u6587\"\ntokenizer = AutoTokenizer.from_pretrained(\"xmj2002/bart_modern_classical\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"xmj2002/bart_modern_classical\")\n\ntext = \"\u66f2\u66f2\u6298\u6298\u7684\u8377\u5858\u4e0a\u9762\uff0c\u5f25\u671b\u65f3\u662f\u7530\u7530\u7684\u53f6\u5b50\u3002\u53f6\u5b50\u51fa\u6c34\u5f88\u9ad8\uff0c\u50cf\u4ead\u4ead\u65f3\u821e\u5973\u65f3\u88d9\u3002\"\ninputs = tokenizer(prefix+text, return_tensors=\"pt\").input_ids\noutputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\ntokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# output\uff1a\u66f2 \u5858 \u4e4b \u4e0a \uff0c \u5f25 \u671b \u5219 \u7530 \u7530 \u4e4b \u53f6 \uff0c \u53f6 \u51fa \u6c34 \u9ad8 \uff0c \u82e5 \u821e \u5973 \u4f4e \u88d9 \u3002\n```", "size_bytes": "561065693", "downloads": 6}