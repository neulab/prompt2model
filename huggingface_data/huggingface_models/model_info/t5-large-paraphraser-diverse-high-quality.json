{"pretrained_model_name": "ramsrigouthamg/t5-large-paraphraser-diverse-high-quality", "description": "Blog post with more details as well as easy to use Google Colab link: https://towardsdatascience.com/high-quality-sentence-paraphraser-using-transformers-in-nlp-c33f4482856f\n\n!pip install transformers==4.10.2\n\n!pip install sentencepiece==0.1.96\n\n```\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"ramsrigouthamg/t5-large-paraphraser-diverse-high-quality\")\ntokenizer = AutoTokenizer.from_pretrained(\"ramsrigouthamg/t5-large-paraphraser-diverse-high-quality\")\n\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint (\"device \",device)\nmodel = model.to(device)\n\n# Beam Search\n\ncontext = \"Once, a group of frogs were roaming around the forest in search of water.\"\ntext = \"paraphrase: \"+context + \" </s>\"\n\nencoding = tokenizer.encode_plus(text,max_length =128, padding=True, return_tensors=\"pt\")\ninput_ids,attention_mask  = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n\nmodel.eval()\nbeam_outputs = model.generate(\n    input_ids=input_ids,attention_mask=attention_mask,\n    max_length=128,\n    early_stopping=True,\n    num_beams=15,\n    num_return_sequences=3\n\n)\n\nprint (\"\\n\\n\")\nprint (\"Original: \",context)\nfor beam_output in beam_outputs:\n    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    print (sent)\n```\n    \n**Output from the above code**\n    \n```\nOriginal:  Once, a group of frogs were roaming around the forest in search of water.\nparaphrasedoutput: A herd of frogs were wandering around the woods in search of water.\nparaphrasedoutput: A herd of frogs was wandering around the woods in search of water.\nparaphrasedoutput: A herd of frogs were wandering around the forest in search of water at one time.\n```", "size_bytes": "2950897543", "downloads": 3586}