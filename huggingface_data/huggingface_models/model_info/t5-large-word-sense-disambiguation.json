{"pretrained_model_name": "jpwahle/t5-large-word-sense-disambiguation", "description": "---\nlanguage: en\nthumbnail: url to a thumbnail used in social sharing\ntags:\n- array\n- of\n- tags\nwidget:\n- text: \"question: which description describes the word \\\" java \\\" best in the following\\\n    \\ context? descriptions: [  \\\" A drink consisting of an infusion of ground coffee\\\n    \\ beans \\\" ,  \\\" a platform-independent programming lanugage \\\" ,  or \\\" an island\\\n    \\ in Indonesia to the south of Borneo \\\" ]  context: I like to drink ' java '\\\n    \\ in the morning .\"\n---\n\n# T5-large for Word Sense Disambiguation\n\nIf you are using this model in your research work, please cite\n\n```bib\n@article{wahle2021incorporating,\n  title={Incorporating Word Sense Disambiguation in Neural Language Models},\n  author={Wahle, Jan Philip and Ruas, Terry and Meuschke, Norman and Gipp, Bela},\n  journal={arXiv preprint arXiv:2106.07967},\n  year={2021}\n}\n```\n\nThis is the checkpoint for T5-large after being trained on the [SemCor 3.0 dataset](http://lcl.uniroma1.it/wsdeval/).\n\nAdditional information about this model:\n\n* [The t5-large model page](https://huggingface.co/t5-large)\n* [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf)\n* [Official implementation by Google](https://github.com/google-research/text-to-text-transfer-transformer)\n\nThe model can be loaded to perform a few-shot classification like so:\n\n```py\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\")\ntokenizer = AutoTokenizer.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\")\n\ninput = '''question: which description describes the word \" java \"\\\n           best in the following context? \\\ndescriptions:[  \" A drink consisting of an infusion of ground coffee beans \", \n                \" a platform-independent programming language \", or\n                \" an island in Indonesia to the south of Borneo \" ] \ncontext: I like to drink \" java \" in the morning .'''\n\n\nexample = tokenizer.tokenize(input, add_special_tokens=True)\n\nanswer = model.generate(input_ids=example['input_ids'], \n                                attention_mask=example['attention_mask'], \n                                max_length=135)\n                                \n# \"a drink consisting of an infusion of ground coffee beans\"\n```\n", "size_bytes": "2950916820", "downloads": 3540}