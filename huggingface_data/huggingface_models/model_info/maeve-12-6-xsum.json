{"pretrained_model_name": "priansh/maeve-12-6-xsum", "description": "---\nlanguage: \n  - en\ntags:\n- text2text-generation\n- pytorch\nlicense: \"gpl-3.0\"\ndatasets:\n- xsum\nwidget:\n- text: \"President Biden met with Russia's Putin over the weekend to discuss a ceasefire in Ukraine.\"\n  example_title: \"Ukrainian Ceasefire\"\n- text: \"Acme Ventures recently led a seed round to provide over $2MM in funding to Aiko Mail, an AI startup tackling email.\"\n  example_title: \"VC Investment\"\n- text: \"In a shocking move, Florida has decided to formally secede from the United States, opting to sink into the Atlantic Ocean.\"\n  example_title: \"Florida secedes\"\n---\n\n# Maeve - XSUM\n\nMaeve is a language model that is similar to BART in structure but trained specially using a CAT (Conditionally Adversarial Transformer).\n\nThis allows the model to learn to create long-form text from short entries with high degrees of control and coherence that are impossible to achieve with traditional transformers.\n\nThis specific model has been trained on the XSUM dataset, and can invert summaries into full-length news articles. Feel free to try examples on the right!\n", "size_bytes": "1222361081", "downloads": 6}