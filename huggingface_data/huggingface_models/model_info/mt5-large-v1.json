{"pretrained_model_name": "9wimu9/mt5-large-v1", "description": "!python /notebooks/seq_2_seq/run_seq2seq_qa.py \\\n  --model_name_or_path google/mt5-large \\\n  --dataset_name 9wimu9/SinQuAD \\\n  --context_column context \\\n  --question_column question \\\n  --answer_column answers \\\n  --do_train \\\n  --do_eval \\\n  --per_device_train_batch_size 8 \\\n  --learning_rate 1e-3 \\\n  --num_train_epochs 1 \\\n  --max_seq_length 384 \\\n  --doc_stride 128 \\\n  --output_dir mt5-large-v1 \\\n  --logging_steps 1 \\\n  --bf16 \\\n  --gradient_accumulation_steps 4 \\\n  --gradient_checkpointing True \\\n  --optim adafactor\n\n\n\n\n{\n   \"eval/loss\":0.9061169624328612,\n   \"_timestamp\":1686240530.1377208,\n   \"_step\":370,\n   \"_runtime\":902.276704788208,\n   \"train/global_step\":369,\n   \"eval/steps_per_second\":7.803,\n   \"train/train_steps_per_second\":0.425,\n   \"_wandb.runtime\":902,\n   \"train/epoch\":1,\n   \"train/total_flos\":26479261148774400,\n   \"train/loss\":0.1842,\n   \"train/train_loss\":0.6567919482060565,\n   \"train/learning_rate\":0,\n   \"train/train_runtime\":868.8715,\n   \"eval/samples_per_second\":62.341,\n   \"train/train_samples_per_second\":13.588,\n   \"eval/runtime\":25.12\n}", "size_bytes": "4918515385", "downloads": 2}