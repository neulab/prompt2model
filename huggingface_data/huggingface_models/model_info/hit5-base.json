{"pretrained_model_name": "hiiamsid/hit5-base", "description": "---\nlanguage: [\"hi\"]\ntags:\n- hindi\nlicense: mit\n---\nThis is a smaller version of the [google/mt5-base](https://huggingface.co/google/mt5-base) model with only hindi embeddings left. \n* The original model has 582M parameters, with 237M of them being input and output embeddings. \n* After shrinking the `sentencepiece` vocabulary from 250K to 25K (top 25K Hindi tokens) the number of model parameters reduced to 237M parameters, and model size reduced from 2.2GB to 0.9GB - 42% of the original one.\n## Citing & Authors\n- Model : [google/mt5-base](https://huggingface.co/google/mt5-base)\n- Reference: [cointegrated/rut5-base](https://huggingface.co/cointegrated/rut5-base)", "size_bytes": "950350925", "downloads": 2}