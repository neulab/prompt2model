{"pretrained_model_name": "Kyrmasch/t5-kazakh-qa", "description": "---\nlicense: apache-2.0\nwidget:\n- text: >-\n    \u049a\u0430\u0437\u0430\u049b\u0441\u0442\u0430\u043d \u0415\u0443\u0440\u0430\u0437\u0438\u044f \u049b\u04b1\u0440\u043b\u044b\u0493\u044b\u043d\u044b\u04a3 \u043e\u0440\u0442\u0430\u043b\u044b\u0493\u044b\u043d\u0434\u0430 \u043e\u0440\u043d\u0430\u043b\u0430\u0441\u049b\u0430\u043d \u0436\u04d9\u043d\u0435 \u0430\u0443\u043c\u0430\u049b\u0442\u044b\u04a3 \u043a\u04e9\u043b\u0435\u043c\u0456\n    \u0431\u043e\u0439\u044b\u043d\u0448\u0430 (\u0436\u0435\u0440 \u0448\u0430\u0440\u044b\u043d\u044b\u04a3 \u0431\u0435\u0442\u0456\u043d\u0434\u0435 2%) \u04d9\u043b\u0435\u043c\u0434\u0435 \u0442\u043e\u0493\u044b\u0437\u044b\u043d\u0448\u044b \u043e\u0440\u044b\u043d\u0493\u0430 \u0438\u0435. \u049a\u0430\u0437\u0430\u049b\u0441\u0442\u0430\u043d\n    \u0430\u0443\u043c\u0430\u0493\u044b \u0431\u04af\u043a\u0456\u043b \u0411\u0430\u0442\u044b\u0441 \u0415\u0443\u0440\u043e\u043f\u0430\u0434\u0430\u043d \u04af\u043b\u043a\u0435\u043d. \u049a\u0430\u0437\u0430\u049b\u0441\u0442\u0430\u043d \u0436\u0435\u0440 \u043a\u04e9\u043b\u0435\u043c\u0456 \u0436\u04e9\u043d\u0456\u043d\u0435\u043d \u0434\u04af\u043d\u0438\u0435\n    \u0436\u04af\u0437\u0456\u043d\u0434\u0435 \u043d\u0435\u0448\u0456\u043d\u0448\u0456 \u043e\u0440\u044b\u043d\u0434\u0430?\n  example_title: example 1\n- text: >-\n    \u049a\u0430\u0440 \u04b1\u0441\u0430\u049b \u043c\u04b1\u0437 \u043a\u0440\u0438\u0441\u0442\u0430\u043b\u0434\u0430\u0440\u044b\u043d\u0430\u043d \u0442\u04b1\u0440\u0430\u0434\u044b. \u049a\u0430\u0440 \u0434\u0435\u043f \u0430\u0442\u043c\u043e\u0441\u0444\u0435\u0440\u0430\u043b\u044b\u049b \u0436\u0430\u0443\u044b\u043d-\u0448\u0430\u0448\u044b\u043d\u0434\u044b \u0430\u0439\u0442\u0430\u0434\u044b. \u049a\u0430\u0440 \u0434\u0435\u0433\u0435\u043d \u043d\u0435?\n  example_title: example 2\n- text: >-\n    \u0410\u0431\u0430\u0439 \u0430\u049b\u044b\u043d \u0442\u0443\u0440\u0430\u043b\u044b 4 \u0442\u043e\u043c\u0434\u044b\u049b \"\u0410\u0431\u0430\u0439 \u0436\u043e\u043b\u044b\" \u0440\u043e\u043c\u0430\u043d\u044b \u0436\u0430\u0437\u044b\u043b\u0493\u0430\u043d. \u0411\u04b1\u043b \u0440\u043e\u043c\u0430\u043d\u043d\u044b\u04a3 \u0430\u0432\u0442\u043e\u0440\u044b \u041c\u04b1\u0445\u0442\u0430\u0440 \u04d8\u0443\u0435\u0437\u043e\u0432. \u0411\u04b1\u043b \u043a\u0456\u0442\u0430\u043f\u0442\u0430\u0440\u0434\u0430 \u0431\u0430\u043b\u0430 \u0410\u0431\u0430\u0439\u0434\u044b\u04a3 \u0442\u04b1\u043b\u0493\u0430, \u04d9\u0440\u0456 \u0431\u043e\u043b\u0430\u0448\u0430\u049b \u0430\u049b\u044b\u043d \u0431\u043e\u043b\u044b\u043f \u049b\u0430\u043b\u044b\u043f\u0442\u0430\u0441\u049b\u0430\u043d\u0493\u0430 \u0434\u0435\u0439\u0456\u043d\u0433\u0456 \u0443\u0430\u049b\u044b\u0442\u0442\u0430\u0440 \u043a\u0435\u0437\u0435\u04a3\u0434\u0435\u0440\u043c\u0435\u043d \u0436\u0430\u0437\u044b\u043b\u0493\u0430\u043d. \u00ab\u0410\u0431\u0430\u0439 \u0436\u043e\u043b\u044b\u00bb \u0440\u043e\u043c\u0430\u043d\u044b\u043d \u0436\u0430\u0437\u0493\u0430\u043d \u043a\u0456\u043c?\n  example_title: example 3\nlanguage:\n- kk\n---\n## Model Details\n- **Developed by**: Aldiyar Saken, Sultaniyar Quandyq, Alibek Kamiluly, Kurmash Apayev and Aliya Nugumanova.\n\n## Model Description\n\nThis model is based on the google/mt5-large model. The model was fine-tuned on a Kazakh language version of the Stanford Question Answering Dataset (SQuAD) using 30,000 samples.\n\n## Inference\n\n```python\n\nfrom transformers import T5Tokenizer, T5TokenizerFast\nfrom transformers import T5ForConditionalGeneration\nimport sentencepiece\n\ntokenizer = T5Tokenizer.from_pretrained(\"Kyrmasch/t5-kazakh-qa\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"Kyrmasch/t5-kazakh-qa\")\n\ncontext = \"\u049a\u0430\u0437\u0430\u049b\u0441\u0442\u0430\u043d \u0415\u0443\u0440\u0430\u0437\u0438\u044f \u049b\u04b1\u0440\u043b\u044b\u0493\u044b\u043d\u044b\u04a3 \u043e\u0440\u0442\u0430\u043b\u044b\u0493\u044b\u043d\u0434\u0430 \u043e\u0440\u043d\u0430\u043b\u0430\u0441\u049b\u0430\u043d \u0436\u04d9\u043d\u0435 \u0430\u0443\u043c\u0430\u049b\u0442\u044b\u04a3 \u043a\u04e9\u043b\u0435\u043c\u0456 \u0431\u043e\u0439\u044b\u043d\u0448\u0430 (\u0436\u0435\u0440 \u0448\u0430\u0440\u044b\u043d\u044b\u04a3 \u0431\u0435\u0442\u0456\u043d\u0434\u0435 2%) \u04d9\u043b\u0435\u043c\u0434\u0435 \u0442\u043e\u0493\u044b\u0437\u044b\u043d\u0448\u044b \u043e\u0440\u044b\u043d\u0493\u0430 \u0438\u0435. \u049a\u0430\u0437\u0430\u049b\u0441\u0442\u0430\u043d \u0430\u0443\u043c\u0430\u0493\u044b \u0431\u04af\u043a\u0456\u043b \u0411\u0430\u0442\u044b\u0441 \u0415\u0443\u0440\u043e\u043f\u0430\u0434\u0430\u043d \u04af\u043b\u043a\u0435\u043d.\"\nquestion = \"\u049a\u0430\u0437\u0430\u049b\u0441\u0442\u0430\u043d \u0436\u0435\u0440 \u043a\u04e9\u043b\u0435\u043c\u0456 \u0436\u04e9\u043d\u0456\u043d\u0435\u043d \u0434\u04af\u043d\u0438\u0435 \u0436\u04af\u0437\u0456\u043d\u0434\u0435 \u043d\u0435\u0448\u0456\u043d\u0448\u0456 \u043e\u0440\u044b\u043d\u0434\u0430?\"\n\nencoded = tokenizer.encode_plus(context, question, max_length=128, pad_to_max_length=True, truncation=True, return_tensors=\"pt\")\ninput_ids = encoded[\"input_ids\"].to('cpu')\nattention_mask = encoded[\"attention_mask\"].to('cpu')\noutput = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\nanswer = ''.join([tokenizer.decode(ids, skip_special_tokens=True) for ids in output])\n```", "size_bytes": "3024807045", "downloads": 22}