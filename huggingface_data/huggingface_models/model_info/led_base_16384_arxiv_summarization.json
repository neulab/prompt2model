{"pretrained_model_name": "ArtifactAI/led_base_16384_arxiv_summarization", "description": "---\nlanguage: en\nlicense: apache-2.0\ntags:\n- summarization\ndatasets: arxiv-summarization\n---\n\n## Introduction\n\nA led-base-16384 model to summarize ArXiv papers. Inputs are the abstracts of papers and full documents, and outputs are the summaries of the papers.\n\n[Allenai's Longformer Encoder-Decoder (LED)](https://github.com/allenai/longformer#longformer).\n\nAs described in [Longformer: The Long-Document Transformer](https://arxiv.org/pdf/2004.05150.pdf) by Iz Beltagy, Matthew E. Peters, Arman Cohan, *led-base-16384* was initialized from [*bart-base*](https://huggingface.co/facebook/bart-base) since both models share the exact same architecture. To be able to process 16K tokens, *bart-base*'s position embedding matrix was simply copied 16 times.\n\n### Rouge 2\n\n| Type | Score |\n| --- | --- |\n| `precision` | 0.1839148953011932 |\n| `recall` | 0.14904707945189774 |\n| `fmeasure` | 0.1580026685776864 |", "size_bytes": "647678513", "downloads": 171}