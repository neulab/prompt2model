{"pretrained_model_name": "DReAMy-lib/t5-base-DreamBank-Generation-Act-Char", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\n- relation-extraction\nmetrics:\n- rouge\nmodel-index:\n- name: t5-base-DreamBank-Generation-Act-Char\n  results: []\nlanguage:\n- en\ninference:\n  parameters:\n    max_length: 128\nwidget:\n- text: >-\n    I was skating on the outdoor ice pond that used to be across the street from\n    my house. I was not alone, but I did not recognize any of the other people\n    who were skating around. I went through my whole repertoire of jumps,\n    spires, and steps-some of which I can do and some of which I'm not yet sure\n    of. They were all executed flawlessly-some I repeated, some I did only once.\n    I seemed to know that if I went into competition, I would be sure of coming\n    in third because there were only three contestants. Up to that time I hadn't\n    considered it because I hadn't thought I was good enough, but now since\n    everything was going so well, I decided to enter.\n  example_title: Dream 1\n- text: >-\n    I was talking on the telephone to the father of an old friend of mine (boy,\n    21 years old). We were discussing the party the Saturday night before to\n    which I had invited his son as a guest. I asked him if his son had a good\n    time at the party. He told me not to tell his son that he had told me, but\n    that he had had a good time, except he was a little surprised that I had\n    acted the way I did.\n  example_title: Dream 2\n- text: I was walking alone with my dog in a forest.\n  example_title: Dream 3\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# t5-base-DreamBank-Generation-Act-Char\n\nThis model is a fine-tuned version of [DReAMy-lib/t5-base-DreamBank-Generation-NER-Char](https://huggingface.co/DReAMy-lib/t5-base-DreamBank-Generation-NER-Char) on the DreamBank dataset.\nThe uploaded model contains the weights of the best-performing model (see table below), tune to annotate a given\ndream report according to [Hall and Van de Castle the Activity feature](https://dreams.ucsc.edu/Coding/activities.html)\n\n## Model description\n\nThe model is trained end-to-end using a text2text solution to annotate dream reports following the Activity feature \nfrom the Hall and Van de Castle scoring framework. Given a report, the model generates texts of the form \n`(initialiser : activity type : receiver)`. For those cases where `initialiser` and `receiver` are the same \nentity, the output will follow the `(initialiser : alone activity type : none)` setting.\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 0.001\n- train_batch_size: 16\n- eval_batch_size: 16\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 10\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step | Validation Loss | Rouge1 | Rouge2 | Rougel | Rougelsum |\n|:-------------:|:-----:|:----:|:---------------:|:------:|:------:|:------:|:---------:|\n| No log        | 1.0   | 49   | 0.3674          | 0.4008 | 0.3122 | 0.3821 | 0.3812    |\n| No log        | 2.0   | 98   | 0.3200          | 0.4240 | 0.3433 | 0.4130 | 0.4121    |\n| No log        | 3.0   | 147  | 0.2845          | 0.4591 | 0.3883 | 0.4459 | 0.4455    |\n| No log        | 4.0   | 196  | 0.2508          | 0.4614 | 0.3930 | 0.4504 | 0.4497    |\n| No log        | 5.0   | 245  | 0.2632          | 0.4614 | 0.3929 | 0.4467 | 0.4459    |\n| No log        | 6.0   | 294  | 0.2688          | 0.4706 | 0.4036 | 0.4537 | 0.4534    |\n| No log        | 7.0   | 343  | 0.2790          | 0.4682 | 0.4043 | 0.4559 | 0.4556    |\n| No log        | 8.0   | 392  | 0.2895          | 0.4670 | 0.3972 | 0.4529 | 0.4534    |\n| No log        | 9.0   | 441  | 0.3058          | 0.4708 | 0.4040 | 0.4576 | 0.4572    |\n| No log        | 10.0  | 490  | 0.3169          | 0.4690 | 0.4001 | 0.4547 | 0.4544    |\n\n\n### Framework versions\n\n- Transformers 4.25.1\n- Pytorch 1.12.1\n- Datasets 2.5.1\n- Tokenizers 0.12.1\n", "size_bytes": "891700799", "downloads": 27}