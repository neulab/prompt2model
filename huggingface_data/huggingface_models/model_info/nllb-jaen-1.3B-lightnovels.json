{"pretrained_model_name": "thefrigidliquidation/nllb-jaen-1.3B-lightnovels", "description": "---\nlanguage:\n- en\n- ja\ntags:\n- nllb\nlicense: cc-by-nc-4.0\n---\n\n# NLLB 1.3B fine-tuned on Japanese to English Light Novel translation\n\nThis model was fine-tuned on light and web novel for Japanese to English translation.\n\nIt can translate sentences and paragraphs up to 512 tokens.\n\n\n## Usage\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"thefrigidliquidation/nllb-jaen-1.3B-lightnovels\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"thefrigidliquidation/nllb-jaen-1.3B-lightnovels\")\n\ngenerated_tokens = model.generate(\n    **inputs,\n    forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n    max_new_tokens=1024,\n    no_repeat_ngram_size=6,\n).cpu()\n\ntranslated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n```\n\nGenerating with diverse beam search seems to work best. Add the following to `model.generate`:\n```python\nnum_beams=8,\nnum_beam_groups=4,\ndo_sample=False,\n```\n\n\n## Glossary\nYou can provide up to 10 custom translations for nouns and character names at runtime. To do so, surround the Japanese term with term tokens. Prefix the word with one of `<t0>, <t1>, ..., <t9>` and suffix the word with `</t>`. The term will be translated as the prefix term token which can then be string replaced.\n\nFor example, in `\u30de\u30a4\u30f3\u3001\u30eb\u30c3\u30c4\u304c\u8fce\u3048\u306b\u6765\u305f\u3088` if you wish to have `\u30de\u30a4\u30f3` translated as `Myne` you would replace `\u30de\u30a4\u30f3` with `<t0>\u30de\u30a4\u30f3</t>`. The model will translate `<t0>\u30de\u30a4\u30f3</t>\u3001\u30eb\u30c3\u30c4\u304c\u8fce\u3048\u306b\u6765\u305f\u3088` as `<t0>, Lutz is here to pick you up.` Then simply do a string replacement on the output, replacing `<t0>` with `Myne`.\n\n\n## Honorifics\nYou can force the model to generate or ignore honorifics.\n\n```python\n# default, the model decides whether to use honorifics\ntokenizer.tgt_lang = \"jpn_Jpan\"\n# no honorifics, the model is discouraged from using honorifics\ntokenizer.tgt_lang = \"zsm_Latn\"\n# honorifics, the model is encouraged to use honorifics\ntokenizer.tgt_lang = \"zul_Latn\"\n```\n", "size_bytes": "5495548056", "downloads": 98}