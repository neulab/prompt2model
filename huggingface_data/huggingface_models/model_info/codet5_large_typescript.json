{"pretrained_model_name": "mishasadhaker/codet5_large_typescript", "description": "---\ndatasets:\n- bleugreen/typescript-instruct\nlanguage:\n- en\ntags:\n- code\n---\n\nThis model is a fune-tuned version of codet5-large on Typescript instruct-code pairs. \n\nTo run this model, you can use following example:\n\n```\nimport torch \ndevice = torch.device('cuda:0') if torch.cuda.is_available() else None\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration\n\ndef generate_code(task_description):\n    # Prepare the task description\n    input_ids = tokenizer.encode(task_description, return_tensors='pt').to(device)\n\n    # Generate the output\n    with torch.no_grad():\n        output_ids = model.generate(input_ids, max_length=200, temperature=0.7, num_beams=5)\n\n    # Decode the output\n    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n    return output\n\nmodel = T5ForConditionalGeneration.from_pretrained('mishasadhaker/codet5_large_typescript').to(device)\ntokenizer = AutoTokenizer.from_pretrained('mishasadhaker/codet5_large_typescript')\n\nprint(generate_code('write function for sum of two numbers and return it'))\n```\n", "size_bytes": "2950733825", "downloads": 26}