{"pretrained_model_name": "Helsinki-NLP/opus-mt-urj-en", "description": "---\nlanguage: \n- se\n- fi\n- hu\n- et\n- urj\n- en\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### urj-eng\n\n* source group: Uralic languages \n* target group: English \n*  OPUS readme: [urj-eng](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/urj-eng/README.md)\n\n*  model: transformer\n* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro\n* target language(s): eng\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* download original weights: [opus2m-2020-08-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.zip)\n* test set translations: [opus2m-2020-08-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.test.txt)\n* test set scores: [opus2m-2020-08-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| newsdev2015-enfi-fineng.fin.eng \t| 22.7 \t| 0.511 |\n| newsdev2018-enet-esteng.est.eng \t| 26.6 \t| 0.545 |\n| newssyscomb2009-huneng.hun.eng \t| 21.3 \t| 0.493 |\n| newstest2009-huneng.hun.eng \t| 20.1 \t| 0.487 |\n| newstest2015-enfi-fineng.fin.eng \t| 23.9 \t| 0.521 |\n| newstest2016-enfi-fineng.fin.eng \t| 25.8 \t| 0.542 |\n| newstest2017-enfi-fineng.fin.eng \t| 28.9 \t| 0.562 |\n| newstest2018-enet-esteng.est.eng \t| 27.0 \t| 0.552 |\n| newstest2018-enfi-fineng.fin.eng \t| 21.2 \t| 0.492 |\n| newstest2019-fien-fineng.fin.eng \t| 25.3 \t| 0.531 |\n| newstestB2016-enfi-fineng.fin.eng \t| 21.3 \t| 0.500 |\n| newstestB2017-enfi-fineng.fin.eng \t| 24.4 \t| 0.528 |\n| newstestB2017-fien-fineng.fin.eng \t| 24.4 \t| 0.528 |\n| Tatoeba-test.chm-eng.chm.eng \t| 0.8 \t| 0.131 |\n| Tatoeba-test.est-eng.est.eng \t| 34.5 \t| 0.526 |\n| Tatoeba-test.fin-eng.fin.eng \t| 28.1 \t| 0.485 |\n| Tatoeba-test.fkv-eng.fkv.eng \t| 6.8 \t| 0.335 |\n| Tatoeba-test.hun-eng.hun.eng \t| 25.1 \t| 0.452 |\n| Tatoeba-test.izh-eng.izh.eng \t| 11.6 \t| 0.224 |\n| Tatoeba-test.kom-eng.kom.eng \t| 2.4 \t| 0.110 |\n| Tatoeba-test.krl-eng.krl.eng \t| 18.6 \t| 0.365 |\n| Tatoeba-test.liv-eng.liv.eng \t| 0.5 \t| 0.078 |\n| Tatoeba-test.mdf-eng.mdf.eng \t| 1.5 \t| 0.117 |\n| Tatoeba-test.multi.eng \t| 47.8 \t| 0.646 |\n| Tatoeba-test.myv-eng.myv.eng \t| 0.5 \t| 0.101 |\n| Tatoeba-test.sma-eng.sma.eng \t| 1.2 \t| 0.110 |\n| Tatoeba-test.sme-eng.sme.eng \t| 1.5 \t| 0.147 |\n| Tatoeba-test.udm-eng.udm.eng \t| 1.0 \t| 0.130 |\n\n\n### System Info: \n- hf_name: urj-eng\n\n- source_languages: urj\n\n- target_languages: eng\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/urj-eng/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['se', 'fi', 'hu', 'et', 'urj', 'en']\n\n- src_constituents: {'izh', 'mdf', 'vep', 'vro', 'sme', 'myv', 'fkv_Latn', 'krl', 'fin', 'hun', 'kpv', 'udm', 'liv_Latn', 'est', 'mhr', 'sma'}\n\n- tgt_constituents: {'eng'}\n\n- src_multilingual: True\n\n- tgt_multilingual: False\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.test.txt\n\n- src_alpha3: urj\n\n- tgt_alpha3: eng\n\n- short_pair: urj-en\n\n- chrF2_score: 0.6459999999999999\n\n- bleu: 47.8\n\n- brevity_penalty: 0.993\n\n- ref_len: 70882.0\n\n- src_name: Uralic languages\n\n- tgt_name: English\n\n- train_date: 2020-08-01\n\n- src_alpha2: urj\n\n- tgt_alpha2: en\n\n- prefer_old: False\n\n- long_pair: urj-eng\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "299658045", "downloads": 9}