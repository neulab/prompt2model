{"pretrained_model_name": "EnglishVoice/t5-base-uk-to-us-english", "description": "---\nlanguage:\n- en\ntags:\n- text2text-generation\n- paraphrase-generation\nlicense: apache-2.0\nwidget:\n - text: \"UK to US: My favourite colour is yellow.\"\n---\n\n### About the model\n\nThe model has been trained on a dataset containing [264519 sentences with UK English spelling](https://www.englishvoice.ai/p/uk-to-us/ \"264519 sentences with UK English spelling\"), along with their US English equivalent.\n\nThe purpose of the model is to rewrite sentences from UK English to US English. It is capable not only of changing the spelling of words (such as \"colour\" to \"color\") but also changes the vocabulary appropriately (for example, \"underground\" to \"subway\", \"solicitor\" to \"lawyer\" and so on).\n\n### Generation examples\n\n| Input | Output |\n| :------------ | :------------ |\n| My favourite colour is yellow. | My favorite color is yellow. |\n| I saw a bloke in yellow trainers at the underground station. | I saw a guy in yellow sneakers at the subway station. |\n| You could have got hurt! | You could have gotten hurt! |\n\n### The dataset\n\nThe dataset was developed by English Voice AI Labs. You can download it from our website:\n[https://www.EnglishVoice.ai/](https://www.EnglishVoice.ai/ \"https://www.EnglishVoice.ai/\")\n\n### Sample code\n\nSample Python code:\n\n```python\nimport torch\nfrom transformers import T5ForConditionalGeneration,T5Tokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"EnglishVoice/t5-base-uk-to-us-english\")\ntokenizer = T5Tokenizer.from_pretrained(\"EnglishVoice/t5-base-uk-to-us-english\")\nmodel = model.to(device)\n\ninput = \"My favourite colour is yellow.\"\n\ntext =  \"UK to US: \" + input\nencoding = tokenizer.encode_plus(text, return_tensors = \"pt\")\ninput_ids = encoding[\"input_ids\"].to(device)\nattention_masks = encoding[\"attention_mask\"].to(device)\nbeam_outputs = model.generate(\n    input_ids = input_ids,\n    attention_mask = attention_masks,\n    early_stopping = True,\n)\n\nresult = tokenizer.decode(beam_outputs[0], skip_special_tokens=True)\nprint(result)\n\n```\n\nOutput:\n\n```My favorite color is yellow.```\n", "size_bytes": "891730879", "downloads": 46}