{"pretrained_model_name": "Helsinki-NLP/opus-mt-en-zlw", "description": "---\nlanguage: \n- en\n- pl\n- cs\n- zlw\n\ntags:\n- translation\n\nlicense: apache-2.0\n---\n\n### eng-zlw\n\n* source group: English \n* target group: West Slavic languages \n*  OPUS readme: [eng-zlw](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-zlw/README.md)\n\n*  model: transformer\n* source language(s): eng\n* target language(s): ces csb_Latn dsb hsb pol\n* model: transformer\n* pre-processing: normalization + SentencePiece (spm32k,spm32k)\n* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)\n* download original weights: [opus2m-2020-08-02.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-zlw/opus2m-2020-08-02.zip)\n* test set translations: [opus2m-2020-08-02.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-zlw/opus2m-2020-08-02.test.txt)\n* test set scores: [opus2m-2020-08-02.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-zlw/opus2m-2020-08-02.eval.txt)\n\n## Benchmarks\n\n| testset               | BLEU  | chr-F |\n|-----------------------|-------|-------|\n| newssyscomb2009-engces.eng.ces \t| 20.6 \t| 0.488 |\n| news-test2008-engces.eng.ces \t| 18.3 \t| 0.466 |\n| newstest2009-engces.eng.ces \t| 19.8 \t| 0.483 |\n| newstest2010-engces.eng.ces \t| 19.8 \t| 0.486 |\n| newstest2011-engces.eng.ces \t| 20.6 \t| 0.489 |\n| newstest2012-engces.eng.ces \t| 18.6 \t| 0.464 |\n| newstest2013-engces.eng.ces \t| 22.3 \t| 0.495 |\n| newstest2015-encs-engces.eng.ces \t| 21.7 \t| 0.502 |\n| newstest2016-encs-engces.eng.ces \t| 24.5 \t| 0.521 |\n| newstest2017-encs-engces.eng.ces \t| 20.1 \t| 0.480 |\n| newstest2018-encs-engces.eng.ces \t| 19.9 \t| 0.483 |\n| newstest2019-encs-engces.eng.ces \t| 21.2 \t| 0.490 |\n| Tatoeba-test.eng-ces.eng.ces \t| 43.7 \t| 0.632 |\n| Tatoeba-test.eng-csb.eng.csb \t| 1.2 \t| 0.188 |\n| Tatoeba-test.eng-dsb.eng.dsb \t| 1.5 \t| 0.167 |\n| Tatoeba-test.eng-hsb.eng.hsb \t| 5.7 \t| 0.199 |\n| Tatoeba-test.eng.multi \t| 42.8 \t| 0.632 |\n| Tatoeba-test.eng-pol.eng.pol \t| 43.2 \t| 0.641 |\n\n\n### System Info: \n- hf_name: eng-zlw\n\n- source_languages: eng\n\n- target_languages: zlw\n\n- opus_readme_url: https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/eng-zlw/README.md\n\n- original_repo: Tatoeba-Challenge\n\n- tags: ['translation']\n\n- languages: ['en', 'pl', 'cs', 'zlw']\n\n- src_constituents: {'eng'}\n\n- tgt_constituents: {'csb_Latn', 'dsb', 'hsb', 'pol', 'ces'}\n\n- src_multilingual: False\n\n- tgt_multilingual: True\n\n- prepro:  normalization + SentencePiece (spm32k,spm32k)\n\n- url_model: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-zlw/opus2m-2020-08-02.zip\n\n- url_test_set: https://object.pouta.csc.fi/Tatoeba-MT-models/eng-zlw/opus2m-2020-08-02.test.txt\n\n- src_alpha3: eng\n\n- tgt_alpha3: zlw\n\n- short_pair: en-zlw\n\n- chrF2_score: 0.632\n\n- bleu: 42.8\n\n- brevity_penalty: 0.973\n\n- ref_len: 65397.0\n\n- src_name: English\n\n- tgt_name: West Slavic languages\n\n- train_date: 2020-08-02\n\n- src_alpha2: en\n\n- tgt_alpha2: zlw\n\n- prefer_old: False\n\n- long_pair: eng-zlw\n\n- helsinki_git_sha: 480fcbe0ee1bf4774bcbe6226ad9f58e63f6c535\n\n- transformers_git_sha: 2207e5d8cb224e954a7cba69fa4ac2309e9ff30b\n\n- port_machine: brutasse\n\n- port_time: 2020-08-21-14:41", "size_bytes": "297827661", "downloads": 69}