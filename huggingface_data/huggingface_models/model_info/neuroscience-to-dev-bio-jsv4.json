{"pretrained_model_name": "levinlab/neuroscience-to-dev-bio-jsv4", "description": "---\nlicense: apache-2.0\ntags:\n- generated_from_trainer\nmodel-index:\n- name: neuroscience-to-dev-bio-jsv4\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# neuroscience-to-dev-bio-jsv4\n\nThis model is a fine-tuned version of [facebook/bart-large](https://huggingface.co/facebook/bart-large) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 0.0695\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 1e-05\n- train_batch_size: 1\n- eval_batch_size: 1\n- seed: 42\n- gradient_accumulation_steps: 128\n- total_train_batch_size: 128\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- lr_scheduler_warmup_steps: 100\n- num_epochs: 100000\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch  | Step | Validation Loss |\n|:-------------:|:------:|:----:|:---------------:|\n| 24.3287       | 0.76   | 3    | 18.8652         |\n| 18.1915       | 1.78   | 7    | 18.8556         |\n| 18.1215       | 2.79   | 11   | 18.8221         |\n| 17.8507       | 3.81   | 15   | 18.6982         |\n| 17.0492       | 4.83   | 19   | 18.2237         |\n| 15.9062       | 5.84   | 23   | 17.5422         |\n| 14.8768       | 6.86   | 27   | 16.4438         |\n| 14.0759       | 7.87   | 31   | 15.5454         |\n| 13.5381       | 8.89   | 35   | 14.7087         |\n| 13.0031       | 9.9    | 39   | 13.8568         |\n| 12.5788       | 10.92  | 43   | 13.2354         |\n| 12.2285       | 11.94  | 47   | 12.7442         |\n| 11.9333       | 12.95  | 51   | 12.3690         |\n| 11.6802       | 13.97  | 55   | 12.0725         |\n| 11.4449       | 14.98  | 59   | 11.7544         |\n| 11.1385       | 16.0   | 63   | 11.3739         |\n| 14.4029       | 16.76  | 66   | 11.0449         |\n| 10.5022       | 17.78  | 70   | 10.6118         |\n| 10.1749       | 18.79  | 74   | 10.1711         |\n| 9.8214        | 19.81  | 78   | 9.6969          |\n| 9.4196        | 20.83  | 82   | 9.1333          |\n| 8.9308        | 21.84  | 86   | 8.3086          |\n| 8.3288        | 22.86  | 90   | 7.4233          |\n| 7.7657        | 23.87  | 94   | 6.8660          |\n| 7.3611        | 24.89  | 98   | 6.5694          |\n| 7.0561        | 25.9   | 102  | 6.3261          |\n| 6.8051        | 26.92  | 106  | 6.1499          |\n| 6.5919        | 27.94  | 110  | 5.9731          |\n| 6.4156        | 28.95  | 114  | 5.8249          |\n| 6.2572        | 29.97  | 118  | 5.6809          |\n| 6.1213        | 30.98  | 122  | 5.5631          |\n| 5.993         | 32.0   | 126  | 5.4450          |\n| 7.8389        | 32.76  | 129  | 5.3694          |\n| 5.7759        | 33.78  | 133  | 5.2713          |\n| 5.6726        | 34.79  | 137  | 5.1745          |\n| 5.5731        | 35.81  | 141  | 5.0841          |\n| 5.4773        | 36.83  | 145  | 4.9938          |\n| 5.3928        | 37.84  | 149  | 4.9069          |\n| 5.2863        | 38.86  | 153  | 4.8186          |\n| 5.1979        | 39.87  | 157  | 4.7304          |\n| 5.1039        | 40.89  | 161  | 4.6431          |\n| 5.0214        | 41.9   | 165  | 4.5553          |\n| 4.9208        | 42.92  | 169  | 4.4656          |\n| 4.8369        | 43.94  | 173  | 4.3771          |\n| 4.7415        | 44.95  | 177  | 4.2874          |\n| 4.6508        | 45.97  | 181  | 4.1996          |\n| 4.5609        | 46.98  | 185  | 4.1074          |\n| 4.4651        | 48.0   | 189  | 4.0151          |\n| 5.8328        | 48.76  | 192  | 3.9468          |\n| 4.2769        | 49.78  | 196  | 3.8541          |\n| 4.19          | 50.79  | 200  | 3.7615          |\n| 4.0956        | 51.81  | 204  | 3.6687          |\n| 3.9945        | 52.83  | 208  | 3.5726          |\n| 3.904         | 53.84  | 212  | 3.4752          |\n| 3.8107        | 54.86  | 216  | 3.3814          |\n| 3.7135        | 55.87  | 220  | 3.2854          |\n| 3.6174        | 56.89  | 224  | 3.1882          |\n| 3.5205        | 57.9   | 228  | 3.0898          |\n| 3.4233        | 58.92  | 232  | 2.9924          |\n| 3.333         | 59.94  | 236  | 2.8947          |\n| 3.2258        | 60.95  | 240  | 2.7939          |\n| 3.1279        | 61.97  | 244  | 2.6950          |\n| 3.0278        | 62.98  | 248  | 2.5971          |\n| 2.9348        | 64.0   | 252  | 2.4995          |\n| 3.7766        | 64.76  | 255  | 2.4249          |\n| 2.7327        | 65.78  | 259  | 2.3260          |\n| 2.6385        | 66.79  | 263  | 2.2277          |\n| 2.5418        | 67.81  | 267  | 2.1310          |\n| 2.4482        | 68.83  | 271  | 2.0338          |\n| 2.3636        | 69.84  | 275  | 1.9374          |\n| 2.2525        | 70.86  | 279  | 1.8416          |\n| 2.1472        | 71.87  | 283  | 1.7484          |\n| 2.0559        | 72.89  | 287  | 1.6557          |\n| 1.9571        | 73.9   | 291  | 1.5656          |\n| 1.8667        | 74.92  | 295  | 1.4765          |\n| 1.7716        | 75.94  | 299  | 1.3897          |\n| 1.6853        | 76.95  | 303  | 1.3049          |\n| 1.5902        | 77.97  | 307  | 1.2224          |\n| 1.5023        | 78.98  | 311  | 1.1420          |\n| 1.4194        | 80.0   | 315  | 1.0651          |\n| 1.7788        | 80.76  | 318  | 1.0091          |\n| 1.2485        | 81.78  | 322  | 0.9366          |\n| 1.1745        | 82.79  | 326  | 0.8685          |\n| 1.0937        | 83.81  | 330  | 0.8023          |\n| 1.0191        | 84.83  | 334  | 0.7405          |\n| 0.9504        | 85.84  | 338  | 0.6814          |\n| 0.8818        | 86.86  | 342  | 0.6264          |\n| 0.8132        | 87.87  | 346  | 0.5749          |\n| 0.7557        | 88.89  | 350  | 0.5265          |\n| 0.6961        | 89.9   | 354  | 0.4816          |\n| 0.6379        | 90.92  | 358  | 0.4399          |\n| 0.5835        | 91.94  | 362  | 0.4015          |\n| 0.5349        | 92.95  | 366  | 0.3657          |\n| 0.4894        | 93.97  | 370  | 0.3336          |\n| 0.448         | 94.98  | 374  | 0.3042          |\n| 0.4121        | 96.0   | 378  | 0.2773          |\n| 0.4961        | 96.76  | 381  | 0.2595          |\n| 0.3365        | 97.78  | 385  | 0.2378          |\n| 0.3104        | 98.79  | 389  | 0.2192          |\n| 0.2786        | 99.81  | 393  | 0.2009          |\n| 0.2543        | 100.83 | 397  | 0.1836          |\n| 0.2335        | 101.84 | 401  | 0.1681          |\n| 0.2148        | 102.86 | 405  | 0.1549          |\n| 0.1932        | 103.87 | 409  | 0.1435          |\n| 0.1766        | 104.89 | 413  | 0.1328          |\n| 0.1607        | 105.9  | 417  | 0.1236          |\n| 0.1451        | 106.92 | 421  | 0.1170          |\n| 0.1314        | 107.94 | 425  | 0.1103          |\n| 0.1196        | 108.95 | 429  | 0.1075          |\n| 0.1094        | 109.97 | 433  | 0.1015          |\n| 0.102         | 110.98 | 437  | 0.0897          |\n| 0.0916        | 112.0  | 441  | 0.0855          |\n| 0.1094        | 112.76 | 444  | 0.0823          |\n| 0.0754        | 113.78 | 448  | 0.0790          |\n| 0.073         | 114.79 | 452  | 0.0775          |\n| 0.0656        | 115.81 | 456  | 0.0734          |\n| 0.0575        | 116.83 | 460  | 0.0712          |\n| 0.0525        | 117.84 | 464  | 0.0680          |\n| 0.0492        | 118.86 | 468  | 0.0667          |\n| 0.0467        | 119.87 | 472  | 0.0650          |\n| 0.042         | 120.89 | 476  | 0.0639          |\n| 0.0385        | 121.9  | 480  | 0.0648          |\n| 0.0355        | 122.92 | 484  | 0.0643          |\n| 0.0338        | 123.94 | 488  | 0.0674          |\n| 0.033         | 124.95 | 492  | 0.0635          |\n| 0.0288        | 125.97 | 496  | 0.0643          |\n| 0.0279        | 126.98 | 500  | 0.0634          |\n| 0.0288        | 128.0  | 504  | 0.0630          |\n| 0.034         | 128.76 | 507  | 0.0640          |\n| 0.0225        | 129.78 | 511  | 0.0641          |\n| 0.0212        | 130.79 | 515  | 0.0683          |\n| 0.022         | 131.81 | 519  | 0.0655          |\n| 0.0197        | 132.83 | 523  | 0.0692          |\n| 0.0192        | 133.84 | 527  | 0.0687          |\n| 0.0188        | 134.86 | 531  | 0.0672          |\n| 0.0184        | 135.87 | 535  | 0.0695          |\n\n\n### Framework versions\n\n- Transformers 4.27.3\n- Pytorch 1.13.1+cu116\n- Datasets 2.10.1\n- Tokenizers 0.13.2\n", "size_bytes": "1625541389", "downloads": 10}