{"pretrained_model_name": "fabiochiu/t5-base-medium-title-generation", "description": "---\ntags:\n- generated_from_keras_callback\nmodel-index:\n- name: t5-base-medium-title-generation\n  results: []\nwidget:\n- text: \"summarize: Many financial institutions started building conversational AI, prior to the Covid19 pandemic, as part of a digital transformation initiative. These initial solutions were high profile, highly personalized virtual assistants \u2014 like the Erica chatbot from Bank of America. As the pandemic hit, the need changed as contact centers were under increased pressures. As Cathal McGloin of ServisBOT explains in 'how it started, and how it is going,' financial institutions were looking for ways to automate solutions to help get back to 'normal' levels of customer service. This resulted in a change from the 'future of conversational AI' to a real tactical assistant that can help in customer service. Haritha Dev of Wells Fargo, saw a similar trend. Banks were originally looking to conversational AI as part of digital transformation to keep up with the times. However, with the pandemic, it has been more about customer retention and customer satisfaction. In addition, new use cases came about as a result of Covid-19 that accelerated adoption of conversational AI. As Vinita Kumar of Deloitte points out, banks were dealing with an influx of calls about new concerns, like questions around the Paycheck Protection Program (PPP) loans. This resulted in an increase in volume, without enough agents to assist customers, and tipped the scale to incorporate conversational AI. When choosing initial use cases to support, financial institutions often start with high volume, low complexity tasks. For example, password resets, checking account balances, or checking the status of a transaction, as Vinita points out. From there, the use cases can evolve as the banks get more mature in developing conversational AI, and as the customers become more engaged with the solutions. Cathal indicates another good way for banks to start is looking at use cases that are a pain point, and also do not require a lot of IT support. Some financial institutions may have a multi-year technology roadmap, which can make it harder to get a new service started. A simple chatbot for document collection in an onboarding process can result in high engagement, and a high return on investment. For example, Cathal has a banking customer that implemented a chatbot to capture a driver\u2019s license to be used in the verification process of adding an additional user to an account \u2014 it has over 85% engagement with high satisfaction. An interesting use case Haritha discovered involved educating customers on financial matters. People feel more comfortable asking a chatbot what might be considered a 'dumb' question, as the chatbot is less judgmental. Users can be more ambiguous with their questions as well, not knowing the right words to use, as chatbot can help narrow things down.\"\n  example_title: \"Banking on Bots\"\n---\n\n<!-- This model card has been generated automatically according to the information Keras had access to. You should\nprobably proofread and complete it, then remove this comment. -->\n\n# Model description\n\nThis model is [t5-base](https://huggingface.co/t5-base) fine-tuned on the [190k Medium Articles](https://www.kaggle.com/datasets/fabiochiusano/medium-articles) dataset for predicting article titles using the article textual content as input.\n\nThere are two versions of the model:\n- [t5-small-medium-title-generation](https://huggingface.co/fabiochiu/t5-small-medium-title-generation): trained from [t5-small](https://huggingface.co/t5-small).\n- [t5-base-medium-title-generation](https://huggingface.co/fabiochiu/t5-base-medium-title-generation): trained from [t5-base](https://huggingface.co/t5-base).\n\nVisit the [title-generation space](https://huggingface.co/spaces/fabiochiu/title-generation) to try the model with different text generation parameters.\n\n# How to use the model\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport nltk\nnltk.download('punkt')\n\ntokenizer = AutoTokenizer.from_pretrained(\"fabiochiu/t5-small-medium-title-generation\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"fabiochiu/t5-small-medium-title-generation\")\n\ntext = \"\"\"\nMany financial institutions started building conversational AI, prior to the Covid19\npandemic, as part of a digital transformation initiative. These initial solutions\nwere high profile, highly personalized virtual assistants \u2014 like the Erica chatbot\nfrom Bank of America. As the pandemic hit, the need changed as contact centers were\nunder increased pressures. As Cathal McGloin of ServisBOT explains in \u201chow it started,\nand how it is going,\u201d financial institutions were looking for ways to automate\nsolutions to help get back to \u201cnormal\u201d levels of customer service. This resulted\nin a change from the \u201cfuture of conversational AI\u201d to a real tactical assistant\nthat can help in customer service. Haritha Dev of Wells Fargo, saw a similar trend.\nBanks were originally looking to conversational AI as part of digital transformation\nto keep up with the times. However, with the pandemic, it has been more about\ncustomer retention and customer satisfaction. In addition, new use cases came about\nas a result of Covid-19 that accelerated adoption of conversational AI. As Vinita\nKumar of Deloitte points out, banks were dealing with an influx of calls about new\nconcerns, like questions around the Paycheck Protection Program (PPP) loans. This\nresulted in an increase in volume, without enough agents to assist customers, and\ntipped the scale to incorporate conversational AI. When choosing initial use cases\nto support, financial institutions often start with high volume, low complexity\ntasks. For example, password resets, checking account balances, or checking the\nstatus of a transaction, as Vinita points out. From there, the use cases can evolve\nas the banks get more mature in developing conversational AI, and as the customers\nbecome more engaged with the solutions. Cathal indicates another good way for banks\nto start is looking at use cases that are a pain point, and also do not require a\nlot of IT support. Some financial institutions may have a multi-year technology\nroadmap, which can make it harder to get a new service started. A simple chatbot\nfor document collection in an onboarding process can result in high engagement,\nand a high return on investment. For example, Cathal has a banking customer that\nimplemented a chatbot to capture a driver\u2019s license to be used in the verification\nprocess of adding an additional user to an account \u2014 it has over 85% engagement\nwith high satisfaction. An interesting use case Haritha discovered involved\neducating customers on financial matters. People feel more comfortable asking a\nchatbot what might be considered a \u201cdumb\u201d question, as the chatbot is less judgmental.\nUsers can be more ambiguous with their questions as well, not knowing the right\nwords to use, as chatbot can help narrow things down.\n\"\"\"\n\ninputs = [\"summarize: \" + text]\n\ninputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\noutput = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\ndecoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\npredicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n\nprint(predicted_title)\n# Conversational AI: The Future of Customer Service\n```\n\n## Training and evaluation data\n\nThe model has been trained on a single epoch spanning about 16000 articles, evaluating on 1000 random articles not used during training.\n\n### Training results\n\nThe model has been evaluated on a random dataset split of 1000 articles not used during training and validation.\n\n- Rouge-1: 37.9%\n- Rouge-2: 24.4%\n- Rouge-L: 35.9%\n- Rouge-Lsum: 35.9%\n- Average length of the generated titles: 13 tokens (about 9 English words)\n\n### Framework versions\n\n- Transformers 4.18.0\n- TensorFlow 2.8.0\n- Datasets 2.1.0\n- Tokenizers 0.12.1\n", "size_bytes": "891697151", "downloads": 59}