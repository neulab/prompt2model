{"pretrained_model_name": "raptorkwok/cantonese-chinese-parallel-corpus-bart-compare-beta", "description": "---\ntags:\n- generated_from_trainer\nmetrics:\n- bleu\nmodel-index:\n- name: cantonese-chinese-parallel-corpus-bart-compare-beta\n  results: []\n---\n\n<!-- This model card has been generated automatically according to the information the Trainer had access to. You\nshould probably proofread and complete it, then remove this comment. -->\n\n# cantonese-chinese-parallel-corpus-bart-compare-beta\n\nThis model is a fine-tuned version of [fnlp/bart-base-chinese](https://huggingface.co/fnlp/bart-base-chinese) on an unknown dataset.\nIt achieves the following results on the evaluation set:\n- Loss: 1.2458\n- Bleu: 28.771\n- Chrf: 27.9227\n- Gen Len: 13.0461\n\n## Model description\n\nMore information needed\n\n## Intended uses & limitations\n\nMore information needed\n\n## Training and evaluation data\n\nMore information needed\n\n## Training procedure\n\n### Training hyperparameters\n\nThe following hyperparameters were used during training:\n- learning_rate: 2e-05\n- train_batch_size: 16\n- eval_batch_size: 16\n- seed: 42\n- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n- lr_scheduler_type: linear\n- num_epochs: 30\n- mixed_precision_training: Native AMP\n\n### Training results\n\n| Training Loss | Epoch | Step  | Validation Loss | Bleu    | Chrf    | Gen Len |\n|:-------------:|:-----:|:-----:|:---------------:|:-------:|:-------:|:-------:|\n| 1.8181        | 0.14  | 1000  | 1.5443          | 23.6818 | 23.1045 | 12.8583 |\n| 1.6135        | 0.29  | 2000  | 1.4509          | 25.1377 | 24.4034 | 12.9507 |\n| 1.5541        | 0.43  | 3000  | 1.4099          | 25.7071 | 25.0015 | 12.969  |\n| 1.5123        | 0.58  | 4000  | 1.3797          | 26.2138 | 25.4768 | 12.992  |\n| 1.4569        | 0.72  | 5000  | 1.3609          | 26.5756 | 25.8499 | 12.9691 |\n| 1.4388        | 0.87  | 6000  | 1.3363          | 26.6829 | 25.9878 | 12.972  |\n| 1.4125        | 1.01  | 7000  | 1.3226          | 26.9986 | 26.2478 | 12.9781 |\n| 1.2784        | 1.16  | 8000  | 1.3180          | 27.1567 | 26.4057 | 12.9631 |\n| 1.2827        | 1.3   | 9000  | 1.3046          | 27.4284 | 26.6004 | 13.0264 |\n| 1.2811        | 1.45  | 10000 | 1.2983          | 27.4094 | 26.6838 | 12.9371 |\n| 1.2746        | 1.59  | 11000 | 1.2949          | 27.5385 | 26.7983 | 12.9954 |\n| 1.2622        | 1.74  | 12000 | 1.2833          | 27.5652 | 26.8946 | 12.9384 |\n| 1.2712        | 1.88  | 13000 | 1.2714          | 27.8813 | 27.0855 | 13.0164 |\n| 1.2344        | 2.03  | 14000 | 1.2806          | 28.0036 | 27.1638 | 13.0395 |\n| 1.1182        | 2.17  | 15000 | 1.2761          | 27.9418 | 27.1263 | 13.0057 |\n| 1.1507        | 2.32  | 16000 | 1.2661          | 28.1307 | 27.3091 | 13.0316 |\n| 1.1433        | 2.46  | 17000 | 1.2592          | 28.337  | 27.4561 | 13.047  |\n| 1.1421        | 2.61  | 18000 | 1.2532          | 28.2723 | 27.3994 | 13.0488 |\n| 1.1374        | 2.75  | 19000 | 1.2567          | 28.3929 | 27.4904 | 13.0525 |\n| 1.1412        | 2.9   | 20000 | 1.2521          | 28.3298 | 27.5249 | 12.9892 |\n| 1.093         | 3.04  | 21000 | 1.2674          | 28.3723 | 27.587  | 12.9846 |\n| 1.0161        | 3.19  | 22000 | 1.2647          | 28.4387 | 27.609  | 13.0113 |\n| 1.0301        | 3.33  | 23000 | 1.2707          | 28.3465 | 27.5865 | 12.9886 |\n| 1.0156        | 3.48  | 24000 | 1.2539          | 28.6021 | 27.7475 | 13.0549 |\n| 1.0185        | 3.62  | 25000 | 1.2586          | 28.5173 | 27.6986 | 13.0352 |\n| 1.0287        | 3.77  | 26000 | 1.2458          | 28.771  | 27.9227 | 13.0461 |\n| 1.0486        | 3.91  | 27000 | 1.2458          | 28.6384 | 27.786  | 13.0314 |\n| 1.0041        | 4.06  | 28000 | 1.2760          | 28.6107 | 27.7425 | 13.0483 |\n| 0.938         | 4.2   | 29000 | 1.2761          | 28.6136 | 27.7685 | 13.0471 |\n\n\n### Framework versions\n\n- Transformers 4.28.1\n- Pytorch 2.0.1+cu117\n- Datasets 2.13.1\n- Tokenizers 0.13.3\n", "size_bytes": "561065693", "downloads": 4}