{"pretrained_model_name": "Den4ikAI/ruT5-small-interpreter", "description": "---\nlicense: mit\ndatasets:\n- inkoziev/incomplete_utterance_restoration\nlanguage:\n- ru\nwidget:\n- text: '- \u041a\u0430\u043a \u0442\u0435\u0431\u044f \u0437\u043e\u0432\u0443\u0442?\\n- \u0418\u0432\u0430\u043d #'\n- text: '- \u0410 \u0436\u0438\u0432\u0435\u0448\u044c \u0433\u0434\u0435?\\n- \u0412 \u041c\u043e\u0441\u043a\u0432\u0435 #'\npipeline_tag: text2text-generation\n---\n# Den4ikAI/ruT5-small-interpreter\n\u041c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u0432\u043e\u0441\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u044f \u0444\u0440\u0430\u0437\u044b \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\u0430 \u0434\u0438\u0430\u043b\u043e\u0433\u0430 (\u0430\u043d\u0430\u0444\u043e\u0440\u0430, \u044d\u043b\u043b\u0438\u043f\u0441\u0438\u0441\u044b, \u0433\u044d\u043f\u043f\u0438\u043d\u0433), \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043e\u0440\u0444\u043e\u0433\u0440\u0430\u0444\u0438\u0438 \u0438 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0442\u0435\u043a\u0441\u0442\u0430 \u0434\u0438\u0430\u043b\u043e\u0433\u043e\u0432\u044b\u0445 \u0440\u0435\u043f\u043b\u0438\u043a.\n\n\u0411\u043e\u043b\u044c\u0448\u0435 \u043e \u0437\u0430\u0434\u0430\u0447\u0435 [\u0442\u0443\u0442](https://huggingface.co/inkoziev/rugpt_interpreter).\n# \u041f\u0440\u0438\u043c\u0435\u0440 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f\n```python\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nmodel_name = 'Den4ikAI/ruT5-small-interpreter'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\nmodel.eval()\nt5_input = '''- \u0422\u044b \u0441\u043e\u0431\u0430\u043a \u043b\u044e\u0431\u0438\u0448\u044c?\n- \u041d\u0435 \u043b\u044e\u0431\u043b\u044e \u044f \u0438\u0445  #'''\ninput_ids = tokenizer(t5_input, return_tensors='pt').input_ids\nout_ids = model.generate(input_ids=input_ids, max_length=100, eos_token_id=tokenizer.eos_token_id, early_stopping=True)\nt5_output = tokenizer.decode(out_ids[0][1:])\nprint(t5_output)\n```\n# Citation\n```\n@MISC{Den4ikAI/ruT5-small-interpreter,\n    author  = {Denis Petrov, Ilya Koziev},\n    title   = {Russian conversations interpreter and normalizer},\n    url     = {https://huggingface.co/Den4ikAI/ruT5-small-interpreter},\n    year    = 2023\n}\n```\n", "size_bytes": "258646749", "downloads": 18}