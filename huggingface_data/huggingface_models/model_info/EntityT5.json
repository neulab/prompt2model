{"pretrained_model_name": "Jaren/EntityT5", "description": "---\ntags:\n- text-2-text-generation\n- t5\n\n---\n\n# Model Card for EntityT5\n \n# Model Details\n \n## Model Description\n \nT5+Trie to predict entities of the last sentence in a dialogue.\n \n- **Developed by:** Jaren Yang\n- **Shared by [Optional]:** Jaren Yang\n- **Model type:** Text2text Generation \n- **Language(s) (NLP):** More information needed\n- **License:** More information needed \n- **Parent Model:** T5\n- **Resources for more information:** More information needed \n \t\n\n\n# Uses\n \n\n## Direct Use\nThis model can be used for the task of text2text generation \n \n## Downstream Use [Optional]\n \nMore information needed.\n \n## Out-of-Scope Use\n \nThe model should not be used to intentionally create hostile or alienating environments for people. \n \n# Bias, Risks, and Limitations\n \n \nSignificant research has explored bias and fairness issues with language models (see, e.g., [Sheng et al. (2021)](https://aclanthology.org/2021.acl-long.330.pdf) and [Bender et al. (2021)](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)). Predictions generated by the model may include disturbing and harmful stereotypes across protected classes; identity characteristics; and sensitive, social, and occupational groups.\n\n\n\n## Recommendations\n \n \nUsers (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.\n\n# Training Details\n \n## Training Data\n \nMore information needed \n \n## Training Procedure\n\n \n### Preprocessing\n \nMore information needed \n \n### Speeds, Sizes, Times\nMore information needed \n\n \n# Evaluation\n \n \n## Testing Data, Factors & Metrics\n \n### Testing Data\n \nMore information needed \n \n \n### Factors\nMore information needed\n \n### Metrics\n \nMore information needed\n \n \n## Results \n \nMore information needed\n\n \n# Model Examination\n \nMore information needed\n \n# Environmental Impact\n \nCarbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).\n \n- **Hardware Type:** More information needed\n- **Hours used:** More information needed\n- **Cloud Provider:** More information needed\n- **Compute Region:** More information needed\n- **Carbon Emitted:** More information needed\n \n# Technical Specifications [optional]\n \n## Model Architecture and Objective\n\nMore information needed \n \n## Compute Infrastructure\n \nMore information needed \n \n### Hardware\n \n \nMore information needed\n \n### Software\n \nMore information needed.\n \n# Citation\n\n \n**BibTeX:**\n\nMore information needed.\n \n \n \n \n# Glossary [optional]\nMore information needed \n \n# More Information [optional]\nMore information needed \n\n \n# Model Card Authors [optional]\n \nJaren Yang in collaboration with Ezi Ozoani and the Hugging Face team\n\n\n# Model Card Contact\n \nMore information needed\n \n# How to Get Started with the Model\n \nUse the code below to get started with the model.\n \n<details>\n<summary> Click to expand </summary>\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"Jaren/EntityT5\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Jaren/EntityT5\")\n ```\n</details>\n", "size_bytes": "990452813", "downloads": 5}