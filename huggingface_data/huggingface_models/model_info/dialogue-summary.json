{"pretrained_model_name": "svjack/dialogue-summary", "description": "---\nlanguage:\n- zh\npipeline_tag: text2text-generation\ntags:\n- t5\n---\n\n```python\nfrom transformers import T5ForConditionalGeneration\nfrom transformers import T5TokenizerFast as T5Tokenizer\nmodel = \"svjack/dialogue-summary\"\ndevice = \"cpu\"\ntokenizer = T5Tokenizer.from_pretrained(model)\nmodel = T5ForConditionalGeneration.from_pretrained(model).to(device).eval()\nprompt =  '''\n\u6c64\u59c6\uff1a\u80fd\u544a\u8bc9\u6211\u5982\u4f55\u53bb\u673a\u573a\u5417\uff1f\n\u6770\u514b\uff1a\u6211\u8ba4\u4e3a\u4f60\u6700\u597d\u5ea7\u673a\u573a\u5927\u5df4\u3002\n\u6c64\u59c6\uff1a\u53ef\u662f\u6211\u6709\u4e9b\u6655\u8f66\u3002\n\u6770\u514b\uff1a\u5982\u679c\u4f60\u89c9\u5f97\u98a0\u7c38\u7684\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u5750\u5730\u94c1\u53bb\u3002\n\u6c64\u59c6\uff1a\u5730\u94c1\u9700\u8981\u591a\u957f\u65f6\u95f4\uff1f\n\u6770\u514b\uff1a1\u5c0f\u65f6\u5de6\u53f3\u3002\n\u6c64\u59c6\uff1a\u5468\u56f4\u6709\u4ec0\u4e48\u597d\u7684\u98ce\u666f\u5417\uff1f\n\u6770\u514b\uff1a\u8def\u8fc7\u9f99\u4e95\u5c71\u3002\n\u6c64\u59c6\uff1a\u90a3\u91cc\u6709\u54ea\u4e9b\u7279\u4ea7\uff1f\n\u6770\u514b\uff1a\u5c71\u4e2d\u51fa\u4ea7\u9f99\u4e95\u8336\u3002\n'''\n\nencode = tokenizer(prompt, return_tensors='pt').to(device)\nanswer = model.generate(encode.input_ids,\n                       max_length = 128,\n    num_beams=2,\n    top_p = 0.95,\n    top_k = 50,\n    repetition_penalty = 2.5,\n    length_penalty=1.0,\n    early_stopping=True,\n                       )[0]\ndecoded = tokenizer.decode(answer, skip_special_tokens=True)\ndecoded\n```\n\n'''\n'\u6c64\u59c6\u60f3\u5750\u5730\u94c1\u53bb\u673a\u573a\u3002\u6770\u514b\u5efa\u8bae\u4ed6\u5230\u9f99\u4e95\u5c71,\u90a3\u91cc\u6709\u9f99\u4e95\u8336\u3002'\n'''", "size_bytes": "990438349", "downloads": 11}