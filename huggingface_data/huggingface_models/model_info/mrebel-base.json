{"pretrained_model_name": "Babelscape/mrebel-base", "description": "---\nlanguage:\n- ar\n- ca\n- de\n- el\n- en\n- es\n- fr\n- hi\n- it\n- ja\n- ko\n- nl\n- pl\n- pt\n- ru\n- sv\n- vi\n- zh\nwidget:\n- text: >-\n    The Red Hot Chili Peppers were formed in Los Angeles by Kiedis, Flea, guitarist Hillel Slovak and drummer Jack Irons.\n  example_title: English\ninference:\n  parameters:\n    src_lang: en\n    tgt_lang: en\ntags:\n- seq2seq\n- relation-extraction\nlicense: cc-by-nc-sa-4.0\npipeline_tag: translation\n---\n# RED<sup>FM</sup>: a Filtered and Multilingual Relation Extraction Dataset\n\nThis is a multilingual version of [REBEL](https://huggingface.co/Babelscape/rebel-large). It can be used as a standalone multulingual Relation Extraction system, or as a pretrained system to be tuned on multilingual Relation Extraction datasets.\n\nmREBEL is introduced in the ACL 2023 paper [RED^{FM}: a Filtered and Multilingual Relation Extraction Dataset](https://arxiv.org/abs/2306.09802). We present a new multilingual Relation Extraction dataset and train a multilingual version of REBEL which reframed Relation Extraction as a seq2seq task. The paper can be found [here](https://arxiv.org/abs/2306.09802). If you use the code or model, please reference this work in your paper:\n\n    @inproceedings{huguet-cabot-et-al-2023-redfm-dataset,\n        title = \"RED$^{\\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset\",\n        author = \"Huguet Cabot, Pere-Llu{\\'\\i}s  and Tedeschi, Simone and Ngonga Ngomo, Axel-Cyrille and\n          Navigli, Roberto\",\n        booktitle = \"Proc. of the 61st Annual Meeting of the Association for Computational Linguistics: ACL 2023\",\n        month = jul,\n        year = \"2023\",\n        address = \"Toronto, Canada\",\n        publisher = \"Association for Computational Linguistics\",\n        url = \"https://arxiv.org/abs/2306.09802\",\n    }\n\nThe original repository for the paper can be found [here](https://github.com/Babelscape/rebel#REDFM)\n\nBe aware that the inference widget at the right does not output special tokens, which are necessary to distinguish the subject, object and relation types. For a demo of mREBEL and its pre-training dataset check the [Spaces demo](https://huggingface.co/spaces/Babelscape/mrebel-demo).\n\n## Pipeline usage\n\n```python\nfrom transformers import pipeline\n\ntriplet_extractor = pipeline('translation_xx_to_yy', model='Babelscape/mrebel-base', tokenizer='Babelscape/mrebel-base')\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"The Red Hot Chili Peppers were formed in Los Angeles by Kiedis, Flea, guitarist Hillel Slovak and drummer Jack Irons.\", src_lang=\"en\", return_tensors=True, return_text=False)[0][\"translation_token_ids\"]]) # change __en__ for the language of the source.\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets_typed(text):\n    triplets = []\n    relation = ''\n    text = text.strip()\n    current = 'x'\n    subject, relation, object_, object_type, subject_type = '','','','',''\n\n    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"tp_XX\", \"\").replace(\"__en__\", \"\").split():\n        if token == \"<triplet>\" or token == \"<relation>\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'head_type': subject_type, 'type': relation.strip(),'tail': object_.strip(), 'tail_type': object_type})\n                relation = ''\n            subject = ''\n        elif token.startswith(\"<\") and token.endswith(\">\"):\n            if current == 't' or current == 'o':\n                current = 's'\n                if relation != '':\n                    triplets.append({'head': subject.strip(), 'head_type': subject_type, 'type': relation.strip(),'tail': object_.strip(), 'tail_type': object_type})\n                object_ = ''\n                subject_type = token[1:-1]\n            else:\n                current = 'o'\n                object_type = token[1:-1]\n                relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '' and object_type != '' and subject_type != '':\n        triplets.append({'head': subject.strip(), 'head_type': subject_type, 'type': relation.strip(),'tail': object_.strip(), 'tail_type': object_type})\n    return triplets\nextracted_triplets = extract_triplets_typed(extracted_text[0])\nprint(extracted_triplets)\n```\n\n## Model and Tokenizer using transformers\n\n```python\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ndef extract_triplets_typed(text):\n    triplets = []\n    relation = ''\n    text = text.strip()\n    current = 'x'\n    subject, relation, object_, object_type, subject_type = '','','','',''\n\n    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"tp_XX\", \"\").replace(\"__en__\", \"\").split():\n        if token == \"<triplet>\" or token == \"<relation>\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'head_type': subject_type, 'type': relation.strip(),'tail': object_.strip(), 'tail_type': object_type})\n                relation = ''\n            subject = ''\n        elif token.startswith(\"<\") and token.endswith(\">\"):\n            if current == 't' or current == 'o':\n                current = 's'\n                if relation != '':\n                    triplets.append({'head': subject.strip(), 'head_type': subject_type, 'type': relation.strip(),'tail': object_.strip(), 'tail_type': object_type})\n                object_ = ''\n                subject_type = token[1:-1]\n            else:\n                current = 'o'\n                object_type = token[1:-1]\n                relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '' and object_type != '' and subject_type != '':\n        triplets.append({'head': subject.strip(), 'head_type': subject_type, 'type': relation.strip(),'tail': object_.strip(), 'tail_type': object_type})\n    return triplets\n\n# Load model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"Babelscape/mrebel-base\", src_lang=\"en\", tgt_lang=\"en\") \n# Here we set English (\"en\") as source language. To change the source language swap the first token of the input for your desired language or change to supported language. \nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/mrebel-base\")\ngen_kwargs = {\n    \"max_length\": 256,\n    \"length_penalty\": 0,\n    \"num_beams\": 3,\n    \"num_return_sequences\": 3,\n    \"forced_bos_token_id\": None,\n}\n\n# Text to extract triplets from\ntext = 'The Red Hot Chili Peppers were formed in Los Angeles by Kiedis, Flea, guitarist Hillel Slovak and drummer Jack Irons.'\n\n# Tokenizer text\nmodel_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')\n\n# Generate\ngenerated_tokens = model.generate(\n    model_inputs[\"input_ids\"].to(model.device),\n    attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n    **gen_kwargs,\n)\n\n# Extract text\ndecoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n\n# Extract triplets\nfor idx, sentence in enumerate(decoded_preds):\n    print(f'Prediction triplets sentence {idx}')\n    print(extract_triplets_typed(sentence))\n```\n\n## License\n\nThis model is licensed under the CC BY-SA 4.0 license. The text of the license can be found [here](https://creativecommons.org/licenses/by-nc-sa/4.0/).", "size_bytes": "1935854535", "downloads": 70}