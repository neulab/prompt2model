{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt2Model - Generate Deployable Models from Instructions\n",
    "\n",
    "[Prompt2Model](https://github.com/neulab/prompt2model) is a system that takes a natural language task description (like the prompts used for large language models such as ChatGPT) to train a small special-purpose model that is conducive for deployment.\n",
    "\n",
    "In this demo, we demonstrate how to use Prompt2Model to create a model that answers questions over documents, but you can adapt it to any task you like by changing the initial prompt and adjusting the following design decisions appropriately. Every place that has a comment saying `CHANGE THIS` is a variable that you can change to adapt the demo to your task.\n",
    "\n",
    "You can run the demo locally or in Colab. If you are running in Colab on GPUs, you will probably want to use an A100 GPU, which has sufficient memory to train most models that prompt2model will suggest.\n",
    "<a href=\"https://colab.research.google.com/github/neulab/prompt2model/blob/main/colab_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "If you have any questions or feedback, please feel free to contact us!\n",
    "\n",
    "- **Github:** open an [issue](https://github.com/neulab/prompt2model/issues) or submit a PR\n",
    "- **Discord:** join us on [discord](https://discord.gg/UCy9csEmFc)\n",
    "- **Twitter:** reach out to [@vijaytarian](https://twitter.com/vijaytarian) and [@Chenan3_Zhao](https://twitter.com/Chenan3_Zhao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "First, start out by installing prompt2model from pypi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prompt2model in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (0.0.0a0)\n",
      "Requirement already satisfied: aiolimiter in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (1.1.0)\n",
      "Requirement already satisfied: bert-score in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.3.13)\n",
      "Requirement already satisfied: datasets in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (2.11.0)\n",
      "Requirement already satisfied: evaluate in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.4.0)\n",
      "Requirement already satisfied: faiss-cpu in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (1.7.4)\n",
      "Requirement already satisfied: fastapi in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.100.0)\n",
      "Requirement already satisfied: gradio in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (3.38.0)\n",
      "Requirement already satisfied: litellm in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.1.544)\n",
      "Requirement already satisfied: mdtex2html in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (1.5.6)\n",
      "Requirement already satisfied: openai in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.27.10)\n",
      "Requirement already satisfied: pandas in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (1.5.3)\n",
      "Requirement already satisfied: protobuf==3.20.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (3.20.0)\n",
      "Requirement already satisfied: psutil in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (5.9.0)\n",
      "Requirement already satisfied: pyfiglet in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.8.post1)\n",
      "Requirement already satisfied: pytest in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (7.3.1)\n",
      "Requirement already satisfied: retriv in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.2.1)\n",
      "Requirement already satisfied: sacrebleu in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.1.99)\n",
      "Requirement already satisfied: termcolor in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (2.3.0)\n",
      "Requirement already satisfied: tevatron in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.1.0)\n",
      "Requirement already satisfied: tiktoken in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (0.4.0)\n",
      "Requirement already satisfied: torch in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (2.0.0)\n",
      "Requirement already satisfied: transformers in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from prompt2model) (4.24.0)\n",
      "Requirement already satisfied: numpy in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from bert-score->prompt2model) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from bert-score->prompt2model) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from bert-score->prompt2model) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from bert-score->prompt2model) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from bert-score->prompt2model) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pandas->prompt2model) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pandas->prompt2model) (2023.3)\n",
      "Requirement already satisfied: filelock in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from torch->prompt2model) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from torch->prompt2model) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from torch->prompt2model) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from torch->prompt2model) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from torch->prompt2model) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from transformers->prompt2model) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from transformers->prompt2model) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from transformers->prompt2model) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from transformers->prompt2model) (0.13.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from datasets->prompt2model) (0.18.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from fastapi->prompt2model) (2.3.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from fastapi->prompt2model) (0.27.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (5.0.1)\n",
      "Requirement already satisfied: ffmpy in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.3.1)\n",
      "Requirement already satisfied: gradio-client>=0.2.10 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.4.0)\n",
      "Requirement already satisfied: httpx in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.24.1)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (2.2.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (2.1.3)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.3.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (3.9.5)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (10.0.0)\n",
      "Requirement already satisfied: pydub in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.0.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (2.10.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from gradio->prompt2model) (11.0.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0.0,>=6.8.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from litellm->prompt2model) (6.8.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from litellm->prompt2model) (1.0.0)\n",
      "Requirement already satisfied: markdown in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from mdtex2html->prompt2model) (3.4.4)\n",
      "Requirement already satisfied: latex2mathml in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from mdtex2html->prompt2model) (3.76.0)\n",
      "Requirement already satisfied: iniconfig in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pytest->prompt2model) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pytest->prompt2model) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pytest->prompt2model) (1.1.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pytest->prompt2model) (2.0.1)\n",
      "Requirement already satisfied: nltk in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (3.8.1)\n",
      "Requirement already satisfied: numba>=0.54.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (0.57.1)\n",
      "Requirement already satisfied: optuna in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (3.3.0)\n",
      "Requirement already satisfied: krovetzstemmer in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (0.8)\n",
      "Requirement already satisfied: pystemmer==2.0.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (2.0.1)\n",
      "Requirement already satisfied: unidecode in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (1.3.6)\n",
      "Requirement already satisfied: ranx in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (0.3.16)\n",
      "Requirement already satisfied: indxr in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (0.1.4)\n",
      "Requirement already satisfied: oneliner-utils in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (0.1.2)\n",
      "Requirement already satisfied: torchvision in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (0.15.1)\n",
      "Requirement already satisfied: torchaudio in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (2.0.1)\n",
      "Requirement already satisfied: autofaiss in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from retriv->prompt2model) (2.15.8)\n",
      "Requirement already satisfied: portalocker in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from sacrebleu->prompt2model) (2.7.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from sacrebleu->prompt2model) (0.9.0)\n",
      "Requirement already satisfied: colorama in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from sacrebleu->prompt2model) (0.4.6)\n",
      "Requirement already satisfied: lxml in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from sacrebleu->prompt2model) (4.9.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from scikit-learn->prompt2model) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from scikit-learn->prompt2model) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from scikit-learn->prompt2model) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from aiohttp->datasets->prompt2model) (1.3.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->prompt2model) (4.19.0)\n",
      "Requirement already satisfied: toolz in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->prompt2model) (0.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from importlib-metadata<7.0.0,>=6.8.0->litellm->prompt2model) (3.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->prompt2model) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->prompt2model) (2.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from matplotlib->bert-score->prompt2model) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from matplotlib->bert-score->prompt2model) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from matplotlib->bert-score->prompt2model) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from matplotlib->bert-score->prompt2model) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from matplotlib->bert-score->prompt2model) (3.0.9)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from numba>=0.54.1->retriv->prompt2model) (0.40.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->fastapi->prompt2model) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->fastapi->prompt2model) (2.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->prompt2model) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from requests->bert-score->prompt2model) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from requests->bert-score->prompt2model) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from requests->bert-score->prompt2model) (2023.7.22)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi->prompt2model) (3.7.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->prompt2model) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->prompt2model) (0.14.0)\n",
      "Requirement already satisfied: fire<0.5.0,>=0.4.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from autofaiss->retriv->prompt2model) (0.4.0)\n",
      "Requirement already satisfied: embedding-reader<2,>=1.5.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from autofaiss->retriv->prompt2model) (1.5.1)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from httpx->gradio->prompt2model) (0.17.3)\n",
      "Requirement already satisfied: sniffio in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from httpx->gradio->prompt2model) (1.3.0)\n",
      "Requirement already satisfied: lz4 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from oneliner-utils->retriv->prompt2model) (4.3.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from optuna->retriv->prompt2model) (1.11.3)\n",
      "Requirement already satisfied: cmaes>=0.10.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from optuna->retriv->prompt2model) (0.10.0)\n",
      "Requirement already satisfied: colorlog in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from optuna->retriv->prompt2model) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from optuna->retriv->prompt2model) (2.0.20)\n",
      "Requirement already satisfied: ir-datasets in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ranx->retriv->prompt2model) (0.5.5)\n",
      "Requirement already satisfied: rich in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ranx->retriv->prompt2model) (13.5.2)\n",
      "Requirement already satisfied: cbor2 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ranx->retriv->prompt2model) (5.4.6)\n",
      "Requirement already satisfied: seaborn in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ranx->retriv->prompt2model) (0.12.2)\n",
      "Requirement already satisfied: fastparquet in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ranx->retriv->prompt2model) (2023.7.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from sympy->torch->prompt2model) (1.3.0)\n",
      "Requirement already satisfied: Mako in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->retriv->prompt2model) (1.2.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->prompt2model) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->prompt2model) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->prompt2model) (0.9.2)\n",
      "Requirement already satisfied: uc-micro-py in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->prompt2model) (1.0.2)\n",
      "Requirement already satisfied: cramjam>=2.3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from fastparquet->ranx->retriv->prompt2model) (2.7.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (4.12.2)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (2.3.2)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (2.6)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (0.2.3)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (0.1.5)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (3.2.3)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (0.1.12)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from ir-datasets->ranx->retriv->prompt2model) (0.2.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from rich->ranx->retriv->prompt2model) (2.16.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->retriv->prompt2model) (2.4.1)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets->ranx->retriv->prompt2model) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install prompt2model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your OpenAI API key as an environment variable. A good way to do this is to create a `.env` file with a single line.\n",
    "\n",
    "```text\n",
    "OPENAI_API_KEY=<your key here>\n",
    "```\n",
    "\n",
    "If you are using Colab, you can create this `.env` file locally, then upload it to Colab by clicking on the file folder on the left side of the screen.\n",
    "\n",
    "And then run the following command to load environment variables from your `.env` file into the running script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check to make sure that the key is actually imported by printing out the first few characters of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify your Prompt\n",
    "\n",
    "The most important design decision in using prompt2model is what prompt you will use to specify your task. In order to do so it is best to:\n",
    "\n",
    "1. Explain your task\n",
    "2. Provide a few examples\n",
    "\n",
    "In this demo, we will use the following prompt to specify a **question answering system**. If you want to try prompt2model on a new task, you can write a similar prompt by swapping in a new description and new examples. Note that this format is a bit flexible, so you don't have to follow this *exact* format, but it is a good starting point. You can also see our suggestions on [writing good prompts](https://github.com/neulab/prompt2model/blob/main/prompt_examples.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS if you want to use a different prompt or tackle a different task\n",
    "prompt = \"\"\"\n",
    "Your task is to generate an answer to a natural question. In this task, the input is a string that consists of both a question and a context passage. The context is a descriptive passage related to the question and contains the answer. And the question can range from Math, Cultural, Social, Geometry, Biology, History, Sports, Technology, Science, and so on.\n",
    "\n",
    "Here are examples with input questions and context passages, along with their expected outputs:\n",
    "\n",
    "input=\"Question: What city did Super Bowl 50 take place in? Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\"\n",
    "output=\"Santa Clara\"\n",
    "\n",
    "input=\"Question: What river runs through Warsaw? Context: Warsaw (Polish: Warszawa [varˈʂava] ( listen); see also other names) is the capital and largest city of Poland. It stands on the Vistula River in east-central Poland, roughly 260 kilometres (160 mi) from the Baltic Sea and 300 kilometres (190 mi) from the Carpathian Mountains. Its population is estimated at 1.740 million residents within a greater metropolitan area of 2.666 million residents, which makes Warsaw the 9th most-populous capital city in the European Union. The city limits cover 516.9 square kilometres (199.6 sq mi), while the metropolitan area covers 6,100.43 square kilometres (2,355.39 sq mi).\"\n",
    "output=\"Vistula River\"\n",
    "\n",
    "input=\"Question: The Ottoman empire controlled territory on three continents, Africa, Asia and which other? Context: The Ottoman Empire was an imperial state that lasted from 1299 to 1923. During the 16th and 17th centuries, in particular at the height of its power under the reign of Suleiman the Magnificent, the Ottoman Empire was a powerful multinational, multilingual empire controlling much of Southeast Europe, Western Asia, the Caucasus, North Africa, and the Horn of Africa. At the beginning of the 17th century the empire contained 32 provinces and numerous vassal states. Some of these were later absorbed into the empire, while others were granted various types of autonomy during the course of centuries.\"\n",
    "output=\"Europe\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the Prompt\n",
    "\n",
    "Next, Prompt2Model parses out the instructions an examples from the prompt.\n",
    "We use the `OpenAIInstructionParser` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gneubig/anaconda3/envs/prompt2model/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Your task is to generate an answer to a natural question. In this task, the input is a string that consists of both a question and a context passage. The context is a descriptive passage related to the question and contains the answer. And the question can range from Math, Cultural, Social, Geometry, Biology, History, Sports, Technology, Science, and so on.\n",
      "\n",
      "Examples:\n",
      "input=\"Question: What city did Super Bowl 50 take place in? Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\"\n",
      "output=\"Santa Clara\"\n",
      "\n",
      "input=\"Question: What river runs through Warsaw? Context: Warsaw (Polish: Warszawa [varˈʂava] ( listen); see also other names) is the capital and largest city of Poland. It stands on the Vistula River in east-central Poland, roughly 260 kilometres (160 mi) from the Baltic Sea and 300 kilometres (190 mi) from the Carpathian Mountains. Its population is estimated at 1.740 million residents within a greater metropolitan area of 2.666 million residents, which makes Warsaw the 9th most-populous capital city in the European Union. The city limits cover 516.9 square kilometres (199.6 sq mi), while the metropolitan area covers 6,100.43 square kilometres (2,355.39 sq mi).\"\n",
      "output=\"Vistula River\"\n",
      "\n",
      "input=\"Question: The Ottoman empire controlled territory on three continents, Africa, Asia and which other? Context: The Ottoman Empire was an imperial state that lasted from 1299 to 1923. During the 16th and 17th centuries, in particular at the height of its power under the reign of Suleiman the Magnificent, the Ottoman Empire was a powerful multinational, multilingual empire controlling much of Southeast Europe, Western Asia, the Caucasus, North Africa, and the Horn of Africa. At the beginning of the 17th century the empire contained 32 provinces and numerous vassal states. Some of these were later absorbed into the empire, while others were granted various types of autonomy during the course of centuries.\"\n",
      "output=\"Europe\"\n"
     ]
    }
   ],
   "source": [
    "from prompt2model.prompt_parser import OpenAIInstructionParser, TaskType\n",
    "\n",
    "prompt_spec = OpenAIInstructionParser(task_type=TaskType.TEXT_GENERATION)\n",
    "prompt_spec.parse_from_prompt(prompt)\n",
    "print(f\"Instruction:\\n{prompt_spec.instruction}\\n\")\n",
    "print(f\"Examples:\\n{prompt_spec.examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Model\n",
    "\n",
    "First, we retrieve a base model that we will train. We can use the `DescriptionModelRetriever` to do so.\n",
    "\n",
    "`top_model_names` is a list of pretrained Hugging Face models. You can choose the first one by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11929/11929 [00:01<00:00, 6064.56it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "API key must be provided or set the environment variable with `export OPENAI_API_KEY=<your key>`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mprompt2model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_retriever\u001b[39;00m \u001b[39mimport\u001b[39;00m DescriptionModelRetriever\n\u001b[1;32m      3\u001b[0m retriever \u001b[39m=\u001b[39m DescriptionModelRetriever(\n\u001b[1;32m      4\u001b[0m     model_descriptions_index_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuggingface_data/huggingface_models/model_info/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     use_bm25\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     use_HyDE\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m top_model_names \u001b[39m=\u001b[39m retriever\u001b[39m.\u001b[39;49mretrieve(prompt_spec)\n\u001b[1;32m      9\u001b[0m pre_train_model_name \u001b[39m=\u001b[39m top_model_names[\u001b[39m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(pre_train_model_name)\n",
      "File \u001b[0;32m~/work/prompt2model/prompt2model/model_retriever/description_based_retriever.py:250\u001b[0m, in \u001b[0;36mDescriptionModelRetriever.retrieve\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_model_descriptions(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_index_path)\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_HyDE:\n\u001b[0;32m--> 250\u001b[0m     query_text \u001b[39m=\u001b[39m generate_hypothetical_model_description(\n\u001b[1;32m    251\u001b[0m         prompt, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopenai_api_key\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     query_text \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39minstruction\n",
      "File \u001b[0;32m~/work/prompt2model/prompt2model/model_retriever/generate_hypothetical_document.py:432\u001b[0m, in \u001b[0;36mgenerate_hypothetical_model_description\u001b[0;34m(prompt, openai_api_key, max_api_calls)\u001b[0m\n\u001b[1;32m    429\u001b[0m api_call_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    431\u001b[0m instruction \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39minstruction\n\u001b[0;32m--> 432\u001b[0m openai_api_agent \u001b[39m=\u001b[39m ChatGPTAgent(openai_api_key, \u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-16k\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    433\u001b[0m chatgpt_prompt \u001b[39m=\u001b[39m (\n\u001b[1;32m    434\u001b[0m     PROMPT_PREFIX\n\u001b[1;32m    435\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInstruction: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00minstruction\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mHypothetical model description:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    437\u001b[0m )\n\u001b[1;32m    438\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/prompt2model/prompt2model/utils/openai_tools.py:51\u001b[0m, in \u001b[0;36mChatGPTAgent.__init__\u001b[0;34m(self, api_key, model_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m api_key\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     52\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAPI key must be provided or set the environment variable \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith `export OPENAI_API_KEY=<your key>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m model_name\n",
      "\u001b[0;31mValueError\u001b[0m: API key must be provided or set the environment variable with `export OPENAI_API_KEY=<your key>`."
     ]
    }
   ],
   "source": [
    "from prompt2model.model_retriever import DescriptionModelRetriever\n",
    "\n",
    "retriever = DescriptionModelRetriever(\n",
    "    model_descriptions_index_path=\"huggingface_data/huggingface_models/model_info/\",\n",
    "    use_bm25=True,\n",
    "    use_HyDE=True,\n",
    ")\n",
    "top_model_names = retriever.retrieve(prompt_spec)\n",
    "pre_train_model_name = top_model_names[0]\n",
    "print(pre_train_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Process Dataset\n",
    "\n",
    "Next, `Prompt2Model` searches for datasets on Hugging Face to try to find training datasets that may be useful for your task. Specifically, we use `DescriptionDatasetRetriever`, which looks up datasets that match the description.\n",
    "\n",
    "First we initialize the retriever. This creates the search index so it may take several minutes the first time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt2model.dataset_retriever import DescriptionDatasetRetriever\n",
    "\n",
    "retriever = DescriptionDatasetRetriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we retriever a list of top datasets for the current prompt (and display their basic data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_dataset_list = retriever.retrieve_top_datasets(prompt_spec)\n",
    "\n",
    "print(\"#\\tName\\tDescription\")\n",
    "for i, d in enumerate(sorted_dataset_list):\n",
    "    description_no_spaces = d.description.replace(\"\\n\", \" \")\n",
    "    print(f\"{i+1}):\\t{d.name}\\t{description_no_spaces}\")\n",
    "\n",
    "retrieved_dataset_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If none of the datasets in the list look useful for your task, you can skip the rest of the section and we won't use any retrieved data.\n",
    "\n",
    "However, if one of the datasets looks useful, set the `retrieved_dataset_name` variable, and continue through the rest of the section. For the question answering example, we will pick the `squad` dataset to train our model, but of course you will want to change this to the dataset that you selected if you're doing a different task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS if you want to use a different retrieved dataset\n",
    "retrieved_dataset_name = \"squad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing datasets on Hugging Face have many different formats, but Prompt2Model expects that a dataset should have one input and one output, both of which are strings. In order to solve this, we do a **canonicalization** step, where we convert the dataset into a format that is compatible with `Prompt2Model`.\n",
    "\n",
    "In order to do so, we examine the dataset and find the different configurations that exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "configs = datasets.get_dataset_config_names(retrieved_dataset_name)\n",
    "print(f\"Available dataset configs {configs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we choose one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS if you want to use a different dataset configuration\n",
    "chosen_config = \"plain_text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the dataset and print out an example. You can use this to check which columns you'd like to use for the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset = datasets.load_dataset(retrieved_dataset_name, chosen_config)\n",
    "if \"train\" not in dataset:\n",
    "    raise ValueError(\n",
    "        f\"Dataset {retrieved_dataset_name} does not have a train split.\"\n",
    "    )\n",
    "train_columns = dataset[\"train\"].column_names\n",
    "train_columns_formatted = \", \".join(train_columns)\n",
    "\n",
    "if len(dataset[\"train\"]) == 0:\n",
    "    raise ValueError(\n",
    "        f\"Dataset {retrieved_dataset_name} has no rows in the train split.\"\n",
    "    )\n",
    "example_rows = json.dumps(dataset[\"train\"][0], indent=4)\n",
    "\n",
    "print(f\"Loaded dataset. Example row:\\n{example_rows}\\n\")\n",
    "\n",
    "print(f\"It has these columns: {train_columns_formatted}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set the following variables to the ones that we'd like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS if you want to use a different dataset configuration\n",
    "input_columns = [\"question\", \"context\"]\n",
    "output_column = \"answers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we canonicalize the dataset, and we have properly prepared our dataset for training. We also save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_dataset_dict = retriever.canonicalize_dataset_using_columns(\n",
    "    dataset, input_columns, output_column\n",
    ")\n",
    "retrieved_dataset_dict.save_to_disk(\"retrieved_dataset_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "\n",
    "Next, we generate some examples for training the model. We can use `OpenAIDatasetGenerator` to generate these examples.\n",
    "\n",
    "Note that there are a number of hyperparameters here. These are in general good defaults, but you might want to play with them. In particular, this generates 5,000 examples, which may be expensive (roughly $5), so you could choose to generate fewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt2model.dataset_generator import OpenAIDatasetGenerator, DatasetSplit\n",
    "\n",
    "dataset_generator = OpenAIDatasetGenerator(\n",
    "    initial_temperature=0.3,\n",
    "    max_temperature=1.4,\n",
    "    responses_per_request=3,\n",
    "    max_api_calls=10000,\n",
    "    requests_per_minute=80,\n",
    ")\n",
    "generated_dataset = dataset_generator.generate_dataset_split(\n",
    "    prompt_spec, 5000, split=DatasetSplit.TRAIN\n",
    ")\n",
    "generated_dataset.save_to_disk(\"generated_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the Model\n",
    "\n",
    "Next, we fine-tune the model. To do so we first combine the retrieved dataset with generated dataset and grab our train/validation, and testing splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt2model.dataset_processor import TextualizeProcessor\n",
    "\n",
    "text_processor = TextualizeProcessor(has_encoder=True)\n",
    "text_modified_dataset_dicts = text_processor.process_dataset_lists(\n",
    "    prompt_spec.instruction,\n",
    "    [generated_dataset, retrieved_dataset_dict[\"train\"]],\n",
    "    train_proportion=0.6,\n",
    "    val_proportion=0.2,\n",
    "    maximum_example_num=3000\n",
    ")\n",
    "train_datasets = [each[\"train\"] for each in text_modified_dataset_dicts]\n",
    "val_datasets = [each[\"val\"] for each in text_modified_dataset_dicts]\n",
    "test_datasets = [each[\"test\"] for each in text_modified_dataset_dicts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the retrieved dataset with generated dataset and use the `GenerationModelTrainer` to finetune the retrieved model. After the finetuning, we save the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt2model.model_trainer import GenerationModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "trainer = GenerationModelTrainer(\n",
    "    pre_train_model_name,\n",
    "    has_encoder=True,\n",
    "    executor_batch_size=8,\n",
    "    tokenizer_max_length=1024,\n",
    "    sequence_max_length=1280,\n",
    ")\n",
    "\n",
    "args_output_root = Path(\"result/training_output\")\n",
    "args_output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trained_model, trained_tokenizer = trainer.train_model(\n",
    "    hyperparameter_choices={\n",
    "        \"output_dir\": str(args_output_root),\n",
    "        \"save_strategy\": \"epoch\",\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"per_device_train_batch_size\": 8,\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "    },\n",
    "    training_datasets=train_datasets,\n",
    "    validation_datasets=val_datasets,\n",
    ")\n",
    "\n",
    "trained_model.save_pretrained(\"trained_model\")\n",
    "trained_tokenizer.save_pretrained(\"trained_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out!\n",
    "\n",
    "Now, you can add input and use your fine-tuned model to do inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt2model.model_executor import GenerationModelExecutor\n",
    "\n",
    "model_executor = GenerationModelExecutor(trained_model, trained_tokenizer)\n",
    "# CHANGE THIS to your own input\n",
    "input = \"Question: How many departments are within the Stinson-Remick Hall of Engineering? Context: The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.\"\n",
    "response = model_executor.make_single_prediction(\n",
    "    text_processor.wrap_single_input(prompt_spec.instruction, input)\n",
    ")\n",
    "print(response.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "After the training, we can evaluate the trained model on the conbined test set with `ModelEvaluator`.\n",
    "This will output a number of metrics indicating how good the answers are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt2model.model_executor import GenerationModelExecutor\n",
    "from prompt2model.model_evaluator import Seq2SeqEvaluator\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trained_model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"trained_model\"\n",
    ").to(device)\n",
    "trained_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"trained_tokenizer\"\n",
    ")\n",
    "\n",
    "test_dataset = datasets.concatenate_datasets(test_datasets)\n",
    "model_executor = GenerationModelExecutor(trained_model, trained_tokenizer, 1)\n",
    "t5_outputs = model_executor.make_prediction(test_dataset, \"model_input\")\n",
    "evaluator = Seq2SeqEvaluator()\n",
    "metric_values = evaluator.evaluate_model(test_dataset, \"model_output\", t5_outputs)\n",
    "print(metric_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Words\n",
    "\n",
    "We hope that you found this demo useful!\n",
    "If you have any questions or feedback, please get in contact. And we would love to have community contributions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt2model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
